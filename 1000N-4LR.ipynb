{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"1000N-4LR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"cWACPRL869I4","executionInfo":{"status":"ok","timestamp":1660714676234,"user_tz":-330,"elapsed":3625,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install gym >/dev/null"],"execution_count":5,"outputs":[]},{"metadata":{"id":"2Os6feRY6ec_","executionInfo":{"status":"ok","timestamp":1660714680831,"user_tz":-330,"elapsed":4616,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install JSAnimation >/dev/null"],"execution_count":6,"outputs":[]},{"metadata":{"id":"wotUOa_e6edP","executionInfo":{"status":"ok","timestamp":1660714680832,"user_tz":-330,"elapsed":8,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%matplotlib inline\n","from JSAnimation.IPython_display import display_animation\n","from matplotlib import animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","\n","def display_frames_as_gif(frames):\n","    \"\"\"\n","    Displays a list of frames as a gif, with controls\n","    \"\"\"\n","    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","\n","    def animate(i):\n","        patch.set_data(frames[i])\n","\n","    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n","    HTML(anim.to_jshtml())"],"execution_count":7,"outputs":[]},{"metadata":{"id":"R66_INeZ9nYX"},"cell_type":"markdown","source":["## Step 2: Playing Pong"]},{"cell_type":"code","source":["%pip install -U gym>=0.21.0\n","%pip install -U gym[atari,accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ngMhg3fB9aA","outputId":"55ebc60b-e495-479c-f326-1da1e588ecdd","executionInfo":{"status":"ok","timestamp":1660714714708,"user_tz":-330,"elapsed":33883,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Collecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 15.1 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=6f2b487a1cbaea789bf619601da3a41d0bfb904f32a8c8e089923d53b5753201\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"]}]},{"metadata":{"id":"MtT2GyK_6edc","outputId":"a9917c6e-363c-4988-a031-02f189d8a389","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660714715474,"user_tz":-330,"elapsed":784,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import gym\n","env = gym.make('Pong-v0')"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  f\"The environment {id} is out of date. You should consider \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}]},{"metadata":{"id":"oRE6WmXQJ1Z0","outputId":"9bd78f32-c919-4f91-dd03-20639139f057","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660714715475,"user_tz":-330,"elapsed":15,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.action_space"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(6)"]},"metadata":{},"execution_count":10}]},{"metadata":{"id":"yl_9d4HFJ31W","outputId":"9bb31d9b-c858-4684-ed7a-9bdd4c052fdc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660714715475,"user_tz":-330,"elapsed":12,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.observation_space"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box(0, 255, (210, 160, 3), uint8)"]},"metadata":{},"execution_count":11}]},{"metadata":{"id":"trwRXI-h6eeI","outputId":"742c9e46-d597-4708-971b-d0616d00a67d","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660714715949,"user_tz":-330,"elapsed":485,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# Run a demo of the environment\n","observation = env.reset()\n","cumulated_reward = 0\n","\n","frames = []\n","for t in range(1000):\n","#     print(observation)\n","    frames.append(env.render(mode = 'rgb_array'))\n","    # very stupid agent, just makes a random action within the allowd action space\n","    action = env.action_space.sample()\n","#     print(\"Action: {}\".format(t+1))    \n","    observation, reward, done, info = env.step(action)\n","#     print(reward)\n","    cumulated_reward += reward\n","    if done:\n","        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","        break\n","print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","\n","env.close()"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -17.0\n"]}]},{"metadata":{"id":"3zZTecVWLLes","executionInfo":{"status":"ok","timestamp":1660714715950,"user_tz":-330,"elapsed":5,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["def sigmoid(x): \n","  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n","\n","def prepro(I):\n","  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n","  I = I[35:195] # crop\n","  I = I[::2,::2,0] # downsample by factor of 2\n","  I[I == 144] = 0 # erase background (background type 1)\n","  I[I == 109] = 0 # erase background (background type 2)\n","  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n","  return I.astype(np.float).ravel()\n","\n","def policy_forward(x):\n","  h = np.dot(model['W1'], x)\n","  h[h<0] = 0 # ReLU nonlinearity\n","  logp = np.dot(model['W2'], h)\n","  p = sigmoid(logp)\n","  return p, h # return probability of taking action 2, and hidden state\n","\n","def model_step(model, observation, prev_x):\n","  # preprocess the observation, set input to network to be difference image\n","  cur_x = prepro(observation)\n","  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","  prev_x = cur_x\n","  \n","  # forward the policy network and sample an action from the returned probability\n","  aprob, _ = policy_forward(x)\n","  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n","  \n","  return action, prev_x\n","\n","def play_game(env, model):\n","  observation = env.reset()\n","\n","  frames = []\n","  cumulated_reward = 0\n","\n","  prev_x = None # used in computing the difference frame\n","\n","  for t in range(1000):\n","      frames.append(env.render(mode = 'rgb_array'))\n","      action, prev_x = model_step(model, observation, prev_x)\n","      observation, reward, done, info = env.step(action)\n","      cumulated_reward += reward\n","      if done:\n","          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","          break\n","  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","  display_frames_as_gif(frames)\n","  env.close()"],"execution_count":13,"outputs":[]},{"metadata":{"id":"6gWvZQ7AQLQt"},"cell_type":"markdown","source":["## Step 3: Policy Gradient from Scratch"]},{"metadata":{"id":"eqFm7hqcItWl","executionInfo":{"status":"ok","timestamp":1660714716991,"user_tz":-330,"elapsed":1046,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import numpy as np\n","\n","# model initialization\n","H = 1000 # number of hidden layer neurons\n","D = 80 * 80 # input dimensionality: 80x80 grid\n","model = {}\n","model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n","model['W2'] = np.random.randn(H) / np.sqrt(H)\n","\n","# import pickle\n","# model = pickle.load(open('model.pkl', 'rb'))"],"execution_count":14,"outputs":[]},{"metadata":{"id":"TwjiwKisQM19","executionInfo":{"status":"ok","timestamp":1660714716992,"user_tz":-330,"elapsed":12,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# hyperparameters\n","batch_size = 10 # every how many episodes to do a param update?\n","# learning_rate = 1e-4\n","learning_rate = 1e-4\n"," \n","gamma = 0.99 # discount factor for reward\n","decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n","  \n","grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n","rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n","\n","def discount_rewards(r):\n","  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n","  discounted_r = np.zeros_like(r, dtype=np.float32)\n","  running_add = 0\n","  for t in reversed(range(0, r.size)):\n","    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n","    running_add = running_add * gamma + r[t]\n","    discounted_r[t] = running_add\n","  return discounted_r\n","\n","def policy_backward(epx, eph, epdlogp):\n","  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n","  dW2 = np.dot(eph.T, epdlogp).ravel()\n","  dh = np.outer(epdlogp, model['W2'])\n","  dh[eph <= 0] = 0 # backpro prelu\n","  dW1 = np.dot(dh.T, epx)\n","  return {'W1':dW1, 'W2':dW2}\n","\n","def train_model(env, model, total_episodes = 100):\n","  hist = []\n","  observation = env.reset()\n","\n","  prev_x = None # used in computing the difference frame\n","  xs,hs,dlogps,drs = [],[],[],[]\n","  running_reward = None\n","  reward_sum = 0\n","  episode_number = 0\n","\n","  while True:\n","    # preprocess the observation, set input to network to be difference image\n","    cur_x = prepro(observation)\n","    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","    prev_x = cur_x\n","\n","    # forward the policy network and sample an action from the returned probability\n","    aprob, h = policy_forward(x)\n","    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n","\n","    # record various intermediates (needed later for backprop)\n","    xs.append(x) # observation\n","    hs.append(h) # hidden state\n","    y = 1 if action == 2 else 0 # a \"fake label\"\n","    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n","\n","    # step the environment and get new measurements\n","    observation, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n","\n","    if done: # an episode finished\n","      episode_number += 1\n","\n","      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n","      epx = np.vstack(xs)\n","      eph = np.vstack(hs)\n","      epdlogp = np.vstack(dlogps)\n","      epr = np.vstack(drs)\n","      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n","\n","      # compute the discounted reward backwards through time\n","      discounted_epr = discount_rewards(epr)\n","      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n","      discounted_epr -= np.mean(discounted_epr)\n","      discounted_epr /= np.std(discounted_epr)\n","\n","      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n","      grad = policy_backward(epx, eph, epdlogp)\n","      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n","\n","      # perform rmsprop parameter update every batch_size episodes\n","      if episode_number % batch_size == 0:\n","        for k,v in model.items():\n","          g = grad_buffer[k] # gradient\n","          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n","          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n","          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n","\n","      # boring book-keeping\n","      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n","      hist.append((episode_number, reward_sum, running_reward))\n","      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n","      reward_sum = 0\n","      observation = env.reset() # reset env\n","      prev_x = None\n","      if episode_number == total_episodes: return hist\n","\n","      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n","        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"],"execution_count":15,"outputs":[]},{"metadata":{"id":"G6Ka_5Vl9Orm","outputId":"d9424135-bc57-4fe0-f1cd-685f742814ac","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660717766751,"user_tz":-330,"elapsed":3049770,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist1 = train_model(env, model, total_episodes=500)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -18.000000. running mean: -18.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -18.030000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -18.059700\n","resetting env. episode 4.000000, reward total was -20.000000. running mean: -18.079103\n","resetting env. episode 5.000000, reward total was -20.000000. running mean: -18.098312\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -18.127329\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -18.146056\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -18.174595\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -18.202849\n","resetting env. episode 10.000000, reward total was -19.000000. running mean: -18.210821\n","resetting env. episode 11.000000, reward total was -19.000000. running mean: -18.218712\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -18.246525\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -18.274060\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -18.301319\n","resetting env. episode 15.000000, reward total was -19.000000. running mean: -18.308306\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -18.335223\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -18.361871\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -18.388252\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -18.414370\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -18.440226\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -18.465824\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -18.491165\n","resetting env. episode 23.000000, reward total was -19.000000. running mean: -18.496254\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -18.521291\n","resetting env. episode 25.000000, reward total was -20.000000. running mean: -18.536078\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -18.560718\n","resetting env. episode 27.000000, reward total was -18.000000. running mean: -18.555110\n","resetting env. episode 28.000000, reward total was -20.000000. running mean: -18.569559\n","resetting env. episode 29.000000, reward total was -20.000000. running mean: -18.583864\n","resetting env. episode 30.000000, reward total was -20.000000. running mean: -18.598025\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -18.612045\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -18.635924\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -18.659565\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -18.682969\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -18.706140\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -18.729078\n","resetting env. episode 37.000000, reward total was -20.000000. running mean: -18.741788\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -18.764370\n","resetting env. episode 39.000000, reward total was -20.000000. running mean: -18.776726\n","resetting env. episode 40.000000, reward total was -20.000000. running mean: -18.788959\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -18.811069\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -18.832958\n","resetting env. episode 43.000000, reward total was -19.000000. running mean: -18.834629\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -18.856283\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -18.877720\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -18.898943\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -18.919953\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -18.940754\n","resetting env. episode 49.000000, reward total was -20.000000. running mean: -18.951346\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -18.961833\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -18.982214\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -19.002392\n","resetting env. episode 53.000000, reward total was -20.000000. running mean: -19.012368\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -19.032245\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -19.051922\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -19.071403\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -19.090689\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -19.109782\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -19.128684\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -19.147397\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -19.165923\n","resetting env. episode 62.000000, reward total was -20.000000. running mean: -19.174264\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -19.192521\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -19.210596\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -19.228490\n","resetting env. episode 66.000000, reward total was -20.000000. running mean: -19.236205\n","resetting env. episode 67.000000, reward total was -20.000000. running mean: -19.243843\n","resetting env. episode 68.000000, reward total was -19.000000. running mean: -19.241405\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -19.258991\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -19.276401\n","resetting env. episode 71.000000, reward total was -19.000000. running mean: -19.273637\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -19.290901\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -19.297992\n","resetting env. episode 74.000000, reward total was -20.000000. running mean: -19.305012\n","resetting env. episode 75.000000, reward total was -20.000000. running mean: -19.311962\n","resetting env. episode 76.000000, reward total was -20.000000. running mean: -19.318842\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -19.335653\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -19.342297\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -19.358874\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -19.375285\n","resetting env. episode 81.000000, reward total was -20.000000. running mean: -19.381532\n","resetting env. episode 82.000000, reward total was -21.000000. running mean: -19.397717\n","resetting env. episode 83.000000, reward total was -19.000000. running mean: -19.393740\n","resetting env. episode 84.000000, reward total was -20.000000. running mean: -19.399803\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -19.405804\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -19.421746\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -19.437529\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -19.453154\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -19.468622\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -19.483936\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -19.499097\n","resetting env. episode 92.000000, reward total was -20.000000. running mean: -19.504106\n","resetting env. episode 93.000000, reward total was -20.000000. running mean: -19.509065\n","resetting env. episode 94.000000, reward total was -20.000000. running mean: -19.513974\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -19.518834\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -19.533646\n","resetting env. episode 97.000000, reward total was -20.000000. running mean: -19.538309\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -19.542926\n","resetting env. episode 99.000000, reward total was -19.000000. running mean: -19.537497\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -19.552122\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -19.556601\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -19.571035\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -19.585324\n","resetting env. episode 104.000000, reward total was -20.000000. running mean: -19.589471\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -19.603576\n","resetting env. episode 106.000000, reward total was -20.000000. running mean: -19.607541\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -19.621465\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -19.635251\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -19.648898\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -19.662409\n","resetting env. episode 111.000000, reward total was -20.000000. running mean: -19.665785\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -19.679127\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -19.692336\n","resetting env. episode 114.000000, reward total was -19.000000. running mean: -19.685413\n","resetting env. episode 115.000000, reward total was -18.000000. running mean: -19.668558\n","resetting env. episode 116.000000, reward total was -20.000000. running mean: -19.671873\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -19.685154\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -19.698303\n","resetting env. episode 119.000000, reward total was -20.000000. running mean: -19.701320\n","resetting env. episode 120.000000, reward total was -18.000000. running mean: -19.684306\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -19.697463\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -19.710489\n","resetting env. episode 123.000000, reward total was -20.000000. running mean: -19.713384\n","resetting env. episode 124.000000, reward total was -20.000000. running mean: -19.716250\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -19.729087\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -19.741797\n","resetting env. episode 127.000000, reward total was -20.000000. running mean: -19.744379\n","resetting env. episode 128.000000, reward total was -19.000000. running mean: -19.736935\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -19.749566\n","resetting env. episode 130.000000, reward total was -20.000000. running mean: -19.752070\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -19.764549\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -19.776904\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -19.789135\n","resetting env. episode 134.000000, reward total was -20.000000. running mean: -19.791243\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -19.803331\n","resetting env. episode 136.000000, reward total was -18.000000. running mean: -19.785298\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -19.797445\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -19.809470\n","resetting env. episode 139.000000, reward total was -20.000000. running mean: -19.811375\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -19.823262\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -19.835029\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -19.846679\n","resetting env. episode 143.000000, reward total was -20.000000. running mean: -19.848212\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -19.859730\n","resetting env. episode 145.000000, reward total was -21.000000. running mean: -19.871133\n","resetting env. episode 146.000000, reward total was -19.000000. running mean: -19.862421\n","resetting env. episode 147.000000, reward total was -20.000000. running mean: -19.863797\n","resetting env. episode 148.000000, reward total was -20.000000. running mean: -19.865159\n","resetting env. episode 149.000000, reward total was -20.000000. running mean: -19.866507\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -19.877842\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -19.889064\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -19.900173\n","resetting env. episode 153.000000, reward total was -20.000000. running mean: -19.901172\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -19.912160\n","resetting env. episode 155.000000, reward total was -20.000000. running mean: -19.913038\n","resetting env. episode 156.000000, reward total was -20.000000. running mean: -19.913908\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -19.924769\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -19.935521\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -19.946166\n","resetting env. episode 160.000000, reward total was -20.000000. running mean: -19.946704\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -19.957237\n","resetting env. episode 162.000000, reward total was -19.000000. running mean: -19.947665\n","resetting env. episode 163.000000, reward total was -20.000000. running mean: -19.948188\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -19.958706\n","resetting env. episode 165.000000, reward total was -19.000000. running mean: -19.949119\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -19.959628\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -19.960032\n","resetting env. episode 168.000000, reward total was -19.000000. running mean: -19.950431\n","resetting env. episode 169.000000, reward total was -18.000000. running mean: -19.930927\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -19.941618\n","resetting env. episode 171.000000, reward total was -20.000000. running mean: -19.942202\n","resetting env. episode 172.000000, reward total was -20.000000. running mean: -19.942780\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -19.943352\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -19.953918\n","resetting env. episode 175.000000, reward total was -20.000000. running mean: -19.954379\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -19.964835\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -19.975187\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -19.985435\n","resetting env. episode 179.000000, reward total was -19.000000. running mean: -19.975581\n","resetting env. episode 180.000000, reward total was -20.000000. running mean: -19.975825\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -19.986067\n","resetting env. episode 182.000000, reward total was -20.000000. running mean: -19.986206\n","resetting env. episode 183.000000, reward total was -17.000000. running mean: -19.956344\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -19.966781\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -19.977113\n","resetting env. episode 186.000000, reward total was -20.000000. running mean: -19.977342\n","resetting env. episode 187.000000, reward total was -19.000000. running mean: -19.967568\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -19.967893\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -19.978214\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -19.988431\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -19.998547\n","resetting env. episode 192.000000, reward total was -20.000000. running mean: -19.998562\n","resetting env. episode 193.000000, reward total was -18.000000. running mean: -19.978576\n","resetting env. episode 194.000000, reward total was -20.000000. running mean: -19.978790\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -19.989002\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -19.999112\n","resetting env. episode 197.000000, reward total was -20.000000. running mean: -19.999121\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -19.999130\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -19.999139\n","resetting env. episode 200.000000, reward total was -20.000000. running mean: -19.999147\n","resetting env. episode 201.000000, reward total was -19.000000. running mean: -19.989156\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -19.999264\n","resetting env. episode 203.000000, reward total was -19.000000. running mean: -19.989272\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -19.999379\n","resetting env. episode 205.000000, reward total was -20.000000. running mean: -19.999385\n","resetting env. episode 206.000000, reward total was -20.000000. running mean: -19.999391\n","resetting env. episode 207.000000, reward total was -20.000000. running mean: -19.999397\n","resetting env. episode 208.000000, reward total was -18.000000. running mean: -19.979403\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -19.989609\n","resetting env. episode 210.000000, reward total was -20.000000. running mean: -19.989713\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -19.999816\n","resetting env. episode 212.000000, reward total was -20.000000. running mean: -19.999818\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.009820\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -20.009722\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.019624\n","resetting env. episode 216.000000, reward total was -20.000000. running mean: -20.019428\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.029234\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.038942\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.048552\n","resetting env. episode 220.000000, reward total was -19.000000. running mean: -20.038067\n","resetting env. episode 221.000000, reward total was -20.000000. running mean: -20.037686\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.047309\n","resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.046836\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.046368\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.045904\n","resetting env. episode 226.000000, reward total was -20.000000. running mean: -20.045445\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.054990\n","resetting env. episode 228.000000, reward total was -19.000000. running mean: -20.044441\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.053996\n","resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.053456\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.062922\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.062292\n","resetting env. episode 233.000000, reward total was -18.000000. running mean: -20.041670\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.041253\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.050840\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.060332\n","resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.049729\n","resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.049231\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.058739\n","resetting env. episode 240.000000, reward total was -19.000000. running mean: -20.048152\n","resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.047670\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.047193\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.056721\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.066154\n","resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.065493\n","resetting env. episode 246.000000, reward total was -20.000000. running mean: -20.064838\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.074189\n","resetting env. episode 248.000000, reward total was -20.000000. running mean: -20.073447\n","resetting env. episode 249.000000, reward total was -20.000000. running mean: -20.072713\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.081986\n","resetting env. episode 251.000000, reward total was -20.000000. running mean: -20.081166\n","resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.080354\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.089551\n","resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.088655\n","resetting env. episode 255.000000, reward total was -20.000000. running mean: -20.087769\n","resetting env. episode 256.000000, reward total was -19.000000. running mean: -20.076891\n","resetting env. episode 257.000000, reward total was -19.000000. running mean: -20.066122\n","resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.065461\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.074806\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.084058\n","resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.083218\n","resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.082385\n","resetting env. episode 263.000000, reward total was -20.000000. running mean: -20.081562\n","resetting env. episode 264.000000, reward total was -20.000000. running mean: -20.080746\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.089939\n","resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.099039\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.108049\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.116968\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.125799\n","resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.134541\n","resetting env. episode 271.000000, reward total was -17.000000. running mean: -20.103195\n","resetting env. episode 272.000000, reward total was -18.000000. running mean: -20.082163\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.091342\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.100428\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.109424\n","resetting env. episode 276.000000, reward total was -20.000000. running mean: -20.108330\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.117246\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.126074\n","resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.124813\n","resetting env. episode 280.000000, reward total was -20.000000. running mean: -20.123565\n","resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.122329\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.131106\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.139795\n","resetting env. episode 284.000000, reward total was -19.000000. running mean: -20.128397\n","resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.127113\n","resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.125842\n","resetting env. episode 287.000000, reward total was -20.000000. running mean: -20.124584\n","resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.123338\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.132104\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.140783\n","resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.139375\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.137982\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.146602\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.155136\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.163585\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.171949\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.180229\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.178427\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.176643\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.174876\n","resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.173127\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.171396\n","resetting env. episode 303.000000, reward total was -18.000000. running mean: -20.149682\n","resetting env. episode 304.000000, reward total was -19.000000. running mean: -20.138185\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.146804\n","resetting env. episode 306.000000, reward total was -20.000000. running mean: -20.145336\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.153882\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.162343\n","resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.160720\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.169113\n","resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.167422\n","resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.165747\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.164090\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.172449\n","resetting env. episode 315.000000, reward total was -18.000000. running mean: -20.150724\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.159217\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.157625\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -20.156049\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.164488\n","resetting env. episode 320.000000, reward total was -18.000000. running mean: -20.142843\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.151415\n","resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.149901\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.158402\n","resetting env. episode 324.000000, reward total was -20.000000. running mean: -20.156818\n","resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.155250\n","resetting env. episode 326.000000, reward total was -20.000000. running mean: -20.153697\n","resetting env. episode 327.000000, reward total was -19.000000. running mean: -20.142160\n","resetting env. episode 328.000000, reward total was -19.000000. running mean: -20.130739\n","resetting env. episode 329.000000, reward total was -19.000000. running mean: -20.119431\n","resetting env. episode 330.000000, reward total was -17.000000. running mean: -20.088237\n","resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.087355\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.096481\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.105516\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.114461\n","resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.113316\n","resetting env. episode 336.000000, reward total was -19.000000. running mean: -20.102183\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.111161\n","resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.110050\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.118949\n","resetting env. episode 340.000000, reward total was -20.000000. running mean: -20.117760\n","resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.116582\n","resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.115416\n","resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.114262\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.123120\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.131888\n","resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.130570\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.139264\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.147871\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.156392\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.164829\n","resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.163180\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.171548\n","resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.169833\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.178135\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.186353\n","resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.184490\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.192645\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.200718\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.208711\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.216624\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.214458\n","resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.212313\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.220190\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.227988\n","resetting env. episode 365.000000, reward total was -19.000000. running mean: -20.215708\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.223551\n","resetting env. episode 367.000000, reward total was -20.000000. running mean: -20.221316\n","resetting env. episode 368.000000, reward total was -19.000000. running mean: -20.209103\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.217012\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.214841\n","resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.222693\n","resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.220466\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.228261\n","resetting env. episode 374.000000, reward total was -18.000000. running mean: -20.205979\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.213919\n","resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.211780\n","resetting env. episode 377.000000, reward total was -19.000000. running mean: -20.199662\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.207665\n","resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.205589\n","resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.203533\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.211498\n","resetting env. episode 382.000000, reward total was -20.000000. running mean: -20.209383\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.217289\n","resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.225116\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.232865\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.240536\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.248131\n","resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.245649\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.253193\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.260661\n","resetting env. episode 391.000000, reward total was -19.000000. running mean: -20.248054\n","resetting env. episode 392.000000, reward total was -19.000000. running mean: -20.235574\n","resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.233218\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.240886\n","resetting env. episode 395.000000, reward total was -19.000000. running mean: -20.228477\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.236192\n","resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.233830\n","resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.241492\n","resetting env. episode 399.000000, reward total was -19.000000. running mean: -20.229077\n","resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.226786\n","resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.224519\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.232273\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.239951\n","resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.237551\n","resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.235176\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.242824\n","resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.240396\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.247992\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.255512\n","resetting env. episode 410.000000, reward total was -20.000000. running mean: -20.252957\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.260427\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.257823\n","resetting env. episode 413.000000, reward total was -19.000000. running mean: -20.245245\n","resetting env. episode 414.000000, reward total was -18.000000. running mean: -20.222792\n","resetting env. episode 415.000000, reward total was -19.000000. running mean: -20.210564\n","resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.208459\n","resetting env. episode 417.000000, reward total was -20.000000. running mean: -20.206374\n","resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.204310\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.212267\n","resetting env. episode 420.000000, reward total was -18.000000. running mean: -20.190144\n","resetting env. episode 421.000000, reward total was -20.000000. running mean: -20.188243\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.196361\n","resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.204397\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.212353\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.220229\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.228027\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.235747\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.243389\n","resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.240956\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.248546\n","resetting env. episode 431.000000, reward total was -20.000000. running mean: -20.246061\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.253600\n","resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.251064\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.258553\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.265968\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.273308\n","resetting env. episode 437.000000, reward total was -19.000000. running mean: -20.260575\n","resetting env. episode 438.000000, reward total was -19.000000. running mean: -20.247969\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.255490\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.262935\n","resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.260305\n","resetting env. episode 442.000000, reward total was -19.000000. running mean: -20.247702\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.255225\n","resetting env. episode 444.000000, reward total was -20.000000. running mean: -20.252673\n","resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.250146\n","resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.247645\n","resetting env. episode 447.000000, reward total was -20.000000. running mean: -20.245168\n","resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.242717\n","resetting env. episode 449.000000, reward total was -19.000000. running mean: -20.230289\n","resetting env. episode 450.000000, reward total was -19.000000. running mean: -20.217987\n","resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.215807\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.223649\n","resetting env. episode 453.000000, reward total was -20.000000. running mean: -20.221412\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.229198\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.236906\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.244537\n","resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.242092\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.249671\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.257174\n","resetting env. episode 460.000000, reward total was -19.000000. running mean: -20.244602\n","resetting env. episode 461.000000, reward total was -19.000000. running mean: -20.232156\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.239835\n","resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.237436\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.245062\n","resetting env. episode 465.000000, reward total was -19.000000. running mean: -20.232611\n","resetting env. episode 466.000000, reward total was -19.000000. running mean: -20.220285\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.228082\n","resetting env. episode 468.000000, reward total was -19.000000. running mean: -20.215802\n","resetting env. episode 469.000000, reward total was -20.000000. running mean: -20.213644\n","resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.211507\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.219392\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.227198\n","resetting env. episode 473.000000, reward total was -18.000000. running mean: -20.204926\n","resetting env. episode 474.000000, reward total was -20.000000. running mean: -20.202877\n","resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.200848\n","resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.198840\n","resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.196851\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.204883\n","resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.212834\n","resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.210706\n","resetting env. episode 481.000000, reward total was -20.000000. running mean: -20.208598\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.206513\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.214447\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.222303\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.230080\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.237779\n","resetting env. episode 487.000000, reward total was -20.000000. running mean: -20.235401\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.233047\n","resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.230717\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.238410\n","resetting env. episode 491.000000, reward total was -19.000000. running mean: -20.226026\n","resetting env. episode 492.000000, reward total was -19.000000. running mean: -20.213765\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.221628\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.229411\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.237117\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.244746\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.252299\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.259776\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.267178\n","resetting env. episode 500.000000, reward total was -15.000000. running mean: -20.214506\n","CPU times: user 1h 24min 2s, sys: 14min 13s, total: 1h 38min 15s\n","Wall time: 50min 50s\n"]}]},{"metadata":{"id":"cHYCDYwhlVLV","outputId":"60b788bb-2c2b-415b-a11c-632b6a7ba392","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660720964350,"user_tz":-330,"elapsed":3197635,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist2 = train_model(env, model, total_episodes=500)"],"execution_count":17,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 4.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.980100\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.980299\n","resetting env. episode 7.000000, reward total was -19.000000. running mean: -20.960496\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.960891\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.961282\n","resetting env. episode 10.000000, reward total was -20.000000. running mean: -20.951669\n","resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.942153\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.942731\n","resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.933304\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.933971\n","resetting env. episode 15.000000, reward total was -20.000000. running mean: -20.924631\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.925385\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.926131\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.926870\n","resetting env. episode 19.000000, reward total was -20.000000. running mean: -20.917601\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.918425\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.919241\n","resetting env. episode 22.000000, reward total was -19.000000. running mean: -20.900048\n","resetting env. episode 23.000000, reward total was -18.000000. running mean: -20.871048\n","resetting env. episode 24.000000, reward total was -19.000000. running mean: -20.852337\n","resetting env. episode 25.000000, reward total was -18.000000. running mean: -20.823814\n","resetting env. episode 26.000000, reward total was -19.000000. running mean: -20.805576\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.797520\n","resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.789545\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.791649\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.793733\n","resetting env. episode 31.000000, reward total was -19.000000. running mean: -20.775796\n","resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.768038\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.770357\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.772654\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.774927\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.777178\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.779406\n","resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.771612\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.773896\n","resetting env. episode 40.000000, reward total was -19.000000. running mean: -20.756157\n","resetting env. episode 41.000000, reward total was -20.000000. running mean: -20.748595\n","resetting env. episode 42.000000, reward total was -17.000000. running mean: -20.711109\n","resetting env. episode 43.000000, reward total was -19.000000. running mean: -20.693998\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.687058\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.690188\n","resetting env. episode 46.000000, reward total was -20.000000. running mean: -20.683286\n","resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.676453\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.679688\n","resetting env. episode 49.000000, reward total was -19.000000. running mean: -20.662892\n","resetting env. episode 50.000000, reward total was -19.000000. running mean: -20.646263\n","resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.639800\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.643402\n","resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.636968\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.640598\n","resetting env. episode 55.000000, reward total was -19.000000. running mean: -20.624192\n","resetting env. episode 56.000000, reward total was -19.000000. running mean: -20.607950\n","resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.601871\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.605852\n","resetting env. episode 59.000000, reward total was -20.000000. running mean: -20.599794\n","resetting env. episode 60.000000, reward total was -20.000000. running mean: -20.593796\n","resetting env. episode 61.000000, reward total was -20.000000. running mean: -20.587858\n","resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.581979\n","resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.576159\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.580398\n","resetting env. episode 65.000000, reward total was -20.000000. running mean: -20.574594\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.578848\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.583059\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.587229\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.591357\n","resetting env. episode 70.000000, reward total was -19.000000. running mean: -20.575443\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.579689\n","resetting env. episode 72.000000, reward total was -20.000000. running mean: -20.573892\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.568153\n","resetting env. episode 74.000000, reward total was -20.000000. running mean: -20.562471\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.566847\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.571178\n","resetting env. episode 77.000000, reward total was -20.000000. running mean: -20.565466\n","resetting env. episode 78.000000, reward total was -19.000000. running mean: -20.549812\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.554313\n","resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.548770\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.553283\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.547750\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.552272\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.556750\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.551182\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.555670\n","resetting env. episode 87.000000, reward total was -19.000000. running mean: -20.540114\n","resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.534712\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.539365\n","resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.533972\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.538632\n","resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.533246\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.537913\n","resetting env. episode 94.000000, reward total was -18.000000. running mean: -20.512534\n","resetting env. episode 95.000000, reward total was -19.000000. running mean: -20.497409\n","resetting env. episode 96.000000, reward total was -18.000000. running mean: -20.472435\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.477710\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.482933\n","resetting env. episode 99.000000, reward total was -20.000000. running mean: -20.478104\n","resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.473323\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.478590\n","resetting env. episode 102.000000, reward total was -18.000000. running mean: -20.453804\n","resetting env. episode 103.000000, reward total was -20.000000. running mean: -20.449266\n","resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.444773\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.450325\n","resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.445822\n","resetting env. episode 107.000000, reward total was -20.000000. running mean: -20.441364\n","resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.436950\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.442581\n","resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.438155\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.443773\n","resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.439336\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.444942\n","resetting env. episode 114.000000, reward total was -17.000000. running mean: -20.410493\n","resetting env. episode 115.000000, reward total was -20.000000. running mean: -20.406388\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.412324\n","resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.408201\n","resetting env. episode 118.000000, reward total was -19.000000. running mean: -20.394119\n","resetting env. episode 119.000000, reward total was -20.000000. running mean: -20.390178\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.396276\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.402313\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.398290\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.404307\n","resetting env. episode 124.000000, reward total was -19.000000. running mean: -20.390264\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.396361\n","resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.392398\n","resetting env. episode 127.000000, reward total was -19.000000. running mean: -20.378474\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.384689\n","resetting env. episode 129.000000, reward total was -20.000000. running mean: -20.380842\n","resetting env. episode 130.000000, reward total was -18.000000. running mean: -20.357034\n","resetting env. episode 131.000000, reward total was -19.000000. running mean: -20.343463\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.350029\n","resetting env. episode 133.000000, reward total was -19.000000. running mean: -20.336528\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.343163\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.349731\n","resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.346234\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.352772\n","resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.349244\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.355752\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.362194\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.368572\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.374886\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.381138\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.387326\n","resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.383453\n","resetting env. episode 146.000000, reward total was -20.000000. running mean: -20.379618\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.385822\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.391964\n","resetting env. episode 149.000000, reward total was -19.000000. running mean: -20.378044\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.384264\n","resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.380421\n","resetting env. episode 152.000000, reward total was -19.000000. running mean: -20.366617\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.372951\n","resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.369221\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.375529\n","resetting env. episode 156.000000, reward total was -20.000000. running mean: -20.371774\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.378056\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.384276\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.390433\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.396529\n","resetting env. episode 161.000000, reward total was -20.000000. running mean: -20.392563\n","resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.388638\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.394751\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.400804\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.406796\n","resetting env. episode 166.000000, reward total was -19.000000. running mean: -20.392728\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.388800\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.394912\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.400963\n","resetting env. episode 170.000000, reward total was -20.000000. running mean: -20.396954\n","resetting env. episode 171.000000, reward total was -20.000000. running mean: -20.392984\n","resetting env. episode 172.000000, reward total was -20.000000. running mean: -20.389054\n","resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.395164\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.401212\n","resetting env. episode 175.000000, reward total was -20.000000. running mean: -20.397200\n","resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.383228\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.389396\n","resetting env. episode 178.000000, reward total was -19.000000. running mean: -20.375502\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.381747\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.387929\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.394050\n","resetting env. episode 182.000000, reward total was -20.000000. running mean: -20.390109\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.396208\n","resetting env. episode 184.000000, reward total was -20.000000. running mean: -20.392246\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.398324\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.404341\n","resetting env. episode 187.000000, reward total was -18.000000. running mean: -20.380297\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.386494\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.392629\n","resetting env. episode 190.000000, reward total was -20.000000. running mean: -20.388703\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.394816\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.400868\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.406859\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.412791\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.418663\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.424476\n","resetting env. episode 197.000000, reward total was -18.000000. running mean: -20.400231\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.406229\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.402167\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.408145\n","resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.404064\n","resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.400023\n","resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.406023\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.411962\n","resetting env. episode 205.000000, reward total was -19.000000. running mean: -20.397843\n","resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.393864\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.399926\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.405926\n","resetting env. episode 209.000000, reward total was -19.000000. running mean: -20.391867\n","resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.387949\n","resetting env. episode 211.000000, reward total was -20.000000. running mean: -20.384069\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.390228\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.396326\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.402363\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.408339\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.414256\n","resetting env. episode 217.000000, reward total was -19.000000. running mean: -20.400113\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.406112\n","resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.402051\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.408030\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.413950\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.419811\n","resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.415613\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.411456\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.417342\n","resetting env. episode 226.000000, reward total was -19.000000. running mean: -20.403168\n","resetting env. episode 227.000000, reward total was -19.000000. running mean: -20.389137\n","resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.395245\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.401293\n","resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.397280\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.403307\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.399274\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.395281\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.391329\n","resetting env. episode 235.000000, reward total was -19.000000. running mean: -20.377415\n","resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.373641\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.379905\n","resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.376106\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.382345\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.388521\n","resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.384636\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.390790\n","resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.386882\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.393013\n","resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.389083\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.395192\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.401240\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.407228\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.413155\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.419024\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.424834\n","resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.420585\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.426379\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.432116\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.437794\n","resetting env. episode 256.000000, reward total was -19.000000. running mean: -20.423416\n","resetting env. episode 257.000000, reward total was -20.000000. running mean: -20.419182\n","resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.414990\n","resetting env. episode 259.000000, reward total was -19.000000. running mean: -20.400841\n","resetting env. episode 260.000000, reward total was -20.000000. running mean: -20.396832\n","resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.402864\n","resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.398835\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.404847\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.410798\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.416690\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.412524\n","resetting env. episode 267.000000, reward total was -20.000000. running mean: -20.408398\n","resetting env. episode 268.000000, reward total was -18.000000. running mean: -20.384314\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.390471\n","resetting env. episode 270.000000, reward total was -18.000000. running mean: -20.366566\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.362901\n","resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.369272\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.375579\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.381823\n","resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.378005\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.384225\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.390383\n","resetting env. episode 278.000000, reward total was -19.000000. running mean: -20.376479\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.382714\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.388887\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.394998\n","resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.391048\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.397138\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.403166\n","resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.399135\n","resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.395143\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.401192\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.407180\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.413108\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.418977\n","resetting env. episode 291.000000, reward total was -19.000000. running mean: -20.404787\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.400739\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.406732\n","resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.402665\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.408638\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.414552\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.420406\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.416202\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.412040\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.417920\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.423740\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.429503\n","resetting env. episode 303.000000, reward total was -19.000000. running mean: -20.415208\n","resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.411056\n","resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.406945\n","resetting env. episode 306.000000, reward total was -20.000000. running mean: -20.402876\n","resetting env. episode 307.000000, reward total was -19.000000. running mean: -20.388847\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.384959\n","resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.381109\n","resetting env. episode 310.000000, reward total was -18.000000. running mean: -20.357298\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.363725\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.370088\n","resetting env. episode 313.000000, reward total was -19.000000. running mean: -20.356387\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.362823\n","resetting env. episode 315.000000, reward total was -20.000000. running mean: -20.359195\n","resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.355603\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.352047\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -20.348526\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.355041\n","resetting env. episode 320.000000, reward total was -19.000000. running mean: -20.341491\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.348076\n","resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.354595\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.361049\n","resetting env. episode 324.000000, reward total was -20.000000. running mean: -20.357439\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.363864\n","resetting env. episode 326.000000, reward total was -19.000000. running mean: -20.350226\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.356723\n","resetting env. episode 328.000000, reward total was -19.000000. running mean: -20.343156\n","resetting env. episode 329.000000, reward total was -19.000000. running mean: -20.329724\n","resetting env. episode 330.000000, reward total was -18.000000. running mean: -20.306427\n","resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.303363\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.310329\n","resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.307226\n","resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.304154\n","resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.301112\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.308101\n","resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.305020\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.311970\n","resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.308850\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.315762\n","resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.312604\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.319478\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.326283\n","resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.323020\n","resetting env. episode 345.000000, reward total was -20.000000. running mean: -20.319790\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.326592\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.333326\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.339993\n","resetting env. episode 349.000000, reward total was -18.000000. running mean: -20.316593\n","resetting env. episode 350.000000, reward total was -20.000000. running mean: -20.313427\n","resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.310293\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.317190\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.324018\n","resetting env. episode 354.000000, reward total was -20.000000. running mean: -20.320778\n","resetting env. episode 355.000000, reward total was -20.000000. running mean: -20.317570\n","resetting env. episode 356.000000, reward total was -19.000000. running mean: -20.304395\n","resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.301351\n","resetting env. episode 358.000000, reward total was -18.000000. running mean: -20.278337\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.285554\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.282698\n","resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.289871\n","resetting env. episode 362.000000, reward total was -19.000000. running mean: -20.276972\n","resetting env. episode 363.000000, reward total was -19.000000. running mean: -20.264203\n","resetting env. episode 364.000000, reward total was -20.000000. running mean: -20.261561\n","resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.268945\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.276256\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.283493\n","resetting env. episode 368.000000, reward total was -19.000000. running mean: -20.270658\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.277952\n","resetting env. episode 370.000000, reward total was -19.000000. running mean: -20.265172\n","resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.262520\n","resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.259895\n","resetting env. episode 373.000000, reward total was -19.000000. running mean: -20.247296\n","resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.254823\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.262275\n","resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.269652\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.276956\n","resetting env. episode 378.000000, reward total was -18.000000. running mean: -20.254186\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.261644\n","resetting env. episode 380.000000, reward total was -18.000000. running mean: -20.239028\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.246638\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.254171\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.261630\n","resetting env. episode 384.000000, reward total was -19.000000. running mean: -20.249013\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.256523\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.263958\n","resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.261318\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.268705\n","resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.266018\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.273358\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.280624\n","resetting env. episode 392.000000, reward total was -19.000000. running mean: -20.267818\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.275140\n","resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.272388\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.279665\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.276868\n","resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.274099\n","resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.271358\n","resetting env. episode 399.000000, reward total was -20.000000. running mean: -20.268645\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.275958\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.283199\n","resetting env. episode 402.000000, reward total was -19.000000. running mean: -20.270367\n","resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.267663\n","resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.264986\n","resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.262336\n","resetting env. episode 406.000000, reward total was -18.000000. running mean: -20.239713\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.247316\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.254843\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.252294\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.259771\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.267174\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.264502\n","resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.261857\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.269238\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.266546\n","resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.263881\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.271242\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.278529\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.285744\n","resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.282887\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.290058\n","resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.287157\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.284286\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.291443\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.298528\n","resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.295543\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.302588\n","resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.299562\n","resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.296566\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.303600\n","resetting env. episode 431.000000, reward total was -18.000000. running mean: -20.280564\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.287759\n","resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.284881\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.292032\n","resetting env. episode 435.000000, reward total was -20.000000. running mean: -20.289112\n","resetting env. episode 436.000000, reward total was -20.000000. running mean: -20.286221\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.293359\n","resetting env. episode 438.000000, reward total was -19.000000. running mean: -20.280425\n","resetting env. episode 439.000000, reward total was -19.000000. running mean: -20.267621\n","resetting env. episode 440.000000, reward total was -19.000000. running mean: -20.254945\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.262395\n","resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.259771\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.267174\n","resetting env. episode 444.000000, reward total was -20.000000. running mean: -20.264502\n","resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.261857\n","resetting env. episode 446.000000, reward total was -19.000000. running mean: -20.249238\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.256746\n","resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.254178\n","resetting env. episode 449.000000, reward total was -19.000000. running mean: -20.241637\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.249220\n","resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.246728\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.254261\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.261718\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.269101\n","resetting env. episode 455.000000, reward total was -20.000000. running mean: -20.266410\n","resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.263746\n","resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.261108\n","resetting env. episode 458.000000, reward total was -19.000000. running mean: -20.248497\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.256012\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.253452\n","resetting env. episode 461.000000, reward total was -16.000000. running mean: -20.210918\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.208809\n","resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.206720\n","resetting env. episode 464.000000, reward total was -19.000000. running mean: -20.194653\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.202707\n","resetting env. episode 466.000000, reward total was -20.000000. running mean: -20.200680\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.198673\n","resetting env. episode 468.000000, reward total was -18.000000. running mean: -20.176686\n","resetting env. episode 469.000000, reward total was -20.000000. running mean: -20.174919\n","resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.173170\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.181438\n","resetting env. episode 472.000000, reward total was -19.000000. running mean: -20.169624\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.177928\n","resetting env. episode 474.000000, reward total was -19.000000. running mean: -20.166148\n","resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.164487\n","resetting env. episode 476.000000, reward total was -19.000000. running mean: -20.152842\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.161314\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.159701\n","resetting env. episode 479.000000, reward total was -18.000000. running mean: -20.138104\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.146723\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.155255\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.153703\n","resetting env. episode 483.000000, reward total was -20.000000. running mean: -20.152166\n","resetting env. episode 484.000000, reward total was -20.000000. running mean: -20.150644\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.159138\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.167546\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.175871\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.184112\n","resetting env. episode 489.000000, reward total was -18.000000. running mean: -20.162271\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.160648\n","resetting env. episode 491.000000, reward total was -19.000000. running mean: -20.149042\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.157551\n","resetting env. episode 493.000000, reward total was -19.000000. running mean: -20.145976\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.154516\n","resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.152971\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.161441\n","resetting env. episode 497.000000, reward total was -20.000000. running mean: -20.159827\n","resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.158229\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.166646\n","resetting env. episode 500.000000, reward total was -20.000000. running mean: -20.164980\n","CPU times: user 1h 28min 25s, sys: 14min 50s, total: 1h 43min 15s\n","Wall time: 53min 17s\n"]}]},{"metadata":{"id":"8fheN9DRlWXQ","outputId":"f2f4cffa-4464-4e87-cc9f-5d8b4280ae41","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1660721003287,"user_tz":-330,"elapsed":38961,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -7.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"id":"9AxOcQhIsKow","outputId":"25029422-e7a8-48ce-eef0-5aa1a76f5fd4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660732073416,"user_tz":-330,"elapsed":11070155,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist3 = train_model(env, model, total_episodes=1500)"],"execution_count":19,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -19.000000. running mean: -19.000000\n","resetting env. episode 2.000000, reward total was -20.000000. running mean: -19.010000\n","resetting env. episode 3.000000, reward total was -18.000000. running mean: -18.999900\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -19.019901\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -19.039702\n","resetting env. episode 6.000000, reward total was -19.000000. running mean: -19.039305\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -19.048912\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -19.068423\n","resetting env. episode 9.000000, reward total was -19.000000. running mean: -19.067739\n","resetting env. episode 10.000000, reward total was -20.000000. running mean: -19.077061\n","resetting env. episode 11.000000, reward total was -19.000000. running mean: -19.076291\n","resetting env. episode 12.000000, reward total was -20.000000. running mean: -19.085528\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -19.104672\n","resetting env. episode 14.000000, reward total was -19.000000. running mean: -19.103626\n","resetting env. episode 15.000000, reward total was -19.000000. running mean: -19.102589\n","resetting env. episode 16.000000, reward total was -19.000000. running mean: -19.101564\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -19.120548\n","resetting env. episode 18.000000, reward total was -20.000000. running mean: -19.129342\n","resetting env. episode 19.000000, reward total was -19.000000. running mean: -19.128049\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -19.146768\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -19.165301\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -19.183648\n","resetting env. episode 23.000000, reward total was -19.000000. running mean: -19.181811\n","resetting env. episode 24.000000, reward total was -20.000000. running mean: -19.189993\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -19.208093\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -19.226012\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -19.243752\n","resetting env. episode 28.000000, reward total was -18.000000. running mean: -19.231315\n","resetting env. episode 29.000000, reward total was -19.000000. running mean: -19.229002\n","resetting env. episode 30.000000, reward total was -20.000000. running mean: -19.236712\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -19.244344\n","resetting env. episode 32.000000, reward total was -20.000000. running mean: -19.251901\n","resetting env. episode 33.000000, reward total was -20.000000. running mean: -19.259382\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -19.276788\n","resetting env. episode 35.000000, reward total was -19.000000. running mean: -19.274020\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -19.291280\n","resetting env. episode 37.000000, reward total was -18.000000. running mean: -19.278367\n","resetting env. episode 38.000000, reward total was -20.000000. running mean: -19.285584\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -19.302728\n","resetting env. episode 40.000000, reward total was -19.000000. running mean: -19.299700\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -19.316703\n","resetting env. episode 42.000000, reward total was -17.000000. running mean: -19.293536\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -19.310601\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -19.327495\n","resetting env. episode 45.000000, reward total was -20.000000. running mean: -19.334220\n","resetting env. episode 46.000000, reward total was -20.000000. running mean: -19.340878\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -19.357469\n","resetting env. episode 48.000000, reward total was -20.000000. running mean: -19.363894\n","resetting env. episode 49.000000, reward total was -20.000000. running mean: -19.370255\n","resetting env. episode 50.000000, reward total was -18.000000. running mean: -19.356553\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -19.372987\n","resetting env. episode 52.000000, reward total was -19.000000. running mean: -19.369258\n","resetting env. episode 53.000000, reward total was -18.000000. running mean: -19.355565\n","resetting env. episode 54.000000, reward total was -20.000000. running mean: -19.362009\n","resetting env. episode 55.000000, reward total was -19.000000. running mean: -19.358389\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -19.374805\n","resetting env. episode 57.000000, reward total was -20.000000. running mean: -19.381057\n","resetting env. episode 58.000000, reward total was -20.000000. running mean: -19.387247\n","resetting env. episode 59.000000, reward total was -20.000000. running mean: -19.393374\n","resetting env. episode 60.000000, reward total was -19.000000. running mean: -19.389440\n","resetting env. episode 61.000000, reward total was -20.000000. running mean: -19.395546\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -19.411591\n","resetting env. episode 63.000000, reward total was -20.000000. running mean: -19.417475\n","resetting env. episode 64.000000, reward total was -20.000000. running mean: -19.423300\n","resetting env. episode 65.000000, reward total was -20.000000. running mean: -19.429067\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -19.444776\n","resetting env. episode 67.000000, reward total was -20.000000. running mean: -19.450329\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -19.465825\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -19.481167\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -19.496355\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -19.501392\n","resetting env. episode 72.000000, reward total was -20.000000. running mean: -19.506378\n","resetting env. episode 73.000000, reward total was -19.000000. running mean: -19.501314\n","resetting env. episode 74.000000, reward total was -19.000000. running mean: -19.496301\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -19.511338\n","resetting env. episode 76.000000, reward total was -20.000000. running mean: -19.516225\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -19.531062\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -19.545752\n","resetting env. episode 79.000000, reward total was -19.000000. running mean: -19.540294\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -19.554891\n","resetting env. episode 81.000000, reward total was -20.000000. running mean: -19.559342\n","resetting env. episode 82.000000, reward total was -21.000000. running mean: -19.573749\n","resetting env. episode 83.000000, reward total was -20.000000. running mean: -19.578011\n","resetting env. episode 84.000000, reward total was -20.000000. running mean: -19.582231\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -19.596409\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -19.610445\n","resetting env. episode 87.000000, reward total was -19.000000. running mean: -19.604340\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -19.618297\n","resetting env. episode 89.000000, reward total was -19.000000. running mean: -19.612114\n","resetting env. episode 90.000000, reward total was -18.000000. running mean: -19.595993\n","resetting env. episode 91.000000, reward total was -19.000000. running mean: -19.590033\n","resetting env. episode 92.000000, reward total was -20.000000. running mean: -19.594133\n","resetting env. episode 93.000000, reward total was -20.000000. running mean: -19.598191\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -19.612209\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -19.626087\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -19.639826\n","resetting env. episode 97.000000, reward total was -20.000000. running mean: -19.643428\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -19.656994\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -19.670424\n","resetting env. episode 100.000000, reward total was -20.000000. running mean: -19.673720\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -19.686983\n","resetting env. episode 102.000000, reward total was -19.000000. running mean: -19.680113\n","resetting env. episode 103.000000, reward total was -20.000000. running mean: -19.683312\n","resetting env. episode 104.000000, reward total was -18.000000. running mean: -19.666478\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -19.679814\n","resetting env. episode 106.000000, reward total was -18.000000. running mean: -19.663016\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -19.676385\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -19.689622\n","resetting env. episode 109.000000, reward total was -20.000000. running mean: -19.692725\n","resetting env. episode 110.000000, reward total was -20.000000. running mean: -19.695798\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -19.708840\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -19.721752\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -19.734534\n","resetting env. episode 114.000000, reward total was -20.000000. running mean: -19.737189\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -19.749817\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -19.762319\n","resetting env. episode 117.000000, reward total was -19.000000. running mean: -19.754696\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -19.767149\n","resetting env. episode 119.000000, reward total was -20.000000. running mean: -19.769477\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -19.781782\n","resetting env. episode 121.000000, reward total was -20.000000. running mean: -19.783965\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -19.786125\n","resetting env. episode 123.000000, reward total was -20.000000. running mean: -19.788264\n","resetting env. episode 124.000000, reward total was -18.000000. running mean: -19.770381\n","resetting env. episode 125.000000, reward total was -20.000000. running mean: -19.772677\n","resetting env. episode 126.000000, reward total was -20.000000. running mean: -19.774950\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -19.787201\n","resetting env. episode 128.000000, reward total was -19.000000. running mean: -19.779329\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -19.791536\n","resetting env. episode 130.000000, reward total was -20.000000. running mean: -19.793620\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -19.805684\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -19.817627\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -19.829451\n","resetting env. episode 134.000000, reward total was -16.000000. running mean: -19.791156\n","resetting env. episode 135.000000, reward total was -20.000000. running mean: -19.793245\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -19.805312\n","resetting env. episode 137.000000, reward total was -20.000000. running mean: -19.807259\n","resetting env. episode 138.000000, reward total was -19.000000. running mean: -19.799187\n","resetting env. episode 139.000000, reward total was -18.000000. running mean: -19.781195\n","resetting env. episode 140.000000, reward total was -20.000000. running mean: -19.783383\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -19.795549\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -19.807594\n","resetting env. episode 143.000000, reward total was -19.000000. running mean: -19.799518\n","resetting env. episode 144.000000, reward total was -18.000000. running mean: -19.781522\n","resetting env. episode 145.000000, reward total was -20.000000. running mean: -19.783707\n","resetting env. episode 146.000000, reward total was -20.000000. running mean: -19.785870\n","resetting env. episode 147.000000, reward total was -19.000000. running mean: -19.778011\n","resetting env. episode 148.000000, reward total was -18.000000. running mean: -19.760231\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -19.772629\n","resetting env. episode 150.000000, reward total was -20.000000. running mean: -19.774903\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -19.787154\n","resetting env. episode 152.000000, reward total was -19.000000. running mean: -19.779282\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -19.791489\n","resetting env. episode 154.000000, reward total was -19.000000. running mean: -19.783574\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -19.795739\n","resetting env. episode 156.000000, reward total was -20.000000. running mean: -19.797781\n","resetting env. episode 157.000000, reward total was -20.000000. running mean: -19.799804\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -19.811805\n","resetting env. episode 159.000000, reward total was -20.000000. running mean: -19.813687\n","resetting env. episode 160.000000, reward total was -20.000000. running mean: -19.815551\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -19.827395\n","resetting env. episode 162.000000, reward total was -20.000000. running mean: -19.829121\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -19.840830\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -19.852422\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -19.863897\n","resetting env. episode 166.000000, reward total was -20.000000. running mean: -19.865258\n","resetting env. episode 167.000000, reward total was -21.000000. running mean: -19.876606\n","resetting env. episode 168.000000, reward total was -19.000000. running mean: -19.867840\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -19.879161\n","resetting env. episode 170.000000, reward total was -18.000000. running mean: -19.860370\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -19.871766\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -19.883048\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -19.884218\n","resetting env. episode 174.000000, reward total was -16.000000. running mean: -19.845376\n","resetting env. episode 175.000000, reward total was -20.000000. running mean: -19.846922\n","resetting env. episode 176.000000, reward total was -20.000000. running mean: -19.848453\n","resetting env. episode 177.000000, reward total was -18.000000. running mean: -19.829968\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -19.841669\n","resetting env. episode 179.000000, reward total was -19.000000. running mean: -19.833252\n","resetting env. episode 180.000000, reward total was -19.000000. running mean: -19.824919\n","resetting env. episode 181.000000, reward total was -20.000000. running mean: -19.826670\n","resetting env. episode 182.000000, reward total was -19.000000. running mean: -19.818403\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -19.830219\n","resetting env. episode 184.000000, reward total was -20.000000. running mean: -19.831917\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -19.843598\n","resetting env. episode 186.000000, reward total was -19.000000. running mean: -19.835162\n","resetting env. episode 187.000000, reward total was -18.000000. running mean: -19.816810\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -19.828642\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -19.840356\n","resetting env. episode 190.000000, reward total was -20.000000. running mean: -19.841952\n","resetting env. episode 191.000000, reward total was -19.000000. running mean: -19.833533\n","resetting env. episode 192.000000, reward total was -20.000000. running mean: -19.835198\n","resetting env. episode 193.000000, reward total was -18.000000. running mean: -19.816846\n","resetting env. episode 194.000000, reward total was -19.000000. running mean: -19.808677\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -19.820590\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -19.832384\n","resetting env. episode 197.000000, reward total was -18.000000. running mean: -19.814061\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -19.815920\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -19.817761\n","resetting env. episode 200.000000, reward total was -20.000000. running mean: -19.819583\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -19.831387\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -19.843073\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -19.844643\n","resetting env. episode 204.000000, reward total was -19.000000. running mean: -19.836196\n","resetting env. episode 205.000000, reward total was -20.000000. running mean: -19.837834\n","resetting env. episode 206.000000, reward total was -20.000000. running mean: -19.839456\n","resetting env. episode 207.000000, reward total was -20.000000. running mean: -19.841061\n","resetting env. episode 208.000000, reward total was -20.000000. running mean: -19.842651\n","resetting env. episode 209.000000, reward total was -20.000000. running mean: -19.844224\n","resetting env. episode 210.000000, reward total was -20.000000. running mean: -19.845782\n","resetting env. episode 211.000000, reward total was -20.000000. running mean: -19.847324\n","resetting env. episode 212.000000, reward total was -19.000000. running mean: -19.838851\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -19.850462\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -19.851958\n","resetting env. episode 215.000000, reward total was -19.000000. running mean: -19.843438\n","resetting env. episode 216.000000, reward total was -20.000000. running mean: -19.845004\n","resetting env. episode 217.000000, reward total was -20.000000. running mean: -19.846554\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -19.858088\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -19.869507\n","resetting env. episode 220.000000, reward total was -20.000000. running mean: -19.870812\n","resetting env. episode 221.000000, reward total was -19.000000. running mean: -19.862104\n","resetting env. episode 222.000000, reward total was -20.000000. running mean: -19.863483\n","resetting env. episode 223.000000, reward total was -20.000000. running mean: -19.864848\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -19.866200\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -19.867538\n","resetting env. episode 226.000000, reward total was -20.000000. running mean: -19.868862\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -19.880174\n","resetting env. episode 228.000000, reward total was -21.000000. running mean: -19.891372\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -19.902458\n","resetting env. episode 230.000000, reward total was -20.000000. running mean: -19.903434\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -19.914399\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -19.915255\n","resetting env. episode 233.000000, reward total was -17.000000. running mean: -19.886103\n","resetting env. episode 234.000000, reward total was -21.000000. running mean: -19.897242\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -19.908269\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -19.919187\n","resetting env. episode 237.000000, reward total was -19.000000. running mean: -19.909995\n","resetting env. episode 238.000000, reward total was -20.000000. running mean: -19.910895\n","resetting env. episode 239.000000, reward total was -20.000000. running mean: -19.911786\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -19.922668\n","resetting env. episode 241.000000, reward total was -20.000000. running mean: -19.923441\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -19.924207\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -19.934965\n","resetting env. episode 244.000000, reward total was -20.000000. running mean: -19.935615\n","resetting env. episode 245.000000, reward total was -17.000000. running mean: -19.906259\n","resetting env. episode 246.000000, reward total was -19.000000. running mean: -19.897197\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -19.908225\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -19.919142\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -19.929951\n","resetting env. episode 250.000000, reward total was -18.000000. running mean: -19.910651\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -19.921545\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -19.932329\n","resetting env. episode 253.000000, reward total was -18.000000. running mean: -19.913006\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -19.923876\n","resetting env. episode 255.000000, reward total was -19.000000. running mean: -19.914637\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -19.925491\n","resetting env. episode 257.000000, reward total was -19.000000. running mean: -19.916236\n","resetting env. episode 258.000000, reward total was -18.000000. running mean: -19.897074\n","resetting env. episode 259.000000, reward total was -20.000000. running mean: -19.898103\n","resetting env. episode 260.000000, reward total was -18.000000. running mean: -19.879122\n","resetting env. episode 261.000000, reward total was -19.000000. running mean: -19.870331\n","resetting env. episode 262.000000, reward total was -19.000000. running mean: -19.861627\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -19.873011\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -19.884281\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -19.895438\n","resetting env. episode 266.000000, reward total was -19.000000. running mean: -19.886484\n","resetting env. episode 267.000000, reward total was -19.000000. running mean: -19.877619\n","resetting env. episode 268.000000, reward total was -19.000000. running mean: -19.868843\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -19.880154\n","resetting env. episode 270.000000, reward total was -20.000000. running mean: -19.881353\n","resetting env. episode 271.000000, reward total was -19.000000. running mean: -19.872539\n","resetting env. episode 272.000000, reward total was -19.000000. running mean: -19.863814\n","resetting env. episode 273.000000, reward total was -19.000000. running mean: -19.855176\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -19.866624\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -19.877958\n","resetting env. episode 276.000000, reward total was -20.000000. running mean: -19.879178\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -19.890386\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -19.901483\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -19.912468\n","resetting env. episode 280.000000, reward total was -19.000000. running mean: -19.903343\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -19.914310\n","resetting env. episode 282.000000, reward total was -20.000000. running mean: -19.915167\n","resetting env. episode 283.000000, reward total was -20.000000. running mean: -19.916015\n","resetting env. episode 284.000000, reward total was -19.000000. running mean: -19.906855\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -19.917786\n","resetting env. episode 286.000000, reward total was -18.000000. running mean: -19.898608\n","resetting env. episode 287.000000, reward total was -20.000000. running mean: -19.899622\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -19.910626\n","resetting env. episode 289.000000, reward total was -20.000000. running mean: -19.911520\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -19.912405\n","resetting env. episode 291.000000, reward total was -18.000000. running mean: -19.893281\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -19.894348\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -19.905404\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -19.916350\n","resetting env. episode 295.000000, reward total was -17.000000. running mean: -19.887187\n","resetting env. episode 296.000000, reward total was -19.000000. running mean: -19.878315\n","resetting env. episode 297.000000, reward total was -19.000000. running mean: -19.869532\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -19.870836\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -19.872128\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -19.873407\n","resetting env. episode 301.000000, reward total was -19.000000. running mean: -19.864673\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -19.866026\n","resetting env. episode 303.000000, reward total was -20.000000. running mean: -19.867366\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -19.878692\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -19.889905\n","resetting env. episode 306.000000, reward total was -20.000000. running mean: -19.891006\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -19.902096\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -19.913075\n","resetting env. episode 309.000000, reward total was -20.000000. running mean: -19.913944\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -19.924805\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -19.935557\n","resetting env. episode 312.000000, reward total was -19.000000. running mean: -19.926201\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -19.926939\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -19.927670\n","resetting env. episode 315.000000, reward total was -20.000000. running mean: -19.928393\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -19.939109\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -19.949718\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -19.960221\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -19.970619\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -19.980912\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -19.981103\n","resetting env. episode 322.000000, reward total was -20.000000. running mean: -19.981292\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -19.991479\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.001565\n","resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.001549\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.011533\n","resetting env. episode 327.000000, reward total was -20.000000. running mean: -20.011418\n","resetting env. episode 328.000000, reward total was -18.000000. running mean: -19.991304\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.001391\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.011377\n","resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.011263\n","resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.011151\n","resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.011039\n","resetting env. episode 334.000000, reward total was -18.000000. running mean: -19.990929\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.001019\n","resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.001009\n","resetting env. episode 337.000000, reward total was -19.000000. running mean: -19.990999\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.001089\n","resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.001078\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.011067\n","resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.010957\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.020847\n","resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.020639\n","resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.020432\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.030228\n","resetting env. episode 346.000000, reward total was -19.000000. running mean: -20.019926\n","resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.019727\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.029529\n","resetting env. episode 349.000000, reward total was -19.000000. running mean: -20.019234\n","resetting env. episode 350.000000, reward total was -19.000000. running mean: -20.009042\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.018951\n","resetting env. episode 352.000000, reward total was -18.000000. running mean: -19.998762\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.008774\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.018686\n","resetting env. episode 355.000000, reward total was -19.000000. running mean: -20.008499\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.018414\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.028230\n","resetting env. episode 358.000000, reward total was -19.000000. running mean: -20.017948\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.027769\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.027491\n","resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.037216\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.046844\n","resetting env. episode 363.000000, reward total was -20.000000. running mean: -20.046375\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.055912\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.055352\n","resetting env. episode 366.000000, reward total was -19.000000. running mean: -20.044799\n","resetting env. episode 367.000000, reward total was -20.000000. running mean: -20.044351\n","resetting env. episode 368.000000, reward total was -19.000000. running mean: -20.033907\n","resetting env. episode 369.000000, reward total was -20.000000. running mean: -20.033568\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.043233\n","resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.042800\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.052372\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.061849\n","resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.061230\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.070618\n","resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.069912\n","resetting env. episode 377.000000, reward total was -20.000000. running mean: -20.069213\n","resetting env. episode 378.000000, reward total was -19.000000. running mean: -20.058520\n","resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.057935\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.067356\n","resetting env. episode 381.000000, reward total was -20.000000. running mean: -20.066682\n","resetting env. episode 382.000000, reward total was -20.000000. running mean: -20.066016\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.065355\n","resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.074702\n","resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.073955\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.083215\n","resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.082383\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.091559\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.100644\n","resetting env. episode 390.000000, reward total was -18.000000. running mean: -20.079637\n","resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.078841\n","resetting env. episode 392.000000, reward total was -18.000000. running mean: -20.058052\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.067472\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.076797\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.086029\n","resetting env. episode 396.000000, reward total was -19.000000. running mean: -20.075169\n","resetting env. episode 397.000000, reward total was -18.000000. running mean: -20.054417\n","resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.053873\n","resetting env. episode 399.000000, reward total was -17.000000. running mean: -20.023334\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.033101\n","resetting env. episode 401.000000, reward total was -19.000000. running mean: -20.022770\n","resetting env. episode 402.000000, reward total was -19.000000. running mean: -20.012542\n","resetting env. episode 403.000000, reward total was -18.000000. running mean: -19.992417\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.002493\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.012468\n","resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.012343\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.022220\n","resetting env. episode 408.000000, reward total was -19.000000. running mean: -20.011997\n","resetting env. episode 409.000000, reward total was -19.000000. running mean: -20.001877\n","resetting env. episode 410.000000, reward total was -17.000000. running mean: -19.971859\n","resetting env. episode 411.000000, reward total was -19.000000. running mean: -19.962140\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -19.962519\n","resetting env. episode 413.000000, reward total was -20.000000. running mean: -19.962894\n","resetting env. episode 414.000000, reward total was -20.000000. running mean: -19.963265\n","resetting env. episode 415.000000, reward total was -19.000000. running mean: -19.953632\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -19.964096\n","resetting env. episode 417.000000, reward total was -20.000000. running mean: -19.964455\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -19.974810\n","resetting env. episode 419.000000, reward total was -20.000000. running mean: -19.975062\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -19.985311\n","resetting env. episode 421.000000, reward total was -19.000000. running mean: -19.975458\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -19.985704\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -19.985847\n","resetting env. episode 424.000000, reward total was -18.000000. running mean: -19.965988\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -19.966328\n","resetting env. episode 426.000000, reward total was -20.000000. running mean: -19.966665\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -19.976998\n","resetting env. episode 428.000000, reward total was -20.000000. running mean: -19.977228\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -19.987456\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -19.987582\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -19.997706\n","resetting env. episode 432.000000, reward total was -19.000000. running mean: -19.987729\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -19.997851\n","resetting env. episode 434.000000, reward total was -19.000000. running mean: -19.987873\n","resetting env. episode 435.000000, reward total was -19.000000. running mean: -19.977994\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -19.988214\n","resetting env. episode 437.000000, reward total was -19.000000. running mean: -19.978332\n","resetting env. episode 438.000000, reward total was -21.000000. running mean: -19.988549\n","resetting env. episode 439.000000, reward total was -20.000000. running mean: -19.988663\n","resetting env. episode 440.000000, reward total was -20.000000. running mean: -19.988777\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -19.998889\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.008900\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.018811\n","resetting env. episode 444.000000, reward total was -20.000000. running mean: -20.018623\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.028437\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.038152\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.047771\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.057293\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.066720\n","resetting env. episode 450.000000, reward total was -19.000000. running mean: -20.056053\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.065492\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.074837\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.084089\n","resetting env. episode 454.000000, reward total was -18.000000. running mean: -20.063248\n","resetting env. episode 455.000000, reward total was -19.000000. running mean: -20.052616\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.062090\n","resetting env. episode 457.000000, reward total was -19.000000. running mean: -20.051469\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.060954\n","resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.060344\n","resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.069741\n","resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.069044\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.068353\n","resetting env. episode 463.000000, reward total was -19.000000. running mean: -20.057670\n","resetting env. episode 464.000000, reward total was -18.000000. running mean: -20.037093\n","resetting env. episode 465.000000, reward total was -18.000000. running mean: -20.016722\n","resetting env. episode 466.000000, reward total was -18.000000. running mean: -19.996555\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -19.996589\n","resetting env. episode 468.000000, reward total was -20.000000. running mean: -19.996623\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.006657\n","resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.006591\n","resetting env. episode 471.000000, reward total was -20.000000. running mean: -20.006525\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.016459\n","resetting env. episode 473.000000, reward total was -20.000000. running mean: -20.016295\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.026132\n","resetting env. episode 475.000000, reward total was -18.000000. running mean: -20.005871\n","resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.005812\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.015754\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.015596\n","resetting env. episode 479.000000, reward total was -16.000000. running mean: -19.975440\n","resetting env. episode 480.000000, reward total was -19.000000. running mean: -19.965686\n","resetting env. episode 481.000000, reward total was -20.000000. running mean: -19.966029\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -19.966369\n","resetting env. episode 483.000000, reward total was -19.000000. running mean: -19.956705\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -19.967138\n","resetting env. episode 485.000000, reward total was -20.000000. running mean: -19.967467\n","resetting env. episode 486.000000, reward total was -19.000000. running mean: -19.957792\n","resetting env. episode 487.000000, reward total was -19.000000. running mean: -19.948214\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -19.948732\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -19.959244\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -19.959652\n","resetting env. episode 491.000000, reward total was -20.000000. running mean: -19.960056\n","resetting env. episode 492.000000, reward total was -19.000000. running mean: -19.950455\n","resetting env. episode 493.000000, reward total was -18.000000. running mean: -19.930950\n","resetting env. episode 494.000000, reward total was -20.000000. running mean: -19.931641\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -19.942325\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -19.952901\n","resetting env. episode 497.000000, reward total was -19.000000. running mean: -19.943372\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -19.953939\n","resetting env. episode 499.000000, reward total was -20.000000. running mean: -19.954399\n","resetting env. episode 500.000000, reward total was -21.000000. running mean: -19.964855\n","resetting env. episode 501.000000, reward total was -21.000000. running mean: -19.975207\n","resetting env. episode 502.000000, reward total was -19.000000. running mean: -19.965455\n","resetting env. episode 503.000000, reward total was -21.000000. running mean: -19.975800\n","resetting env. episode 504.000000, reward total was -20.000000. running mean: -19.976042\n","resetting env. episode 505.000000, reward total was -21.000000. running mean: -19.986282\n","resetting env. episode 506.000000, reward total was -21.000000. running mean: -19.996419\n","resetting env. episode 507.000000, reward total was -19.000000. running mean: -19.986455\n","resetting env. episode 508.000000, reward total was -20.000000. running mean: -19.986590\n","resetting env. episode 509.000000, reward total was -19.000000. running mean: -19.976724\n","resetting env. episode 510.000000, reward total was -21.000000. running mean: -19.986957\n","resetting env. episode 511.000000, reward total was -19.000000. running mean: -19.977087\n","resetting env. episode 512.000000, reward total was -18.000000. running mean: -19.957316\n","resetting env. episode 513.000000, reward total was -20.000000. running mean: -19.957743\n","resetting env. episode 514.000000, reward total was -21.000000. running mean: -19.968166\n","resetting env. episode 515.000000, reward total was -19.000000. running mean: -19.958484\n","resetting env. episode 516.000000, reward total was -17.000000. running mean: -19.928899\n","resetting env. episode 517.000000, reward total was -21.000000. running mean: -19.939610\n","resetting env. episode 518.000000, reward total was -19.000000. running mean: -19.930214\n","resetting env. episode 519.000000, reward total was -19.000000. running mean: -19.920912\n","resetting env. episode 520.000000, reward total was -20.000000. running mean: -19.921703\n","resetting env. episode 521.000000, reward total was -20.000000. running mean: -19.922486\n","resetting env. episode 522.000000, reward total was -15.000000. running mean: -19.873261\n","resetting env. episode 523.000000, reward total was -19.000000. running mean: -19.864528\n","resetting env. episode 524.000000, reward total was -20.000000. running mean: -19.865883\n","resetting env. episode 525.000000, reward total was -20.000000. running mean: -19.867224\n","resetting env. episode 526.000000, reward total was -21.000000. running mean: -19.878552\n","resetting env. episode 527.000000, reward total was -21.000000. running mean: -19.889767\n","resetting env. episode 528.000000, reward total was -18.000000. running mean: -19.870869\n","resetting env. episode 529.000000, reward total was -18.000000. running mean: -19.852160\n","resetting env. episode 530.000000, reward total was -21.000000. running mean: -19.863639\n","resetting env. episode 531.000000, reward total was -21.000000. running mean: -19.875002\n","resetting env. episode 532.000000, reward total was -21.000000. running mean: -19.886252\n","resetting env. episode 533.000000, reward total was -21.000000. running mean: -19.897390\n","resetting env. episode 534.000000, reward total was -20.000000. running mean: -19.898416\n","resetting env. episode 535.000000, reward total was -19.000000. running mean: -19.889432\n","resetting env. episode 536.000000, reward total was -20.000000. running mean: -19.890537\n","resetting env. episode 537.000000, reward total was -18.000000. running mean: -19.871632\n","resetting env. episode 538.000000, reward total was -20.000000. running mean: -19.872916\n","resetting env. episode 539.000000, reward total was -20.000000. running mean: -19.874186\n","resetting env. episode 540.000000, reward total was -21.000000. running mean: -19.885445\n","resetting env. episode 541.000000, reward total was -21.000000. running mean: -19.896590\n","resetting env. episode 542.000000, reward total was -20.000000. running mean: -19.897624\n","resetting env. episode 543.000000, reward total was -20.000000. running mean: -19.898648\n","resetting env. episode 544.000000, reward total was -21.000000. running mean: -19.909662\n","resetting env. episode 545.000000, reward total was -19.000000. running mean: -19.900565\n","resetting env. episode 546.000000, reward total was -21.000000. running mean: -19.911559\n","resetting env. episode 547.000000, reward total was -19.000000. running mean: -19.902444\n","resetting env. episode 548.000000, reward total was -20.000000. running mean: -19.903419\n","resetting env. episode 549.000000, reward total was -19.000000. running mean: -19.894385\n","resetting env. episode 550.000000, reward total was -20.000000. running mean: -19.895441\n","resetting env. episode 551.000000, reward total was -19.000000. running mean: -19.886487\n","resetting env. episode 552.000000, reward total was -17.000000. running mean: -19.857622\n","resetting env. episode 553.000000, reward total was -20.000000. running mean: -19.859046\n","resetting env. episode 554.000000, reward total was -21.000000. running mean: -19.870455\n","resetting env. episode 555.000000, reward total was -20.000000. running mean: -19.871751\n","resetting env. episode 556.000000, reward total was -19.000000. running mean: -19.863033\n","resetting env. episode 557.000000, reward total was -20.000000. running mean: -19.864403\n","resetting env. episode 558.000000, reward total was -20.000000. running mean: -19.865759\n","resetting env. episode 559.000000, reward total was -20.000000. running mean: -19.867101\n","resetting env. episode 560.000000, reward total was -20.000000. running mean: -19.868430\n","resetting env. episode 561.000000, reward total was -19.000000. running mean: -19.859746\n","resetting env. episode 562.000000, reward total was -17.000000. running mean: -19.831148\n","resetting env. episode 563.000000, reward total was -18.000000. running mean: -19.812837\n","resetting env. episode 564.000000, reward total was -21.000000. running mean: -19.824709\n","resetting env. episode 565.000000, reward total was -20.000000. running mean: -19.826462\n","resetting env. episode 566.000000, reward total was -21.000000. running mean: -19.838197\n","resetting env. episode 567.000000, reward total was -18.000000. running mean: -19.819815\n","resetting env. episode 568.000000, reward total was -21.000000. running mean: -19.831617\n","resetting env. episode 569.000000, reward total was -21.000000. running mean: -19.843301\n","resetting env. episode 570.000000, reward total was -21.000000. running mean: -19.854868\n","resetting env. episode 571.000000, reward total was -20.000000. running mean: -19.856319\n","resetting env. episode 572.000000, reward total was -19.000000. running mean: -19.847756\n","resetting env. episode 573.000000, reward total was -21.000000. running mean: -19.859278\n","resetting env. episode 574.000000, reward total was -21.000000. running mean: -19.870685\n","resetting env. episode 575.000000, reward total was -19.000000. running mean: -19.861979\n","resetting env. episode 576.000000, reward total was -21.000000. running mean: -19.873359\n","resetting env. episode 577.000000, reward total was -19.000000. running mean: -19.864625\n","resetting env. episode 578.000000, reward total was -20.000000. running mean: -19.865979\n","resetting env. episode 579.000000, reward total was -20.000000. running mean: -19.867319\n","resetting env. episode 580.000000, reward total was -21.000000. running mean: -19.878646\n","resetting env. episode 581.000000, reward total was -20.000000. running mean: -19.879859\n","resetting env. episode 582.000000, reward total was -19.000000. running mean: -19.871061\n","resetting env. episode 583.000000, reward total was -18.000000. running mean: -19.852350\n","resetting env. episode 584.000000, reward total was -18.000000. running mean: -19.833827\n","resetting env. episode 585.000000, reward total was -21.000000. running mean: -19.845489\n","resetting env. episode 586.000000, reward total was -21.000000. running mean: -19.857034\n","resetting env. episode 587.000000, reward total was -19.000000. running mean: -19.848463\n","resetting env. episode 588.000000, reward total was -18.000000. running mean: -19.829979\n","resetting env. episode 589.000000, reward total was -17.000000. running mean: -19.801679\n","resetting env. episode 590.000000, reward total was -19.000000. running mean: -19.793662\n","resetting env. episode 591.000000, reward total was -21.000000. running mean: -19.805725\n","resetting env. episode 592.000000, reward total was -21.000000. running mean: -19.817668\n","resetting env. episode 593.000000, reward total was -20.000000. running mean: -19.819492\n","resetting env. episode 594.000000, reward total was -19.000000. running mean: -19.811297\n","resetting env. episode 595.000000, reward total was -19.000000. running mean: -19.803184\n","resetting env. episode 596.000000, reward total was -18.000000. running mean: -19.785152\n","resetting env. episode 597.000000, reward total was -20.000000. running mean: -19.787300\n","resetting env. episode 598.000000, reward total was -20.000000. running mean: -19.789427\n","resetting env. episode 599.000000, reward total was -21.000000. running mean: -19.801533\n","resetting env. episode 600.000000, reward total was -20.000000. running mean: -19.803518\n","resetting env. episode 601.000000, reward total was -19.000000. running mean: -19.795483\n","resetting env. episode 602.000000, reward total was -19.000000. running mean: -19.787528\n","resetting env. episode 603.000000, reward total was -21.000000. running mean: -19.799652\n","resetting env. episode 604.000000, reward total was -20.000000. running mean: -19.801656\n","resetting env. episode 605.000000, reward total was -20.000000. running mean: -19.803639\n","resetting env. episode 606.000000, reward total was -21.000000. running mean: -19.815603\n","resetting env. episode 607.000000, reward total was -21.000000. running mean: -19.827447\n","resetting env. episode 608.000000, reward total was -21.000000. running mean: -19.839172\n","resetting env. episode 609.000000, reward total was -21.000000. running mean: -19.850781\n","resetting env. episode 610.000000, reward total was -20.000000. running mean: -19.852273\n","resetting env. episode 611.000000, reward total was -21.000000. running mean: -19.863750\n","resetting env. episode 612.000000, reward total was -20.000000. running mean: -19.865113\n","resetting env. episode 613.000000, reward total was -21.000000. running mean: -19.876462\n","resetting env. episode 614.000000, reward total was -18.000000. running mean: -19.857697\n","resetting env. episode 615.000000, reward total was -19.000000. running mean: -19.849120\n","resetting env. episode 616.000000, reward total was -17.000000. running mean: -19.820629\n","resetting env. episode 617.000000, reward total was -21.000000. running mean: -19.832422\n","resetting env. episode 618.000000, reward total was -18.000000. running mean: -19.814098\n","resetting env. episode 619.000000, reward total was -20.000000. running mean: -19.815957\n","resetting env. episode 620.000000, reward total was -20.000000. running mean: -19.817798\n","resetting env. episode 621.000000, reward total was -19.000000. running mean: -19.809620\n","resetting env. episode 622.000000, reward total was -21.000000. running mean: -19.821524\n","resetting env. episode 623.000000, reward total was -20.000000. running mean: -19.823308\n","resetting env. episode 624.000000, reward total was -20.000000. running mean: -19.825075\n","resetting env. episode 625.000000, reward total was -18.000000. running mean: -19.806824\n","resetting env. episode 626.000000, reward total was -19.000000. running mean: -19.798756\n","resetting env. episode 627.000000, reward total was -20.000000. running mean: -19.800769\n","resetting env. episode 628.000000, reward total was -21.000000. running mean: -19.812761\n","resetting env. episode 629.000000, reward total was -21.000000. running mean: -19.824633\n","resetting env. episode 630.000000, reward total was -21.000000. running mean: -19.836387\n","resetting env. episode 631.000000, reward total was -19.000000. running mean: -19.828023\n","resetting env. episode 632.000000, reward total was -20.000000. running mean: -19.829743\n","resetting env. episode 633.000000, reward total was -19.000000. running mean: -19.821445\n","resetting env. episode 634.000000, reward total was -20.000000. running mean: -19.823231\n","resetting env. episode 635.000000, reward total was -18.000000. running mean: -19.804999\n","resetting env. episode 636.000000, reward total was -19.000000. running mean: -19.796949\n","resetting env. episode 637.000000, reward total was -19.000000. running mean: -19.788979\n","resetting env. episode 638.000000, reward total was -21.000000. running mean: -19.801089\n","resetting env. episode 639.000000, reward total was -21.000000. running mean: -19.813079\n","resetting env. episode 640.000000, reward total was -19.000000. running mean: -19.804948\n","resetting env. episode 641.000000, reward total was -20.000000. running mean: -19.806898\n","resetting env. episode 642.000000, reward total was -18.000000. running mean: -19.788829\n","resetting env. episode 643.000000, reward total was -21.000000. running mean: -19.800941\n","resetting env. episode 644.000000, reward total was -21.000000. running mean: -19.812932\n","resetting env. episode 645.000000, reward total was -21.000000. running mean: -19.824802\n","resetting env. episode 646.000000, reward total was -19.000000. running mean: -19.816554\n","resetting env. episode 647.000000, reward total was -21.000000. running mean: -19.828389\n","resetting env. episode 648.000000, reward total was -20.000000. running mean: -19.830105\n","resetting env. episode 649.000000, reward total was -21.000000. running mean: -19.841804\n","resetting env. episode 650.000000, reward total was -17.000000. running mean: -19.813386\n","resetting env. episode 651.000000, reward total was -20.000000. running mean: -19.815252\n","resetting env. episode 652.000000, reward total was -19.000000. running mean: -19.807099\n","resetting env. episode 653.000000, reward total was -21.000000. running mean: -19.819028\n","resetting env. episode 654.000000, reward total was -21.000000. running mean: -19.830838\n","resetting env. episode 655.000000, reward total was -20.000000. running mean: -19.832530\n","resetting env. episode 656.000000, reward total was -20.000000. running mean: -19.834204\n","resetting env. episode 657.000000, reward total was -20.000000. running mean: -19.835862\n","resetting env. episode 658.000000, reward total was -16.000000. running mean: -19.797504\n","resetting env. episode 659.000000, reward total was -20.000000. running mean: -19.799529\n","resetting env. episode 660.000000, reward total was -19.000000. running mean: -19.791533\n","resetting env. episode 661.000000, reward total was -19.000000. running mean: -19.783618\n","resetting env. episode 662.000000, reward total was -18.000000. running mean: -19.765782\n","resetting env. episode 663.000000, reward total was -18.000000. running mean: -19.748124\n","resetting env. episode 664.000000, reward total was -18.000000. running mean: -19.730643\n","resetting env. episode 665.000000, reward total was -19.000000. running mean: -19.723336\n","resetting env. episode 666.000000, reward total was -20.000000. running mean: -19.726103\n","resetting env. episode 667.000000, reward total was -20.000000. running mean: -19.728842\n","resetting env. episode 668.000000, reward total was -21.000000. running mean: -19.741554\n","resetting env. episode 669.000000, reward total was -21.000000. running mean: -19.754138\n","resetting env. episode 670.000000, reward total was -21.000000. running mean: -19.766597\n","resetting env. episode 671.000000, reward total was -20.000000. running mean: -19.768931\n","resetting env. episode 672.000000, reward total was -18.000000. running mean: -19.751241\n","resetting env. episode 673.000000, reward total was -19.000000. running mean: -19.743729\n","resetting env. episode 674.000000, reward total was -20.000000. running mean: -19.746292\n","resetting env. episode 675.000000, reward total was -17.000000. running mean: -19.718829\n","resetting env. episode 676.000000, reward total was -20.000000. running mean: -19.721641\n","resetting env. episode 677.000000, reward total was -21.000000. running mean: -19.734424\n","resetting env. episode 678.000000, reward total was -19.000000. running mean: -19.727080\n","resetting env. episode 679.000000, reward total was -19.000000. running mean: -19.719809\n","resetting env. episode 680.000000, reward total was -21.000000. running mean: -19.732611\n","resetting env. episode 681.000000, reward total was -20.000000. running mean: -19.735285\n","resetting env. episode 682.000000, reward total was -20.000000. running mean: -19.737932\n","resetting env. episode 683.000000, reward total was -20.000000. running mean: -19.740553\n","resetting env. episode 684.000000, reward total was -19.000000. running mean: -19.733147\n","resetting env. episode 685.000000, reward total was -19.000000. running mean: -19.725816\n","resetting env. episode 686.000000, reward total was -19.000000. running mean: -19.718558\n","resetting env. episode 687.000000, reward total was -19.000000. running mean: -19.711372\n","resetting env. episode 688.000000, reward total was -18.000000. running mean: -19.694258\n","resetting env. episode 689.000000, reward total was -18.000000. running mean: -19.677316\n","resetting env. episode 690.000000, reward total was -20.000000. running mean: -19.680543\n","resetting env. episode 691.000000, reward total was -20.000000. running mean: -19.683737\n","resetting env. episode 692.000000, reward total was -19.000000. running mean: -19.676900\n","resetting env. episode 693.000000, reward total was -21.000000. running mean: -19.690131\n","resetting env. episode 694.000000, reward total was -19.000000. running mean: -19.683229\n","resetting env. episode 695.000000, reward total was -18.000000. running mean: -19.666397\n","resetting env. episode 696.000000, reward total was -18.000000. running mean: -19.649733\n","resetting env. episode 697.000000, reward total was -21.000000. running mean: -19.663236\n","resetting env. episode 698.000000, reward total was -21.000000. running mean: -19.676603\n","resetting env. episode 699.000000, reward total was -20.000000. running mean: -19.679837\n","resetting env. episode 700.000000, reward total was -21.000000. running mean: -19.693039\n","resetting env. episode 701.000000, reward total was -19.000000. running mean: -19.686109\n","resetting env. episode 702.000000, reward total was -20.000000. running mean: -19.689248\n","resetting env. episode 703.000000, reward total was -19.000000. running mean: -19.682355\n","resetting env. episode 704.000000, reward total was -19.000000. running mean: -19.675532\n","resetting env. episode 705.000000, reward total was -19.000000. running mean: -19.668776\n","resetting env. episode 706.000000, reward total was -21.000000. running mean: -19.682088\n","resetting env. episode 707.000000, reward total was -19.000000. running mean: -19.675268\n","resetting env. episode 708.000000, reward total was -18.000000. running mean: -19.658515\n","resetting env. episode 709.000000, reward total was -20.000000. running mean: -19.661930\n","resetting env. episode 710.000000, reward total was -21.000000. running mean: -19.675310\n","resetting env. episode 711.000000, reward total was -21.000000. running mean: -19.688557\n","resetting env. episode 712.000000, reward total was -21.000000. running mean: -19.701672\n","resetting env. episode 713.000000, reward total was -21.000000. running mean: -19.714655\n","resetting env. episode 714.000000, reward total was -18.000000. running mean: -19.697509\n","resetting env. episode 715.000000, reward total was -21.000000. running mean: -19.710533\n","resetting env. episode 716.000000, reward total was -21.000000. running mean: -19.723428\n","resetting env. episode 717.000000, reward total was -20.000000. running mean: -19.726194\n","resetting env. episode 718.000000, reward total was -20.000000. running mean: -19.728932\n","resetting env. episode 719.000000, reward total was -19.000000. running mean: -19.721643\n","resetting env. episode 720.000000, reward total was -20.000000. running mean: -19.724426\n","resetting env. episode 721.000000, reward total was -19.000000. running mean: -19.717182\n","resetting env. episode 722.000000, reward total was -17.000000. running mean: -19.690010\n","resetting env. episode 723.000000, reward total was -18.000000. running mean: -19.673110\n","resetting env. episode 724.000000, reward total was -19.000000. running mean: -19.666379\n","resetting env. episode 725.000000, reward total was -17.000000. running mean: -19.639715\n","resetting env. episode 726.000000, reward total was -20.000000. running mean: -19.643318\n","resetting env. episode 727.000000, reward total was -21.000000. running mean: -19.656885\n","resetting env. episode 728.000000, reward total was -20.000000. running mean: -19.660316\n","resetting env. episode 729.000000, reward total was -21.000000. running mean: -19.673713\n","resetting env. episode 730.000000, reward total was -21.000000. running mean: -19.686976\n","resetting env. episode 731.000000, reward total was -21.000000. running mean: -19.700106\n","resetting env. episode 732.000000, reward total was -20.000000. running mean: -19.703105\n","resetting env. episode 733.000000, reward total was -19.000000. running mean: -19.696074\n","resetting env. episode 734.000000, reward total was -20.000000. running mean: -19.699113\n","resetting env. episode 735.000000, reward total was -19.000000. running mean: -19.692122\n","resetting env. episode 736.000000, reward total was -19.000000. running mean: -19.685201\n","resetting env. episode 737.000000, reward total was -21.000000. running mean: -19.698349\n","resetting env. episode 738.000000, reward total was -21.000000. running mean: -19.711365\n","resetting env. episode 739.000000, reward total was -21.000000. running mean: -19.724252\n","resetting env. episode 740.000000, reward total was -20.000000. running mean: -19.727009\n","resetting env. episode 741.000000, reward total was -21.000000. running mean: -19.739739\n","resetting env. episode 742.000000, reward total was -18.000000. running mean: -19.722342\n","resetting env. episode 743.000000, reward total was -20.000000. running mean: -19.725118\n","resetting env. episode 744.000000, reward total was -19.000000. running mean: -19.717867\n","resetting env. episode 745.000000, reward total was -21.000000. running mean: -19.730688\n","resetting env. episode 746.000000, reward total was -20.000000. running mean: -19.733381\n","resetting env. episode 747.000000, reward total was -19.000000. running mean: -19.726048\n","resetting env. episode 748.000000, reward total was -18.000000. running mean: -19.708787\n","resetting env. episode 749.000000, reward total was -21.000000. running mean: -19.721699\n","resetting env. episode 750.000000, reward total was -21.000000. running mean: -19.734482\n","resetting env. episode 751.000000, reward total was -19.000000. running mean: -19.727137\n","resetting env. episode 752.000000, reward total was -20.000000. running mean: -19.729866\n","resetting env. episode 753.000000, reward total was -18.000000. running mean: -19.712567\n","resetting env. episode 754.000000, reward total was -21.000000. running mean: -19.725442\n","resetting env. episode 755.000000, reward total was -20.000000. running mean: -19.728187\n","resetting env. episode 756.000000, reward total was -20.000000. running mean: -19.730905\n","resetting env. episode 757.000000, reward total was -18.000000. running mean: -19.713596\n","resetting env. episode 758.000000, reward total was -20.000000. running mean: -19.716460\n","resetting env. episode 759.000000, reward total was -21.000000. running mean: -19.729296\n","resetting env. episode 760.000000, reward total was -18.000000. running mean: -19.712003\n","resetting env. episode 761.000000, reward total was -20.000000. running mean: -19.714883\n","resetting env. episode 762.000000, reward total was -19.000000. running mean: -19.707734\n","resetting env. episode 763.000000, reward total was -21.000000. running mean: -19.720657\n","resetting env. episode 764.000000, reward total was -20.000000. running mean: -19.723450\n","resetting env. episode 765.000000, reward total was -21.000000. running mean: -19.736216\n","resetting env. episode 766.000000, reward total was -19.000000. running mean: -19.728853\n","resetting env. episode 767.000000, reward total was -21.000000. running mean: -19.741565\n","resetting env. episode 768.000000, reward total was -19.000000. running mean: -19.734149\n","resetting env. episode 769.000000, reward total was -21.000000. running mean: -19.746808\n","resetting env. episode 770.000000, reward total was -21.000000. running mean: -19.759340\n","resetting env. episode 771.000000, reward total was -21.000000. running mean: -19.771746\n","resetting env. episode 772.000000, reward total was -17.000000. running mean: -19.744029\n","resetting env. episode 773.000000, reward total was -19.000000. running mean: -19.736588\n","resetting env. episode 774.000000, reward total was -21.000000. running mean: -19.749223\n","resetting env. episode 775.000000, reward total was -21.000000. running mean: -19.761730\n","resetting env. episode 776.000000, reward total was -18.000000. running mean: -19.744113\n","resetting env. episode 777.000000, reward total was -20.000000. running mean: -19.746672\n","resetting env. episode 778.000000, reward total was -21.000000. running mean: -19.759205\n","resetting env. episode 779.000000, reward total was -21.000000. running mean: -19.771613\n","resetting env. episode 780.000000, reward total was -19.000000. running mean: -19.763897\n","resetting env. episode 781.000000, reward total was -17.000000. running mean: -19.736258\n","resetting env. episode 782.000000, reward total was -20.000000. running mean: -19.738895\n","resetting env. episode 783.000000, reward total was -21.000000. running mean: -19.751507\n","resetting env. episode 784.000000, reward total was -20.000000. running mean: -19.753991\n","resetting env. episode 785.000000, reward total was -21.000000. running mean: -19.766452\n","resetting env. episode 786.000000, reward total was -20.000000. running mean: -19.768787\n","resetting env. episode 787.000000, reward total was -21.000000. running mean: -19.781099\n","resetting env. episode 788.000000, reward total was -20.000000. running mean: -19.783288\n","resetting env. episode 789.000000, reward total was -18.000000. running mean: -19.765455\n","resetting env. episode 790.000000, reward total was -21.000000. running mean: -19.777801\n","resetting env. episode 791.000000, reward total was -18.000000. running mean: -19.760023\n","resetting env. episode 792.000000, reward total was -20.000000. running mean: -19.762423\n","resetting env. episode 793.000000, reward total was -21.000000. running mean: -19.774798\n","resetting env. episode 794.000000, reward total was -18.000000. running mean: -19.757050\n","resetting env. episode 795.000000, reward total was -21.000000. running mean: -19.769480\n","resetting env. episode 796.000000, reward total was -21.000000. running mean: -19.781785\n","resetting env. episode 797.000000, reward total was -19.000000. running mean: -19.773967\n","resetting env. episode 798.000000, reward total was -19.000000. running mean: -19.766227\n","resetting env. episode 799.000000, reward total was -20.000000. running mean: -19.768565\n","resetting env. episode 800.000000, reward total was -21.000000. running mean: -19.780880\n","resetting env. episode 801.000000, reward total was -19.000000. running mean: -19.773071\n","resetting env. episode 802.000000, reward total was -21.000000. running mean: -19.785340\n","resetting env. episode 803.000000, reward total was -20.000000. running mean: -19.787487\n","resetting env. episode 804.000000, reward total was -18.000000. running mean: -19.769612\n","resetting env. episode 805.000000, reward total was -20.000000. running mean: -19.771916\n","resetting env. episode 806.000000, reward total was -17.000000. running mean: -19.744197\n","resetting env. episode 807.000000, reward total was -21.000000. running mean: -19.756755\n","resetting env. episode 808.000000, reward total was -20.000000. running mean: -19.759187\n","resetting env. episode 809.000000, reward total was -18.000000. running mean: -19.741595\n","resetting env. episode 810.000000, reward total was -19.000000. running mean: -19.734179\n","resetting env. episode 811.000000, reward total was -20.000000. running mean: -19.736837\n","resetting env. episode 812.000000, reward total was -20.000000. running mean: -19.739469\n","resetting env. episode 813.000000, reward total was -17.000000. running mean: -19.712074\n","resetting env. episode 814.000000, reward total was -18.000000. running mean: -19.694954\n","resetting env. episode 815.000000, reward total was -19.000000. running mean: -19.688004\n","resetting env. episode 816.000000, reward total was -20.000000. running mean: -19.691124\n","resetting env. episode 817.000000, reward total was -17.000000. running mean: -19.664213\n","resetting env. episode 818.000000, reward total was -21.000000. running mean: -19.677571\n","resetting env. episode 819.000000, reward total was -21.000000. running mean: -19.690795\n","resetting env. episode 820.000000, reward total was -21.000000. running mean: -19.703887\n","resetting env. episode 821.000000, reward total was -16.000000. running mean: -19.666848\n","resetting env. episode 822.000000, reward total was -20.000000. running mean: -19.670180\n","resetting env. episode 823.000000, reward total was -18.000000. running mean: -19.653478\n","resetting env. episode 824.000000, reward total was -20.000000. running mean: -19.656943\n","resetting env. episode 825.000000, reward total was -21.000000. running mean: -19.670374\n","resetting env. episode 826.000000, reward total was -20.000000. running mean: -19.673670\n","resetting env. episode 827.000000, reward total was -21.000000. running mean: -19.686933\n","resetting env. episode 828.000000, reward total was -21.000000. running mean: -19.700064\n","resetting env. episode 829.000000, reward total was -20.000000. running mean: -19.703063\n","resetting env. episode 830.000000, reward total was -20.000000. running mean: -19.706033\n","resetting env. episode 831.000000, reward total was -19.000000. running mean: -19.698972\n","resetting env. episode 832.000000, reward total was -18.000000. running mean: -19.681983\n","resetting env. episode 833.000000, reward total was -19.000000. running mean: -19.675163\n","resetting env. episode 834.000000, reward total was -19.000000. running mean: -19.668411\n","resetting env. episode 835.000000, reward total was -21.000000. running mean: -19.681727\n","resetting env. episode 836.000000, reward total was -19.000000. running mean: -19.674910\n","resetting env. episode 837.000000, reward total was -21.000000. running mean: -19.688161\n","resetting env. episode 838.000000, reward total was -21.000000. running mean: -19.701279\n","resetting env. episode 839.000000, reward total was -20.000000. running mean: -19.704266\n","resetting env. episode 840.000000, reward total was -20.000000. running mean: -19.707224\n","resetting env. episode 841.000000, reward total was -20.000000. running mean: -19.710151\n","resetting env. episode 842.000000, reward total was -19.000000. running mean: -19.703050\n","resetting env. episode 843.000000, reward total was -19.000000. running mean: -19.696019\n","resetting env. episode 844.000000, reward total was -20.000000. running mean: -19.699059\n","resetting env. episode 845.000000, reward total was -21.000000. running mean: -19.712069\n","resetting env. episode 846.000000, reward total was -21.000000. running mean: -19.724948\n","resetting env. episode 847.000000, reward total was -16.000000. running mean: -19.687698\n","resetting env. episode 848.000000, reward total was -21.000000. running mean: -19.700821\n","resetting env. episode 849.000000, reward total was -21.000000. running mean: -19.713813\n","resetting env. episode 850.000000, reward total was -21.000000. running mean: -19.726675\n","resetting env. episode 851.000000, reward total was -18.000000. running mean: -19.709408\n","resetting env. episode 852.000000, reward total was -21.000000. running mean: -19.722314\n","resetting env. episode 853.000000, reward total was -20.000000. running mean: -19.725091\n","resetting env. episode 854.000000, reward total was -20.000000. running mean: -19.727840\n","resetting env. episode 855.000000, reward total was -21.000000. running mean: -19.740562\n","resetting env. episode 856.000000, reward total was -20.000000. running mean: -19.743156\n","resetting env. episode 857.000000, reward total was -21.000000. running mean: -19.755725\n","resetting env. episode 858.000000, reward total was -19.000000. running mean: -19.748167\n","resetting env. episode 859.000000, reward total was -19.000000. running mean: -19.740686\n","resetting env. episode 860.000000, reward total was -21.000000. running mean: -19.753279\n","resetting env. episode 861.000000, reward total was -20.000000. running mean: -19.755746\n","resetting env. episode 862.000000, reward total was -21.000000. running mean: -19.768189\n","resetting env. episode 863.000000, reward total was -21.000000. running mean: -19.780507\n","resetting env. episode 864.000000, reward total was -19.000000. running mean: -19.772702\n","resetting env. episode 865.000000, reward total was -18.000000. running mean: -19.754975\n","resetting env. episode 866.000000, reward total was -20.000000. running mean: -19.757425\n","resetting env. episode 867.000000, reward total was -21.000000. running mean: -19.769851\n","resetting env. episode 868.000000, reward total was -21.000000. running mean: -19.782152\n","resetting env. episode 869.000000, reward total was -19.000000. running mean: -19.774331\n","resetting env. episode 870.000000, reward total was -21.000000. running mean: -19.786587\n","resetting env. episode 871.000000, reward total was -19.000000. running mean: -19.778721\n","resetting env. episode 872.000000, reward total was -21.000000. running mean: -19.790934\n","resetting env. episode 873.000000, reward total was -19.000000. running mean: -19.783025\n","resetting env. episode 874.000000, reward total was -21.000000. running mean: -19.795195\n","resetting env. episode 875.000000, reward total was -21.000000. running mean: -19.807243\n","resetting env. episode 876.000000, reward total was -18.000000. running mean: -19.789170\n","resetting env. episode 877.000000, reward total was -20.000000. running mean: -19.791278\n","resetting env. episode 878.000000, reward total was -20.000000. running mean: -19.793366\n","resetting env. episode 879.000000, reward total was -20.000000. running mean: -19.795432\n","resetting env. episode 880.000000, reward total was -18.000000. running mean: -19.777478\n","resetting env. episode 881.000000, reward total was -19.000000. running mean: -19.769703\n","resetting env. episode 882.000000, reward total was -20.000000. running mean: -19.772006\n","resetting env. episode 883.000000, reward total was -20.000000. running mean: -19.774286\n","resetting env. episode 884.000000, reward total was -20.000000. running mean: -19.776543\n","resetting env. episode 885.000000, reward total was -20.000000. running mean: -19.778778\n","resetting env. episode 886.000000, reward total was -17.000000. running mean: -19.750990\n","resetting env. episode 887.000000, reward total was -18.000000. running mean: -19.733480\n","resetting env. episode 888.000000, reward total was -18.000000. running mean: -19.716145\n","resetting env. episode 889.000000, reward total was -21.000000. running mean: -19.728984\n","resetting env. episode 890.000000, reward total was -21.000000. running mean: -19.741694\n","resetting env. episode 891.000000, reward total was -21.000000. running mean: -19.754277\n","resetting env. episode 892.000000, reward total was -18.000000. running mean: -19.736734\n","resetting env. episode 893.000000, reward total was -21.000000. running mean: -19.749367\n","resetting env. episode 894.000000, reward total was -17.000000. running mean: -19.721873\n","resetting env. episode 895.000000, reward total was -21.000000. running mean: -19.734654\n","resetting env. episode 896.000000, reward total was -20.000000. running mean: -19.737308\n","resetting env. episode 897.000000, reward total was -16.000000. running mean: -19.699935\n","resetting env. episode 898.000000, reward total was -19.000000. running mean: -19.692935\n","resetting env. episode 899.000000, reward total was -20.000000. running mean: -19.696006\n","resetting env. episode 900.000000, reward total was -17.000000. running mean: -19.669046\n","resetting env. episode 901.000000, reward total was -20.000000. running mean: -19.672356\n","resetting env. episode 902.000000, reward total was -21.000000. running mean: -19.685632\n","resetting env. episode 903.000000, reward total was -20.000000. running mean: -19.688776\n","resetting env. episode 904.000000, reward total was -20.000000. running mean: -19.691888\n","resetting env. episode 905.000000, reward total was -21.000000. running mean: -19.704969\n","resetting env. episode 906.000000, reward total was -18.000000. running mean: -19.687919\n","resetting env. episode 907.000000, reward total was -21.000000. running mean: -19.701040\n","resetting env. episode 908.000000, reward total was -21.000000. running mean: -19.714030\n","resetting env. episode 909.000000, reward total was -18.000000. running mean: -19.696889\n","resetting env. episode 910.000000, reward total was -21.000000. running mean: -19.709921\n","resetting env. episode 911.000000, reward total was -21.000000. running mean: -19.722821\n","resetting env. episode 912.000000, reward total was -21.000000. running mean: -19.735593\n","resetting env. episode 913.000000, reward total was -21.000000. running mean: -19.748237\n","resetting env. episode 914.000000, reward total was -21.000000. running mean: -19.760755\n","resetting env. episode 915.000000, reward total was -20.000000. running mean: -19.763147\n","resetting env. episode 916.000000, reward total was -19.000000. running mean: -19.755516\n","resetting env. episode 917.000000, reward total was -20.000000. running mean: -19.757961\n","resetting env. episode 918.000000, reward total was -20.000000. running mean: -19.760381\n","resetting env. episode 919.000000, reward total was -20.000000. running mean: -19.762777\n","resetting env. episode 920.000000, reward total was -18.000000. running mean: -19.745149\n","resetting env. episode 921.000000, reward total was -20.000000. running mean: -19.747698\n","resetting env. episode 922.000000, reward total was -20.000000. running mean: -19.750221\n","resetting env. episode 923.000000, reward total was -21.000000. running mean: -19.762719\n","resetting env. episode 924.000000, reward total was -20.000000. running mean: -19.765092\n","resetting env. episode 925.000000, reward total was -18.000000. running mean: -19.747441\n","resetting env. episode 926.000000, reward total was -20.000000. running mean: -19.749966\n","resetting env. episode 927.000000, reward total was -21.000000. running mean: -19.762467\n","resetting env. episode 928.000000, reward total was -19.000000. running mean: -19.754842\n","resetting env. episode 929.000000, reward total was -21.000000. running mean: -19.767294\n","resetting env. episode 930.000000, reward total was -21.000000. running mean: -19.779621\n","resetting env. episode 931.000000, reward total was -19.000000. running mean: -19.771824\n","resetting env. episode 932.000000, reward total was -20.000000. running mean: -19.774106\n","resetting env. episode 933.000000, reward total was -21.000000. running mean: -19.786365\n","resetting env. episode 934.000000, reward total was -21.000000. running mean: -19.798501\n","resetting env. episode 935.000000, reward total was -20.000000. running mean: -19.800516\n","resetting env. episode 936.000000, reward total was -20.000000. running mean: -19.802511\n","resetting env. episode 937.000000, reward total was -20.000000. running mean: -19.804486\n","resetting env. episode 938.000000, reward total was -21.000000. running mean: -19.816441\n","resetting env. episode 939.000000, reward total was -19.000000. running mean: -19.808277\n","resetting env. episode 940.000000, reward total was -21.000000. running mean: -19.820194\n","resetting env. episode 941.000000, reward total was -21.000000. running mean: -19.831992\n","resetting env. episode 942.000000, reward total was -20.000000. running mean: -19.833672\n","resetting env. episode 943.000000, reward total was -20.000000. running mean: -19.835335\n","resetting env. episode 944.000000, reward total was -20.000000. running mean: -19.836982\n","resetting env. episode 945.000000, reward total was -21.000000. running mean: -19.848612\n","resetting env. episode 946.000000, reward total was -21.000000. running mean: -19.860126\n","resetting env. episode 947.000000, reward total was -20.000000. running mean: -19.861525\n","resetting env. episode 948.000000, reward total was -21.000000. running mean: -19.872910\n","resetting env. episode 949.000000, reward total was -20.000000. running mean: -19.874181\n","resetting env. episode 950.000000, reward total was -21.000000. running mean: -19.885439\n","resetting env. episode 951.000000, reward total was -18.000000. running mean: -19.866584\n","resetting env. episode 952.000000, reward total was -21.000000. running mean: -19.877919\n","resetting env. episode 953.000000, reward total was -19.000000. running mean: -19.869139\n","resetting env. episode 954.000000, reward total was -20.000000. running mean: -19.870448\n","resetting env. episode 955.000000, reward total was -20.000000. running mean: -19.871743\n","resetting env. episode 956.000000, reward total was -21.000000. running mean: -19.883026\n","resetting env. episode 957.000000, reward total was -21.000000. running mean: -19.894196\n","resetting env. episode 958.000000, reward total was -19.000000. running mean: -19.885254\n","resetting env. episode 959.000000, reward total was -18.000000. running mean: -19.866401\n","resetting env. episode 960.000000, reward total was -19.000000. running mean: -19.857737\n","resetting env. episode 961.000000, reward total was -20.000000. running mean: -19.859160\n","resetting env. episode 962.000000, reward total was -21.000000. running mean: -19.870568\n","resetting env. episode 963.000000, reward total was -21.000000. running mean: -19.881863\n","resetting env. episode 964.000000, reward total was -19.000000. running mean: -19.873044\n","resetting env. episode 965.000000, reward total was -21.000000. running mean: -19.884314\n","resetting env. episode 966.000000, reward total was -19.000000. running mean: -19.875470\n","resetting env. episode 967.000000, reward total was -19.000000. running mean: -19.866716\n","resetting env. episode 968.000000, reward total was -21.000000. running mean: -19.878049\n","resetting env. episode 969.000000, reward total was -17.000000. running mean: -19.849268\n","resetting env. episode 970.000000, reward total was -20.000000. running mean: -19.850775\n","resetting env. episode 971.000000, reward total was -21.000000. running mean: -19.862268\n","resetting env. episode 972.000000, reward total was -20.000000. running mean: -19.863645\n","resetting env. episode 973.000000, reward total was -20.000000. running mean: -19.865009\n","resetting env. episode 974.000000, reward total was -21.000000. running mean: -19.876358\n","resetting env. episode 975.000000, reward total was -21.000000. running mean: -19.887595\n","resetting env. episode 976.000000, reward total was -19.000000. running mean: -19.878719\n","resetting env. episode 977.000000, reward total was -20.000000. running mean: -19.879932\n","resetting env. episode 978.000000, reward total was -19.000000. running mean: -19.871132\n","resetting env. episode 979.000000, reward total was -19.000000. running mean: -19.862421\n","resetting env. episode 980.000000, reward total was -20.000000. running mean: -19.863797\n","resetting env. episode 981.000000, reward total was -17.000000. running mean: -19.835159\n","resetting env. episode 982.000000, reward total was -20.000000. running mean: -19.836807\n","resetting env. episode 983.000000, reward total was -18.000000. running mean: -19.818439\n","resetting env. episode 984.000000, reward total was -19.000000. running mean: -19.810255\n","resetting env. episode 985.000000, reward total was -20.000000. running mean: -19.812152\n","resetting env. episode 986.000000, reward total was -19.000000. running mean: -19.804031\n","resetting env. episode 987.000000, reward total was -21.000000. running mean: -19.815990\n","resetting env. episode 988.000000, reward total was -21.000000. running mean: -19.827831\n","resetting env. episode 989.000000, reward total was -21.000000. running mean: -19.839552\n","resetting env. episode 990.000000, reward total was -20.000000. running mean: -19.841157\n","resetting env. episode 991.000000, reward total was -18.000000. running mean: -19.822745\n","resetting env. episode 992.000000, reward total was -20.000000. running mean: -19.824518\n","resetting env. episode 993.000000, reward total was -21.000000. running mean: -19.836273\n","resetting env. episode 994.000000, reward total was -21.000000. running mean: -19.847910\n","resetting env. episode 995.000000, reward total was -21.000000. running mean: -19.859431\n","resetting env. episode 996.000000, reward total was -19.000000. running mean: -19.850836\n","resetting env. episode 997.000000, reward total was -21.000000. running mean: -19.862328\n","resetting env. episode 998.000000, reward total was -21.000000. running mean: -19.873705\n","resetting env. episode 999.000000, reward total was -21.000000. running mean: -19.884968\n","resetting env. episode 1000.000000, reward total was -18.000000. running mean: -19.866118\n","resetting env. episode 1001.000000, reward total was -18.000000. running mean: -19.847457\n","resetting env. episode 1002.000000, reward total was -20.000000. running mean: -19.848982\n","resetting env. episode 1003.000000, reward total was -21.000000. running mean: -19.860492\n","resetting env. episode 1004.000000, reward total was -21.000000. running mean: -19.871888\n","resetting env. episode 1005.000000, reward total was -20.000000. running mean: -19.873169\n","resetting env. episode 1006.000000, reward total was -18.000000. running mean: -19.854437\n","resetting env. episode 1007.000000, reward total was -19.000000. running mean: -19.845893\n","resetting env. episode 1008.000000, reward total was -20.000000. running mean: -19.847434\n","resetting env. episode 1009.000000, reward total was -19.000000. running mean: -19.838959\n","resetting env. episode 1010.000000, reward total was -21.000000. running mean: -19.850570\n","resetting env. episode 1011.000000, reward total was -21.000000. running mean: -19.862064\n","resetting env. episode 1012.000000, reward total was -20.000000. running mean: -19.863443\n","resetting env. episode 1013.000000, reward total was -21.000000. running mean: -19.874809\n","resetting env. episode 1014.000000, reward total was -13.000000. running mean: -19.806061\n","resetting env. episode 1015.000000, reward total was -18.000000. running mean: -19.788000\n","resetting env. episode 1016.000000, reward total was -20.000000. running mean: -19.790120\n","resetting env. episode 1017.000000, reward total was -19.000000. running mean: -19.782219\n","resetting env. episode 1018.000000, reward total was -21.000000. running mean: -19.794397\n","resetting env. episode 1019.000000, reward total was -21.000000. running mean: -19.806453\n","resetting env. episode 1020.000000, reward total was -21.000000. running mean: -19.818388\n","resetting env. episode 1021.000000, reward total was -17.000000. running mean: -19.790204\n","resetting env. episode 1022.000000, reward total was -18.000000. running mean: -19.772302\n","resetting env. episode 1023.000000, reward total was -20.000000. running mean: -19.774579\n","resetting env. episode 1024.000000, reward total was -18.000000. running mean: -19.756834\n","resetting env. episode 1025.000000, reward total was -15.000000. running mean: -19.709265\n","resetting env. episode 1026.000000, reward total was -19.000000. running mean: -19.702173\n","resetting env. episode 1027.000000, reward total was -16.000000. running mean: -19.665151\n","resetting env. episode 1028.000000, reward total was -21.000000. running mean: -19.678499\n","resetting env. episode 1029.000000, reward total was -19.000000. running mean: -19.671714\n","resetting env. episode 1030.000000, reward total was -20.000000. running mean: -19.674997\n","resetting env. episode 1031.000000, reward total was -21.000000. running mean: -19.688247\n","resetting env. episode 1032.000000, reward total was -19.000000. running mean: -19.681365\n","resetting env. episode 1033.000000, reward total was -20.000000. running mean: -19.684551\n","resetting env. episode 1034.000000, reward total was -21.000000. running mean: -19.697706\n","resetting env. episode 1035.000000, reward total was -21.000000. running mean: -19.710729\n","resetting env. episode 1036.000000, reward total was -21.000000. running mean: -19.723621\n","resetting env. episode 1037.000000, reward total was -19.000000. running mean: -19.716385\n","resetting env. episode 1038.000000, reward total was -20.000000. running mean: -19.719221\n","resetting env. episode 1039.000000, reward total was -20.000000. running mean: -19.722029\n","resetting env. episode 1040.000000, reward total was -21.000000. running mean: -19.734809\n","resetting env. episode 1041.000000, reward total was -19.000000. running mean: -19.727461\n","resetting env. episode 1042.000000, reward total was -20.000000. running mean: -19.730186\n","resetting env. episode 1043.000000, reward total was -19.000000. running mean: -19.722884\n","resetting env. episode 1044.000000, reward total was -19.000000. running mean: -19.715655\n","resetting env. episode 1045.000000, reward total was -21.000000. running mean: -19.728499\n","resetting env. episode 1046.000000, reward total was -19.000000. running mean: -19.721214\n","resetting env. episode 1047.000000, reward total was -19.000000. running mean: -19.714002\n","resetting env. episode 1048.000000, reward total was -19.000000. running mean: -19.706862\n","resetting env. episode 1049.000000, reward total was -20.000000. running mean: -19.709793\n","resetting env. episode 1050.000000, reward total was -18.000000. running mean: -19.692695\n","resetting env. episode 1051.000000, reward total was -20.000000. running mean: -19.695768\n","resetting env. episode 1052.000000, reward total was -20.000000. running mean: -19.698810\n","resetting env. episode 1053.000000, reward total was -19.000000. running mean: -19.691822\n","resetting env. episode 1054.000000, reward total was -20.000000. running mean: -19.694904\n","resetting env. episode 1055.000000, reward total was -20.000000. running mean: -19.697955\n","resetting env. episode 1056.000000, reward total was -18.000000. running mean: -19.680976\n","resetting env. episode 1057.000000, reward total was -21.000000. running mean: -19.694166\n","resetting env. episode 1058.000000, reward total was -20.000000. running mean: -19.697224\n","resetting env. episode 1059.000000, reward total was -21.000000. running mean: -19.710252\n","resetting env. episode 1060.000000, reward total was -20.000000. running mean: -19.713149\n","resetting env. episode 1061.000000, reward total was -21.000000. running mean: -19.726018\n","resetting env. episode 1062.000000, reward total was -17.000000. running mean: -19.698758\n","resetting env. episode 1063.000000, reward total was -17.000000. running mean: -19.671770\n","resetting env. episode 1064.000000, reward total was -21.000000. running mean: -19.685052\n","resetting env. episode 1065.000000, reward total was -20.000000. running mean: -19.688202\n","resetting env. episode 1066.000000, reward total was -21.000000. running mean: -19.701320\n","resetting env. episode 1067.000000, reward total was -20.000000. running mean: -19.704307\n","resetting env. episode 1068.000000, reward total was -20.000000. running mean: -19.707264\n","resetting env. episode 1069.000000, reward total was -21.000000. running mean: -19.720191\n","resetting env. episode 1070.000000, reward total was -16.000000. running mean: -19.682989\n","resetting env. episode 1071.000000, reward total was -19.000000. running mean: -19.676159\n","resetting env. episode 1072.000000, reward total was -21.000000. running mean: -19.689398\n","resetting env. episode 1073.000000, reward total was -21.000000. running mean: -19.702504\n","resetting env. episode 1074.000000, reward total was -21.000000. running mean: -19.715479\n","resetting env. episode 1075.000000, reward total was -21.000000. running mean: -19.728324\n","resetting env. episode 1076.000000, reward total was -19.000000. running mean: -19.721041\n","resetting env. episode 1077.000000, reward total was -20.000000. running mean: -19.723830\n","resetting env. episode 1078.000000, reward total was -19.000000. running mean: -19.716592\n","resetting env. episode 1079.000000, reward total was -20.000000. running mean: -19.719426\n","resetting env. episode 1080.000000, reward total was -19.000000. running mean: -19.712232\n","resetting env. episode 1081.000000, reward total was -20.000000. running mean: -19.715109\n","resetting env. episode 1082.000000, reward total was -19.000000. running mean: -19.707958\n","resetting env. episode 1083.000000, reward total was -17.000000. running mean: -19.680879\n","resetting env. episode 1084.000000, reward total was -21.000000. running mean: -19.694070\n","resetting env. episode 1085.000000, reward total was -19.000000. running mean: -19.687129\n","resetting env. episode 1086.000000, reward total was -15.000000. running mean: -19.640258\n","resetting env. episode 1087.000000, reward total was -21.000000. running mean: -19.653855\n","resetting env. episode 1088.000000, reward total was -21.000000. running mean: -19.667317\n","resetting env. episode 1089.000000, reward total was -18.000000. running mean: -19.650644\n","resetting env. episode 1090.000000, reward total was -20.000000. running mean: -19.654137\n","resetting env. episode 1091.000000, reward total was -19.000000. running mean: -19.647596\n","resetting env. episode 1092.000000, reward total was -16.000000. running mean: -19.611120\n","resetting env. episode 1093.000000, reward total was -20.000000. running mean: -19.615009\n","resetting env. episode 1094.000000, reward total was -21.000000. running mean: -19.628859\n","resetting env. episode 1095.000000, reward total was -21.000000. running mean: -19.642570\n","resetting env. episode 1096.000000, reward total was -19.000000. running mean: -19.636144\n","resetting env. episode 1097.000000, reward total was -20.000000. running mean: -19.639783\n","resetting env. episode 1098.000000, reward total was -21.000000. running mean: -19.653385\n","resetting env. episode 1099.000000, reward total was -20.000000. running mean: -19.656851\n","resetting env. episode 1100.000000, reward total was -21.000000. running mean: -19.670283\n","resetting env. episode 1101.000000, reward total was -18.000000. running mean: -19.653580\n","resetting env. episode 1102.000000, reward total was -20.000000. running mean: -19.657044\n","resetting env. episode 1103.000000, reward total was -21.000000. running mean: -19.670474\n","resetting env. episode 1104.000000, reward total was -20.000000. running mean: -19.673769\n","resetting env. episode 1105.000000, reward total was -19.000000. running mean: -19.667031\n","resetting env. episode 1106.000000, reward total was -20.000000. running mean: -19.670361\n","resetting env. episode 1107.000000, reward total was -21.000000. running mean: -19.683657\n","resetting env. episode 1108.000000, reward total was -19.000000. running mean: -19.676821\n","resetting env. episode 1109.000000, reward total was -17.000000. running mean: -19.650052\n","resetting env. episode 1110.000000, reward total was -18.000000. running mean: -19.633552\n","resetting env. episode 1111.000000, reward total was -18.000000. running mean: -19.617216\n","resetting env. episode 1112.000000, reward total was -20.000000. running mean: -19.621044\n","resetting env. episode 1113.000000, reward total was -21.000000. running mean: -19.634834\n","resetting env. episode 1114.000000, reward total was -19.000000. running mean: -19.628485\n","resetting env. episode 1115.000000, reward total was -16.000000. running mean: -19.592201\n","resetting env. episode 1116.000000, reward total was -19.000000. running mean: -19.586279\n","resetting env. episode 1117.000000, reward total was -21.000000. running mean: -19.600416\n","resetting env. episode 1118.000000, reward total was -20.000000. running mean: -19.604412\n","resetting env. episode 1119.000000, reward total was -20.000000. running mean: -19.608368\n","resetting env. episode 1120.000000, reward total was -18.000000. running mean: -19.592284\n","resetting env. episode 1121.000000, reward total was -19.000000. running mean: -19.586361\n","resetting env. episode 1122.000000, reward total was -19.000000. running mean: -19.580497\n","resetting env. episode 1123.000000, reward total was -21.000000. running mean: -19.594692\n","resetting env. episode 1124.000000, reward total was -20.000000. running mean: -19.598746\n","resetting env. episode 1125.000000, reward total was -20.000000. running mean: -19.602758\n","resetting env. episode 1126.000000, reward total was -18.000000. running mean: -19.586730\n","resetting env. episode 1127.000000, reward total was -17.000000. running mean: -19.560863\n","resetting env. episode 1128.000000, reward total was -19.000000. running mean: -19.555255\n","resetting env. episode 1129.000000, reward total was -20.000000. running mean: -19.559702\n","resetting env. episode 1130.000000, reward total was -18.000000. running mean: -19.544105\n","resetting env. episode 1131.000000, reward total was -21.000000. running mean: -19.558664\n","resetting env. episode 1132.000000, reward total was -18.000000. running mean: -19.543077\n","resetting env. episode 1133.000000, reward total was -20.000000. running mean: -19.547647\n","resetting env. episode 1134.000000, reward total was -17.000000. running mean: -19.522170\n","resetting env. episode 1135.000000, reward total was -21.000000. running mean: -19.536948\n","resetting env. episode 1136.000000, reward total was -19.000000. running mean: -19.531579\n","resetting env. episode 1137.000000, reward total was -20.000000. running mean: -19.536263\n","resetting env. episode 1138.000000, reward total was -20.000000. running mean: -19.540900\n","resetting env. episode 1139.000000, reward total was -19.000000. running mean: -19.535491\n","resetting env. episode 1140.000000, reward total was -19.000000. running mean: -19.530137\n","resetting env. episode 1141.000000, reward total was -21.000000. running mean: -19.544835\n","resetting env. episode 1142.000000, reward total was -17.000000. running mean: -19.519387\n","resetting env. episode 1143.000000, reward total was -21.000000. running mean: -19.534193\n","resetting env. episode 1144.000000, reward total was -19.000000. running mean: -19.528851\n","resetting env. episode 1145.000000, reward total was -21.000000. running mean: -19.543563\n","resetting env. episode 1146.000000, reward total was -17.000000. running mean: -19.518127\n","resetting env. episode 1147.000000, reward total was -19.000000. running mean: -19.512946\n","resetting env. episode 1148.000000, reward total was -19.000000. running mean: -19.507816\n","resetting env. episode 1149.000000, reward total was -21.000000. running mean: -19.522738\n","resetting env. episode 1150.000000, reward total was -16.000000. running mean: -19.487511\n","resetting env. episode 1151.000000, reward total was -20.000000. running mean: -19.492636\n","resetting env. episode 1152.000000, reward total was -19.000000. running mean: -19.487709\n","resetting env. episode 1153.000000, reward total was -21.000000. running mean: -19.502832\n","resetting env. episode 1154.000000, reward total was -20.000000. running mean: -19.507804\n","resetting env. episode 1155.000000, reward total was -20.000000. running mean: -19.512726\n","resetting env. episode 1156.000000, reward total was -19.000000. running mean: -19.507598\n","resetting env. episode 1157.000000, reward total was -20.000000. running mean: -19.512522\n","resetting env. episode 1158.000000, reward total was -19.000000. running mean: -19.507397\n","resetting env. episode 1159.000000, reward total was -19.000000. running mean: -19.502323\n","resetting env. episode 1160.000000, reward total was -17.000000. running mean: -19.477300\n","resetting env. episode 1161.000000, reward total was -17.000000. running mean: -19.452527\n","resetting env. episode 1162.000000, reward total was -20.000000. running mean: -19.458002\n","resetting env. episode 1163.000000, reward total was -19.000000. running mean: -19.453422\n","resetting env. episode 1164.000000, reward total was -21.000000. running mean: -19.468888\n","resetting env. episode 1165.000000, reward total was -18.000000. running mean: -19.454199\n","resetting env. episode 1166.000000, reward total was -19.000000. running mean: -19.449657\n","resetting env. episode 1167.000000, reward total was -19.000000. running mean: -19.445160\n","resetting env. episode 1168.000000, reward total was -20.000000. running mean: -19.450708\n","resetting env. episode 1169.000000, reward total was -15.000000. running mean: -19.406201\n","resetting env. episode 1170.000000, reward total was -16.000000. running mean: -19.372139\n","resetting env. episode 1171.000000, reward total was -20.000000. running mean: -19.378418\n","resetting env. episode 1172.000000, reward total was -20.000000. running mean: -19.384634\n","resetting env. episode 1173.000000, reward total was -18.000000. running mean: -19.370787\n","resetting env. episode 1174.000000, reward total was -20.000000. running mean: -19.377080\n","resetting env. episode 1175.000000, reward total was -18.000000. running mean: -19.363309\n","resetting env. episode 1176.000000, reward total was -19.000000. running mean: -19.359676\n","resetting env. episode 1177.000000, reward total was -21.000000. running mean: -19.376079\n","resetting env. episode 1178.000000, reward total was -21.000000. running mean: -19.392318\n","resetting env. episode 1179.000000, reward total was -21.000000. running mean: -19.408395\n","resetting env. episode 1180.000000, reward total was -21.000000. running mean: -19.424311\n","resetting env. episode 1181.000000, reward total was -20.000000. running mean: -19.430068\n","resetting env. episode 1182.000000, reward total was -20.000000. running mean: -19.435767\n","resetting env. episode 1183.000000, reward total was -19.000000. running mean: -19.431410\n","resetting env. episode 1184.000000, reward total was -19.000000. running mean: -19.427095\n","resetting env. episode 1185.000000, reward total was -21.000000. running mean: -19.442825\n","resetting env. episode 1186.000000, reward total was -21.000000. running mean: -19.458396\n","resetting env. episode 1187.000000, reward total was -21.000000. running mean: -19.473812\n","resetting env. episode 1188.000000, reward total was -20.000000. running mean: -19.479074\n","resetting env. episode 1189.000000, reward total was -20.000000. running mean: -19.484283\n","resetting env. episode 1190.000000, reward total was -21.000000. running mean: -19.499441\n","resetting env. episode 1191.000000, reward total was -21.000000. running mean: -19.514446\n","resetting env. episode 1192.000000, reward total was -18.000000. running mean: -19.499302\n","resetting env. episode 1193.000000, reward total was -20.000000. running mean: -19.504309\n","resetting env. episode 1194.000000, reward total was -18.000000. running mean: -19.489266\n","resetting env. episode 1195.000000, reward total was -21.000000. running mean: -19.504373\n","resetting env. episode 1196.000000, reward total was -20.000000. running mean: -19.509329\n","resetting env. episode 1197.000000, reward total was -18.000000. running mean: -19.494236\n","resetting env. episode 1198.000000, reward total was -21.000000. running mean: -19.509294\n","resetting env. episode 1199.000000, reward total was -20.000000. running mean: -19.514201\n","resetting env. episode 1200.000000, reward total was -20.000000. running mean: -19.519059\n","resetting env. episode 1201.000000, reward total was -19.000000. running mean: -19.513868\n","resetting env. episode 1202.000000, reward total was -19.000000. running mean: -19.508729\n","resetting env. episode 1203.000000, reward total was -18.000000. running mean: -19.493642\n","resetting env. episode 1204.000000, reward total was -21.000000. running mean: -19.508706\n","resetting env. episode 1205.000000, reward total was -20.000000. running mean: -19.513619\n","resetting env. episode 1206.000000, reward total was -19.000000. running mean: -19.508482\n","resetting env. episode 1207.000000, reward total was -20.000000. running mean: -19.513398\n","resetting env. episode 1208.000000, reward total was -20.000000. running mean: -19.518264\n","resetting env. episode 1209.000000, reward total was -21.000000. running mean: -19.533081\n","resetting env. episode 1210.000000, reward total was -20.000000. running mean: -19.537750\n","resetting env. episode 1211.000000, reward total was -19.000000. running mean: -19.532373\n","resetting env. episode 1212.000000, reward total was -21.000000. running mean: -19.547049\n","resetting env. episode 1213.000000, reward total was -21.000000. running mean: -19.561578\n","resetting env. episode 1214.000000, reward total was -20.000000. running mean: -19.565963\n","resetting env. episode 1215.000000, reward total was -20.000000. running mean: -19.570303\n","resetting env. episode 1216.000000, reward total was -19.000000. running mean: -19.564600\n","resetting env. episode 1217.000000, reward total was -21.000000. running mean: -19.578954\n","resetting env. episode 1218.000000, reward total was -20.000000. running mean: -19.583164\n","resetting env. episode 1219.000000, reward total was -18.000000. running mean: -19.567333\n","resetting env. episode 1220.000000, reward total was -20.000000. running mean: -19.571660\n","resetting env. episode 1221.000000, reward total was -18.000000. running mean: -19.555943\n","resetting env. episode 1222.000000, reward total was -19.000000. running mean: -19.550383\n","resetting env. episode 1223.000000, reward total was -19.000000. running mean: -19.544880\n","resetting env. episode 1224.000000, reward total was -19.000000. running mean: -19.539431\n","resetting env. episode 1225.000000, reward total was -19.000000. running mean: -19.534037\n","resetting env. episode 1226.000000, reward total was -19.000000. running mean: -19.528696\n","resetting env. episode 1227.000000, reward total was -21.000000. running mean: -19.543409\n","resetting env. episode 1228.000000, reward total was -21.000000. running mean: -19.557975\n","resetting env. episode 1229.000000, reward total was -21.000000. running mean: -19.572395\n","resetting env. episode 1230.000000, reward total was -19.000000. running mean: -19.566671\n","resetting env. episode 1231.000000, reward total was -18.000000. running mean: -19.551005\n","resetting env. episode 1232.000000, reward total was -19.000000. running mean: -19.545495\n","resetting env. episode 1233.000000, reward total was -20.000000. running mean: -19.550040\n","resetting env. episode 1234.000000, reward total was -19.000000. running mean: -19.544539\n","resetting env. episode 1235.000000, reward total was -19.000000. running mean: -19.539094\n","resetting env. episode 1236.000000, reward total was -19.000000. running mean: -19.533703\n","resetting env. episode 1237.000000, reward total was -18.000000. running mean: -19.518366\n","resetting env. episode 1238.000000, reward total was -21.000000. running mean: -19.533182\n","resetting env. episode 1239.000000, reward total was -21.000000. running mean: -19.547850\n","resetting env. episode 1240.000000, reward total was -19.000000. running mean: -19.542372\n","resetting env. episode 1241.000000, reward total was -19.000000. running mean: -19.536948\n","resetting env. episode 1242.000000, reward total was -21.000000. running mean: -19.551579\n","resetting env. episode 1243.000000, reward total was -19.000000. running mean: -19.546063\n","resetting env. episode 1244.000000, reward total was -16.000000. running mean: -19.510602\n","resetting env. episode 1245.000000, reward total was -21.000000. running mean: -19.525496\n","resetting env. episode 1246.000000, reward total was -16.000000. running mean: -19.490241\n","resetting env. episode 1247.000000, reward total was -21.000000. running mean: -19.505339\n","resetting env. episode 1248.000000, reward total was -21.000000. running mean: -19.520286\n","resetting env. episode 1249.000000, reward total was -21.000000. running mean: -19.535083\n","resetting env. episode 1250.000000, reward total was -21.000000. running mean: -19.549732\n","resetting env. episode 1251.000000, reward total was -18.000000. running mean: -19.534235\n","resetting env. episode 1252.000000, reward total was -19.000000. running mean: -19.528892\n","resetting env. episode 1253.000000, reward total was -21.000000. running mean: -19.543603\n","resetting env. episode 1254.000000, reward total was -21.000000. running mean: -19.558167\n","resetting env. episode 1255.000000, reward total was -20.000000. running mean: -19.562586\n","resetting env. episode 1256.000000, reward total was -20.000000. running mean: -19.566960\n","resetting env. episode 1257.000000, reward total was -19.000000. running mean: -19.561290\n","resetting env. episode 1258.000000, reward total was -13.000000. running mean: -19.495677\n","resetting env. episode 1259.000000, reward total was -20.000000. running mean: -19.500720\n","resetting env. episode 1260.000000, reward total was -16.000000. running mean: -19.465713\n","resetting env. episode 1261.000000, reward total was -21.000000. running mean: -19.481056\n","resetting env. episode 1262.000000, reward total was -19.000000. running mean: -19.476246\n","resetting env. episode 1263.000000, reward total was -19.000000. running mean: -19.471483\n","resetting env. episode 1264.000000, reward total was -19.000000. running mean: -19.466768\n","resetting env. episode 1265.000000, reward total was -19.000000. running mean: -19.462101\n","resetting env. episode 1266.000000, reward total was -18.000000. running mean: -19.447480\n","resetting env. episode 1267.000000, reward total was -17.000000. running mean: -19.423005\n","resetting env. episode 1268.000000, reward total was -21.000000. running mean: -19.438775\n","resetting env. episode 1269.000000, reward total was -21.000000. running mean: -19.454387\n","resetting env. episode 1270.000000, reward total was -20.000000. running mean: -19.459843\n","resetting env. episode 1271.000000, reward total was -21.000000. running mean: -19.475245\n","resetting env. episode 1272.000000, reward total was -18.000000. running mean: -19.460492\n","resetting env. episode 1273.000000, reward total was -21.000000. running mean: -19.475887\n","resetting env. episode 1274.000000, reward total was -17.000000. running mean: -19.451128\n","resetting env. episode 1275.000000, reward total was -21.000000. running mean: -19.466617\n","resetting env. episode 1276.000000, reward total was -19.000000. running mean: -19.461951\n","resetting env. episode 1277.000000, reward total was -21.000000. running mean: -19.477331\n","resetting env. episode 1278.000000, reward total was -21.000000. running mean: -19.492558\n","resetting env. episode 1279.000000, reward total was -19.000000. running mean: -19.487633\n","resetting env. episode 1280.000000, reward total was -18.000000. running mean: -19.472756\n","resetting env. episode 1281.000000, reward total was -18.000000. running mean: -19.458029\n","resetting env. episode 1282.000000, reward total was -21.000000. running mean: -19.473448\n","resetting env. episode 1283.000000, reward total was -19.000000. running mean: -19.468714\n","resetting env. episode 1284.000000, reward total was -19.000000. running mean: -19.464027\n","resetting env. episode 1285.000000, reward total was -21.000000. running mean: -19.479387\n","resetting env. episode 1286.000000, reward total was -19.000000. running mean: -19.474593\n","resetting env. episode 1287.000000, reward total was -19.000000. running mean: -19.469847\n","resetting env. episode 1288.000000, reward total was -19.000000. running mean: -19.465148\n","resetting env. episode 1289.000000, reward total was -21.000000. running mean: -19.480497\n","resetting env. episode 1290.000000, reward total was -18.000000. running mean: -19.465692\n","resetting env. episode 1291.000000, reward total was -21.000000. running mean: -19.481035\n","resetting env. episode 1292.000000, reward total was -18.000000. running mean: -19.466225\n","resetting env. episode 1293.000000, reward total was -20.000000. running mean: -19.471562\n","resetting env. episode 1294.000000, reward total was -17.000000. running mean: -19.446847\n","resetting env. episode 1295.000000, reward total was -20.000000. running mean: -19.452378\n","resetting env. episode 1296.000000, reward total was -19.000000. running mean: -19.447854\n","resetting env. episode 1297.000000, reward total was -19.000000. running mean: -19.443376\n","resetting env. episode 1298.000000, reward total was -20.000000. running mean: -19.448942\n","resetting env. episode 1299.000000, reward total was -18.000000. running mean: -19.434453\n","resetting env. episode 1300.000000, reward total was -19.000000. running mean: -19.430108\n","resetting env. episode 1301.000000, reward total was -20.000000. running mean: -19.435807\n","resetting env. episode 1302.000000, reward total was -19.000000. running mean: -19.431449\n","resetting env. episode 1303.000000, reward total was -16.000000. running mean: -19.397135\n","resetting env. episode 1304.000000, reward total was -19.000000. running mean: -19.393163\n","resetting env. episode 1305.000000, reward total was -20.000000. running mean: -19.399232\n","resetting env. episode 1306.000000, reward total was -18.000000. running mean: -19.385239\n","resetting env. episode 1307.000000, reward total was -18.000000. running mean: -19.371387\n","resetting env. episode 1308.000000, reward total was -21.000000. running mean: -19.387673\n","resetting env. episode 1309.000000, reward total was -21.000000. running mean: -19.403796\n","resetting env. episode 1310.000000, reward total was -17.000000. running mean: -19.379758\n","resetting env. episode 1311.000000, reward total was -20.000000. running mean: -19.385961\n","resetting env. episode 1312.000000, reward total was -19.000000. running mean: -19.382101\n","resetting env. episode 1313.000000, reward total was -20.000000. running mean: -19.388280\n","resetting env. episode 1314.000000, reward total was -20.000000. running mean: -19.394397\n","resetting env. episode 1315.000000, reward total was -19.000000. running mean: -19.390453\n","resetting env. episode 1316.000000, reward total was -21.000000. running mean: -19.406549\n","resetting env. episode 1317.000000, reward total was -19.000000. running mean: -19.402483\n","resetting env. episode 1318.000000, reward total was -19.000000. running mean: -19.398458\n","resetting env. episode 1319.000000, reward total was -18.000000. running mean: -19.384474\n","resetting env. episode 1320.000000, reward total was -20.000000. running mean: -19.390629\n","resetting env. episode 1321.000000, reward total was -19.000000. running mean: -19.386723\n","resetting env. episode 1322.000000, reward total was -19.000000. running mean: -19.382856\n","resetting env. episode 1323.000000, reward total was -19.000000. running mean: -19.379027\n","resetting env. episode 1324.000000, reward total was -20.000000. running mean: -19.385237\n","resetting env. episode 1325.000000, reward total was -21.000000. running mean: -19.401384\n","resetting env. episode 1326.000000, reward total was -21.000000. running mean: -19.417371\n","resetting env. episode 1327.000000, reward total was -19.000000. running mean: -19.413197\n","resetting env. episode 1328.000000, reward total was -20.000000. running mean: -19.419065\n","resetting env. episode 1329.000000, reward total was -18.000000. running mean: -19.404874\n","resetting env. episode 1330.000000, reward total was -20.000000. running mean: -19.410826\n","resetting env. episode 1331.000000, reward total was -21.000000. running mean: -19.426717\n","resetting env. episode 1332.000000, reward total was -19.000000. running mean: -19.422450\n","resetting env. episode 1333.000000, reward total was -21.000000. running mean: -19.438226\n","resetting env. episode 1334.000000, reward total was -20.000000. running mean: -19.443843\n","resetting env. episode 1335.000000, reward total was -20.000000. running mean: -19.449405\n","resetting env. episode 1336.000000, reward total was -20.000000. running mean: -19.454911\n","resetting env. episode 1337.000000, reward total was -20.000000. running mean: -19.460362\n","resetting env. episode 1338.000000, reward total was -19.000000. running mean: -19.455758\n","resetting env. episode 1339.000000, reward total was -21.000000. running mean: -19.471201\n","resetting env. episode 1340.000000, reward total was -20.000000. running mean: -19.476489\n","resetting env. episode 1341.000000, reward total was -21.000000. running mean: -19.491724\n","resetting env. episode 1342.000000, reward total was -20.000000. running mean: -19.496806\n","resetting env. episode 1343.000000, reward total was -19.000000. running mean: -19.491838\n","resetting env. episode 1344.000000, reward total was -20.000000. running mean: -19.496920\n","resetting env. episode 1345.000000, reward total was -18.000000. running mean: -19.481951\n","resetting env. episode 1346.000000, reward total was -18.000000. running mean: -19.467131\n","resetting env. episode 1347.000000, reward total was -20.000000. running mean: -19.472460\n","resetting env. episode 1348.000000, reward total was -20.000000. running mean: -19.477735\n","resetting env. episode 1349.000000, reward total was -19.000000. running mean: -19.472958\n","resetting env. episode 1350.000000, reward total was -21.000000. running mean: -19.488228\n","resetting env. episode 1351.000000, reward total was -15.000000. running mean: -19.443346\n","resetting env. episode 1352.000000, reward total was -19.000000. running mean: -19.438913\n","resetting env. episode 1353.000000, reward total was -19.000000. running mean: -19.434524\n","resetting env. episode 1354.000000, reward total was -21.000000. running mean: -19.450178\n","resetting env. episode 1355.000000, reward total was -20.000000. running mean: -19.455677\n","resetting env. episode 1356.000000, reward total was -20.000000. running mean: -19.461120\n","resetting env. episode 1357.000000, reward total was -18.000000. running mean: -19.446509\n","resetting env. episode 1358.000000, reward total was -20.000000. running mean: -19.452043\n","resetting env. episode 1359.000000, reward total was -21.000000. running mean: -19.467523\n","resetting env. episode 1360.000000, reward total was -16.000000. running mean: -19.432848\n","resetting env. episode 1361.000000, reward total was -21.000000. running mean: -19.448519\n","resetting env. episode 1362.000000, reward total was -19.000000. running mean: -19.444034\n","resetting env. episode 1363.000000, reward total was -21.000000. running mean: -19.459594\n","resetting env. episode 1364.000000, reward total was -20.000000. running mean: -19.464998\n","resetting env. episode 1365.000000, reward total was -19.000000. running mean: -19.460348\n","resetting env. episode 1366.000000, reward total was -19.000000. running mean: -19.455744\n","resetting env. episode 1367.000000, reward total was -19.000000. running mean: -19.451187\n","resetting env. episode 1368.000000, reward total was -20.000000. running mean: -19.456675\n","resetting env. episode 1369.000000, reward total was -17.000000. running mean: -19.432108\n","resetting env. episode 1370.000000, reward total was -21.000000. running mean: -19.447787\n","resetting env. episode 1371.000000, reward total was -19.000000. running mean: -19.443309\n","resetting env. episode 1372.000000, reward total was -19.000000. running mean: -19.438876\n","resetting env. episode 1373.000000, reward total was -18.000000. running mean: -19.424488\n","resetting env. episode 1374.000000, reward total was -19.000000. running mean: -19.420243\n","resetting env. episode 1375.000000, reward total was -19.000000. running mean: -19.416040\n","resetting env. episode 1376.000000, reward total was -20.000000. running mean: -19.421880\n","resetting env. episode 1377.000000, reward total was -20.000000. running mean: -19.427661\n","resetting env. episode 1378.000000, reward total was -18.000000. running mean: -19.413384\n","resetting env. episode 1379.000000, reward total was -17.000000. running mean: -19.389251\n","resetting env. episode 1380.000000, reward total was -20.000000. running mean: -19.395358\n","resetting env. episode 1381.000000, reward total was -21.000000. running mean: -19.411404\n","resetting env. episode 1382.000000, reward total was -19.000000. running mean: -19.407290\n","resetting env. episode 1383.000000, reward total was -19.000000. running mean: -19.403218\n","resetting env. episode 1384.000000, reward total was -21.000000. running mean: -19.419185\n","resetting env. episode 1385.000000, reward total was -17.000000. running mean: -19.394994\n","resetting env. episode 1386.000000, reward total was -18.000000. running mean: -19.381044\n","resetting env. episode 1387.000000, reward total was -19.000000. running mean: -19.377233\n","resetting env. episode 1388.000000, reward total was -20.000000. running mean: -19.383461\n","resetting env. episode 1389.000000, reward total was -19.000000. running mean: -19.379626\n","resetting env. episode 1390.000000, reward total was -21.000000. running mean: -19.395830\n","resetting env. episode 1391.000000, reward total was -19.000000. running mean: -19.391872\n","resetting env. episode 1392.000000, reward total was -20.000000. running mean: -19.397953\n","resetting env. episode 1393.000000, reward total was -19.000000. running mean: -19.393973\n","resetting env. episode 1394.000000, reward total was -18.000000. running mean: -19.380034\n","resetting env. episode 1395.000000, reward total was -17.000000. running mean: -19.356233\n","resetting env. episode 1396.000000, reward total was -20.000000. running mean: -19.362671\n","resetting env. episode 1397.000000, reward total was -20.000000. running mean: -19.369044\n","resetting env. episode 1398.000000, reward total was -19.000000. running mean: -19.365354\n","resetting env. episode 1399.000000, reward total was -19.000000. running mean: -19.361700\n","resetting env. episode 1400.000000, reward total was -16.000000. running mean: -19.328083\n","resetting env. episode 1401.000000, reward total was -21.000000. running mean: -19.344802\n","resetting env. episode 1402.000000, reward total was -21.000000. running mean: -19.361354\n","resetting env. episode 1403.000000, reward total was -18.000000. running mean: -19.347741\n","resetting env. episode 1404.000000, reward total was -20.000000. running mean: -19.354263\n","resetting env. episode 1405.000000, reward total was -18.000000. running mean: -19.340721\n","resetting env. episode 1406.000000, reward total was -21.000000. running mean: -19.357314\n","resetting env. episode 1407.000000, reward total was -21.000000. running mean: -19.373740\n","resetting env. episode 1408.000000, reward total was -19.000000. running mean: -19.370003\n","resetting env. episode 1409.000000, reward total was -21.000000. running mean: -19.386303\n","resetting env. episode 1410.000000, reward total was -20.000000. running mean: -19.392440\n","resetting env. episode 1411.000000, reward total was -21.000000. running mean: -19.408516\n","resetting env. episode 1412.000000, reward total was -17.000000. running mean: -19.384430\n","resetting env. episode 1413.000000, reward total was -18.000000. running mean: -19.370586\n","resetting env. episode 1414.000000, reward total was -17.000000. running mean: -19.346880\n","resetting env. episode 1415.000000, reward total was -16.000000. running mean: -19.313412\n","resetting env. episode 1416.000000, reward total was -19.000000. running mean: -19.310277\n","resetting env. episode 1417.000000, reward total was -19.000000. running mean: -19.307175\n","resetting env. episode 1418.000000, reward total was -21.000000. running mean: -19.324103\n","resetting env. episode 1419.000000, reward total was -21.000000. running mean: -19.340862\n","resetting env. episode 1420.000000, reward total was -19.000000. running mean: -19.337453\n","resetting env. episode 1421.000000, reward total was -21.000000. running mean: -19.354079\n","resetting env. episode 1422.000000, reward total was -20.000000. running mean: -19.360538\n","resetting env. episode 1423.000000, reward total was -20.000000. running mean: -19.366933\n","resetting env. episode 1424.000000, reward total was -20.000000. running mean: -19.373263\n","resetting env. episode 1425.000000, reward total was -21.000000. running mean: -19.389531\n","resetting env. episode 1426.000000, reward total was -20.000000. running mean: -19.395635\n","resetting env. episode 1427.000000, reward total was -21.000000. running mean: -19.411679\n","resetting env. episode 1428.000000, reward total was -20.000000. running mean: -19.417562\n","resetting env. episode 1429.000000, reward total was -19.000000. running mean: -19.413386\n","resetting env. episode 1430.000000, reward total was -20.000000. running mean: -19.419253\n","resetting env. episode 1431.000000, reward total was -19.000000. running mean: -19.415060\n","resetting env. episode 1432.000000, reward total was -21.000000. running mean: -19.430910\n","resetting env. episode 1433.000000, reward total was -19.000000. running mean: -19.426600\n","resetting env. episode 1434.000000, reward total was -20.000000. running mean: -19.432334\n","resetting env. episode 1435.000000, reward total was -21.000000. running mean: -19.448011\n","resetting env. episode 1436.000000, reward total was -20.000000. running mean: -19.453531\n","resetting env. episode 1437.000000, reward total was -20.000000. running mean: -19.458996\n","resetting env. episode 1438.000000, reward total was -20.000000. running mean: -19.464406\n","resetting env. episode 1439.000000, reward total was -20.000000. running mean: -19.469762\n","resetting env. episode 1440.000000, reward total was -19.000000. running mean: -19.465064\n","resetting env. episode 1441.000000, reward total was -19.000000. running mean: -19.460413\n","resetting env. episode 1442.000000, reward total was -18.000000. running mean: -19.445809\n","resetting env. episode 1443.000000, reward total was -19.000000. running mean: -19.441351\n","resetting env. episode 1444.000000, reward total was -21.000000. running mean: -19.456938\n","resetting env. episode 1445.000000, reward total was -19.000000. running mean: -19.452368\n","resetting env. episode 1446.000000, reward total was -18.000000. running mean: -19.437845\n","resetting env. episode 1447.000000, reward total was -19.000000. running mean: -19.433466\n","resetting env. episode 1448.000000, reward total was -19.000000. running mean: -19.429131\n","resetting env. episode 1449.000000, reward total was -21.000000. running mean: -19.444840\n","resetting env. episode 1450.000000, reward total was -21.000000. running mean: -19.460392\n","resetting env. episode 1451.000000, reward total was -16.000000. running mean: -19.425788\n","resetting env. episode 1452.000000, reward total was -18.000000. running mean: -19.411530\n","resetting env. episode 1453.000000, reward total was -21.000000. running mean: -19.427415\n","resetting env. episode 1454.000000, reward total was -18.000000. running mean: -19.413141\n","resetting env. episode 1455.000000, reward total was -19.000000. running mean: -19.409009\n","resetting env. episode 1456.000000, reward total was -20.000000. running mean: -19.414919\n","resetting env. episode 1457.000000, reward total was -20.000000. running mean: -19.420770\n","resetting env. episode 1458.000000, reward total was -21.000000. running mean: -19.436562\n","resetting env. episode 1459.000000, reward total was -21.000000. running mean: -19.452197\n","resetting env. episode 1460.000000, reward total was -21.000000. running mean: -19.467675\n","resetting env. episode 1461.000000, reward total was -19.000000. running mean: -19.462998\n","resetting env. episode 1462.000000, reward total was -17.000000. running mean: -19.438368\n","resetting env. episode 1463.000000, reward total was -21.000000. running mean: -19.453984\n","resetting env. episode 1464.000000, reward total was -18.000000. running mean: -19.439444\n","resetting env. episode 1465.000000, reward total was -21.000000. running mean: -19.455050\n","resetting env. episode 1466.000000, reward total was -21.000000. running mean: -19.470499\n","resetting env. episode 1467.000000, reward total was -21.000000. running mean: -19.485794\n","resetting env. episode 1468.000000, reward total was -20.000000. running mean: -19.490936\n","resetting env. episode 1469.000000, reward total was -19.000000. running mean: -19.486027\n","resetting env. episode 1470.000000, reward total was -21.000000. running mean: -19.501167\n","resetting env. episode 1471.000000, reward total was -21.000000. running mean: -19.516155\n","resetting env. episode 1472.000000, reward total was -18.000000. running mean: -19.500994\n","resetting env. episode 1473.000000, reward total was -20.000000. running mean: -19.505984\n","resetting env. episode 1474.000000, reward total was -20.000000. running mean: -19.510924\n","resetting env. episode 1475.000000, reward total was -20.000000. running mean: -19.515815\n","resetting env. episode 1476.000000, reward total was -20.000000. running mean: -19.520656\n","resetting env. episode 1477.000000, reward total was -20.000000. running mean: -19.525450\n","resetting env. episode 1478.000000, reward total was -21.000000. running mean: -19.540195\n","resetting env. episode 1479.000000, reward total was -19.000000. running mean: -19.534793\n","resetting env. episode 1480.000000, reward total was -19.000000. running mean: -19.529445\n","resetting env. episode 1481.000000, reward total was -21.000000. running mean: -19.544151\n","resetting env. episode 1482.000000, reward total was -21.000000. running mean: -19.558709\n","resetting env. episode 1483.000000, reward total was -21.000000. running mean: -19.573122\n","resetting env. episode 1484.000000, reward total was -17.000000. running mean: -19.547391\n","resetting env. episode 1485.000000, reward total was -21.000000. running mean: -19.561917\n","resetting env. episode 1486.000000, reward total was -20.000000. running mean: -19.566298\n","resetting env. episode 1487.000000, reward total was -19.000000. running mean: -19.560635\n","resetting env. episode 1488.000000, reward total was -20.000000. running mean: -19.565029\n","resetting env. episode 1489.000000, reward total was -21.000000. running mean: -19.579378\n","resetting env. episode 1490.000000, reward total was -18.000000. running mean: -19.563585\n","resetting env. episode 1491.000000, reward total was -20.000000. running mean: -19.567949\n","resetting env. episode 1492.000000, reward total was -20.000000. running mean: -19.572269\n","resetting env. episode 1493.000000, reward total was -21.000000. running mean: -19.586547\n","resetting env. episode 1494.000000, reward total was -19.000000. running mean: -19.580681\n","resetting env. episode 1495.000000, reward total was -17.000000. running mean: -19.554874\n","resetting env. episode 1496.000000, reward total was -19.000000. running mean: -19.549326\n","resetting env. episode 1497.000000, reward total was -21.000000. running mean: -19.563832\n","resetting env. episode 1498.000000, reward total was -20.000000. running mean: -19.568194\n","resetting env. episode 1499.000000, reward total was -18.000000. running mean: -19.552512\n","resetting env. episode 1500.000000, reward total was -20.000000. running mean: -19.556987\n","CPU times: user 5h 8min 25s, sys: 49min 45s, total: 5h 58min 10s\n","Wall time: 3h 4min 30s\n"]}]},{"metadata":{"id":"w2NblmwDsL3y","outputId":"b1e8957d-3b9a-48cd-d208-14e3319e58dc","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"ok","timestamp":1660732110506,"user_tz":-330,"elapsed":37114,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":20,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -5.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQ4AAAFZCAYAAABpOsHqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAHFElEQVR4nO3dTYudZx3A4fvExExm0uZl8qJDNRsTirgU0UVBcGM/hrhyIV36CbpwI+jOTyD4BbpyaTciKKWiBRWS4CSS90kyk5jkuFGxOanM75jmOUmva3nP3MwfZvjxPDfznGc2n88HQHFg6gGAl49wAJlwAJlwAJlwAJlwAJlwAJlwAJlwAJlwAJlwAJlwAJlwANnBZTd+9ytH9v1Y7YHZGG+dOzzWD61+pzaPHxvHjr62sH7jzu1x687OBBPxouy8cXLsvLG5sH70bzfH6xevTTDRp++d927Mltm3dDjePn9k2a0rbfP48XFua2vxCxeHcLzi7nxpc2x/68LC+tnf/PmVDceyVv8SAFg5wgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkwgFkS//L+WfNaxvr44unT+/7++/v7o7bd+9+ihPBdIRjn85sbo4zm4sPQH2Sy1euCgevLLcqQCYcQCYcQCYcQOZwdJ/u3r8/7u3uLqxvrB0ZRzfWJ5gIpiMc+3T12vXxl8uXF9bPbW2NCxvnJpgIpuNWBciEA8iEA8iEA8gcju7TkbXD4+SxYwvr62trE0wD0xKOfdo6c2ZsnTkz9RiwEtyqAJlwAJlwAJlwAJnD0afsPXg4bu/8/y+X3n2w9xym4UX6/N29sbF9a3F9x+/yacLxlIvb2+Pi9vbUYzCBUx9cGqc+uDT1GC8F4YB/mU09wEvEGQeQCQeQLX2r8tYPf/Y85wBeIrP5fL7UxuvXry+3EVgZm5ubSx3tuFUBMuEAMuEAMuEAMuEAMuEAMuEAMuEAMuEAMuEAMuEAMuEAMuEAsqUfq//dL3/yPOcAJvCdH7y71L6lH6v/6dsnPVYPL7l33rvhsXrgxRAOIBMOIBMOIBMOIBMOIBMOIPMKSJjYw6Nr4+b5LyysH7r3YJz4aHslX00pHDCxvRMb49K3vzrG7OOJ2Ni+NU58tJovQHerAmTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWTCAWRejwAT+9zDR2Pjyu2F9bXrOxNMsz/CARNbv3p7vPmLXz/za6v4MqYxhAMmt6px+F+ccQCZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcACZcADZwakH+CTra2vjwIHFru3u7Y3HT55MMBEvytGzXx6HDm+MMcbY+fvF8Wjv3sQT8bSVDcfXzp8frx/dWFj/7Yd/GDfv3JlgIl6Ub37/3XH2zW+MMcb41Y+/N658+P7EE/G0lQ3HbDbGbDb72Np8Pp9oGl6k2Ww2Zv++2nzqb4DV4IwDyIQDyIQDyFb2jIPPrvs3row7238dY4zx+MHuxNPwLMLBynn/5z/6z6Ho/PHjiafhWYSDlTN/IharzhkHkAkHkAkHkAkHkAkHkAkHkAkHkAkHkAkHkAkHkAkHkAkHkAkHkAkHkAkHkK3s53E8fvJkPHrGh7j4pHOY3sqG4/d//NPC6xHGGOMfjx5NMA3w31Y2HAIBq8sZB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AdXHbj6Qtff55zAC+R2Xw+X2rjtWvXltsIrIxTp07Nltm39BXHbLbUzwNeAc44gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gGzp96oAn12uOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIDsn2F+v5YIgwtEAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}}]}]}