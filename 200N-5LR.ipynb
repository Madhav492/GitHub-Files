{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"200N-5LR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"cWACPRL869I4","executionInfo":{"status":"ok","timestamp":1660755798897,"user_tz":-330,"elapsed":3871,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install gym >/dev/null"],"execution_count":1,"outputs":[]},{"metadata":{"id":"2Os6feRY6ec_","executionInfo":{"status":"ok","timestamp":1660755803876,"user_tz":-330,"elapsed":4987,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install JSAnimation >/dev/null"],"execution_count":2,"outputs":[]},{"metadata":{"id":"wotUOa_e6edP","executionInfo":{"status":"ok","timestamp":1660755803877,"user_tz":-330,"elapsed":10,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%matplotlib inline\n","from JSAnimation.IPython_display import display_animation\n","from matplotlib import animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","\n","def display_frames_as_gif(frames):\n","    \"\"\"\n","    Displays a list of frames as a gif, with controls\n","    \"\"\"\n","    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","\n","    def animate(i):\n","        patch.set_data(frames[i])\n","\n","    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n","    HTML(anim.to_jshtml())"],"execution_count":3,"outputs":[]},{"metadata":{"id":"R66_INeZ9nYX"},"cell_type":"markdown","source":["## Step 2: Playing Pong"]},{"cell_type":"code","source":["%pip install -U gym>=0.21.0\n","%pip install -U gym[atari,accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ngMhg3fB9aA","outputId":"c308f098-b5c5-454c-d755-96130e24329f","executionInfo":{"status":"ok","timestamp":1660755836168,"user_tz":-330,"elapsed":32300,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 30.4 MB/s \n","\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=d8ca6943a871de53ff7fffe133691edc8b36013048491a9a4637a5c2d9649370\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"]}]},{"metadata":{"id":"MtT2GyK_6edc","outputId":"4479742b-1b14-4cf8-a4ec-86d292e5112b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660755837442,"user_tz":-330,"elapsed":1292,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import gym\n","env = gym.make('Pong-v0')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  f\"The environment {id} is out of date. You should consider \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}]},{"metadata":{"id":"oRE6WmXQJ1Z0","outputId":"185aa716-2343-4b2d-821c-ddadd9e7d677","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660755837443,"user_tz":-330,"elapsed":14,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.action_space"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(6)"]},"metadata":{},"execution_count":6}]},{"metadata":{"id":"yl_9d4HFJ31W","outputId":"1b9a57a2-b93f-4f92-ab00-d2cac05823de","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660755837444,"user_tz":-330,"elapsed":12,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.observation_space"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box(0, 255, (210, 160, 3), uint8)"]},"metadata":{},"execution_count":7}]},{"metadata":{"id":"trwRXI-h6eeI","outputId":"18ccd221-3a0f-4877-e6be-4b5a5595c974","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660755838080,"user_tz":-330,"elapsed":646,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# Run a demo of the environment\n","observation = env.reset()\n","cumulated_reward = 0\n","\n","frames = []\n","for t in range(1000):\n","#     print(observation)\n","    frames.append(env.render(mode = 'rgb_array'))\n","    # very stupid agent, just makes a random action within the allowd action space\n","    action = env.action_space.sample()\n","#     print(\"Action: {}\".format(t+1))    \n","    observation, reward, done, info = env.step(action)\n","#     print(reward)\n","    cumulated_reward += reward\n","    if done:\n","        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","        break\n","print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","\n","env.close()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -17.0\n"]}]},{"metadata":{"id":"3zZTecVWLLes","executionInfo":{"status":"ok","timestamp":1660755838082,"user_tz":-330,"elapsed":8,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["def sigmoid(x): \n","  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n","\n","def prepro(I):\n","  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n","  I = I[35:195] # crop\n","  I = I[::2,::2,0] # downsample by factor of 2\n","  I[I == 144] = 0 # erase background (background type 1)\n","  I[I == 109] = 0 # erase background (background type 2)\n","  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n","  return I.astype(np.float).ravel()\n","\n","def policy_forward(x):\n","  h = np.dot(model['W1'], x)\n","  h[h<0] = 0 # ReLU nonlinearity\n","  logp = np.dot(model['W2'], h)\n","  p = sigmoid(logp)\n","  return p, h # return probability of taking action 2, and hidden state\n","\n","def model_step(model, observation, prev_x):\n","  # preprocess the observation, set input to network to be difference image\n","  cur_x = prepro(observation)\n","  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","  prev_x = cur_x\n","  \n","  # forward the policy network and sample an action from the returned probability\n","  aprob, _ = policy_forward(x)\n","  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n","  \n","  return action, prev_x\n","\n","def play_game(env, model):\n","  observation = env.reset()\n","\n","  frames = []\n","  cumulated_reward = 0\n","\n","  prev_x = None # used in computing the difference frame\n","\n","  for t in range(1000):\n","      frames.append(env.render(mode = 'rgb_array'))\n","      action, prev_x = model_step(model, observation, prev_x)\n","      observation, reward, done, info = env.step(action)\n","      cumulated_reward += reward\n","      if done:\n","          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","          break\n","  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","  display_frames_as_gif(frames)\n","  env.close()"],"execution_count":9,"outputs":[]},{"metadata":{"id":"6gWvZQ7AQLQt"},"cell_type":"markdown","source":["## Step 3: Policy Gradient from Scratch"]},{"metadata":{"id":"eqFm7hqcItWl","executionInfo":{"status":"ok","timestamp":1660755838497,"user_tz":-330,"elapsed":421,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import numpy as np\n","\n","# model initialization\n","H = 200 # number of hidden layer neurons\n","D = 80 * 80 # input dimensionality: 80x80 grid\n","model = {}\n","model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n","model['W2'] = np.random.randn(H) / np.sqrt(H)\n","\n","# import pickle\n","# model = pickle.load(open('model.pkl', 'rb'))"],"execution_count":10,"outputs":[]},{"metadata":{"id":"TwjiwKisQM19","executionInfo":{"status":"ok","timestamp":1660755838498,"user_tz":-330,"elapsed":8,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# hyperparameters\n","batch_size = 10 # every how many episodes to do a param update?\n","# learning_rate = 1e-5\n","learning_rate = 1e-5\n"," \n","gamma = 0.99 # discount factor for reward\n","decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n","  \n","grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n","rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n","\n","def discount_rewards(r):\n","  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n","  discounted_r = np.zeros_like(r, dtype=np.float32)\n","  running_add = 0\n","  for t in reversed(range(0, r.size)):\n","    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n","    running_add = running_add * gamma + r[t]\n","    discounted_r[t] = running_add\n","  return discounted_r\n","\n","def policy_backward(epx, eph, epdlogp):\n","  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n","  dW2 = np.dot(eph.T, epdlogp).ravel()\n","  dh = np.outer(epdlogp, model['W2'])\n","  dh[eph <= 0] = 0 # backpro prelu\n","  dW1 = np.dot(dh.T, epx)\n","  return {'W1':dW1, 'W2':dW2}\n","\n","def train_model(env, model, total_episodes = 100):\n","  hist = []\n","  observation = env.reset()\n","\n","  prev_x = None # used in computing the difference frame\n","  xs,hs,dlogps,drs = [],[],[],[]\n","  running_reward = None\n","  reward_sum = 0\n","  episode_number = 0\n","\n","  while True:\n","    # preprocess the observation, set input to network to be difference image\n","    cur_x = prepro(observation)\n","    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","    prev_x = cur_x\n","\n","    # forward the policy network and sample an action from the returned probability\n","    aprob, h = policy_forward(x)\n","    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n","\n","    # record various intermediates (needed later for backprop)\n","    xs.append(x) # observation\n","    hs.append(h) # hidden state\n","    y = 1 if action == 2 else 0 # a \"fake label\"\n","    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n","\n","    # step the environment and get new measurements\n","    observation, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n","\n","    if done: # an episode finished\n","      episode_number += 1\n","\n","      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n","      epx = np.vstack(xs)\n","      eph = np.vstack(hs)\n","      epdlogp = np.vstack(dlogps)\n","      epr = np.vstack(drs)\n","      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n","\n","      # compute the discounted reward backwards through time\n","      discounted_epr = discount_rewards(epr)\n","      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n","      discounted_epr -= np.mean(discounted_epr)\n","      discounted_epr /= np.std(discounted_epr)\n","\n","      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n","      grad = policy_backward(epx, eph, epdlogp)\n","      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n","\n","      # perform rmsprop parameter update every batch_size episodes\n","      if episode_number % batch_size == 0:\n","        for k,v in model.items():\n","          g = grad_buffer[k] # gradient\n","          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n","          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n","          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n","\n","      # boring book-keeping\n","      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n","      hist.append((episode_number, reward_sum, running_reward))\n","      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n","      reward_sum = 0\n","      observation = env.reset() # reset env\n","      prev_x = None\n","      if episode_number == total_episodes: return hist\n","\n","      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n","        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"],"execution_count":11,"outputs":[]},{"metadata":{"id":"G6Ka_5Vl9Orm","outputId":"7bb17531-164d-4737-b5b4-381bd46a64c7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660756931063,"user_tz":-330,"elapsed":1092572,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist1 = train_model(env, model, total_episodes=500)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -20.010000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -20.019900\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.029701\n","resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.029404\n","resetting env. episode 6.000000, reward total was -20.000000. running mean: -20.029110\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.028819\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.038531\n","resetting env. episode 9.000000, reward total was -18.000000. running mean: -20.018145\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.027964\n","resetting env. episode 11.000000, reward total was -17.000000. running mean: -19.997684\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.007707\n","resetting env. episode 13.000000, reward total was -19.000000. running mean: -19.997630\n","resetting env. episode 14.000000, reward total was -20.000000. running mean: -19.997654\n","resetting env. episode 15.000000, reward total was -20.000000. running mean: -19.997678\n","resetting env. episode 16.000000, reward total was -18.000000. running mean: -19.977701\n","resetting env. episode 17.000000, reward total was -20.000000. running mean: -19.977924\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -19.988144\n","resetting env. episode 19.000000, reward total was -20.000000. running mean: -19.988263\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -19.998380\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.008397\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.018313\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.028130\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.037848\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.047470\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.056995\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.066425\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.075761\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.085003\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.094153\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.103212\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.112180\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.121058\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.129847\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.138549\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.147163\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.155692\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.164135\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.172493\n","resetting env. episode 40.000000, reward total was -19.000000. running mean: -20.160768\n","resetting env. episode 41.000000, reward total was -18.000000. running mean: -20.139161\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.147769\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.156291\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.154728\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.163181\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.171549\n","resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.169834\n","resetting env. episode 48.000000, reward total was -19.000000. running mean: -20.158136\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.166554\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.174889\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.183140\n","resetting env. episode 52.000000, reward total was -19.000000. running mean: -20.171308\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.179595\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.187799\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.195921\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.203962\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.211923\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.219803\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.227605\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.235329\n","resetting env. episode 61.000000, reward total was -20.000000. running mean: -20.232976\n","resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.230646\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.238340\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.245956\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.253497\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.260962\n","resetting env. episode 67.000000, reward total was -20.000000. running mean: -20.258352\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.265769\n","resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.263111\n","resetting env. episode 70.000000, reward total was -20.000000. running mean: -20.260480\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.267875\n","resetting env. episode 72.000000, reward total was -19.000000. running mean: -20.255196\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.262644\n","resetting env. episode 74.000000, reward total was -20.000000. running mean: -20.260018\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.267418\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.274744\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.281996\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.289176\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.296284\n","resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.293322\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.300388\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.297384\n","resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.294411\n","resetting env. episode 84.000000, reward total was -18.000000. running mean: -20.271466\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.278752\n","resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.275964\n","resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.273205\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.280473\n","resetting env. episode 89.000000, reward total was -20.000000. running mean: -20.277668\n","resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.274891\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.282142\n","resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.279321\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.286528\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.293662\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.300726\n","resetting env. episode 96.000000, reward total was -20.000000. running mean: -20.297718\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.304741\n","resetting env. episode 98.000000, reward total was -19.000000. running mean: -20.291694\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.298777\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.305789\n","resetting env. episode 101.000000, reward total was -19.000000. running mean: -20.292731\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.299804\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.306806\n","resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.303738\n","resetting env. episode 105.000000, reward total was -20.000000. running mean: -20.300701\n","resetting env. episode 106.000000, reward total was -18.000000. running mean: -20.277693\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.284917\n","resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.282067\n","resetting env. episode 109.000000, reward total was -17.000000. running mean: -20.249247\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.256754\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.264187\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.271545\n","resetting env. episode 113.000000, reward total was -20.000000. running mean: -20.268829\n","resetting env. episode 114.000000, reward total was -18.000000. running mean: -20.246141\n","resetting env. episode 115.000000, reward total was -19.000000. running mean: -20.233680\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.241343\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.248929\n","resetting env. episode 118.000000, reward total was -20.000000. running mean: -20.246440\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.253976\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.261436\n","resetting env. episode 121.000000, reward total was -20.000000. running mean: -20.258822\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.256233\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.263671\n","resetting env. episode 124.000000, reward total was -20.000000. running mean: -20.261034\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.268424\n","resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.265740\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.273082\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.280352\n","resetting env. episode 129.000000, reward total was -16.000000. running mean: -20.237548\n","resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.235173\n","resetting env. episode 131.000000, reward total was -20.000000. running mean: -20.232821\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.230493\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.238188\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.245806\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.253348\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.260814\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.268206\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.275524\n","resetting env. episode 139.000000, reward total was -20.000000. running mean: -20.272769\n","resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.270041\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.277341\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.284567\n","resetting env. episode 143.000000, reward total was -20.000000. running mean: -20.281722\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.288904\n","resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.296015\n","resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.303055\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.310025\n","resetting env. episode 148.000000, reward total was -19.000000. running mean: -20.296924\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.303955\n","resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.300916\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.307907\n","resetting env. episode 152.000000, reward total was -19.000000. running mean: -20.294827\n","resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.291879\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.298960\n","resetting env. episode 155.000000, reward total was -18.000000. running mean: -20.275971\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.283211\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.290379\n","resetting env. episode 158.000000, reward total was -19.000000. running mean: -20.277475\n","resetting env. episode 159.000000, reward total was -19.000000. running mean: -20.264700\n","resetting env. episode 160.000000, reward total was -19.000000. running mean: -20.252053\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.259533\n","resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.256938\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.264368\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.271724\n","resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.269007\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.276317\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.273554\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.280818\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.288010\n","resetting env. episode 170.000000, reward total was -19.000000. running mean: -20.275130\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.282379\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.289555\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.286660\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.293793\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.300855\n","resetting env. episode 176.000000, reward total was -20.000000. running mean: -20.297846\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.304868\n","resetting env. episode 178.000000, reward total was -19.000000. running mean: -20.291819\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.298901\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.305912\n","resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.302853\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.309824\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.316726\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.323559\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.330323\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.337020\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.343650\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.340213\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.346811\n","resetting env. episode 190.000000, reward total was -19.000000. running mean: -20.333343\n","resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.330010\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.336710\n","resetting env. episode 193.000000, reward total was -19.000000. running mean: -20.323343\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.330109\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.336808\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.343440\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.350006\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.356506\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.362940\n","resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.359311\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.365718\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.372061\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.368340\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.374657\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.380910\n","resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.377101\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.383330\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.389497\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.395602\n","resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.391646\n","resetting env. episode 211.000000, reward total was -20.000000. running mean: -20.387729\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.393852\n","resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.389914\n","resetting env. episode 214.000000, reward total was -19.000000. running mean: -20.376014\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.382254\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.388432\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.394547\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.400602\n","resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.396596\n","resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.392630\n","resetting env. episode 221.000000, reward total was -19.000000. running mean: -20.378704\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.384917\n","resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.381067\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.377257\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.373484\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.379749\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.385952\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.382092\n","resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.378271\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.384489\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.390644\n","resetting env. episode 232.000000, reward total was -19.000000. running mean: -20.376737\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.382970\n","resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.389140\n","resetting env. episode 235.000000, reward total was -19.000000. running mean: -20.375249\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.381496\n","resetting env. episode 237.000000, reward total was -20.000000. running mean: -20.377681\n","resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.373905\n","resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.370166\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.376464\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.382699\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.388872\n","resetting env. episode 243.000000, reward total was -19.000000. running mean: -20.374984\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.381234\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.387421\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.393547\n","resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.389612\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.395716\n","resetting env. episode 249.000000, reward total was -20.000000. running mean: -20.391758\n","resetting env. episode 250.000000, reward total was -19.000000. running mean: -20.377841\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.384062\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.390222\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.396320\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.402356\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.408333\n","resetting env. episode 256.000000, reward total was -20.000000. running mean: -20.404250\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.410207\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.416105\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.421944\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.427724\n","resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.433447\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.439113\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.444722\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.450274\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.455772\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.451214\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.456702\n","resetting env. episode 268.000000, reward total was -18.000000. running mean: -20.432135\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.437813\n","resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.443435\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.439001\n","resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.444611\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.450165\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.455663\n","resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.451107\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.456595\n","resetting env. episode 277.000000, reward total was -20.000000. running mean: -20.452030\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.457509\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.462934\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.468305\n","resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.463622\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.468986\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.474296\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.479553\n","resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.474757\n","resetting env. episode 286.000000, reward total was -19.000000. running mean: -20.460010\n","resetting env. episode 287.000000, reward total was -20.000000. running mean: -20.455410\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.460855\n","resetting env. episode 289.000000, reward total was -20.000000. running mean: -20.456247\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.461684\n","resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.467068\n","resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.472397\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.477673\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.482896\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.488067\n","resetting env. episode 296.000000, reward total was -19.000000. running mean: -20.473187\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.478455\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.483670\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.488833\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.483945\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.489106\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.494215\n","resetting env. episode 303.000000, reward total was -20.000000. running mean: -20.489272\n","resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.484380\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.489536\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.494641\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.499694\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.504697\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.509650\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.514554\n","resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.509408\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.514314\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.519171\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.513979\n","resetting env. episode 315.000000, reward total was -20.000000. running mean: -20.508839\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.513751\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.518614\n","resetting env. episode 318.000000, reward total was -19.000000. running mean: -20.503427\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.508393\n","resetting env. episode 320.000000, reward total was -19.000000. running mean: -20.493309\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.488376\n","resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.493492\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.498557\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.503572\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.508536\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.513451\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.518316\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.523133\n","resetting env. episode 329.000000, reward total was -20.000000. running mean: -20.517902\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.522723\n","resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.517496\n","resetting env. episode 332.000000, reward total was -19.000000. running mean: -20.502321\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.507297\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.512224\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.517102\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.521931\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.526712\n","resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.521445\n","resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.516230\n","resetting env. episode 340.000000, reward total was -18.000000. running mean: -20.491068\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.496157\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.501196\n","resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.496184\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.501222\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.506210\n","resetting env. episode 346.000000, reward total was -18.000000. running mean: -20.481148\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.486336\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.491473\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.496558\n","resetting env. episode 350.000000, reward total was -19.000000. running mean: -20.481592\n","resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.476777\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.482009\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.487189\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.492317\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.497394\n","resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.492420\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.497495\n","resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.492521\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.497595\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.502619\n","resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.507593\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.512517\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.517392\n","resetting env. episode 364.000000, reward total was -20.000000. running mean: -20.512218\n","resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.517096\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.521925\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.526706\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.531439\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.536124\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.530763\n","resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.535455\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.540101\n","resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.534700\n","resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.529353\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.534059\n","resetting env. episode 376.000000, reward total was -19.000000. running mean: -20.518719\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.523532\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.528296\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.533013\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.537683\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.542306\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.546883\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.551414\n","resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.555900\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.560341\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.564738\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.569091\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.573400\n","resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.567666\n","resetting env. episode 390.000000, reward total was -20.000000. running mean: -20.561989\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.566369\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.570705\n","resetting env. episode 393.000000, reward total was -18.000000. running mean: -20.544998\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.549548\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.554053\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.558512\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.562927\n","resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.567298\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.571625\n","resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.565909\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.570250\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.574547\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.578802\n","resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.573014\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.577283\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.581511\n","resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.575696\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.579939\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.574139\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.578398\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.582614\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.576788\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.581020\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.585210\n","resetting env. episode 415.000000, reward total was -19.000000. running mean: -20.569358\n","resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.563664\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.568027\n","resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.562347\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.566724\n","resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.561056\n","resetting env. episode 421.000000, reward total was -19.000000. running mean: -20.545446\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.549991\n","resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.554491\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.558946\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.563357\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.567723\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.572046\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.576326\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.580562\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.584757\n","resetting env. episode 431.000000, reward total was -19.000000. running mean: -20.568909\n","resetting env. episode 432.000000, reward total was -19.000000. running mean: -20.553220\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.557688\n","resetting env. episode 434.000000, reward total was -19.000000. running mean: -20.542111\n","resetting env. episode 435.000000, reward total was -19.000000. running mean: -20.526690\n","resetting env. episode 436.000000, reward total was -20.000000. running mean: -20.521423\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.526209\n","resetting env. episode 438.000000, reward total was -17.000000. running mean: -20.490947\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.496037\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.501077\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.506066\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.511006\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.515895\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.520737\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.525529\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.530274\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.534971\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.539621\n","resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.534225\n","resetting env. episode 450.000000, reward total was -19.000000. running mean: -20.518883\n","resetting env. episode 451.000000, reward total was -19.000000. running mean: -20.503694\n","resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.498657\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.503671\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.508634\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.513548\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.518412\n","resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.513228\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.518096\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.522915\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.517686\n","resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.512509\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.517384\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.522210\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.526988\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.531718\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.536401\n","resetting env. episode 467.000000, reward total was -19.000000. running mean: -20.521037\n","resetting env. episode 468.000000, reward total was -20.000000. running mean: -20.515826\n","resetting env. episode 469.000000, reward total was -20.000000. running mean: -20.510668\n","resetting env. episode 470.000000, reward total was -19.000000. running mean: -20.495561\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.500606\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.505600\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.510544\n","resetting env. episode 474.000000, reward total was -20.000000. running mean: -20.505438\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.510384\n","resetting env. episode 476.000000, reward total was -19.000000. running mean: -20.495280\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.500327\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.505324\n","resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.510271\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.515168\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.520016\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.524816\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.529568\n","resetting env. episode 484.000000, reward total was -20.000000. running mean: -20.524272\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.529030\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.533739\n","resetting env. episode 487.000000, reward total was -19.000000. running mean: -20.518402\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.513218\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.518086\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.512905\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.517776\n","resetting env. episode 492.000000, reward total was -19.000000. running mean: -20.502598\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.507572\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.512496\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.517371\n","resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.512198\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.517076\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.521905\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.526686\n","resetting env. episode 500.000000, reward total was -20.000000. running mean: -20.521419\n","CPU times: user 24min 13s, sys: 10min 50s, total: 35min 4s\n","Wall time: 18min 12s\n"]}]},{"metadata":{"id":"cHYCDYwhlVLV","outputId":"5a309810-efcb-4622-df72-98cc8982dc0e","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660758026753,"user_tz":-330,"elapsed":1095727,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist2 = train_model(env, model, total_episodes=500)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.990199\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.990297\n","resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.990394\n","resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.980490\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.980685\n","resetting env. episode 10.000000, reward total was -20.000000. running mean: -20.970878\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.971170\n","resetting env. episode 12.000000, reward total was -19.000000. running mean: -20.951458\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.951943\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.952424\n","resetting env. episode 15.000000, reward total was -19.000000. running mean: -20.932900\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.933571\n","resetting env. episode 17.000000, reward total was -19.000000. running mean: -20.914235\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.915093\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.915942\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.916782\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.917614\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.918438\n","resetting env. episode 23.000000, reward total was -19.000000. running mean: -20.899254\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.900261\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.901259\n","resetting env. episode 26.000000, reward total was -19.000000. running mean: -20.882246\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.873424\n","resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.864689\n","resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.856043\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.857482\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.848907\n","resetting env. episode 32.000000, reward total was -19.000000. running mean: -20.830418\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.832114\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.833793\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.835455\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.837100\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.838729\n","resetting env. episode 38.000000, reward total was -17.000000. running mean: -20.800342\n","resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.792339\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.794415\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.796471\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.798506\n","resetting env. episode 43.000000, reward total was -20.000000. running mean: -20.790521\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.792616\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.794690\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.796743\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.798776\n","resetting env. episode 48.000000, reward total was -19.000000. running mean: -20.780788\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.782980\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.785150\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.787299\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.789426\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.791531\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.793616\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.795680\n","resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.787723\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.789846\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.791948\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.794028\n","resetting env. episode 60.000000, reward total was -20.000000. running mean: -20.786088\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.788227\n","resetting env. episode 62.000000, reward total was -19.000000. running mean: -20.770345\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.772641\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.774915\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.777166\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.779394\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.781600\n","resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.773784\n","resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.766046\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.768386\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.770702\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.772995\n","resetting env. episode 73.000000, reward total was -19.000000. running mean: -20.755265\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.757712\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.760135\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.762534\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.764908\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.767259\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.769587\n","resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.761891\n","resetting env. episode 81.000000, reward total was -20.000000. running mean: -20.754272\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.746729\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.749262\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.751769\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.754252\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.756709\n","resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.749142\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.751651\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.754134\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.756593\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.759027\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.761437\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.763822\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.766184\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.768522\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.770837\n","resetting env. episode 97.000000, reward total was -20.000000. running mean: -20.763129\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.755497\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.757942\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.760363\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.762759\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.765132\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.767480\n","resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.759806\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.762207\n","resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.764585\n","resetting env. episode 107.000000, reward total was -20.000000. running mean: -20.756940\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.759370\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.761776\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.764159\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.766517\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.768852\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.771163\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.773452\n","resetting env. episode 115.000000, reward total was -19.000000. running mean: -20.755717\n","resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.748160\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.750678\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.753172\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.755640\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.758084\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.760503\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.762898\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.765269\n","resetting env. episode 124.000000, reward total was -20.000000. running mean: -20.757616\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.760040\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.762440\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.764815\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.767167\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.769495\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.771800\n","resetting env. episode 131.000000, reward total was -20.000000. running mean: -20.764082\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.766442\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.768777\n","resetting env. episode 134.000000, reward total was -19.000000. running mean: -20.751089\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.753578\n","resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.746043\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.748582\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.751096\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.753585\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.756050\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.758489\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.760904\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.763295\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.765662\n","resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.758006\n","resetting env. episode 146.000000, reward total was -19.000000. running mean: -20.740426\n","resetting env. episode 147.000000, reward total was -20.000000. running mean: -20.733021\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.735691\n","resetting env. episode 149.000000, reward total was -20.000000. running mean: -20.728334\n","resetting env. episode 150.000000, reward total was -18.000000. running mean: -20.701051\n","resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.694040\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.697100\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.700129\n","resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.693128\n","resetting env. episode 155.000000, reward total was -18.000000. running mean: -20.666196\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.669534\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.672839\n","resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.666111\n","resetting env. episode 159.000000, reward total was -20.000000. running mean: -20.659450\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.662855\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.666226\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.669564\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.672869\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.676140\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.679378\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.682585\n","resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.685759\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.688901\n","resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.682012\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.685192\n","resetting env. episode 171.000000, reward total was -20.000000. running mean: -20.678340\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.681557\n","resetting env. episode 173.000000, reward total was -18.000000. running mean: -20.654741\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.658194\n","resetting env. episode 175.000000, reward total was -20.000000. running mean: -20.651612\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.655096\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.658545\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.661959\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.665340\n","resetting env. episode 180.000000, reward total was -20.000000. running mean: -20.658686\n","resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.652100\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.655579\n","resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.649023\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.652532\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.656007\n","resetting env. episode 186.000000, reward total was -20.000000. running mean: -20.649447\n","resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.642953\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.646523\n","resetting env. episode 189.000000, reward total was -19.000000. running mean: -20.630058\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.633757\n","resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.627420\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.631146\n","resetting env. episode 193.000000, reward total was -20.000000. running mean: -20.624834\n","resetting env. episode 194.000000, reward total was -19.000000. running mean: -20.608586\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.612500\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.616375\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.620211\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.624009\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.627769\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.631491\n","resetting env. episode 201.000000, reward total was -19.000000. running mean: -20.615176\n","resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.609025\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.602934\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.606905\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.610836\n","resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.604728\n","resetting env. episode 207.000000, reward total was -19.000000. running mean: -20.588680\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.592793\n","resetting env. episode 209.000000, reward total was -20.000000. running mean: -20.586866\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.590997\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.595087\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.599136\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.603145\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.607113\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.611042\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.614932\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.618782\n","resetting env. episode 218.000000, reward total was -19.000000. running mean: -20.602595\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.606569\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.610503\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.614398\n","resetting env. episode 222.000000, reward total was -19.000000. running mean: -20.598254\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.602271\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.606249\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.600186\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.604184\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.608142\n","resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.612061\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.615940\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.619781\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.623583\n","resetting env. episode 232.000000, reward total was -19.000000. running mean: -20.607347\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.601274\n","resetting env. episode 234.000000, reward total was -19.000000. running mean: -20.585261\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.589409\n","resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.583514\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.587679\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.591803\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.595885\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.599926\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.603926\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.597887\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.601908\n","resetting env. episode 244.000000, reward total was -18.000000. running mean: -20.575889\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.580130\n","resetting env. episode 246.000000, reward total was -20.000000. running mean: -20.574329\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.578586\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.582800\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.586972\n","resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.581102\n","resetting env. episode 251.000000, reward total was -20.000000. running mean: -20.575291\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.579538\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.583743\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.587905\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.592026\n","resetting env. episode 256.000000, reward total was -20.000000. running mean: -20.586106\n","resetting env. episode 257.000000, reward total was -20.000000. running mean: -20.580245\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.584443\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.588598\n","resetting env. episode 260.000000, reward total was -20.000000. running mean: -20.582712\n","resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.586885\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.591016\n","resetting env. episode 263.000000, reward total was -20.000000. running mean: -20.585106\n","resetting env. episode 264.000000, reward total was -20.000000. running mean: -20.579255\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.583462\n","resetting env. episode 266.000000, reward total was -16.000000. running mean: -20.537628\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.542252\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.546829\n","resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.541361\n","resetting env. episode 270.000000, reward total was -19.000000. running mean: -20.525947\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.530688\n","resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.535381\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.540027\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.544627\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.549180\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.553689\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.558152\n","resetting env. episode 278.000000, reward total was -19.000000. running mean: -20.542570\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.547144\n","resetting env. episode 280.000000, reward total was -19.000000. running mean: -20.531673\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.536356\n","resetting env. episode 282.000000, reward total was -18.000000. running mean: -20.510993\n","resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.505883\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.510824\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.515716\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.520559\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.525353\n","resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.520099\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.524898\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.529650\n","resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.534353\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.529009\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.533719\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.538382\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.542998\n","resetting env. episode 296.000000, reward total was -20.000000. running mean: -20.537568\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.542193\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.546771\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.551303\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.555790\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.560232\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.554630\n","resetting env. episode 303.000000, reward total was -20.000000. running mean: -20.549084\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.553593\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.558057\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.562476\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.566851\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.561183\n","resetting env. episode 309.000000, reward total was -19.000000. running mean: -20.545571\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.550115\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.554614\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.559068\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.553477\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.547943\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.552463\n","resetting env. episode 316.000000, reward total was -19.000000. running mean: -20.536939\n","resetting env. episode 317.000000, reward total was -19.000000. running mean: -20.521569\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -20.516353\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.521190\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.525978\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.530718\n","resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.525411\n","resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.520157\n","resetting env. episode 324.000000, reward total was -19.000000. running mean: -20.504955\n","resetting env. episode 325.000000, reward total was -19.000000. running mean: -20.489906\n","resetting env. episode 326.000000, reward total was -19.000000. running mean: -20.475007\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.480257\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.485454\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.490600\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.495694\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.500737\n","resetting env. episode 332.000000, reward total was -19.000000. running mean: -20.485729\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.490872\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.495963\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.501004\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.505994\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.510934\n","resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.505824\n","resetting env. episode 339.000000, reward total was -19.000000. running mean: -20.490766\n","resetting env. episode 340.000000, reward total was -20.000000. running mean: -20.485858\n","resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.481000\n","resetting env. episode 342.000000, reward total was -19.000000. running mean: -20.466190\n","resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.461528\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.466913\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.472244\n","resetting env. episode 346.000000, reward total was -18.000000. running mean: -20.447521\n","resetting env. episode 347.000000, reward total was -19.000000. running mean: -20.433046\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.438715\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.444328\n","resetting env. episode 350.000000, reward total was -20.000000. running mean: -20.439885\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.445486\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.451031\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.456521\n","resetting env. episode 354.000000, reward total was -18.000000. running mean: -20.431956\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.437636\n","resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.433260\n","resetting env. episode 357.000000, reward total was -19.000000. running mean: -20.418927\n","resetting env. episode 358.000000, reward total was -17.000000. running mean: -20.384738\n","resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.380891\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.387082\n","resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.393211\n","resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.389279\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.395386\n","resetting env. episode 364.000000, reward total was -19.000000. running mean: -20.381432\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.377618\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.383842\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.390003\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.396103\n","resetting env. episode 369.000000, reward total was -19.000000. running mean: -20.382142\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.378321\n","resetting env. episode 371.000000, reward total was -18.000000. running mean: -20.354538\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.360992\n","resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.357382\n","resetting env. episode 374.000000, reward total was -18.000000. running mean: -20.333808\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.340470\n","resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.337066\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.343695\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.350258\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.356755\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.363188\n","resetting env. episode 381.000000, reward total was -20.000000. running mean: -20.359556\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.365960\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.372301\n","resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.378578\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.384792\n","resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.380944\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.387135\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.393263\n","resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.389331\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.395437\n","resetting env. episode 391.000000, reward total was -19.000000. running mean: -20.381483\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.387668\n","resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.383792\n","resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.379954\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.386154\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.392293\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.398370\n","resetting env. episode 398.000000, reward total was -18.000000. running mean: -20.374386\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.380642\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.386836\n","resetting env. episode 401.000000, reward total was -19.000000. running mean: -20.372967\n","resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.369238\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.375545\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.381790\n","resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.377972\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.384192\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.390350\n","resetting env. episode 408.000000, reward total was -19.000000. running mean: -20.376447\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.372682\n","resetting env. episode 410.000000, reward total was -20.000000. running mean: -20.368955\n","resetting env. episode 411.000000, reward total was -20.000000. running mean: -20.365266\n","resetting env. episode 412.000000, reward total was -18.000000. running mean: -20.341613\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.348197\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.354715\n","resetting env. episode 415.000000, reward total was -19.000000. running mean: -20.341168\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.347756\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.354279\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.360736\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.367129\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.373457\n","resetting env. episode 421.000000, reward total was -20.000000. running mean: -20.369723\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.376025\n","resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.382265\n","resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.378443\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.384658\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.390812\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.396903\n","resetting env. episode 428.000000, reward total was -19.000000. running mean: -20.382934\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.389105\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.395214\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.401262\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.407249\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.413177\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.419045\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.424855\n","resetting env. episode 436.000000, reward total was -20.000000. running mean: -20.420606\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.426400\n","resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.432136\n","resetting env. episode 439.000000, reward total was -18.000000. running mean: -20.407815\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.413736\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.419599\n","resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.415403\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.421249\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.427037\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.432766\n","resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.428439\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.434154\n","resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.429813\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.435514\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.441159\n","resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.436748\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.442380\n","resetting env. episode 453.000000, reward total was -20.000000. running mean: -20.437956\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.443577\n","resetting env. episode 455.000000, reward total was -20.000000. running mean: -20.439141\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.444750\n","resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.440302\n","resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.435899\n","resetting env. episode 459.000000, reward total was -19.000000. running mean: -20.421540\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.417325\n","resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.413152\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.409020\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.414930\n","resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.410781\n","resetting env. episode 465.000000, reward total was -20.000000. running mean: -20.406673\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.412606\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.418480\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.424295\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.430052\n","resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.425752\n","resetting env. episode 471.000000, reward total was -20.000000. running mean: -20.421494\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.427279\n","resetting env. episode 473.000000, reward total was -19.000000. running mean: -20.413006\n","resetting env. episode 474.000000, reward total was -19.000000. running mean: -20.398876\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.404888\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.410839\n","resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.406730\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.412663\n","resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.418536\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.424351\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.430108\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.435806\n","resetting env. episode 483.000000, reward total was -20.000000. running mean: -20.431448\n","resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.417134\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.422963\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.428733\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.434446\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.440101\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.445700\n","resetting env. episode 490.000000, reward total was -19.000000. running mean: -20.431243\n","resetting env. episode 491.000000, reward total was -18.000000. running mean: -20.406931\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.412861\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.418733\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.424545\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.430300\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.435997\n","resetting env. episode 497.000000, reward total was -19.000000. running mean: -20.421637\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.427421\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.433146\n","resetting env. episode 500.000000, reward total was -19.000000. running mean: -20.418815\n","CPU times: user 24min 28s, sys: 10min 51s, total: 35min 20s\n","Wall time: 18min 15s\n"]}]},{"metadata":{"id":"8fheN9DRlWXQ","outputId":"dd9a3578-40d9-4bb9-d2cc-25913c5b2727","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1660758068124,"user_tz":-330,"elapsed":41381,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -19.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"id":"9AxOcQhIsKow","outputId":"3e6f3b89-7811-4cca-865b-a7bbe50e4a5c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660761404189,"user_tz":-330,"elapsed":3336139,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist3 = train_model(env, model, total_episodes=1500)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -18.000000. running mean: -20.970000\n","resetting env. episode 4.000000, reward total was -18.000000. running mean: -20.940300\n","resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.930897\n","resetting env. episode 6.000000, reward total was -20.000000. running mean: -20.921588\n","resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.922372\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.923148\n","resetting env. episode 9.000000, reward total was -20.000000. running mean: -20.913917\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.914778\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.915630\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.916474\n","resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.907309\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.908236\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.909154\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.910062\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.910961\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.911852\n","resetting env. episode 19.000000, reward total was -20.000000. running mean: -20.902733\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.903706\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.904669\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.905622\n","resetting env. episode 23.000000, reward total was -20.000000. running mean: -20.896566\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.897600\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.898624\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.899638\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.890642\n","resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.881735\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.882918\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.884089\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.885248\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.886395\n","resetting env. episode 33.000000, reward total was -18.000000. running mean: -20.857531\n","resetting env. episode 34.000000, reward total was -19.000000. running mean: -20.838956\n","resetting env. episode 35.000000, reward total was -20.000000. running mean: -20.830566\n","resetting env. episode 36.000000, reward total was -19.000000. running mean: -20.812261\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.814138\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.815997\n","resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.807837\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.809759\n","resetting env. episode 41.000000, reward total was -19.000000. running mean: -20.791661\n","resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.783744\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.785907\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.788048\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.790167\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.792266\n","resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.784343\n","resetting env. episode 48.000000, reward total was -16.000000. running mean: -20.736500\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.739135\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.741743\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.744326\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.746883\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.749414\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.751920\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.754400\n","resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.746856\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.749388\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.751894\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.754375\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.756831\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.759263\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.761670\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.764054\n","resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.756413\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.758849\n","resetting env. episode 66.000000, reward total was -20.000000. running mean: -20.751260\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.753748\n","resetting env. episode 68.000000, reward total was -18.000000. running mean: -20.726210\n","resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.718948\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.721759\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.714541\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.717396\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.720222\n","resetting env. episode 74.000000, reward total was -17.000000. running mean: -20.683020\n","resetting env. episode 75.000000, reward total was -19.000000. running mean: -20.666189\n","resetting env. episode 76.000000, reward total was -20.000000. running mean: -20.659528\n","resetting env. episode 77.000000, reward total was -19.000000. running mean: -20.642932\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.646503\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.650038\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.653537\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.657002\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.650432\n","resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.643928\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.647489\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.651014\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.654503\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.657958\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.661379\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.664765\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.668117\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.671436\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.674722\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.677975\n","resetting env. episode 94.000000, reward total was -20.000000. running mean: -20.671195\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.664483\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.667838\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.671160\n","resetting env. episode 98.000000, reward total was -19.000000. running mean: -20.654448\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.657904\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.661325\n","resetting env. episode 101.000000, reward total was -19.000000. running mean: -20.644711\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.648264\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.651782\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.655264\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.658711\n","resetting env. episode 106.000000, reward total was -19.000000. running mean: -20.642124\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.645703\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.649246\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.652753\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.656226\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.659664\n","resetting env. episode 112.000000, reward total was -18.000000. running mean: -20.633067\n","resetting env. episode 113.000000, reward total was -20.000000. running mean: -20.626736\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.630469\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.634164\n","resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.627823\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.631544\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.635229\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.638877\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.642488\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.646063\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.639602\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.643206\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.646774\n","resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.640306\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.643903\n","resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.637464\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.641090\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.644679\n","resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.638232\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.641850\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.645431\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.648977\n","resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.642487\n","resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.636062\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.639702\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.643305\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.646872\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.650403\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.653899\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.657360\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.660786\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.664178\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.667537\n","resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.670861\n","resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.674153\n","resetting env. episode 147.000000, reward total was -20.000000. running mean: -20.667411\n","resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.660737\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.664130\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.667488\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.670813\n","resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.664105\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.667464\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.670790\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.674082\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.677341\n","resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.670568\n","resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.663862\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.667223\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.670551\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.673845\n","resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.667107\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.670436\n","resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.663732\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.667094\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.670423\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.663719\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.667082\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.670411\n","resetting env. episode 170.000000, reward total was -18.000000. running mean: -20.643707\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.647270\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.650797\n","resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.654289\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.657746\n","resetting env. episode 175.000000, reward total was -20.000000. running mean: -20.651169\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.654657\n","resetting env. episode 177.000000, reward total was -20.000000. running mean: -20.648111\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.651630\n","resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.645113\n","resetting env. episode 180.000000, reward total was -20.000000. running mean: -20.638662\n","resetting env. episode 181.000000, reward total was -19.000000. running mean: -20.622275\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.626053\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.629792\n","resetting env. episode 184.000000, reward total was -20.000000. running mean: -20.623494\n","resetting env. episode 185.000000, reward total was -20.000000. running mean: -20.617259\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.621087\n","resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.614876\n","resetting env. episode 188.000000, reward total was -18.000000. running mean: -20.588727\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.592840\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.596911\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.600942\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.604933\n","resetting env. episode 193.000000, reward total was -19.000000. running mean: -20.588884\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.592995\n","resetting env. episode 195.000000, reward total was -20.000000. running mean: -20.587065\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.591194\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.595282\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.589329\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.593436\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.597502\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.601527\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.605511\n","resetting env. episode 203.000000, reward total was -19.000000. running mean: -20.589456\n","resetting env. episode 204.000000, reward total was -20.000000. running mean: -20.583562\n","resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.577726\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.581949\n","resetting env. episode 207.000000, reward total was -18.000000. running mean: -20.556129\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.560568\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.564962\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.569313\n","resetting env. episode 211.000000, reward total was -20.000000. running mean: -20.563620\n","resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.557983\n","resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.552404\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -20.546880\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.551411\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.555897\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.560338\n","resetting env. episode 218.000000, reward total was -19.000000. running mean: -20.544734\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.549287\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.553794\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.558256\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.562674\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.567047\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.561376\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.565763\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.570105\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.574404\n","resetting env. episode 228.000000, reward total was -19.000000. running mean: -20.558660\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.563073\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.567443\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.571768\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.566051\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.560390\n","resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.564786\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.569138\n","resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.563447\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.567812\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.572134\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.576413\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.580649\n","resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.574842\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.569094\n","resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.563403\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.567769\n","resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.562091\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.566470\n","resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.560806\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.565198\n","resetting env. episode 249.000000, reward total was -20.000000. running mean: -20.559546\n","resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.553950\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.558411\n","resetting env. episode 252.000000, reward total was -19.000000. running mean: -20.542827\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.547398\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.551924\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.556405\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.560841\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.565233\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.569580\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.573884\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.578146\n","resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.572364\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.576640\n","resetting env. episode 263.000000, reward total was -19.000000. running mean: -20.560874\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.565265\n","resetting env. episode 265.000000, reward total was -20.000000. running mean: -20.559613\n","resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.564017\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.568376\n","resetting env. episode 268.000000, reward total was -19.000000. running mean: -20.552693\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.557166\n","resetting env. episode 270.000000, reward total was -20.000000. running mean: -20.551594\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.556078\n","resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.550517\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.555012\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.559462\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.563867\n","resetting env. episode 276.000000, reward total was -20.000000. running mean: -20.558229\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.562646\n","resetting env. episode 278.000000, reward total was -18.000000. running mean: -20.537020\n","resetting env. episode 279.000000, reward total was -19.000000. running mean: -20.521650\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.526433\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.531169\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.535857\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.540499\n","resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.535094\n","resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.529743\n","resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.524445\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.529201\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.533909\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.538570\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.533184\n","resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.527852\n","resetting env. episode 292.000000, reward total was -19.000000. running mean: -20.512574\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.517448\n","resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.512274\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.517151\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.521979\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.526759\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.521492\n","resetting env. episode 299.000000, reward total was -18.000000. running mean: -20.496277\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.491314\n","resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.486401\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.481537\n","resetting env. episode 303.000000, reward total was -18.000000. running mean: -20.456722\n","resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.452154\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.457633\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.463057\n","resetting env. episode 307.000000, reward total was -20.000000. running mean: -20.458426\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.463842\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.469203\n","resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.464511\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.469866\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.475168\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.470416\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.465712\n","resetting env. episode 315.000000, reward total was -19.000000. running mean: -20.451055\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.456544\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.461979\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.467359\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.472685\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.477958\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.483179\n","resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.488347\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.493464\n","resetting env. episode 324.000000, reward total was -17.000000. running mean: -20.458529\n","resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.453944\n","resetting env. episode 326.000000, reward total was -20.000000. running mean: -20.449404\n","resetting env. episode 327.000000, reward total was -19.000000. running mean: -20.434910\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.440561\n","resetting env. episode 329.000000, reward total was -20.000000. running mean: -20.436155\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.441794\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.447376\n","resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.442902\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.448473\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.453988\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.459449\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.464854\n","resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.460205\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.465603\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.470947\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.476238\n","resetting env. episode 341.000000, reward total was -18.000000. running mean: -20.451476\n","resetting env. episode 342.000000, reward total was -19.000000. running mean: -20.436961\n","resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.432591\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.438265\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.443883\n","resetting env. episode 346.000000, reward total was -19.000000. running mean: -20.429444\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.435149\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.440798\n","resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.436390\n","resetting env. episode 350.000000, reward total was -19.000000. running mean: -20.422026\n","resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.417806\n","resetting env. episode 352.000000, reward total was -17.000000. running mean: -20.383628\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.389791\n","resetting env. episode 354.000000, reward total was -20.000000. running mean: -20.385893\n","resetting env. episode 355.000000, reward total was -20.000000. running mean: -20.382035\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.388214\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.394332\n","resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.390389\n","resetting env. episode 359.000000, reward total was -19.000000. running mean: -20.376485\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.382720\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.378893\n","resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.375104\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.381353\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.387539\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.383664\n","resetting env. episode 366.000000, reward total was -19.000000. running mean: -20.369827\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.376129\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.382368\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.388544\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.394659\n","resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.390712\n","resetting env. episode 372.000000, reward total was -19.000000. running mean: -20.376805\n","resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.373037\n","resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.379306\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.385513\n","resetting env. episode 376.000000, reward total was -19.000000. running mean: -20.371658\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.377942\n","resetting env. episode 378.000000, reward total was -20.000000. running mean: -20.374162\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.380421\n","resetting env. episode 380.000000, reward total was -19.000000. running mean: -20.366616\n","resetting env. episode 381.000000, reward total was -19.000000. running mean: -20.352950\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.359421\n","resetting env. episode 383.000000, reward total was -19.000000. running mean: -20.345827\n","resetting env. episode 384.000000, reward total was -18.000000. running mean: -20.322368\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.329145\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.335853\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.342495\n","resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.339070\n","resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.335679\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.342322\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.348899\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.355410\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.361856\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.368237\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.374555\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.380809\n","resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.377001\n","resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.383231\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.389399\n","resetting env. episode 400.000000, reward total was -19.000000. running mean: -20.375505\n","resetting env. episode 401.000000, reward total was -19.000000. running mean: -20.361750\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.368132\n","resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.364451\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.370807\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.377099\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.383328\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.389494\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.395599\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.401643\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.407627\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.413551\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.419415\n","resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.415221\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.421069\n","resetting env. episode 415.000000, reward total was -17.000000. running mean: -20.386858\n","resetting env. episode 416.000000, reward total was -19.000000. running mean: -20.372990\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.379260\n","resetting env. episode 418.000000, reward total was -19.000000. running mean: -20.365467\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.371812\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.378094\n","resetting env. episode 421.000000, reward total was -18.000000. running mean: -20.354313\n","resetting env. episode 422.000000, reward total was -19.000000. running mean: -20.340770\n","resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.347362\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.353889\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.350350\n","resetting env. episode 426.000000, reward total was -19.000000. running mean: -20.336846\n","resetting env. episode 427.000000, reward total was -19.000000. running mean: -20.323478\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.330243\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.336941\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -20.333571\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.340236\n","resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.336833\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.343465\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.350030\n","resetting env. episode 435.000000, reward total was -20.000000. running mean: -20.346530\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.353065\n","resetting env. episode 437.000000, reward total was -20.000000. running mean: -20.349534\n","resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.346039\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.352578\n","resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.349053\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.355562\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.362006\n","resetting env. episode 443.000000, reward total was -20.000000. running mean: -20.358386\n","resetting env. episode 444.000000, reward total was -20.000000. running mean: -20.354802\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.361254\n","resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.357642\n","resetting env. episode 447.000000, reward total was -19.000000. running mean: -20.344065\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.350625\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.357119\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.363547\n","resetting env. episode 451.000000, reward total was -19.000000. running mean: -20.349912\n","resetting env. episode 452.000000, reward total was -19.000000. running mean: -20.336413\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.343049\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.349618\n","resetting env. episode 455.000000, reward total was -16.000000. running mean: -20.306122\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.313061\n","resetting env. episode 457.000000, reward total was -19.000000. running mean: -20.299930\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.306931\n","resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.303862\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.300823\n","resetting env. episode 461.000000, reward total was -19.000000. running mean: -20.287815\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.294937\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.301987\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.308967\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.315878\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.322719\n","resetting env. episode 467.000000, reward total was -18.000000. running mean: -20.299492\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.306497\n","resetting env. episode 469.000000, reward total was -19.000000. running mean: -20.293432\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.300497\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.307493\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.314418\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.321273\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.328061\n","resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.324780\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.331532\n","resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.328217\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.334935\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.331585\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.338270\n","resetting env. episode 481.000000, reward total was -20.000000. running mean: -20.334887\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.341538\n","resetting env. episode 483.000000, reward total was -20.000000. running mean: -20.338123\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.344741\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.351294\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.357781\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.364203\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.360561\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.366956\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.363286\n","resetting env. episode 491.000000, reward total was -19.000000. running mean: -20.349653\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.356157\n","resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.352595\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.359069\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.365478\n","resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.361824\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.368205\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.374523\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.380778\n","resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.386970\n","resetting env. episode 501.000000, reward total was -20.000000. running mean: -20.383101\n","resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.389270\n","resetting env. episode 503.000000, reward total was -19.000000. running mean: -20.375377\n","resetting env. episode 504.000000, reward total was -21.000000. running mean: -20.381623\n","resetting env. episode 505.000000, reward total was -21.000000. running mean: -20.387807\n","resetting env. episode 506.000000, reward total was -21.000000. running mean: -20.393929\n","resetting env. episode 507.000000, reward total was -18.000000. running mean: -20.369990\n","resetting env. episode 508.000000, reward total was -19.000000. running mean: -20.356290\n","resetting env. episode 509.000000, reward total was -21.000000. running mean: -20.362727\n","resetting env. episode 510.000000, reward total was -20.000000. running mean: -20.359100\n","resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.365509\n","resetting env. episode 512.000000, reward total was -21.000000. running mean: -20.371853\n","resetting env. episode 513.000000, reward total was -21.000000. running mean: -20.378135\n","resetting env. episode 514.000000, reward total was -21.000000. running mean: -20.384354\n","resetting env. episode 515.000000, reward total was -18.000000. running mean: -20.360510\n","resetting env. episode 516.000000, reward total was -21.000000. running mean: -20.366905\n","resetting env. episode 517.000000, reward total was -17.000000. running mean: -20.333236\n","resetting env. episode 518.000000, reward total was -21.000000. running mean: -20.339904\n","resetting env. episode 519.000000, reward total was -20.000000. running mean: -20.336504\n","resetting env. episode 520.000000, reward total was -21.000000. running mean: -20.343139\n","resetting env. episode 521.000000, reward total was -21.000000. running mean: -20.349708\n","resetting env. episode 522.000000, reward total was -21.000000. running mean: -20.356211\n","resetting env. episode 523.000000, reward total was -21.000000. running mean: -20.362649\n","resetting env. episode 524.000000, reward total was -21.000000. running mean: -20.369022\n","resetting env. episode 525.000000, reward total was -21.000000. running mean: -20.375332\n","resetting env. episode 526.000000, reward total was -21.000000. running mean: -20.381579\n","resetting env. episode 527.000000, reward total was -19.000000. running mean: -20.367763\n","resetting env. episode 528.000000, reward total was -21.000000. running mean: -20.374085\n","resetting env. episode 529.000000, reward total was -18.000000. running mean: -20.350345\n","resetting env. episode 530.000000, reward total was -21.000000. running mean: -20.356841\n","resetting env. episode 531.000000, reward total was -20.000000. running mean: -20.353273\n","resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.359740\n","resetting env. episode 533.000000, reward total was -21.000000. running mean: -20.366143\n","resetting env. episode 534.000000, reward total was -21.000000. running mean: -20.372481\n","resetting env. episode 535.000000, reward total was -21.000000. running mean: -20.378756\n","resetting env. episode 536.000000, reward total was -20.000000. running mean: -20.374969\n","resetting env. episode 537.000000, reward total was -19.000000. running mean: -20.361219\n","resetting env. episode 538.000000, reward total was -19.000000. running mean: -20.347607\n","resetting env. episode 539.000000, reward total was -21.000000. running mean: -20.354131\n","resetting env. episode 540.000000, reward total was -20.000000. running mean: -20.350590\n","resetting env. episode 541.000000, reward total was -20.000000. running mean: -20.347084\n","resetting env. episode 542.000000, reward total was -21.000000. running mean: -20.353613\n","resetting env. episode 543.000000, reward total was -21.000000. running mean: -20.360077\n","resetting env. episode 544.000000, reward total was -20.000000. running mean: -20.356476\n","resetting env. episode 545.000000, reward total was -20.000000. running mean: -20.352911\n","resetting env. episode 546.000000, reward total was -21.000000. running mean: -20.359382\n","resetting env. episode 547.000000, reward total was -20.000000. running mean: -20.355788\n","resetting env. episode 548.000000, reward total was -21.000000. running mean: -20.362230\n","resetting env. episode 549.000000, reward total was -21.000000. running mean: -20.368608\n","resetting env. episode 550.000000, reward total was -21.000000. running mean: -20.374922\n","resetting env. episode 551.000000, reward total was -20.000000. running mean: -20.371173\n","resetting env. episode 552.000000, reward total was -20.000000. running mean: -20.367461\n","resetting env. episode 553.000000, reward total was -21.000000. running mean: -20.373786\n","resetting env. episode 554.000000, reward total was -21.000000. running mean: -20.380049\n","resetting env. episode 555.000000, reward total was -21.000000. running mean: -20.386248\n","resetting env. episode 556.000000, reward total was -21.000000. running mean: -20.392386\n","resetting env. episode 557.000000, reward total was -20.000000. running mean: -20.388462\n","resetting env. episode 558.000000, reward total was -21.000000. running mean: -20.394577\n","resetting env. episode 559.000000, reward total was -20.000000. running mean: -20.390631\n","resetting env. episode 560.000000, reward total was -21.000000. running mean: -20.396725\n","resetting env. episode 561.000000, reward total was -21.000000. running mean: -20.402758\n","resetting env. episode 562.000000, reward total was -21.000000. running mean: -20.408730\n","resetting env. episode 563.000000, reward total was -20.000000. running mean: -20.404643\n","resetting env. episode 564.000000, reward total was -21.000000. running mean: -20.410596\n","resetting env. episode 565.000000, reward total was -21.000000. running mean: -20.416490\n","resetting env. episode 566.000000, reward total was -19.000000. running mean: -20.402326\n","resetting env. episode 567.000000, reward total was -21.000000. running mean: -20.408302\n","resetting env. episode 568.000000, reward total was -21.000000. running mean: -20.414219\n","resetting env. episode 569.000000, reward total was -21.000000. running mean: -20.420077\n","resetting env. episode 570.000000, reward total was -21.000000. running mean: -20.425876\n","resetting env. episode 571.000000, reward total was -21.000000. running mean: -20.431618\n","resetting env. episode 572.000000, reward total was -20.000000. running mean: -20.427301\n","resetting env. episode 573.000000, reward total was -21.000000. running mean: -20.433028\n","resetting env. episode 574.000000, reward total was -21.000000. running mean: -20.438698\n","resetting env. episode 575.000000, reward total was -21.000000. running mean: -20.444311\n","resetting env. episode 576.000000, reward total was -21.000000. running mean: -20.449868\n","resetting env. episode 577.000000, reward total was -20.000000. running mean: -20.445369\n","resetting env. episode 578.000000, reward total was -21.000000. running mean: -20.450916\n","resetting env. episode 579.000000, reward total was -21.000000. running mean: -20.456406\n","resetting env. episode 580.000000, reward total was -19.000000. running mean: -20.441842\n","resetting env. episode 581.000000, reward total was -21.000000. running mean: -20.447424\n","resetting env. episode 582.000000, reward total was -21.000000. running mean: -20.452950\n","resetting env. episode 583.000000, reward total was -21.000000. running mean: -20.458420\n","resetting env. episode 584.000000, reward total was -21.000000. running mean: -20.463836\n","resetting env. episode 585.000000, reward total was -19.000000. running mean: -20.449198\n","resetting env. episode 586.000000, reward total was -21.000000. running mean: -20.454706\n","resetting env. episode 587.000000, reward total was -19.000000. running mean: -20.440159\n","resetting env. episode 588.000000, reward total was -21.000000. running mean: -20.445757\n","resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.451299\n","resetting env. episode 590.000000, reward total was -21.000000. running mean: -20.456786\n","resetting env. episode 591.000000, reward total was -21.000000. running mean: -20.462219\n","resetting env. episode 592.000000, reward total was -21.000000. running mean: -20.467596\n","resetting env. episode 593.000000, reward total was -20.000000. running mean: -20.462920\n","resetting env. episode 594.000000, reward total was -21.000000. running mean: -20.468291\n","resetting env. episode 595.000000, reward total was -21.000000. running mean: -20.473608\n","resetting env. episode 596.000000, reward total was -21.000000. running mean: -20.478872\n","resetting env. episode 597.000000, reward total was -21.000000. running mean: -20.484084\n","resetting env. episode 598.000000, reward total was -21.000000. running mean: -20.489243\n","resetting env. episode 599.000000, reward total was -19.000000. running mean: -20.474350\n","resetting env. episode 600.000000, reward total was -21.000000. running mean: -20.479607\n","resetting env. episode 601.000000, reward total was -21.000000. running mean: -20.484811\n","resetting env. episode 602.000000, reward total was -20.000000. running mean: -20.479963\n","resetting env. episode 603.000000, reward total was -21.000000. running mean: -20.485163\n","resetting env. episode 604.000000, reward total was -21.000000. running mean: -20.490311\n","resetting env. episode 605.000000, reward total was -20.000000. running mean: -20.485408\n","resetting env. episode 606.000000, reward total was -21.000000. running mean: -20.490554\n","resetting env. episode 607.000000, reward total was -21.000000. running mean: -20.495649\n","resetting env. episode 608.000000, reward total was -21.000000. running mean: -20.500692\n","resetting env. episode 609.000000, reward total was -20.000000. running mean: -20.495685\n","resetting env. episode 610.000000, reward total was -20.000000. running mean: -20.490728\n","resetting env. episode 611.000000, reward total was -20.000000. running mean: -20.485821\n","resetting env. episode 612.000000, reward total was -21.000000. running mean: -20.490963\n","resetting env. episode 613.000000, reward total was -18.000000. running mean: -20.466053\n","resetting env. episode 614.000000, reward total was -21.000000. running mean: -20.471393\n","resetting env. episode 615.000000, reward total was -21.000000. running mean: -20.476679\n","resetting env. episode 616.000000, reward total was -21.000000. running mean: -20.481912\n","resetting env. episode 617.000000, reward total was -21.000000. running mean: -20.487093\n","resetting env. episode 618.000000, reward total was -19.000000. running mean: -20.472222\n","resetting env. episode 619.000000, reward total was -21.000000. running mean: -20.477500\n","resetting env. episode 620.000000, reward total was -21.000000. running mean: -20.482725\n","resetting env. episode 621.000000, reward total was -21.000000. running mean: -20.487897\n","resetting env. episode 622.000000, reward total was -21.000000. running mean: -20.493018\n","resetting env. episode 623.000000, reward total was -20.000000. running mean: -20.488088\n","resetting env. episode 624.000000, reward total was -20.000000. running mean: -20.483207\n","resetting env. episode 625.000000, reward total was -21.000000. running mean: -20.488375\n","resetting env. episode 626.000000, reward total was -20.000000. running mean: -20.483492\n","resetting env. episode 627.000000, reward total was -21.000000. running mean: -20.488657\n","resetting env. episode 628.000000, reward total was -21.000000. running mean: -20.493770\n","resetting env. episode 629.000000, reward total was -21.000000. running mean: -20.498832\n","resetting env. episode 630.000000, reward total was -19.000000. running mean: -20.483844\n","resetting env. episode 631.000000, reward total was -21.000000. running mean: -20.489006\n","resetting env. episode 632.000000, reward total was -20.000000. running mean: -20.484116\n","resetting env. episode 633.000000, reward total was -20.000000. running mean: -20.479274\n","resetting env. episode 634.000000, reward total was -19.000000. running mean: -20.464482\n","resetting env. episode 635.000000, reward total was -20.000000. running mean: -20.459837\n","resetting env. episode 636.000000, reward total was -21.000000. running mean: -20.465239\n","resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.470586\n","resetting env. episode 638.000000, reward total was -20.000000. running mean: -20.465880\n","resetting env. episode 639.000000, reward total was -21.000000. running mean: -20.471221\n","resetting env. episode 640.000000, reward total was -21.000000. running mean: -20.476509\n","resetting env. episode 641.000000, reward total was -20.000000. running mean: -20.471744\n","resetting env. episode 642.000000, reward total was -21.000000. running mean: -20.477027\n","resetting env. episode 643.000000, reward total was -20.000000. running mean: -20.472256\n","resetting env. episode 644.000000, reward total was -20.000000. running mean: -20.467534\n","resetting env. episode 645.000000, reward total was -20.000000. running mean: -20.462859\n","resetting env. episode 646.000000, reward total was -21.000000. running mean: -20.468230\n","resetting env. episode 647.000000, reward total was -21.000000. running mean: -20.473548\n","resetting env. episode 648.000000, reward total was -21.000000. running mean: -20.478812\n","resetting env. episode 649.000000, reward total was -21.000000. running mean: -20.484024\n","resetting env. episode 650.000000, reward total was -21.000000. running mean: -20.489184\n","resetting env. episode 651.000000, reward total was -20.000000. running mean: -20.484292\n","resetting env. episode 652.000000, reward total was -21.000000. running mean: -20.489449\n","resetting env. episode 653.000000, reward total was -21.000000. running mean: -20.494555\n","resetting env. episode 654.000000, reward total was -21.000000. running mean: -20.499609\n","resetting env. episode 655.000000, reward total was -21.000000. running mean: -20.504613\n","resetting env. episode 656.000000, reward total was -21.000000. running mean: -20.509567\n","resetting env. episode 657.000000, reward total was -21.000000. running mean: -20.514471\n","resetting env. episode 658.000000, reward total was -18.000000. running mean: -20.489326\n","resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.494433\n","resetting env. episode 660.000000, reward total was -20.000000. running mean: -20.489489\n","resetting env. episode 661.000000, reward total was -21.000000. running mean: -20.494594\n","resetting env. episode 662.000000, reward total was -21.000000. running mean: -20.499648\n","resetting env. episode 663.000000, reward total was -19.000000. running mean: -20.484652\n","resetting env. episode 664.000000, reward total was -21.000000. running mean: -20.489805\n","resetting env. episode 665.000000, reward total was -20.000000. running mean: -20.484907\n","resetting env. episode 666.000000, reward total was -18.000000. running mean: -20.460058\n","resetting env. episode 667.000000, reward total was -19.000000. running mean: -20.445457\n","resetting env. episode 668.000000, reward total was -21.000000. running mean: -20.451003\n","resetting env. episode 669.000000, reward total was -21.000000. running mean: -20.456493\n","resetting env. episode 670.000000, reward total was -21.000000. running mean: -20.461928\n","resetting env. episode 671.000000, reward total was -21.000000. running mean: -20.467309\n","resetting env. episode 672.000000, reward total was -21.000000. running mean: -20.472635\n","resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.477909\n","resetting env. episode 674.000000, reward total was -21.000000. running mean: -20.483130\n","resetting env. episode 675.000000, reward total was -21.000000. running mean: -20.488299\n","resetting env. episode 676.000000, reward total was -21.000000. running mean: -20.493416\n","resetting env. episode 677.000000, reward total was -21.000000. running mean: -20.498482\n","resetting env. episode 678.000000, reward total was -21.000000. running mean: -20.503497\n","resetting env. episode 679.000000, reward total was -21.000000. running mean: -20.508462\n","resetting env. episode 680.000000, reward total was -19.000000. running mean: -20.493377\n","resetting env. episode 681.000000, reward total was -21.000000. running mean: -20.498443\n","resetting env. episode 682.000000, reward total was -21.000000. running mean: -20.503459\n","resetting env. episode 683.000000, reward total was -21.000000. running mean: -20.508424\n","resetting env. episode 684.000000, reward total was -21.000000. running mean: -20.513340\n","resetting env. episode 685.000000, reward total was -21.000000. running mean: -20.518207\n","resetting env. episode 686.000000, reward total was -20.000000. running mean: -20.513025\n","resetting env. episode 687.000000, reward total was -20.000000. running mean: -20.507894\n","resetting env. episode 688.000000, reward total was -21.000000. running mean: -20.512815\n","resetting env. episode 689.000000, reward total was -20.000000. running mean: -20.507687\n","resetting env. episode 690.000000, reward total was -21.000000. running mean: -20.512610\n","resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.517484\n","resetting env. episode 692.000000, reward total was -20.000000. running mean: -20.512309\n","resetting env. episode 693.000000, reward total was -20.000000. running mean: -20.507186\n","resetting env. episode 694.000000, reward total was -21.000000. running mean: -20.512115\n","resetting env. episode 695.000000, reward total was -21.000000. running mean: -20.516993\n","resetting env. episode 696.000000, reward total was -21.000000. running mean: -20.521823\n","resetting env. episode 697.000000, reward total was -20.000000. running mean: -20.516605\n","resetting env. episode 698.000000, reward total was -21.000000. running mean: -20.521439\n","resetting env. episode 699.000000, reward total was -20.000000. running mean: -20.516225\n","resetting env. episode 700.000000, reward total was -20.000000. running mean: -20.511062\n","resetting env. episode 701.000000, reward total was -21.000000. running mean: -20.515952\n","resetting env. episode 702.000000, reward total was -21.000000. running mean: -20.520792\n","resetting env. episode 703.000000, reward total was -21.000000. running mean: -20.525584\n","resetting env. episode 704.000000, reward total was -20.000000. running mean: -20.520329\n","resetting env. episode 705.000000, reward total was -21.000000. running mean: -20.525125\n","resetting env. episode 706.000000, reward total was -20.000000. running mean: -20.519874\n","resetting env. episode 707.000000, reward total was -21.000000. running mean: -20.524675\n","resetting env. episode 708.000000, reward total was -21.000000. running mean: -20.529429\n","resetting env. episode 709.000000, reward total was -21.000000. running mean: -20.534134\n","resetting env. episode 710.000000, reward total was -21.000000. running mean: -20.538793\n","resetting env. episode 711.000000, reward total was -21.000000. running mean: -20.543405\n","resetting env. episode 712.000000, reward total was -19.000000. running mean: -20.527971\n","resetting env. episode 713.000000, reward total was -20.000000. running mean: -20.522691\n","resetting env. episode 714.000000, reward total was -21.000000. running mean: -20.527464\n","resetting env. episode 715.000000, reward total was -21.000000. running mean: -20.532190\n","resetting env. episode 716.000000, reward total was -21.000000. running mean: -20.536868\n","resetting env. episode 717.000000, reward total was -21.000000. running mean: -20.541499\n","resetting env. episode 718.000000, reward total was -20.000000. running mean: -20.536084\n","resetting env. episode 719.000000, reward total was -19.000000. running mean: -20.520723\n","resetting env. episode 720.000000, reward total was -21.000000. running mean: -20.525516\n","resetting env. episode 721.000000, reward total was -21.000000. running mean: -20.530261\n","resetting env. episode 722.000000, reward total was -21.000000. running mean: -20.534958\n","resetting env. episode 723.000000, reward total was -21.000000. running mean: -20.539609\n","resetting env. episode 724.000000, reward total was -19.000000. running mean: -20.524213\n","resetting env. episode 725.000000, reward total was -21.000000. running mean: -20.528970\n","resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.533681\n","resetting env. episode 727.000000, reward total was -21.000000. running mean: -20.538344\n","resetting env. episode 728.000000, reward total was -21.000000. running mean: -20.542961\n","resetting env. episode 729.000000, reward total was -21.000000. running mean: -20.547531\n","resetting env. episode 730.000000, reward total was -21.000000. running mean: -20.552056\n","resetting env. episode 731.000000, reward total was -21.000000. running mean: -20.556535\n","resetting env. episode 732.000000, reward total was -20.000000. running mean: -20.550970\n","resetting env. episode 733.000000, reward total was -21.000000. running mean: -20.555460\n","resetting env. episode 734.000000, reward total was -21.000000. running mean: -20.559905\n","resetting env. episode 735.000000, reward total was -20.000000. running mean: -20.554306\n","resetting env. episode 736.000000, reward total was -21.000000. running mean: -20.558763\n","resetting env. episode 737.000000, reward total was -21.000000. running mean: -20.563176\n","resetting env. episode 738.000000, reward total was -21.000000. running mean: -20.567544\n","resetting env. episode 739.000000, reward total was -21.000000. running mean: -20.571868\n","resetting env. episode 740.000000, reward total was -21.000000. running mean: -20.576150\n","resetting env. episode 741.000000, reward total was -20.000000. running mean: -20.570388\n","resetting env. episode 742.000000, reward total was -19.000000. running mean: -20.554684\n","resetting env. episode 743.000000, reward total was -21.000000. running mean: -20.559138\n","resetting env. episode 744.000000, reward total was -21.000000. running mean: -20.563546\n","resetting env. episode 745.000000, reward total was -20.000000. running mean: -20.557911\n","resetting env. episode 746.000000, reward total was -20.000000. running mean: -20.552332\n","resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.556808\n","resetting env. episode 748.000000, reward total was -21.000000. running mean: -20.561240\n","resetting env. episode 749.000000, reward total was -21.000000. running mean: -20.565628\n","resetting env. episode 750.000000, reward total was -21.000000. running mean: -20.569972\n","resetting env. episode 751.000000, reward total was -20.000000. running mean: -20.564272\n","resetting env. episode 752.000000, reward total was -20.000000. running mean: -20.558629\n","resetting env. episode 753.000000, reward total was -21.000000. running mean: -20.563043\n","resetting env. episode 754.000000, reward total was -21.000000. running mean: -20.567412\n","resetting env. episode 755.000000, reward total was -21.000000. running mean: -20.571738\n","resetting env. episode 756.000000, reward total was -21.000000. running mean: -20.576021\n","resetting env. episode 757.000000, reward total was -21.000000. running mean: -20.580261\n","resetting env. episode 758.000000, reward total was -21.000000. running mean: -20.584458\n","resetting env. episode 759.000000, reward total was -21.000000. running mean: -20.588613\n","resetting env. episode 760.000000, reward total was -21.000000. running mean: -20.592727\n","resetting env. episode 761.000000, reward total was -21.000000. running mean: -20.596800\n","resetting env. episode 762.000000, reward total was -20.000000. running mean: -20.590832\n","resetting env. episode 763.000000, reward total was -20.000000. running mean: -20.584924\n","resetting env. episode 764.000000, reward total was -20.000000. running mean: -20.579075\n","resetting env. episode 765.000000, reward total was -17.000000. running mean: -20.543284\n","resetting env. episode 766.000000, reward total was -20.000000. running mean: -20.537851\n","resetting env. episode 767.000000, reward total was -21.000000. running mean: -20.542472\n","resetting env. episode 768.000000, reward total was -21.000000. running mean: -20.547048\n","resetting env. episode 769.000000, reward total was -21.000000. running mean: -20.551577\n","resetting env. episode 770.000000, reward total was -21.000000. running mean: -20.556061\n","resetting env. episode 771.000000, reward total was -21.000000. running mean: -20.560501\n","resetting env. episode 772.000000, reward total was -21.000000. running mean: -20.564896\n","resetting env. episode 773.000000, reward total was -21.000000. running mean: -20.569247\n","resetting env. episode 774.000000, reward total was -20.000000. running mean: -20.563554\n","resetting env. episode 775.000000, reward total was -19.000000. running mean: -20.547919\n","resetting env. episode 776.000000, reward total was -19.000000. running mean: -20.532440\n","resetting env. episode 777.000000, reward total was -21.000000. running mean: -20.537115\n","resetting env. episode 778.000000, reward total was -21.000000. running mean: -20.541744\n","resetting env. episode 779.000000, reward total was -21.000000. running mean: -20.546327\n","resetting env. episode 780.000000, reward total was -21.000000. running mean: -20.550863\n","resetting env. episode 781.000000, reward total was -21.000000. running mean: -20.555355\n","resetting env. episode 782.000000, reward total was -18.000000. running mean: -20.529801\n","resetting env. episode 783.000000, reward total was -21.000000. running mean: -20.534503\n","resetting env. episode 784.000000, reward total was -21.000000. running mean: -20.539158\n","resetting env. episode 785.000000, reward total was -18.000000. running mean: -20.513767\n","resetting env. episode 786.000000, reward total was -21.000000. running mean: -20.518629\n","resetting env. episode 787.000000, reward total was -21.000000. running mean: -20.523443\n","resetting env. episode 788.000000, reward total was -21.000000. running mean: -20.528208\n","resetting env. episode 789.000000, reward total was -21.000000. running mean: -20.532926\n","resetting env. episode 790.000000, reward total was -21.000000. running mean: -20.537597\n","resetting env. episode 791.000000, reward total was -21.000000. running mean: -20.542221\n","resetting env. episode 792.000000, reward total was -21.000000. running mean: -20.546799\n","resetting env. episode 793.000000, reward total was -21.000000. running mean: -20.551331\n","resetting env. episode 794.000000, reward total was -21.000000. running mean: -20.555817\n","resetting env. episode 795.000000, reward total was -21.000000. running mean: -20.560259\n","resetting env. episode 796.000000, reward total was -20.000000. running mean: -20.554657\n","resetting env. episode 797.000000, reward total was -21.000000. running mean: -20.559110\n","resetting env. episode 798.000000, reward total was -19.000000. running mean: -20.543519\n","resetting env. episode 799.000000, reward total was -21.000000. running mean: -20.548084\n","resetting env. episode 800.000000, reward total was -21.000000. running mean: -20.552603\n","resetting env. episode 801.000000, reward total was -21.000000. running mean: -20.557077\n","resetting env. episode 802.000000, reward total was -19.000000. running mean: -20.541506\n","resetting env. episode 803.000000, reward total was -21.000000. running mean: -20.546091\n","resetting env. episode 804.000000, reward total was -21.000000. running mean: -20.550630\n","resetting env. episode 805.000000, reward total was -21.000000. running mean: -20.555124\n","resetting env. episode 806.000000, reward total was -21.000000. running mean: -20.559573\n","resetting env. episode 807.000000, reward total was -21.000000. running mean: -20.563977\n","resetting env. episode 808.000000, reward total was -21.000000. running mean: -20.568337\n","resetting env. episode 809.000000, reward total was -21.000000. running mean: -20.572654\n","resetting env. episode 810.000000, reward total was -21.000000. running mean: -20.576927\n","resetting env. episode 811.000000, reward total was -21.000000. running mean: -20.581158\n","resetting env. episode 812.000000, reward total was -19.000000. running mean: -20.565346\n","resetting env. episode 813.000000, reward total was -21.000000. running mean: -20.569693\n","resetting env. episode 814.000000, reward total was -21.000000. running mean: -20.573996\n","resetting env. episode 815.000000, reward total was -21.000000. running mean: -20.578256\n","resetting env. episode 816.000000, reward total was -20.000000. running mean: -20.572473\n","resetting env. episode 817.000000, reward total was -20.000000. running mean: -20.566749\n","resetting env. episode 818.000000, reward total was -20.000000. running mean: -20.561081\n","resetting env. episode 819.000000, reward total was -19.000000. running mean: -20.545470\n","resetting env. episode 820.000000, reward total was -21.000000. running mean: -20.550016\n","resetting env. episode 821.000000, reward total was -21.000000. running mean: -20.554516\n","resetting env. episode 822.000000, reward total was -19.000000. running mean: -20.538970\n","resetting env. episode 823.000000, reward total was -21.000000. running mean: -20.543581\n","resetting env. episode 824.000000, reward total was -20.000000. running mean: -20.538145\n","resetting env. episode 825.000000, reward total was -19.000000. running mean: -20.522763\n","resetting env. episode 826.000000, reward total was -21.000000. running mean: -20.527536\n","resetting env. episode 827.000000, reward total was -19.000000. running mean: -20.512260\n","resetting env. episode 828.000000, reward total was -21.000000. running mean: -20.517138\n","resetting env. episode 829.000000, reward total was -21.000000. running mean: -20.521966\n","resetting env. episode 830.000000, reward total was -21.000000. running mean: -20.526747\n","resetting env. episode 831.000000, reward total was -21.000000. running mean: -20.531479\n","resetting env. episode 832.000000, reward total was -20.000000. running mean: -20.526165\n","resetting env. episode 833.000000, reward total was -20.000000. running mean: -20.520903\n","resetting env. episode 834.000000, reward total was -21.000000. running mean: -20.525694\n","resetting env. episode 835.000000, reward total was -21.000000. running mean: -20.530437\n","resetting env. episode 836.000000, reward total was -21.000000. running mean: -20.535133\n","resetting env. episode 837.000000, reward total was -20.000000. running mean: -20.529781\n","resetting env. episode 838.000000, reward total was -20.000000. running mean: -20.524483\n","resetting env. episode 839.000000, reward total was -21.000000. running mean: -20.529239\n","resetting env. episode 840.000000, reward total was -20.000000. running mean: -20.523946\n","resetting env. episode 841.000000, reward total was -20.000000. running mean: -20.518707\n","resetting env. episode 842.000000, reward total was -20.000000. running mean: -20.513520\n","resetting env. episode 843.000000, reward total was -21.000000. running mean: -20.518384\n","resetting env. episode 844.000000, reward total was -20.000000. running mean: -20.513201\n","resetting env. episode 845.000000, reward total was -19.000000. running mean: -20.498069\n","resetting env. episode 846.000000, reward total was -21.000000. running mean: -20.503088\n","resetting env. episode 847.000000, reward total was -21.000000. running mean: -20.508057\n","resetting env. episode 848.000000, reward total was -20.000000. running mean: -20.502976\n","resetting env. episode 849.000000, reward total was -21.000000. running mean: -20.507947\n","resetting env. episode 850.000000, reward total was -21.000000. running mean: -20.512867\n","resetting env. episode 851.000000, reward total was -21.000000. running mean: -20.517739\n","resetting env. episode 852.000000, reward total was -20.000000. running mean: -20.512561\n","resetting env. episode 853.000000, reward total was -21.000000. running mean: -20.517436\n","resetting env. episode 854.000000, reward total was -21.000000. running mean: -20.522261\n","resetting env. episode 855.000000, reward total was -21.000000. running mean: -20.527039\n","resetting env. episode 856.000000, reward total was -19.000000. running mean: -20.511768\n","resetting env. episode 857.000000, reward total was -20.000000. running mean: -20.506651\n","resetting env. episode 858.000000, reward total was -18.000000. running mean: -20.481584\n","resetting env. episode 859.000000, reward total was -21.000000. running mean: -20.486768\n","resetting env. episode 860.000000, reward total was -21.000000. running mean: -20.491901\n","resetting env. episode 861.000000, reward total was -21.000000. running mean: -20.496982\n","resetting env. episode 862.000000, reward total was -21.000000. running mean: -20.502012\n","resetting env. episode 863.000000, reward total was -21.000000. running mean: -20.506992\n","resetting env. episode 864.000000, reward total was -21.000000. running mean: -20.511922\n","resetting env. episode 865.000000, reward total was -21.000000. running mean: -20.516802\n","resetting env. episode 866.000000, reward total was -21.000000. running mean: -20.521634\n","resetting env. episode 867.000000, reward total was -19.000000. running mean: -20.506418\n","resetting env. episode 868.000000, reward total was -19.000000. running mean: -20.491354\n","resetting env. episode 869.000000, reward total was -21.000000. running mean: -20.496440\n","resetting env. episode 870.000000, reward total was -21.000000. running mean: -20.501476\n","resetting env. episode 871.000000, reward total was -20.000000. running mean: -20.496461\n","resetting env. episode 872.000000, reward total was -19.000000. running mean: -20.481497\n","resetting env. episode 873.000000, reward total was -20.000000. running mean: -20.476682\n","resetting env. episode 874.000000, reward total was -21.000000. running mean: -20.481915\n","resetting env. episode 875.000000, reward total was -19.000000. running mean: -20.467096\n","resetting env. episode 876.000000, reward total was -21.000000. running mean: -20.472425\n","resetting env. episode 877.000000, reward total was -21.000000. running mean: -20.477700\n","resetting env. episode 878.000000, reward total was -19.000000. running mean: -20.462923\n","resetting env. episode 879.000000, reward total was -21.000000. running mean: -20.468294\n","resetting env. episode 880.000000, reward total was -21.000000. running mean: -20.473611\n","resetting env. episode 881.000000, reward total was -20.000000. running mean: -20.468875\n","resetting env. episode 882.000000, reward total was -19.000000. running mean: -20.454186\n","resetting env. episode 883.000000, reward total was -21.000000. running mean: -20.459645\n","resetting env. episode 884.000000, reward total was -21.000000. running mean: -20.465048\n","resetting env. episode 885.000000, reward total was -21.000000. running mean: -20.470398\n","resetting env. episode 886.000000, reward total was -21.000000. running mean: -20.475694\n","resetting env. episode 887.000000, reward total was -21.000000. running mean: -20.480937\n","resetting env. episode 888.000000, reward total was -20.000000. running mean: -20.476127\n","resetting env. episode 889.000000, reward total was -21.000000. running mean: -20.481366\n","resetting env. episode 890.000000, reward total was -20.000000. running mean: -20.476552\n","resetting env. episode 891.000000, reward total was -21.000000. running mean: -20.481787\n","resetting env. episode 892.000000, reward total was -21.000000. running mean: -20.486969\n","resetting env. episode 893.000000, reward total was -21.000000. running mean: -20.492099\n","resetting env. episode 894.000000, reward total was -21.000000. running mean: -20.497178\n","resetting env. episode 895.000000, reward total was -21.000000. running mean: -20.502207\n","resetting env. episode 896.000000, reward total was -21.000000. running mean: -20.507184\n","resetting env. episode 897.000000, reward total was -21.000000. running mean: -20.512113\n","resetting env. episode 898.000000, reward total was -20.000000. running mean: -20.506992\n","resetting env. episode 899.000000, reward total was -20.000000. running mean: -20.501922\n","resetting env. episode 900.000000, reward total was -19.000000. running mean: -20.486902\n","resetting env. episode 901.000000, reward total was -21.000000. running mean: -20.492033\n","resetting env. episode 902.000000, reward total was -21.000000. running mean: -20.497113\n","resetting env. episode 903.000000, reward total was -18.000000. running mean: -20.472142\n","resetting env. episode 904.000000, reward total was -20.000000. running mean: -20.467420\n","resetting env. episode 905.000000, reward total was -18.000000. running mean: -20.442746\n","resetting env. episode 906.000000, reward total was -21.000000. running mean: -20.448319\n","resetting env. episode 907.000000, reward total was -19.000000. running mean: -20.433836\n","resetting env. episode 908.000000, reward total was -20.000000. running mean: -20.429497\n","resetting env. episode 909.000000, reward total was -21.000000. running mean: -20.435202\n","resetting env. episode 910.000000, reward total was -21.000000. running mean: -20.440850\n","resetting env. episode 911.000000, reward total was -19.000000. running mean: -20.426442\n","resetting env. episode 912.000000, reward total was -21.000000. running mean: -20.432177\n","resetting env. episode 913.000000, reward total was -20.000000. running mean: -20.427856\n","resetting env. episode 914.000000, reward total was -21.000000. running mean: -20.433577\n","resetting env. episode 915.000000, reward total was -21.000000. running mean: -20.439241\n","resetting env. episode 916.000000, reward total was -20.000000. running mean: -20.434849\n","resetting env. episode 917.000000, reward total was -20.000000. running mean: -20.430500\n","resetting env. episode 918.000000, reward total was -21.000000. running mean: -20.436195\n","resetting env. episode 919.000000, reward total was -20.000000. running mean: -20.431833\n","resetting env. episode 920.000000, reward total was -21.000000. running mean: -20.437515\n","resetting env. episode 921.000000, reward total was -21.000000. running mean: -20.443140\n","resetting env. episode 922.000000, reward total was -21.000000. running mean: -20.448709\n","resetting env. episode 923.000000, reward total was -21.000000. running mean: -20.454221\n","resetting env. episode 924.000000, reward total was -19.000000. running mean: -20.439679\n","resetting env. episode 925.000000, reward total was -21.000000. running mean: -20.445282\n","resetting env. episode 926.000000, reward total was -21.000000. running mean: -20.450830\n","resetting env. episode 927.000000, reward total was -21.000000. running mean: -20.456321\n","resetting env. episode 928.000000, reward total was -20.000000. running mean: -20.451758\n","resetting env. episode 929.000000, reward total was -20.000000. running mean: -20.447240\n","resetting env. episode 930.000000, reward total was -19.000000. running mean: -20.432768\n","resetting env. episode 931.000000, reward total was -20.000000. running mean: -20.428440\n","resetting env. episode 932.000000, reward total was -21.000000. running mean: -20.434156\n","resetting env. episode 933.000000, reward total was -20.000000. running mean: -20.429814\n","resetting env. episode 934.000000, reward total was -21.000000. running mean: -20.435516\n","resetting env. episode 935.000000, reward total was -21.000000. running mean: -20.441161\n","resetting env. episode 936.000000, reward total was -21.000000. running mean: -20.446750\n","resetting env. episode 937.000000, reward total was -21.000000. running mean: -20.452282\n","resetting env. episode 938.000000, reward total was -21.000000. running mean: -20.457759\n","resetting env. episode 939.000000, reward total was -21.000000. running mean: -20.463182\n","resetting env. episode 940.000000, reward total was -21.000000. running mean: -20.468550\n","resetting env. episode 941.000000, reward total was -21.000000. running mean: -20.473864\n","resetting env. episode 942.000000, reward total was -21.000000. running mean: -20.479126\n","resetting env. episode 943.000000, reward total was -21.000000. running mean: -20.484334\n","resetting env. episode 944.000000, reward total was -20.000000. running mean: -20.479491\n","resetting env. episode 945.000000, reward total was -20.000000. running mean: -20.474696\n","resetting env. episode 946.000000, reward total was -21.000000. running mean: -20.479949\n","resetting env. episode 947.000000, reward total was -21.000000. running mean: -20.485150\n","resetting env. episode 948.000000, reward total was -21.000000. running mean: -20.490298\n","resetting env. episode 949.000000, reward total was -21.000000. running mean: -20.495395\n","resetting env. episode 950.000000, reward total was -20.000000. running mean: -20.490441\n","resetting env. episode 951.000000, reward total was -21.000000. running mean: -20.495537\n","resetting env. episode 952.000000, reward total was -19.000000. running mean: -20.480581\n","resetting env. episode 953.000000, reward total was -21.000000. running mean: -20.485776\n","resetting env. episode 954.000000, reward total was -21.000000. running mean: -20.490918\n","resetting env. episode 955.000000, reward total was -20.000000. running mean: -20.486009\n","resetting env. episode 956.000000, reward total was -21.000000. running mean: -20.491149\n","resetting env. episode 957.000000, reward total was -21.000000. running mean: -20.496237\n","resetting env. episode 958.000000, reward total was -21.000000. running mean: -20.501275\n","resetting env. episode 959.000000, reward total was -20.000000. running mean: -20.496262\n","resetting env. episode 960.000000, reward total was -20.000000. running mean: -20.491299\n","resetting env. episode 961.000000, reward total was -20.000000. running mean: -20.486386\n","resetting env. episode 962.000000, reward total was -21.000000. running mean: -20.491523\n","resetting env. episode 963.000000, reward total was -21.000000. running mean: -20.496607\n","resetting env. episode 964.000000, reward total was -21.000000. running mean: -20.501641\n","resetting env. episode 965.000000, reward total was -21.000000. running mean: -20.506625\n","resetting env. episode 966.000000, reward total was -21.000000. running mean: -20.511559\n","resetting env. episode 967.000000, reward total was -21.000000. running mean: -20.516443\n","resetting env. episode 968.000000, reward total was -19.000000. running mean: -20.501279\n","resetting env. episode 969.000000, reward total was -21.000000. running mean: -20.506266\n","resetting env. episode 970.000000, reward total was -19.000000. running mean: -20.491203\n","resetting env. episode 971.000000, reward total was -20.000000. running mean: -20.486291\n","resetting env. episode 972.000000, reward total was -21.000000. running mean: -20.491428\n","resetting env. episode 973.000000, reward total was -20.000000. running mean: -20.486514\n","resetting env. episode 974.000000, reward total was -21.000000. running mean: -20.491649\n","resetting env. episode 975.000000, reward total was -21.000000. running mean: -20.496732\n","resetting env. episode 976.000000, reward total was -21.000000. running mean: -20.501765\n","resetting env. episode 977.000000, reward total was -21.000000. running mean: -20.506747\n","resetting env. episode 978.000000, reward total was -21.000000. running mean: -20.511680\n","resetting env. episode 979.000000, reward total was -20.000000. running mean: -20.506563\n","resetting env. episode 980.000000, reward total was -21.000000. running mean: -20.511497\n","resetting env. episode 981.000000, reward total was -21.000000. running mean: -20.516382\n","resetting env. episode 982.000000, reward total was -21.000000. running mean: -20.521219\n","resetting env. episode 983.000000, reward total was -19.000000. running mean: -20.506006\n","resetting env. episode 984.000000, reward total was -21.000000. running mean: -20.510946\n","resetting env. episode 985.000000, reward total was -21.000000. running mean: -20.515837\n","resetting env. episode 986.000000, reward total was -20.000000. running mean: -20.510679\n","resetting env. episode 987.000000, reward total was -21.000000. running mean: -20.515572\n","resetting env. episode 988.000000, reward total was -21.000000. running mean: -20.520416\n","resetting env. episode 989.000000, reward total was -20.000000. running mean: -20.515212\n","resetting env. episode 990.000000, reward total was -20.000000. running mean: -20.510060\n","resetting env. episode 991.000000, reward total was -21.000000. running mean: -20.514959\n","resetting env. episode 992.000000, reward total was -21.000000. running mean: -20.519810\n","resetting env. episode 993.000000, reward total was -19.000000. running mean: -20.504611\n","resetting env. episode 994.000000, reward total was -21.000000. running mean: -20.509565\n","resetting env. episode 995.000000, reward total was -21.000000. running mean: -20.514470\n","resetting env. episode 996.000000, reward total was -21.000000. running mean: -20.519325\n","resetting env. episode 997.000000, reward total was -21.000000. running mean: -20.524132\n","resetting env. episode 998.000000, reward total was -21.000000. running mean: -20.528890\n","resetting env. episode 999.000000, reward total was -20.000000. running mean: -20.523602\n","resetting env. episode 1000.000000, reward total was -20.000000. running mean: -20.518366\n","resetting env. episode 1001.000000, reward total was -21.000000. running mean: -20.523182\n","resetting env. episode 1002.000000, reward total was -21.000000. running mean: -20.527950\n","resetting env. episode 1003.000000, reward total was -21.000000. running mean: -20.532671\n","resetting env. episode 1004.000000, reward total was -21.000000. running mean: -20.537344\n","resetting env. episode 1005.000000, reward total was -21.000000. running mean: -20.541970\n","resetting env. episode 1006.000000, reward total was -20.000000. running mean: -20.536551\n","resetting env. episode 1007.000000, reward total was -20.000000. running mean: -20.531185\n","resetting env. episode 1008.000000, reward total was -18.000000. running mean: -20.505873\n","resetting env. episode 1009.000000, reward total was -21.000000. running mean: -20.510815\n","resetting env. episode 1010.000000, reward total was -18.000000. running mean: -20.485706\n","resetting env. episode 1011.000000, reward total was -19.000000. running mean: -20.470849\n","resetting env. episode 1012.000000, reward total was -21.000000. running mean: -20.476141\n","resetting env. episode 1013.000000, reward total was -20.000000. running mean: -20.471379\n","resetting env. episode 1014.000000, reward total was -20.000000. running mean: -20.466666\n","resetting env. episode 1015.000000, reward total was -21.000000. running mean: -20.471999\n","resetting env. episode 1016.000000, reward total was -21.000000. running mean: -20.477279\n","resetting env. episode 1017.000000, reward total was -20.000000. running mean: -20.472506\n","resetting env. episode 1018.000000, reward total was -21.000000. running mean: -20.477781\n","resetting env. episode 1019.000000, reward total was -21.000000. running mean: -20.483003\n","resetting env. episode 1020.000000, reward total was -20.000000. running mean: -20.478173\n","resetting env. episode 1021.000000, reward total was -21.000000. running mean: -20.483392\n","resetting env. episode 1022.000000, reward total was -21.000000. running mean: -20.488558\n","resetting env. episode 1023.000000, reward total was -20.000000. running mean: -20.483672\n","resetting env. episode 1024.000000, reward total was -21.000000. running mean: -20.488835\n","resetting env. episode 1025.000000, reward total was -21.000000. running mean: -20.493947\n","resetting env. episode 1026.000000, reward total was -19.000000. running mean: -20.479008\n","resetting env. episode 1027.000000, reward total was -20.000000. running mean: -20.474218\n","resetting env. episode 1028.000000, reward total was -21.000000. running mean: -20.479475\n","resetting env. episode 1029.000000, reward total was -21.000000. running mean: -20.484681\n","resetting env. episode 1030.000000, reward total was -20.000000. running mean: -20.479834\n","resetting env. episode 1031.000000, reward total was -20.000000. running mean: -20.475035\n","resetting env. episode 1032.000000, reward total was -21.000000. running mean: -20.480285\n","resetting env. episode 1033.000000, reward total was -21.000000. running mean: -20.485482\n","resetting env. episode 1034.000000, reward total was -19.000000. running mean: -20.470627\n","resetting env. episode 1035.000000, reward total was -21.000000. running mean: -20.475921\n","resetting env. episode 1036.000000, reward total was -21.000000. running mean: -20.481162\n","resetting env. episode 1037.000000, reward total was -18.000000. running mean: -20.456350\n","resetting env. episode 1038.000000, reward total was -21.000000. running mean: -20.461787\n","resetting env. episode 1039.000000, reward total was -21.000000. running mean: -20.467169\n","resetting env. episode 1040.000000, reward total was -21.000000. running mean: -20.472497\n","resetting env. episode 1041.000000, reward total was -21.000000. running mean: -20.477772\n","resetting env. episode 1042.000000, reward total was -20.000000. running mean: -20.472995\n","resetting env. episode 1043.000000, reward total was -21.000000. running mean: -20.478265\n","resetting env. episode 1044.000000, reward total was -21.000000. running mean: -20.483482\n","resetting env. episode 1045.000000, reward total was -21.000000. running mean: -20.488647\n","resetting env. episode 1046.000000, reward total was -17.000000. running mean: -20.453761\n","resetting env. episode 1047.000000, reward total was -21.000000. running mean: -20.459223\n","resetting env. episode 1048.000000, reward total was -17.000000. running mean: -20.424631\n","resetting env. episode 1049.000000, reward total was -21.000000. running mean: -20.430385\n","resetting env. episode 1050.000000, reward total was -20.000000. running mean: -20.426081\n","resetting env. episode 1051.000000, reward total was -20.000000. running mean: -20.421820\n","resetting env. episode 1052.000000, reward total was -21.000000. running mean: -20.427602\n","resetting env. episode 1053.000000, reward total was -20.000000. running mean: -20.423326\n","resetting env. episode 1054.000000, reward total was -16.000000. running mean: -20.379092\n","resetting env. episode 1055.000000, reward total was -21.000000. running mean: -20.385301\n","resetting env. episode 1056.000000, reward total was -21.000000. running mean: -20.391448\n","resetting env. episode 1057.000000, reward total was -21.000000. running mean: -20.397534\n","resetting env. episode 1058.000000, reward total was -18.000000. running mean: -20.373559\n","resetting env. episode 1059.000000, reward total was -20.000000. running mean: -20.369823\n","resetting env. episode 1060.000000, reward total was -21.000000. running mean: -20.376125\n","resetting env. episode 1061.000000, reward total was -20.000000. running mean: -20.372364\n","resetting env. episode 1062.000000, reward total was -21.000000. running mean: -20.378640\n","resetting env. episode 1063.000000, reward total was -21.000000. running mean: -20.384854\n","resetting env. episode 1064.000000, reward total was -21.000000. running mean: -20.391005\n","resetting env. episode 1065.000000, reward total was -20.000000. running mean: -20.387095\n","resetting env. episode 1066.000000, reward total was -20.000000. running mean: -20.383224\n","resetting env. episode 1067.000000, reward total was -20.000000. running mean: -20.379392\n","resetting env. episode 1068.000000, reward total was -21.000000. running mean: -20.385598\n","resetting env. episode 1069.000000, reward total was -21.000000. running mean: -20.391742\n","resetting env. episode 1070.000000, reward total was -21.000000. running mean: -20.397824\n","resetting env. episode 1071.000000, reward total was -21.000000. running mean: -20.403846\n","resetting env. episode 1072.000000, reward total was -21.000000. running mean: -20.409808\n","resetting env. episode 1073.000000, reward total was -21.000000. running mean: -20.415710\n","resetting env. episode 1074.000000, reward total was -20.000000. running mean: -20.411553\n","resetting env. episode 1075.000000, reward total was -21.000000. running mean: -20.417437\n","resetting env. episode 1076.000000, reward total was -21.000000. running mean: -20.423263\n","resetting env. episode 1077.000000, reward total was -21.000000. running mean: -20.429030\n","resetting env. episode 1078.000000, reward total was -21.000000. running mean: -20.434740\n","resetting env. episode 1079.000000, reward total was -21.000000. running mean: -20.440392\n","resetting env. episode 1080.000000, reward total was -20.000000. running mean: -20.435988\n","resetting env. episode 1081.000000, reward total was -20.000000. running mean: -20.431629\n","resetting env. episode 1082.000000, reward total was -20.000000. running mean: -20.427312\n","resetting env. episode 1083.000000, reward total was -20.000000. running mean: -20.423039\n","resetting env. episode 1084.000000, reward total was -21.000000. running mean: -20.428809\n","resetting env. episode 1085.000000, reward total was -21.000000. running mean: -20.434521\n","resetting env. episode 1086.000000, reward total was -21.000000. running mean: -20.440175\n","resetting env. episode 1087.000000, reward total was -20.000000. running mean: -20.435774\n","resetting env. episode 1088.000000, reward total was -21.000000. running mean: -20.441416\n","resetting env. episode 1089.000000, reward total was -20.000000. running mean: -20.437002\n","resetting env. episode 1090.000000, reward total was -20.000000. running mean: -20.432632\n","resetting env. episode 1091.000000, reward total was -19.000000. running mean: -20.418305\n","resetting env. episode 1092.000000, reward total was -20.000000. running mean: -20.414122\n","resetting env. episode 1093.000000, reward total was -21.000000. running mean: -20.419981\n","resetting env. episode 1094.000000, reward total was -21.000000. running mean: -20.425781\n","resetting env. episode 1095.000000, reward total was -18.000000. running mean: -20.401524\n","resetting env. episode 1096.000000, reward total was -20.000000. running mean: -20.397508\n","resetting env. episode 1097.000000, reward total was -21.000000. running mean: -20.403533\n","resetting env. episode 1098.000000, reward total was -21.000000. running mean: -20.409498\n","resetting env. episode 1099.000000, reward total was -21.000000. running mean: -20.415403\n","resetting env. episode 1100.000000, reward total was -20.000000. running mean: -20.411249\n","resetting env. episode 1101.000000, reward total was -21.000000. running mean: -20.417136\n","resetting env. episode 1102.000000, reward total was -20.000000. running mean: -20.412965\n","resetting env. episode 1103.000000, reward total was -21.000000. running mean: -20.418835\n","resetting env. episode 1104.000000, reward total was -20.000000. running mean: -20.414647\n","resetting env. episode 1105.000000, reward total was -20.000000. running mean: -20.410501\n","resetting env. episode 1106.000000, reward total was -20.000000. running mean: -20.406396\n","resetting env. episode 1107.000000, reward total was -21.000000. running mean: -20.412332\n","resetting env. episode 1108.000000, reward total was -21.000000. running mean: -20.418208\n","resetting env. episode 1109.000000, reward total was -20.000000. running mean: -20.414026\n","resetting env. episode 1110.000000, reward total was -21.000000. running mean: -20.419886\n","resetting env. episode 1111.000000, reward total was -20.000000. running mean: -20.415687\n","resetting env. episode 1112.000000, reward total was -21.000000. running mean: -20.421530\n","resetting env. episode 1113.000000, reward total was -20.000000. running mean: -20.417315\n","resetting env. episode 1114.000000, reward total was -19.000000. running mean: -20.403142\n","resetting env. episode 1115.000000, reward total was -21.000000. running mean: -20.409110\n","resetting env. episode 1116.000000, reward total was -21.000000. running mean: -20.415019\n","resetting env. episode 1117.000000, reward total was -21.000000. running mean: -20.420869\n","resetting env. episode 1118.000000, reward total was -20.000000. running mean: -20.416660\n","resetting env. episode 1119.000000, reward total was -20.000000. running mean: -20.412494\n","resetting env. episode 1120.000000, reward total was -21.000000. running mean: -20.418369\n","resetting env. episode 1121.000000, reward total was -21.000000. running mean: -20.424185\n","resetting env. episode 1122.000000, reward total was -21.000000. running mean: -20.429943\n","resetting env. episode 1123.000000, reward total was -20.000000. running mean: -20.425644\n","resetting env. episode 1124.000000, reward total was -20.000000. running mean: -20.421387\n","resetting env. episode 1125.000000, reward total was -20.000000. running mean: -20.417174\n","resetting env. episode 1126.000000, reward total was -19.000000. running mean: -20.403002\n","resetting env. episode 1127.000000, reward total was -21.000000. running mean: -20.408972\n","resetting env. episode 1128.000000, reward total was -21.000000. running mean: -20.414882\n","resetting env. episode 1129.000000, reward total was -21.000000. running mean: -20.420733\n","resetting env. episode 1130.000000, reward total was -21.000000. running mean: -20.426526\n","resetting env. episode 1131.000000, reward total was -21.000000. running mean: -20.432261\n","resetting env. episode 1132.000000, reward total was -20.000000. running mean: -20.427938\n","resetting env. episode 1133.000000, reward total was -20.000000. running mean: -20.423659\n","resetting env. episode 1134.000000, reward total was -21.000000. running mean: -20.429422\n","resetting env. episode 1135.000000, reward total was -21.000000. running mean: -20.435128\n","resetting env. episode 1136.000000, reward total was -21.000000. running mean: -20.440777\n","resetting env. episode 1137.000000, reward total was -18.000000. running mean: -20.416369\n","resetting env. episode 1138.000000, reward total was -19.000000. running mean: -20.402205\n","resetting env. episode 1139.000000, reward total was -21.000000. running mean: -20.408183\n","resetting env. episode 1140.000000, reward total was -20.000000. running mean: -20.404101\n","resetting env. episode 1141.000000, reward total was -20.000000. running mean: -20.400060\n","resetting env. episode 1142.000000, reward total was -20.000000. running mean: -20.396060\n","resetting env. episode 1143.000000, reward total was -21.000000. running mean: -20.402099\n","resetting env. episode 1144.000000, reward total was -21.000000. running mean: -20.408078\n","resetting env. episode 1145.000000, reward total was -21.000000. running mean: -20.413997\n","resetting env. episode 1146.000000, reward total was -20.000000. running mean: -20.409857\n","resetting env. episode 1147.000000, reward total was -20.000000. running mean: -20.405759\n","resetting env. episode 1148.000000, reward total was -20.000000. running mean: -20.401701\n","resetting env. episode 1149.000000, reward total was -20.000000. running mean: -20.397684\n","resetting env. episode 1150.000000, reward total was -21.000000. running mean: -20.403707\n","resetting env. episode 1151.000000, reward total was -21.000000. running mean: -20.409670\n","resetting env. episode 1152.000000, reward total was -21.000000. running mean: -20.415573\n","resetting env. episode 1153.000000, reward total was -20.000000. running mean: -20.411418\n","resetting env. episode 1154.000000, reward total was -20.000000. running mean: -20.407304\n","resetting env. episode 1155.000000, reward total was -20.000000. running mean: -20.403231\n","resetting env. episode 1156.000000, reward total was -21.000000. running mean: -20.409198\n","resetting env. episode 1157.000000, reward total was -20.000000. running mean: -20.405106\n","resetting env. episode 1158.000000, reward total was -21.000000. running mean: -20.411055\n","resetting env. episode 1159.000000, reward total was -19.000000. running mean: -20.396945\n","resetting env. episode 1160.000000, reward total was -20.000000. running mean: -20.392975\n","resetting env. episode 1161.000000, reward total was -21.000000. running mean: -20.399045\n","resetting env. episode 1162.000000, reward total was -21.000000. running mean: -20.405055\n","resetting env. episode 1163.000000, reward total was -21.000000. running mean: -20.411004\n","resetting env. episode 1164.000000, reward total was -21.000000. running mean: -20.416894\n","resetting env. episode 1165.000000, reward total was -19.000000. running mean: -20.402725\n","resetting env. episode 1166.000000, reward total was -21.000000. running mean: -20.408698\n","resetting env. episode 1167.000000, reward total was -21.000000. running mean: -20.414611\n","resetting env. episode 1168.000000, reward total was -20.000000. running mean: -20.410465\n","resetting env. episode 1169.000000, reward total was -21.000000. running mean: -20.416360\n","resetting env. episode 1170.000000, reward total was -19.000000. running mean: -20.402197\n","resetting env. episode 1171.000000, reward total was -20.000000. running mean: -20.398175\n","resetting env. episode 1172.000000, reward total was -19.000000. running mean: -20.384193\n","resetting env. episode 1173.000000, reward total was -21.000000. running mean: -20.390351\n","resetting env. episode 1174.000000, reward total was -20.000000. running mean: -20.386448\n","resetting env. episode 1175.000000, reward total was -21.000000. running mean: -20.392583\n","resetting env. episode 1176.000000, reward total was -21.000000. running mean: -20.398657\n","resetting env. episode 1177.000000, reward total was -19.000000. running mean: -20.384671\n","resetting env. episode 1178.000000, reward total was -21.000000. running mean: -20.390824\n","resetting env. episode 1179.000000, reward total was -20.000000. running mean: -20.386916\n","resetting env. episode 1180.000000, reward total was -21.000000. running mean: -20.393047\n","resetting env. episode 1181.000000, reward total was -21.000000. running mean: -20.399116\n","resetting env. episode 1182.000000, reward total was -20.000000. running mean: -20.395125\n","resetting env. episode 1183.000000, reward total was -20.000000. running mean: -20.391174\n","resetting env. episode 1184.000000, reward total was -18.000000. running mean: -20.367262\n","resetting env. episode 1185.000000, reward total was -21.000000. running mean: -20.373589\n","resetting env. episode 1186.000000, reward total was -21.000000. running mean: -20.379854\n","resetting env. episode 1187.000000, reward total was -20.000000. running mean: -20.376055\n","resetting env. episode 1188.000000, reward total was -18.000000. running mean: -20.352294\n","resetting env. episode 1189.000000, reward total was -21.000000. running mean: -20.358772\n","resetting env. episode 1190.000000, reward total was -20.000000. running mean: -20.355184\n","resetting env. episode 1191.000000, reward total was -21.000000. running mean: -20.361632\n","resetting env. episode 1192.000000, reward total was -21.000000. running mean: -20.368016\n","resetting env. episode 1193.000000, reward total was -21.000000. running mean: -20.374336\n","resetting env. episode 1194.000000, reward total was -21.000000. running mean: -20.380592\n","resetting env. episode 1195.000000, reward total was -21.000000. running mean: -20.386786\n","resetting env. episode 1196.000000, reward total was -19.000000. running mean: -20.372918\n","resetting env. episode 1197.000000, reward total was -21.000000. running mean: -20.379189\n","resetting env. episode 1198.000000, reward total was -20.000000. running mean: -20.375397\n","resetting env. episode 1199.000000, reward total was -21.000000. running mean: -20.381643\n","resetting env. episode 1200.000000, reward total was -21.000000. running mean: -20.387827\n","resetting env. episode 1201.000000, reward total was -18.000000. running mean: -20.363949\n","resetting env. episode 1202.000000, reward total was -19.000000. running mean: -20.350309\n","resetting env. episode 1203.000000, reward total was -21.000000. running mean: -20.356806\n","resetting env. episode 1204.000000, reward total was -21.000000. running mean: -20.363238\n","resetting env. episode 1205.000000, reward total was -19.000000. running mean: -20.349606\n","resetting env. episode 1206.000000, reward total was -21.000000. running mean: -20.356110\n","resetting env. episode 1207.000000, reward total was -18.000000. running mean: -20.332548\n","resetting env. episode 1208.000000, reward total was -21.000000. running mean: -20.339223\n","resetting env. episode 1209.000000, reward total was -21.000000. running mean: -20.345831\n","resetting env. episode 1210.000000, reward total was -21.000000. running mean: -20.352372\n","resetting env. episode 1211.000000, reward total was -21.000000. running mean: -20.358849\n","resetting env. episode 1212.000000, reward total was -21.000000. running mean: -20.365260\n","resetting env. episode 1213.000000, reward total was -21.000000. running mean: -20.371608\n","resetting env. episode 1214.000000, reward total was -21.000000. running mean: -20.377892\n","resetting env. episode 1215.000000, reward total was -21.000000. running mean: -20.384113\n","resetting env. episode 1216.000000, reward total was -21.000000. running mean: -20.390271\n","resetting env. episode 1217.000000, reward total was -21.000000. running mean: -20.396369\n","resetting env. episode 1218.000000, reward total was -20.000000. running mean: -20.392405\n","resetting env. episode 1219.000000, reward total was -20.000000. running mean: -20.388481\n","resetting env. episode 1220.000000, reward total was -21.000000. running mean: -20.394596\n","resetting env. episode 1221.000000, reward total was -21.000000. running mean: -20.400650\n","resetting env. episode 1222.000000, reward total was -19.000000. running mean: -20.386644\n","resetting env. episode 1223.000000, reward total was -21.000000. running mean: -20.392777\n","resetting env. episode 1224.000000, reward total was -21.000000. running mean: -20.398850\n","resetting env. episode 1225.000000, reward total was -19.000000. running mean: -20.384861\n","resetting env. episode 1226.000000, reward total was -21.000000. running mean: -20.391012\n","resetting env. episode 1227.000000, reward total was -20.000000. running mean: -20.387102\n","resetting env. episode 1228.000000, reward total was -20.000000. running mean: -20.383231\n","resetting env. episode 1229.000000, reward total was -21.000000. running mean: -20.389399\n","resetting env. episode 1230.000000, reward total was -21.000000. running mean: -20.395505\n","resetting env. episode 1231.000000, reward total was -21.000000. running mean: -20.401550\n","resetting env. episode 1232.000000, reward total was -20.000000. running mean: -20.397534\n","resetting env. episode 1233.000000, reward total was -21.000000. running mean: -20.403559\n","resetting env. episode 1234.000000, reward total was -20.000000. running mean: -20.399524\n","resetting env. episode 1235.000000, reward total was -20.000000. running mean: -20.395528\n","resetting env. episode 1236.000000, reward total was -20.000000. running mean: -20.391573\n","resetting env. episode 1237.000000, reward total was -21.000000. running mean: -20.397657\n","resetting env. episode 1238.000000, reward total was -19.000000. running mean: -20.383681\n","resetting env. episode 1239.000000, reward total was -21.000000. running mean: -20.389844\n","resetting env. episode 1240.000000, reward total was -20.000000. running mean: -20.385945\n","resetting env. episode 1241.000000, reward total was -18.000000. running mean: -20.362086\n","resetting env. episode 1242.000000, reward total was -20.000000. running mean: -20.358465\n","resetting env. episode 1243.000000, reward total was -20.000000. running mean: -20.354880\n","resetting env. episode 1244.000000, reward total was -21.000000. running mean: -20.361332\n","resetting env. episode 1245.000000, reward total was -21.000000. running mean: -20.367718\n","resetting env. episode 1246.000000, reward total was -21.000000. running mean: -20.374041\n","resetting env. episode 1247.000000, reward total was -21.000000. running mean: -20.380301\n","resetting env. episode 1248.000000, reward total was -19.000000. running mean: -20.366498\n","resetting env. episode 1249.000000, reward total was -21.000000. running mean: -20.372833\n","resetting env. episode 1250.000000, reward total was -21.000000. running mean: -20.379104\n","resetting env. episode 1251.000000, reward total was -21.000000. running mean: -20.385313\n","resetting env. episode 1252.000000, reward total was -20.000000. running mean: -20.381460\n","resetting env. episode 1253.000000, reward total was -21.000000. running mean: -20.387646\n","resetting env. episode 1254.000000, reward total was -19.000000. running mean: -20.373769\n","resetting env. episode 1255.000000, reward total was -21.000000. running mean: -20.380032\n","resetting env. episode 1256.000000, reward total was -19.000000. running mean: -20.366231\n","resetting env. episode 1257.000000, reward total was -21.000000. running mean: -20.372569\n","resetting env. episode 1258.000000, reward total was -20.000000. running mean: -20.368843\n","resetting env. episode 1259.000000, reward total was -21.000000. running mean: -20.375155\n","resetting env. episode 1260.000000, reward total was -21.000000. running mean: -20.381403\n","resetting env. episode 1261.000000, reward total was -21.000000. running mean: -20.387589\n","resetting env. episode 1262.000000, reward total was -19.000000. running mean: -20.373713\n","resetting env. episode 1263.000000, reward total was -21.000000. running mean: -20.379976\n","resetting env. episode 1264.000000, reward total was -21.000000. running mean: -20.386176\n","resetting env. episode 1265.000000, reward total was -21.000000. running mean: -20.392315\n","resetting env. episode 1266.000000, reward total was -20.000000. running mean: -20.388391\n","resetting env. episode 1267.000000, reward total was -21.000000. running mean: -20.394508\n","resetting env. episode 1268.000000, reward total was -21.000000. running mean: -20.400563\n","resetting env. episode 1269.000000, reward total was -21.000000. running mean: -20.406557\n","resetting env. episode 1270.000000, reward total was -21.000000. running mean: -20.412491\n","resetting env. episode 1271.000000, reward total was -21.000000. running mean: -20.418366\n","resetting env. episode 1272.000000, reward total was -20.000000. running mean: -20.414183\n","resetting env. episode 1273.000000, reward total was -19.000000. running mean: -20.400041\n","resetting env. episode 1274.000000, reward total was -21.000000. running mean: -20.406040\n","resetting env. episode 1275.000000, reward total was -21.000000. running mean: -20.411980\n","resetting env. episode 1276.000000, reward total was -20.000000. running mean: -20.407860\n","resetting env. episode 1277.000000, reward total was -21.000000. running mean: -20.413782\n","resetting env. episode 1278.000000, reward total was -21.000000. running mean: -20.419644\n","resetting env. episode 1279.000000, reward total was -21.000000. running mean: -20.425447\n","resetting env. episode 1280.000000, reward total was -20.000000. running mean: -20.421193\n","resetting env. episode 1281.000000, reward total was -20.000000. running mean: -20.416981\n","resetting env. episode 1282.000000, reward total was -21.000000. running mean: -20.422811\n","resetting env. episode 1283.000000, reward total was -21.000000. running mean: -20.428583\n","resetting env. episode 1284.000000, reward total was -19.000000. running mean: -20.414297\n","resetting env. episode 1285.000000, reward total was -21.000000. running mean: -20.420154\n","resetting env. episode 1286.000000, reward total was -21.000000. running mean: -20.425953\n","resetting env. episode 1287.000000, reward total was -21.000000. running mean: -20.431693\n","resetting env. episode 1288.000000, reward total was -21.000000. running mean: -20.437376\n","resetting env. episode 1289.000000, reward total was -18.000000. running mean: -20.413003\n","resetting env. episode 1290.000000, reward total was -20.000000. running mean: -20.408873\n","resetting env. episode 1291.000000, reward total was -21.000000. running mean: -20.414784\n","resetting env. episode 1292.000000, reward total was -21.000000. running mean: -20.420636\n","resetting env. episode 1293.000000, reward total was -21.000000. running mean: -20.426430\n","resetting env. episode 1294.000000, reward total was -20.000000. running mean: -20.422165\n","resetting env. episode 1295.000000, reward total was -17.000000. running mean: -20.387944\n","resetting env. episode 1296.000000, reward total was -20.000000. running mean: -20.384064\n","resetting env. episode 1297.000000, reward total was -20.000000. running mean: -20.380224\n","resetting env. episode 1298.000000, reward total was -21.000000. running mean: -20.386421\n","resetting env. episode 1299.000000, reward total was -19.000000. running mean: -20.372557\n","resetting env. episode 1300.000000, reward total was -20.000000. running mean: -20.368832\n","resetting env. episode 1301.000000, reward total was -20.000000. running mean: -20.365143\n","resetting env. episode 1302.000000, reward total was -20.000000. running mean: -20.361492\n","resetting env. episode 1303.000000, reward total was -21.000000. running mean: -20.367877\n","resetting env. episode 1304.000000, reward total was -20.000000. running mean: -20.364198\n","resetting env. episode 1305.000000, reward total was -21.000000. running mean: -20.370556\n","resetting env. episode 1306.000000, reward total was -21.000000. running mean: -20.376851\n","resetting env. episode 1307.000000, reward total was -21.000000. running mean: -20.383082\n","resetting env. episode 1308.000000, reward total was -21.000000. running mean: -20.389251\n","resetting env. episode 1309.000000, reward total was -21.000000. running mean: -20.395359\n","resetting env. episode 1310.000000, reward total was -21.000000. running mean: -20.401405\n","resetting env. episode 1311.000000, reward total was -21.000000. running mean: -20.407391\n","resetting env. episode 1312.000000, reward total was -20.000000. running mean: -20.403317\n","resetting env. episode 1313.000000, reward total was -21.000000. running mean: -20.409284\n","resetting env. episode 1314.000000, reward total was -20.000000. running mean: -20.405191\n","resetting env. episode 1315.000000, reward total was -21.000000. running mean: -20.411139\n","resetting env. episode 1316.000000, reward total was -21.000000. running mean: -20.417028\n","resetting env. episode 1317.000000, reward total was -21.000000. running mean: -20.422858\n","resetting env. episode 1318.000000, reward total was -21.000000. running mean: -20.428629\n","resetting env. episode 1319.000000, reward total was -20.000000. running mean: -20.424343\n","resetting env. episode 1320.000000, reward total was -21.000000. running mean: -20.430099\n","resetting env. episode 1321.000000, reward total was -21.000000. running mean: -20.435798\n","resetting env. episode 1322.000000, reward total was -19.000000. running mean: -20.421440\n","resetting env. episode 1323.000000, reward total was -21.000000. running mean: -20.427226\n","resetting env. episode 1324.000000, reward total was -21.000000. running mean: -20.432954\n","resetting env. episode 1325.000000, reward total was -19.000000. running mean: -20.418624\n","resetting env. episode 1326.000000, reward total was -21.000000. running mean: -20.424438\n","resetting env. episode 1327.000000, reward total was -19.000000. running mean: -20.410193\n","resetting env. episode 1328.000000, reward total was -21.000000. running mean: -20.416092\n","resetting env. episode 1329.000000, reward total was -21.000000. running mean: -20.421931\n","resetting env. episode 1330.000000, reward total was -20.000000. running mean: -20.417711\n","resetting env. episode 1331.000000, reward total was -21.000000. running mean: -20.423534\n","resetting env. episode 1332.000000, reward total was -20.000000. running mean: -20.419299\n","resetting env. episode 1333.000000, reward total was -21.000000. running mean: -20.425106\n","resetting env. episode 1334.000000, reward total was -20.000000. running mean: -20.420855\n","resetting env. episode 1335.000000, reward total was -20.000000. running mean: -20.416646\n","resetting env. episode 1336.000000, reward total was -21.000000. running mean: -20.422480\n","resetting env. episode 1337.000000, reward total was -21.000000. running mean: -20.428255\n","resetting env. episode 1338.000000, reward total was -18.000000. running mean: -20.403972\n","resetting env. episode 1339.000000, reward total was -21.000000. running mean: -20.409933\n","resetting env. episode 1340.000000, reward total was -18.000000. running mean: -20.385833\n","resetting env. episode 1341.000000, reward total was -21.000000. running mean: -20.391975\n","resetting env. episode 1342.000000, reward total was -21.000000. running mean: -20.398055\n","resetting env. episode 1343.000000, reward total was -21.000000. running mean: -20.404075\n","resetting env. episode 1344.000000, reward total was -21.000000. running mean: -20.410034\n","resetting env. episode 1345.000000, reward total was -20.000000. running mean: -20.405934\n","resetting env. episode 1346.000000, reward total was -21.000000. running mean: -20.411874\n","resetting env. episode 1347.000000, reward total was -20.000000. running mean: -20.407756\n","resetting env. episode 1348.000000, reward total was -20.000000. running mean: -20.403678\n","resetting env. episode 1349.000000, reward total was -21.000000. running mean: -20.409641\n","resetting env. episode 1350.000000, reward total was -21.000000. running mean: -20.415545\n","resetting env. episode 1351.000000, reward total was -21.000000. running mean: -20.421389\n","resetting env. episode 1352.000000, reward total was -21.000000. running mean: -20.427176\n","resetting env. episode 1353.000000, reward total was -21.000000. running mean: -20.432904\n","resetting env. episode 1354.000000, reward total was -21.000000. running mean: -20.438575\n","resetting env. episode 1355.000000, reward total was -21.000000. running mean: -20.444189\n","resetting env. episode 1356.000000, reward total was -21.000000. running mean: -20.449747\n","resetting env. episode 1357.000000, reward total was -20.000000. running mean: -20.445250\n","resetting env. episode 1358.000000, reward total was -20.000000. running mean: -20.440797\n","resetting env. episode 1359.000000, reward total was -20.000000. running mean: -20.436389\n","resetting env. episode 1360.000000, reward total was -19.000000. running mean: -20.422025\n","resetting env. episode 1361.000000, reward total was -21.000000. running mean: -20.427805\n","resetting env. episode 1362.000000, reward total was -20.000000. running mean: -20.423527\n","resetting env. episode 1363.000000, reward total was -20.000000. running mean: -20.419292\n","resetting env. episode 1364.000000, reward total was -21.000000. running mean: -20.425099\n","resetting env. episode 1365.000000, reward total was -21.000000. running mean: -20.430848\n","resetting env. episode 1366.000000, reward total was -21.000000. running mean: -20.436539\n","resetting env. episode 1367.000000, reward total was -20.000000. running mean: -20.432174\n","resetting env. episode 1368.000000, reward total was -21.000000. running mean: -20.437852\n","resetting env. episode 1369.000000, reward total was -21.000000. running mean: -20.443474\n","resetting env. episode 1370.000000, reward total was -20.000000. running mean: -20.439039\n","resetting env. episode 1371.000000, reward total was -18.000000. running mean: -20.414649\n","resetting env. episode 1372.000000, reward total was -21.000000. running mean: -20.420502\n","resetting env. episode 1373.000000, reward total was -21.000000. running mean: -20.426297\n","resetting env. episode 1374.000000, reward total was -21.000000. running mean: -20.432034\n","resetting env. episode 1375.000000, reward total was -21.000000. running mean: -20.437714\n","resetting env. episode 1376.000000, reward total was -20.000000. running mean: -20.433337\n","resetting env. episode 1377.000000, reward total was -21.000000. running mean: -20.439003\n","resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.444613\n","resetting env. episode 1379.000000, reward total was -21.000000. running mean: -20.450167\n","resetting env. episode 1380.000000, reward total was -21.000000. running mean: -20.455665\n","resetting env. episode 1381.000000, reward total was -21.000000. running mean: -20.461109\n","resetting env. episode 1382.000000, reward total was -20.000000. running mean: -20.456498\n","resetting env. episode 1383.000000, reward total was -20.000000. running mean: -20.451933\n","resetting env. episode 1384.000000, reward total was -21.000000. running mean: -20.457413\n","resetting env. episode 1385.000000, reward total was -21.000000. running mean: -20.462839\n","resetting env. episode 1386.000000, reward total was -21.000000. running mean: -20.468211\n","resetting env. episode 1387.000000, reward total was -20.000000. running mean: -20.463529\n","resetting env. episode 1388.000000, reward total was -21.000000. running mean: -20.468893\n","resetting env. episode 1389.000000, reward total was -21.000000. running mean: -20.474204\n","resetting env. episode 1390.000000, reward total was -21.000000. running mean: -20.479462\n","resetting env. episode 1391.000000, reward total was -20.000000. running mean: -20.474668\n","resetting env. episode 1392.000000, reward total was -21.000000. running mean: -20.479921\n","resetting env. episode 1393.000000, reward total was -19.000000. running mean: -20.465122\n","resetting env. episode 1394.000000, reward total was -21.000000. running mean: -20.470471\n","resetting env. episode 1395.000000, reward total was -20.000000. running mean: -20.465766\n","resetting env. episode 1396.000000, reward total was -21.000000. running mean: -20.471108\n","resetting env. episode 1397.000000, reward total was -21.000000. running mean: -20.476397\n","resetting env. episode 1398.000000, reward total was -20.000000. running mean: -20.471633\n","resetting env. episode 1399.000000, reward total was -18.000000. running mean: -20.446917\n","resetting env. episode 1400.000000, reward total was -20.000000. running mean: -20.442448\n","resetting env. episode 1401.000000, reward total was -20.000000. running mean: -20.438023\n","resetting env. episode 1402.000000, reward total was -20.000000. running mean: -20.433643\n","resetting env. episode 1403.000000, reward total was -21.000000. running mean: -20.439307\n","resetting env. episode 1404.000000, reward total was -21.000000. running mean: -20.444914\n","resetting env. episode 1405.000000, reward total was -20.000000. running mean: -20.440464\n","resetting env. episode 1406.000000, reward total was -21.000000. running mean: -20.446060\n","resetting env. episode 1407.000000, reward total was -21.000000. running mean: -20.451599\n","resetting env. episode 1408.000000, reward total was -21.000000. running mean: -20.457083\n","resetting env. episode 1409.000000, reward total was -19.000000. running mean: -20.442512\n","resetting env. episode 1410.000000, reward total was -20.000000. running mean: -20.438087\n","resetting env. episode 1411.000000, reward total was -21.000000. running mean: -20.443706\n","resetting env. episode 1412.000000, reward total was -21.000000. running mean: -20.449269\n","resetting env. episode 1413.000000, reward total was -21.000000. running mean: -20.454777\n","resetting env. episode 1414.000000, reward total was -21.000000. running mean: -20.460229\n","resetting env. episode 1415.000000, reward total was -21.000000. running mean: -20.465627\n","resetting env. episode 1416.000000, reward total was -21.000000. running mean: -20.470970\n","resetting env. episode 1417.000000, reward total was -20.000000. running mean: -20.466261\n","resetting env. episode 1418.000000, reward total was -21.000000. running mean: -20.471598\n","resetting env. episode 1419.000000, reward total was -21.000000. running mean: -20.476882\n","resetting env. episode 1420.000000, reward total was -20.000000. running mean: -20.472113\n","resetting env. episode 1421.000000, reward total was -20.000000. running mean: -20.467392\n","resetting env. episode 1422.000000, reward total was -21.000000. running mean: -20.472718\n","resetting env. episode 1423.000000, reward total was -21.000000. running mean: -20.477991\n","resetting env. episode 1424.000000, reward total was -21.000000. running mean: -20.483211\n","resetting env. episode 1425.000000, reward total was -21.000000. running mean: -20.488379\n","resetting env. episode 1426.000000, reward total was -21.000000. running mean: -20.493495\n","resetting env. episode 1427.000000, reward total was -21.000000. running mean: -20.498560\n","resetting env. episode 1428.000000, reward total was -18.000000. running mean: -20.473575\n","resetting env. episode 1429.000000, reward total was -21.000000. running mean: -20.478839\n","resetting env. episode 1430.000000, reward total was -21.000000. running mean: -20.484050\n","resetting env. episode 1431.000000, reward total was -20.000000. running mean: -20.479210\n","resetting env. episode 1432.000000, reward total was -21.000000. running mean: -20.484418\n","resetting env. episode 1433.000000, reward total was -19.000000. running mean: -20.469574\n","resetting env. episode 1434.000000, reward total was -18.000000. running mean: -20.444878\n","resetting env. episode 1435.000000, reward total was -20.000000. running mean: -20.440429\n","resetting env. episode 1436.000000, reward total was -19.000000. running mean: -20.426025\n","resetting env. episode 1437.000000, reward total was -21.000000. running mean: -20.431765\n","resetting env. episode 1438.000000, reward total was -19.000000. running mean: -20.417447\n","resetting env. episode 1439.000000, reward total was -21.000000. running mean: -20.423272\n","resetting env. episode 1440.000000, reward total was -21.000000. running mean: -20.429040\n","resetting env. episode 1441.000000, reward total was -19.000000. running mean: -20.414749\n","resetting env. episode 1442.000000, reward total was -21.000000. running mean: -20.420602\n","resetting env. episode 1443.000000, reward total was -21.000000. running mean: -20.426396\n","resetting env. episode 1444.000000, reward total was -20.000000. running mean: -20.422132\n","resetting env. episode 1445.000000, reward total was -19.000000. running mean: -20.407911\n","resetting env. episode 1446.000000, reward total was -18.000000. running mean: -20.383831\n","resetting env. episode 1447.000000, reward total was -20.000000. running mean: -20.379993\n","resetting env. episode 1448.000000, reward total was -21.000000. running mean: -20.386193\n","resetting env. episode 1449.000000, reward total was -21.000000. running mean: -20.392331\n","resetting env. episode 1450.000000, reward total was -17.000000. running mean: -20.358408\n","resetting env. episode 1451.000000, reward total was -21.000000. running mean: -20.364824\n","resetting env. episode 1452.000000, reward total was -20.000000. running mean: -20.361176\n","resetting env. episode 1453.000000, reward total was -19.000000. running mean: -20.347564\n","resetting env. episode 1454.000000, reward total was -19.000000. running mean: -20.334088\n","resetting env. episode 1455.000000, reward total was -20.000000. running mean: -20.330747\n","resetting env. episode 1456.000000, reward total was -20.000000. running mean: -20.327440\n","resetting env. episode 1457.000000, reward total was -21.000000. running mean: -20.334166\n","resetting env. episode 1458.000000, reward total was -19.000000. running mean: -20.320824\n","resetting env. episode 1459.000000, reward total was -21.000000. running mean: -20.327616\n","resetting env. episode 1460.000000, reward total was -19.000000. running mean: -20.314339\n","resetting env. episode 1461.000000, reward total was -20.000000. running mean: -20.311196\n","resetting env. episode 1462.000000, reward total was -20.000000. running mean: -20.308084\n","resetting env. episode 1463.000000, reward total was -18.000000. running mean: -20.285003\n","resetting env. episode 1464.000000, reward total was -21.000000. running mean: -20.292153\n","resetting env. episode 1465.000000, reward total was -20.000000. running mean: -20.289232\n","resetting env. episode 1466.000000, reward total was -21.000000. running mean: -20.296339\n","resetting env. episode 1467.000000, reward total was -21.000000. running mean: -20.303376\n","resetting env. episode 1468.000000, reward total was -19.000000. running mean: -20.290342\n","resetting env. episode 1469.000000, reward total was -20.000000. running mean: -20.287439\n","resetting env. episode 1470.000000, reward total was -21.000000. running mean: -20.294564\n","resetting env. episode 1471.000000, reward total was -21.000000. running mean: -20.301619\n","resetting env. episode 1472.000000, reward total was -21.000000. running mean: -20.308603\n","resetting env. episode 1473.000000, reward total was -21.000000. running mean: -20.315517\n","resetting env. episode 1474.000000, reward total was -21.000000. running mean: -20.322361\n","resetting env. episode 1475.000000, reward total was -20.000000. running mean: -20.319138\n","resetting env. episode 1476.000000, reward total was -21.000000. running mean: -20.325946\n","resetting env. episode 1477.000000, reward total was -20.000000. running mean: -20.322687\n","resetting env. episode 1478.000000, reward total was -21.000000. running mean: -20.329460\n","resetting env. episode 1479.000000, reward total was -20.000000. running mean: -20.326165\n","resetting env. episode 1480.000000, reward total was -21.000000. running mean: -20.332904\n","resetting env. episode 1481.000000, reward total was -20.000000. running mean: -20.329575\n","resetting env. episode 1482.000000, reward total was -21.000000. running mean: -20.336279\n","resetting env. episode 1483.000000, reward total was -21.000000. running mean: -20.342916\n","resetting env. episode 1484.000000, reward total was -20.000000. running mean: -20.339487\n","resetting env. episode 1485.000000, reward total was -20.000000. running mean: -20.336092\n","resetting env. episode 1486.000000, reward total was -19.000000. running mean: -20.322731\n","resetting env. episode 1487.000000, reward total was -20.000000. running mean: -20.319504\n","resetting env. episode 1488.000000, reward total was -20.000000. running mean: -20.316309\n","resetting env. episode 1489.000000, reward total was -21.000000. running mean: -20.323146\n","resetting env. episode 1490.000000, reward total was -20.000000. running mean: -20.319914\n","resetting env. episode 1491.000000, reward total was -20.000000. running mean: -20.316715\n","resetting env. episode 1492.000000, reward total was -21.000000. running mean: -20.323548\n","resetting env. episode 1493.000000, reward total was -21.000000. running mean: -20.330313\n","resetting env. episode 1494.000000, reward total was -21.000000. running mean: -20.337009\n","resetting env. episode 1495.000000, reward total was -21.000000. running mean: -20.343639\n","resetting env. episode 1496.000000, reward total was -21.000000. running mean: -20.350203\n","resetting env. episode 1497.000000, reward total was -21.000000. running mean: -20.356701\n","resetting env. episode 1498.000000, reward total was -21.000000. running mean: -20.363134\n","resetting env. episode 1499.000000, reward total was -21.000000. running mean: -20.369503\n","resetting env. episode 1500.000000, reward total was -21.000000. running mean: -20.375808\n","CPU times: user 1h 14min 38s, sys: 32min 59s, total: 1h 47min 38s\n","Wall time: 55min 36s\n"]}]},{"metadata":{"id":"w2NblmwDsL3y","outputId":"228ad1e8-429e-453a-a274-3a791ac50122","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"ok","timestamp":1660761445138,"user_tz":-330,"elapsed":40962,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -15.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}