{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"400N-4LR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"cells":[{"metadata":{"id":"cWACPRL869I4","executionInfo":{"status":"ok","timestamp":1660631734763,"user_tz":-330,"elapsed":4537,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install gym >/dev/null"],"execution_count":1,"outputs":[]},{"metadata":{"id":"2Os6feRY6ec_","executionInfo":{"status":"ok","timestamp":1660631740164,"user_tz":-330,"elapsed":5414,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install JSAnimation >/dev/null"],"execution_count":2,"outputs":[]},{"metadata":{"id":"wotUOa_e6edP","executionInfo":{"status":"ok","timestamp":1660631740896,"user_tz":-330,"elapsed":745,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%matplotlib inline\n","from JSAnimation.IPython_display import display_animation\n","from matplotlib import animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","\n","def display_frames_as_gif(frames):\n","    \"\"\"\n","    Displays a list of frames as a gif, with controls\n","    \"\"\"\n","    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","\n","    def animate(i):\n","        patch.set_data(frames[i])\n","\n","    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n","    HTML(anim.to_jshtml())"],"execution_count":3,"outputs":[]},{"metadata":{"id":"R66_INeZ9nYX"},"cell_type":"markdown","source":["## Step 2: Playing Pong"]},{"cell_type":"code","source":["%pip install -U gym>=0.21.0\n","%pip install -U gym[atari,accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ngMhg3fB9aA","outputId":"d8678566-0455-4c00-931e-a631388dbad0","executionInfo":{"status":"ok","timestamp":1660631774215,"user_tz":-330,"elapsed":33326,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n","Collecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=9a34d2e287200160a5e437f77c12873f999ecdbc5b0a946457b3869ef57467ba\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"]}]},{"metadata":{"id":"MtT2GyK_6edc","outputId":"8b7636a2-cf49-4ccc-9de0-d10b1465eb60","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660631776012,"user_tz":-330,"elapsed":1818,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import gym\n","env = gym.make('Pong-v0')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  f\"The environment {id} is out of date. You should consider \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}]},{"metadata":{"id":"oRE6WmXQJ1Z0","outputId":"c59888ff-6aca-499f-981f-965c36e9a3da","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660631776013,"user_tz":-330,"elapsed":29,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.action_space"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(6)"]},"metadata":{},"execution_count":6}]},{"metadata":{"id":"yl_9d4HFJ31W","outputId":"f14a62ad-9a2d-4666-d3d9-8b94accff993","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660631776013,"user_tz":-330,"elapsed":22,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.observation_space"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box(0, 255, (210, 160, 3), uint8)"]},"metadata":{},"execution_count":7}]},{"metadata":{"id":"trwRXI-h6eeI","outputId":"43262506-1765-4297-bac3-fe9ee31eadf7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660631776881,"user_tz":-330,"elapsed":888,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# Run a demo of the environment\n","observation = env.reset()\n","cumulated_reward = 0\n","\n","frames = []\n","for t in range(1000):\n","#     print(observation)\n","    frames.append(env.render(mode = 'rgb_array'))\n","    # very stupid agent, just makes a random action within the allowd action space\n","    action = env.action_space.sample()\n","#     print(\"Action: {}\".format(t+1))    \n","    observation, reward, done, info = env.step(action)\n","#     print(reward)\n","    cumulated_reward += reward\n","    if done:\n","        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","        break\n","print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","\n","env.close()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -16.0\n"]}]},{"metadata":{"id":"3zZTecVWLLes","executionInfo":{"status":"ok","timestamp":1660631776882,"user_tz":-330,"elapsed":14,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["def sigmoid(x): \n","  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n","\n","def prepro(I):\n","  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n","  I = I[35:195] # crop\n","  I = I[::2,::2,0] # downsample by factor of 2\n","  I[I == 144] = 0 # erase background (background type 1)\n","  I[I == 109] = 0 # erase background (background type 2)\n","  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n","  return I.astype(np.float).ravel()\n","\n","def policy_forward(x):\n","  h = np.dot(model['W1'], x)\n","  h[h<0] = 0 # ReLU nonlinearity\n","  logp = np.dot(model['W2'], h)\n","  p = sigmoid(logp)\n","  return p, h # return probability of taking action 2, and hidden state\n","\n","def model_step(model, observation, prev_x):\n","  # preprocess the observation, set input to network to be difference image\n","  cur_x = prepro(observation)\n","  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","  prev_x = cur_x\n","  \n","  # forward the policy network and sample an action from the returned probability\n","  aprob, _ = policy_forward(x)\n","  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n","  \n","  return action, prev_x\n","\n","def play_game(env, model):\n","  observation = env.reset()\n","\n","  frames = []\n","  cumulated_reward = 0\n","\n","  prev_x = None # used in computing the difference frame\n","\n","  for t in range(1000):\n","      frames.append(env.render(mode = 'rgb_array'))\n","      action, prev_x = model_step(model, observation, prev_x)\n","      observation, reward, done, info = env.step(action)\n","      cumulated_reward += reward\n","      if done:\n","          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","          break\n","  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","  display_frames_as_gif(frames)\n","  env.close()"],"execution_count":9,"outputs":[]},{"metadata":{"id":"6gWvZQ7AQLQt"},"cell_type":"markdown","source":["## Step 3: Policy Gradient from Scratch"]},{"metadata":{"id":"eqFm7hqcItWl","executionInfo":{"status":"ok","timestamp":1660631776883,"user_tz":-330,"elapsed":15,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import numpy as np\n","\n","# model initialization\n","H = 400 # number of hidden layer neurons\n","D = 80 * 80 # input dimensionality: 80x80 grid\n","model = {}\n","model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n","model['W2'] = np.random.randn(H) / np.sqrt(H)\n","\n","# import pickle\n","# model = pickle.load(open('model.pkl', 'rb'))"],"execution_count":10,"outputs":[]},{"metadata":{"id":"TwjiwKisQM19","executionInfo":{"status":"ok","timestamp":1660631776883,"user_tz":-330,"elapsed":15,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# hyperparameters\n","batch_size = 10 # every how many episodes to do a param update?\n","# learning_rate = 1e-4\n","learning_rate = 1e-4\n"," \n","gamma = 0.99 # discount factor for reward\n","decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n","  \n","grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n","rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n","\n","def discount_rewards(r):\n","  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n","  discounted_r = np.zeros_like(r, dtype=np.float32)\n","  running_add = 0\n","  for t in reversed(range(0, r.size)):\n","    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n","    running_add = running_add * gamma + r[t]\n","    discounted_r[t] = running_add\n","  return discounted_r\n","\n","def policy_backward(epx, eph, epdlogp):\n","  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n","  dW2 = np.dot(eph.T, epdlogp).ravel()\n","  dh = np.outer(epdlogp, model['W2'])\n","  dh[eph <= 0] = 0 # backpro prelu\n","  dW1 = np.dot(dh.T, epx)\n","  return {'W1':dW1, 'W2':dW2}\n","\n","def train_model(env, model, total_episodes = 100):\n","  hist = []\n","  observation = env.reset()\n","\n","  prev_x = None # used in computing the difference frame\n","  xs,hs,dlogps,drs = [],[],[],[]\n","  running_reward = None\n","  reward_sum = 0\n","  episode_number = 0\n","\n","  while True:\n","    # preprocess the observation, set input to network to be difference image\n","    cur_x = prepro(observation)\n","    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","    prev_x = cur_x\n","\n","    # forward the policy network and sample an action from the returned probability\n","    aprob, h = policy_forward(x)\n","    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n","\n","    # record various intermediates (needed later for backprop)\n","    xs.append(x) # observation\n","    hs.append(h) # hidden state\n","    y = 1 if action == 2 else 0 # a \"fake label\"\n","    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n","\n","    # step the environment and get new measurements\n","    observation, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n","\n","    if done: # an episode finished\n","      episode_number += 1\n","\n","      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n","      epx = np.vstack(xs)\n","      eph = np.vstack(hs)\n","      epdlogp = np.vstack(dlogps)\n","      epr = np.vstack(drs)\n","      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n","\n","      # compute the discounted reward backwards through time\n","      discounted_epr = discount_rewards(epr)\n","      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n","      discounted_epr -= np.mean(discounted_epr)\n","      discounted_epr /= np.std(discounted_epr)\n","\n","      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n","      grad = policy_backward(epx, eph, epdlogp)\n","      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n","\n","      # perform rmsprop parameter update every batch_size episodes\n","      if episode_number % batch_size == 0:\n","        for k,v in model.items():\n","          g = grad_buffer[k] # gradient\n","          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n","          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n","          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n","\n","      # boring book-keeping\n","      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n","      hist.append((episode_number, reward_sum, running_reward))\n","      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n","      reward_sum = 0\n","      observation = env.reset() # reset env\n","      prev_x = None\n","      if episode_number == total_episodes: return hist\n","\n","      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n","        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"],"execution_count":11,"outputs":[]},{"metadata":{"id":"G6Ka_5Vl9Orm","outputId":"22384038-cb51-4f15-a126-b7d91ac4f805","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660633643940,"user_tz":-330,"elapsed":1867071,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist1 = train_model(env, model, total_episodes=500)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.990199\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.990297\n","resetting env. episode 6.000000, reward total was -20.000000. running mean: -20.980394\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.970590\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.970884\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.971175\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.971464\n","resetting env. episode 11.000000, reward total was -19.000000. running mean: -20.951749\n","resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.942231\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.942809\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.943381\n","resetting env. episode 15.000000, reward total was -20.000000. running mean: -20.933947\n","resetting env. episode 16.000000, reward total was -20.000000. running mean: -20.924608\n","resetting env. episode 17.000000, reward total was -18.000000. running mean: -20.895362\n","resetting env. episode 18.000000, reward total was -20.000000. running mean: -20.886408\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.887544\n","resetting env. episode 20.000000, reward total was -19.000000. running mean: -20.868669\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.869982\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.871282\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.872569\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.873844\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.875105\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.876354\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.877591\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.878815\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.880026\n","resetting env. episode 30.000000, reward total was -20.000000. running mean: -20.871226\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.872514\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.873789\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.875051\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.876300\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.877537\n","resetting env. episode 36.000000, reward total was -18.000000. running mean: -20.848762\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.850274\n","resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.841772\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.843354\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.844920\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.846471\n","resetting env. episode 42.000000, reward total was -19.000000. running mean: -20.828006\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.829726\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.821429\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.823215\n","resetting env. episode 46.000000, reward total was -20.000000. running mean: -20.814983\n","resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.806833\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.808765\n","resetting env. episode 49.000000, reward total was -18.000000. running mean: -20.780677\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.772870\n","resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.765141\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.767490\n","resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.759815\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.762217\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.764595\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.766949\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.769279\n","resetting env. episode 58.000000, reward total was -17.000000. running mean: -20.731587\n","resetting env. episode 59.000000, reward total was -20.000000. running mean: -20.724271\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.727028\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.729758\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.732460\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.735136\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.737784\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.740406\n","resetting env. episode 66.000000, reward total was -20.000000. running mean: -20.733002\n","resetting env. episode 67.000000, reward total was -20.000000. running mean: -20.725672\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.728416\n","resetting env. episode 69.000000, reward total was -18.000000. running mean: -20.701131\n","resetting env. episode 70.000000, reward total was -20.000000. running mean: -20.694120\n","resetting env. episode 71.000000, reward total was -18.000000. running mean: -20.667179\n","resetting env. episode 72.000000, reward total was -19.000000. running mean: -20.650507\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.644002\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.647562\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.651086\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.654576\n","resetting env. episode 77.000000, reward total was -19.000000. running mean: -20.638030\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.631649\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.635333\n","resetting env. episode 80.000000, reward total was -18.000000. running mean: -20.608980\n","resetting env. episode 81.000000, reward total was -20.000000. running mean: -20.602890\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.596861\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.600892\n","resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.594883\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.598935\n","resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.592945\n","resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.587016\n","resetting env. episode 88.000000, reward total was -19.000000. running mean: -20.571146\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.575434\n","resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.569680\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.573983\n","resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.568243\n","resetting env. episode 93.000000, reward total was -19.000000. running mean: -20.552561\n","resetting env. episode 94.000000, reward total was -19.000000. running mean: -20.537035\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.531665\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.536348\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.540985\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.535575\n","resetting env. episode 99.000000, reward total was -17.000000. running mean: -20.500219\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.505217\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.500165\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.505163\n","resetting env. episode 103.000000, reward total was -20.000000. running mean: -20.500111\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.505110\n","resetting env. episode 105.000000, reward total was -19.000000. running mean: -20.490059\n","resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.485159\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.490307\n","resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.485404\n","resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.480550\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.485744\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.490887\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.495978\n","resetting env. episode 113.000000, reward total was -20.000000. running mean: -20.491018\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.496108\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.501147\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.506136\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.511074\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.515964\n","resetting env. episode 119.000000, reward total was -19.000000. running mean: -20.500804\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.505796\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.510738\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.505630\n","resetting env. episode 123.000000, reward total was -20.000000. running mean: -20.500574\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.505568\n","resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.500513\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.505508\n","resetting env. episode 127.000000, reward total was -19.000000. running mean: -20.490453\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.495548\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.500593\n","resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.495587\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.500631\n","resetting env. episode 132.000000, reward total was -19.000000. running mean: -20.485624\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.490768\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.495861\n","resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.490902\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.495993\n","resetting env. episode 137.000000, reward total was -19.000000. running mean: -20.481033\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.486223\n","resetting env. episode 139.000000, reward total was -20.000000. running mean: -20.481360\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.486547\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.491681\n","resetting env. episode 142.000000, reward total was -16.000000. running mean: -20.446765\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.452297\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.457774\n","resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.463196\n","resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.468564\n","resetting env. episode 147.000000, reward total was -19.000000. running mean: -20.453879\n","resetting env. episode 148.000000, reward total was -18.000000. running mean: -20.429340\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.435046\n","resetting env. episode 150.000000, reward total was -19.000000. running mean: -20.420696\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.426489\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.432224\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.437902\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.443523\n","resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.439088\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.444697\n","resetting env. episode 157.000000, reward total was -19.000000. running mean: -20.430250\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.435947\n","resetting env. episode 159.000000, reward total was -20.000000. running mean: -20.431588\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.437272\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.442899\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.448470\n","resetting env. episode 163.000000, reward total was -19.000000. running mean: -20.433985\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.439646\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.445249\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.450797\n","resetting env. episode 167.000000, reward total was -19.000000. running mean: -20.436289\n","resetting env. episode 168.000000, reward total was -20.000000. running mean: -20.431926\n","resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.427607\n","resetting env. episode 170.000000, reward total was -20.000000. running mean: -20.423331\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.429097\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.434806\n","resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.440458\n","resetting env. episode 174.000000, reward total was -20.000000. running mean: -20.436054\n","resetting env. episode 175.000000, reward total was -19.000000. running mean: -20.421693\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.427476\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.433201\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.438869\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.444481\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.450036\n","resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.445535\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.451080\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.456569\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.462004\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.467384\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.472710\n","resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.467983\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.463303\n","resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.458670\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.464083\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.469442\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.474748\n","resetting env. episode 193.000000, reward total was -20.000000. running mean: -20.470000\n","resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.465300\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.470647\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.475941\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.481181\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.476370\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.481606\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.486790\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.491922\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.497003\n","resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.502033\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.507012\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.511942\n","resetting env. episode 206.000000, reward total was -19.000000. running mean: -20.496823\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.501855\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.506836\n","resetting env. episode 209.000000, reward total was -19.000000. running mean: -20.491768\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.496850\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.501882\n","resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.496863\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.501894\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -20.496875\n","resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.491906\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.496987\n","resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.492018\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.497097\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.502126\n","resetting env. episode 220.000000, reward total was -20.000000. running mean: -20.497105\n","resetting env. episode 221.000000, reward total was -18.000000. running mean: -20.472134\n","resetting env. episode 222.000000, reward total was -20.000000. running mean: -20.467413\n","resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.462739\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.468111\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.473430\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.478696\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.483909\n","resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.489070\n","resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.484179\n","resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.479337\n","resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.474544\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.469798\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.465100\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.460449\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.465845\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.471186\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.476475\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.481710\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.486893\n","resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.482024\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.487204\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.492332\n","resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.487408\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.492534\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.497609\n","resetting env. episode 246.000000, reward total was -20.000000. running mean: -20.492633\n","resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.487706\n","resetting env. episode 248.000000, reward total was -20.000000. running mean: -20.482829\n","resetting env. episode 249.000000, reward total was -20.000000. running mean: -20.478001\n","resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.473221\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.478489\n","resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.473704\n","resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.468967\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.474277\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.479534\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.484739\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.489892\n","resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.484993\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.490143\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.495241\n","resetting env. episode 261.000000, reward total was -18.000000. running mean: -20.470289\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.475586\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.480830\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.486022\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.491162\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.486250\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.491388\n","resetting env. episode 268.000000, reward total was -20.000000. running mean: -20.486474\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.491609\n","resetting env. episode 270.000000, reward total was -20.000000. running mean: -20.486693\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.491826\n","resetting env. episode 272.000000, reward total was -17.000000. running mean: -20.456908\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.462339\n","resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.457715\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.463138\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.468507\n","resetting env. episode 277.000000, reward total was -18.000000. running mean: -20.443822\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.449383\n","resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.444890\n","resetting env. episode 280.000000, reward total was -20.000000. running mean: -20.440441\n","resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.436036\n","resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.431676\n","resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.427359\n","resetting env. episode 284.000000, reward total was -19.000000. running mean: -20.413086\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.418955\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.424765\n","resetting env. episode 287.000000, reward total was -19.000000. running mean: -20.410518\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.416412\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.422248\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.428026\n","resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.423746\n","resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.429508\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.435213\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.440861\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.446452\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.451988\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.457468\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.462893\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.458264\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.463682\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.469045\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.474354\n","resetting env. episode 303.000000, reward total was -20.000000. running mean: -20.469611\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.474915\n","resetting env. episode 305.000000, reward total was -19.000000. running mean: -20.460166\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.465564\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.470908\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.466199\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.471537\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.476822\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.482054\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.487233\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.492361\n","resetting env. episode 314.000000, reward total was -19.000000. running mean: -20.477437\n","resetting env. episode 315.000000, reward total was -19.000000. running mean: -20.462663\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.468036\n","resetting env. episode 317.000000, reward total was -19.000000. running mean: -20.453356\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.458822\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.464234\n","resetting env. episode 320.000000, reward total was -20.000000. running mean: -20.459592\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.464996\n","resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.470346\n","resetting env. episode 323.000000, reward total was -19.000000. running mean: -20.455642\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.461086\n","resetting env. episode 325.000000, reward total was -19.000000. running mean: -20.446475\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.452010\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.457490\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.462915\n","resetting env. episode 329.000000, reward total was -19.000000. running mean: -20.448286\n","resetting env. episode 330.000000, reward total was -19.000000. running mean: -20.433803\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.439465\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.445071\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.450620\n","resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.446114\n","resetting env. episode 335.000000, reward total was -19.000000. running mean: -20.431653\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.437336\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.442963\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.448533\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.454048\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.459507\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.464912\n","resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.460263\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.465660\n","resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.461004\n","resetting env. episode 345.000000, reward total was -20.000000. running mean: -20.456394\n","resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.451830\n","resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.447312\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.452838\n","resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.448310\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.453827\n","resetting env. episode 351.000000, reward total was -19.000000. running mean: -20.439289\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.444896\n","resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.440447\n","resetting env. episode 354.000000, reward total was -20.000000. running mean: -20.436042\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.441682\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.447265\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.452792\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.458265\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.463682\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.459045\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.454455\n","resetting env. episode 362.000000, reward total was -19.000000. running mean: -20.439910\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.445511\n","resetting env. episode 364.000000, reward total was -19.000000. running mean: -20.431056\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.426745\n","resetting env. episode 366.000000, reward total was -20.000000. running mean: -20.422478\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.428253\n","resetting env. episode 368.000000, reward total was -20.000000. running mean: -20.423971\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.429731\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.425434\n","resetting env. episode 371.000000, reward total was -18.000000. running mean: -20.401179\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.407167\n","resetting env. episode 373.000000, reward total was -19.000000. running mean: -20.393096\n","resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.389165\n","resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.385273\n","resetting env. episode 376.000000, reward total was -18.000000. running mean: -20.361420\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.367806\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.374128\n","resetting env. episode 379.000000, reward total was -19.000000. running mean: -20.360387\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.366783\n","resetting env. episode 381.000000, reward total was -18.000000. running mean: -20.343115\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.349684\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.356187\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.352625\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.359099\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.365508\n","resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.361853\n","resetting env. episode 388.000000, reward total was -18.000000. running mean: -20.338234\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.344852\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.351404\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.357890\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.364311\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.370668\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.376961\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.373191\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.369459\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.375765\n","resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.372007\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.378287\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.384504\n","resetting env. episode 401.000000, reward total was -19.000000. running mean: -20.370659\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.376952\n","resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.373183\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.379451\n","resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.375657\n","resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.371900\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.378181\n","resetting env. episode 408.000000, reward total was -20.000000. running mean: -20.374399\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.380655\n","resetting env. episode 410.000000, reward total was -19.000000. running mean: -20.366849\n","resetting env. episode 411.000000, reward total was -19.000000. running mean: -20.353180\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.359648\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.366052\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.372391\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.368668\n","resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.364981\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.371331\n","resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.367618\n","resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.363942\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.370302\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.376599\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.382833\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.379005\n","resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.375215\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.381463\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.387648\n","resetting env. episode 427.000000, reward total was -19.000000. running mean: -20.373771\n","resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.370034\n","resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.366333\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -20.362670\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.369043\n","resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.365353\n","resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.361699\n","resetting env. episode 434.000000, reward total was -20.000000. running mean: -20.358082\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.364502\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.370857\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.377148\n","resetting env. episode 438.000000, reward total was -19.000000. running mean: -20.363377\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.369743\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.376045\n","resetting env. episode 441.000000, reward total was -18.000000. running mean: -20.352285\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.358762\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.365174\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.371523\n","resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.367807\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.374129\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.380388\n","resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.376584\n","resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.372818\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.379090\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.385299\n","resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.381446\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.387632\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.393756\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.399818\n","resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.395820\n","resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.401862\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.407843\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.413765\n","resetting env. episode 460.000000, reward total was -19.000000. running mean: -20.399627\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.405631\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.401574\n","resetting env. episode 463.000000, reward total was -19.000000. running mean: -20.387559\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.393683\n","resetting env. episode 465.000000, reward total was -20.000000. running mean: -20.389746\n","resetting env. episode 466.000000, reward total was -19.000000. running mean: -20.375849\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.372090\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.378369\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.384586\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.390740\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.396832\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.402864\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.408835\n","resetting env. episode 474.000000, reward total was -19.000000. running mean: -20.394747\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.400800\n","resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.396792\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.402824\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.398795\n","resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.404807\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.410759\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.416652\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.412485\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.418360\n","resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.404177\n","resetting env. episode 485.000000, reward total was -20.000000. running mean: -20.400135\n","resetting env. episode 486.000000, reward total was -20.000000. running mean: -20.396134\n","resetting env. episode 487.000000, reward total was -19.000000. running mean: -20.382172\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.378351\n","resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.374567\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.370821\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.377113\n","resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.373342\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.379609\n","resetting env. episode 494.000000, reward total was -20.000000. running mean: -20.375813\n","resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.372054\n","resetting env. episode 496.000000, reward total was -18.000000. running mean: -20.348334\n","resetting env. episode 497.000000, reward total was -20.000000. running mean: -20.344851\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.351402\n","resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.347888\n","resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.354409\n","CPU times: user 46min 34s, sys: 13min 24s, total: 59min 58s\n","Wall time: 31min 7s\n"]}]},{"metadata":{"id":"cHYCDYwhlVLV","outputId":"b2f45ddd-04cc-4912-b10c-bf35bd1746d4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660635555744,"user_tz":-330,"elapsed":1911823,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist2 = train_model(env, model, total_episodes=500)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 7.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.990199\n","resetting env. episode 11.000000, reward total was -19.000000. running mean: -20.970297\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.970594\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.970888\n","resetting env. episode 14.000000, reward total was -17.000000. running mean: -20.931179\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.931867\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.932549\n","resetting env. episode 17.000000, reward total was -20.000000. running mean: -20.923223\n","resetting env. episode 18.000000, reward total was -20.000000. running mean: -20.913991\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.914851\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.915703\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.916546\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.917380\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.918206\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.919024\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.919834\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.920636\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.911429\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.912315\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.913192\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.914060\n","resetting env. episode 31.000000, reward total was -18.000000. running mean: -20.884919\n","resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.876070\n","resetting env. episode 33.000000, reward total was -19.000000. running mean: -20.857309\n","resetting env. episode 34.000000, reward total was -20.000000. running mean: -20.848736\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.850249\n","resetting env. episode 36.000000, reward total was -19.000000. running mean: -20.831747\n","resetting env. episode 37.000000, reward total was -20.000000. running mean: -20.823429\n","resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.815195\n","resetting env. episode 39.000000, reward total was -19.000000. running mean: -20.797043\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.799072\n","resetting env. episode 41.000000, reward total was -20.000000. running mean: -20.791082\n","resetting env. episode 42.000000, reward total was -19.000000. running mean: -20.773171\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.775439\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.777685\n","resetting env. episode 45.000000, reward total was -19.000000. running mean: -20.759908\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.762309\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.764686\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.767039\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.769368\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.771675\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.773958\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.776218\n","resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.768456\n","resetting env. episode 54.000000, reward total was -19.000000. running mean: -20.750772\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.753264\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.755731\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.758174\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.760592\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.762986\n","resetting env. episode 60.000000, reward total was -20.000000. running mean: -20.755357\n","resetting env. episode 61.000000, reward total was -19.000000. running mean: -20.737803\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.740425\n","resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.733021\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.735690\n","resetting env. episode 65.000000, reward total was -20.000000. running mean: -20.728334\n","resetting env. episode 66.000000, reward total was -20.000000. running mean: -20.721050\n","resetting env. episode 67.000000, reward total was -19.000000. running mean: -20.703840\n","resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.696801\n","resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.689833\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.692935\n","resetting env. episode 71.000000, reward total was -18.000000. running mean: -20.666006\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.669346\n","resetting env. episode 73.000000, reward total was -19.000000. running mean: -20.652652\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.656126\n","resetting env. episode 75.000000, reward total was -19.000000. running mean: -20.639564\n","resetting env. episode 76.000000, reward total was -20.000000. running mean: -20.633169\n","resetting env. episode 77.000000, reward total was -19.000000. running mean: -20.616837\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.610669\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.614562\n","resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.608416\n","resetting env. episode 81.000000, reward total was -20.000000. running mean: -20.602332\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.596309\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.600346\n","resetting env. episode 84.000000, reward total was -19.000000. running mean: -20.584342\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.578499\n","resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.572714\n","resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.566987\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.571317\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.575604\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.579848\n","resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.574049\n","resetting env. episode 92.000000, reward total was -19.000000. running mean: -20.558309\n","resetting env. episode 93.000000, reward total was -20.000000. running mean: -20.552726\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.557198\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.561626\n","resetting env. episode 96.000000, reward total was -19.000000. running mean: -20.546010\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.550550\n","resetting env. episode 98.000000, reward total was -19.000000. running mean: -20.535045\n","resetting env. episode 99.000000, reward total was -20.000000. running mean: -20.529694\n","resetting env. episode 100.000000, reward total was -19.000000. running mean: -20.514397\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.519253\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.524061\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.528820\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.533532\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.538197\n","resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.542815\n","resetting env. episode 107.000000, reward total was -20.000000. running mean: -20.537386\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.542013\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.546592\n","resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.541126\n","resetting env. episode 111.000000, reward total was -19.000000. running mean: -20.525715\n","resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.520458\n","resetting env. episode 113.000000, reward total was -19.000000. running mean: -20.505253\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.510201\n","resetting env. episode 115.000000, reward total was -19.000000. running mean: -20.495099\n","resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.490148\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.495246\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.500294\n","resetting env. episode 119.000000, reward total was -20.000000. running mean: -20.495291\n","resetting env. episode 120.000000, reward total was -20.000000. running mean: -20.490338\n","resetting env. episode 121.000000, reward total was -19.000000. running mean: -20.475435\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.480680\n","resetting env. episode 123.000000, reward total was -20.000000. running mean: -20.475874\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.481115\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.486304\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.491441\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.496526\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.501561\n","resetting env. episode 129.000000, reward total was -20.000000. running mean: -20.496545\n","resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.491580\n","resetting env. episode 131.000000, reward total was -20.000000. running mean: -20.486664\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.481798\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.486980\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.492110\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.497189\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.502217\n","resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.497195\n","resetting env. episode 138.000000, reward total was -19.000000. running mean: -20.482223\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.487400\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.492526\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.497601\n","resetting env. episode 142.000000, reward total was -19.000000. running mean: -20.482625\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.487799\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.492921\n","resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.487992\n","resetting env. episode 146.000000, reward total was -17.000000. running mean: -20.453112\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.458581\n","resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.453995\n","resetting env. episode 149.000000, reward total was -20.000000. running mean: -20.449455\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.454960\n","resetting env. episode 151.000000, reward total was -19.000000. running mean: -20.440411\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.446007\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.451547\n","resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.447031\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.452561\n","resetting env. episode 156.000000, reward total was -19.000000. running mean: -20.438035\n","resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.433655\n","resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.429318\n","resetting env. episode 159.000000, reward total was -19.000000. running mean: -20.415025\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.420875\n","resetting env. episode 161.000000, reward total was -20.000000. running mean: -20.416666\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.422499\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.428274\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.433992\n","resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.429652\n","resetting env. episode 166.000000, reward total was -17.000000. running mean: -20.395355\n","resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.401402\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.407388\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.413314\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.419181\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.424989\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.430739\n","resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.436432\n","resetting env. episode 174.000000, reward total was -20.000000. running mean: -20.432067\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.437747\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.443369\n","resetting env. episode 177.000000, reward total was -19.000000. running mean: -20.428935\n","resetting env. episode 178.000000, reward total was -20.000000. running mean: -20.424646\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.430400\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.436096\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.441735\n","resetting env. episode 182.000000, reward total was -20.000000. running mean: -20.437317\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.442944\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.448515\n","resetting env. episode 185.000000, reward total was -19.000000. running mean: -20.434030\n","resetting env. episode 186.000000, reward total was -19.000000. running mean: -20.419689\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.425492\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.431237\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.436925\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.442556\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.448130\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.453649\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.459112\n","resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.454521\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.459976\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.465376\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.470723\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.476015\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.481255\n","resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.476443\n","resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.471678\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.476961\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.472192\n","resetting env. episode 204.000000, reward total was -20.000000. running mean: -20.467470\n","resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.462795\n","resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.458167\n","resetting env. episode 207.000000, reward total was -20.000000. running mean: -20.453586\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.459050\n","resetting env. episode 209.000000, reward total was -20.000000. running mean: -20.454459\n","resetting env. episode 210.000000, reward total was -18.000000. running mean: -20.429915\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.435616\n","resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.431259\n","resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.426947\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.432677\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.438351\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.443967\n","resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.439527\n","resetting env. episode 218.000000, reward total was -20.000000. running mean: -20.435132\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.440781\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.446373\n","resetting env. episode 221.000000, reward total was -20.000000. running mean: -20.441909\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.447490\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.453015\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.448485\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.444000\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.449560\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.455065\n","resetting env. episode 228.000000, reward total was -19.000000. running mean: -20.440514\n","resetting env. episode 229.000000, reward total was -19.000000. running mean: -20.426109\n","resetting env. episode 230.000000, reward total was -18.000000. running mean: -20.401848\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.407829\n","resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.413751\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.419613\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.415417\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.421263\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.427051\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.432780\n","resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.428452\n","resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.424168\n","resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.419926\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.425727\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.421470\n","resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.417255\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.423082\n","resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.418851\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.424663\n","resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.420416\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.426212\n","resetting env. episode 249.000000, reward total was -19.000000. running mean: -20.411950\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.417831\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.423652\n","resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.419416\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.425222\n","resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.420969\n","resetting env. episode 255.000000, reward total was -17.000000. running mean: -20.386760\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.392892\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.398963\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.404973\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.410924\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.416815\n","resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.412646\n","resetting env. episode 262.000000, reward total was -18.000000. running mean: -20.388520\n","resetting env. episode 263.000000, reward total was -19.000000. running mean: -20.374635\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.380888\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.387079\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.383209\n","resetting env. episode 267.000000, reward total was -20.000000. running mean: -20.379377\n","resetting env. episode 268.000000, reward total was -19.000000. running mean: -20.365583\n","resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.361927\n","resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.368308\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.364625\n","resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.370978\n","resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.367269\n","resetting env. episode 274.000000, reward total was -19.000000. running mean: -20.353596\n","resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.350060\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.356559\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.362994\n","resetting env. episode 278.000000, reward total was -19.000000. running mean: -20.349364\n","resetting env. episode 279.000000, reward total was -19.000000. running mean: -20.335870\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.342511\n","resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.339086\n","resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.335696\n","resetting env. episode 283.000000, reward total was -19.000000. running mean: -20.322339\n","resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.319115\n","resetting env. episode 285.000000, reward total was -18.000000. running mean: -20.295924\n","resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.292965\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.300035\n","resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.297035\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.304064\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.301024\n","resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.308014\n","resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.314933\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.321784\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.328566\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.335281\n","resetting env. episode 296.000000, reward total was -20.000000. running mean: -20.331928\n","resetting env. episode 297.000000, reward total was -20.000000. running mean: -20.328608\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.325322\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.322069\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.318848\n","resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.315660\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.312503\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.319378\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.326185\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.332923\n","resetting env. episode 306.000000, reward total was -20.000000. running mean: -20.329594\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.336298\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.342935\n","resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.339505\n","resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.336110\n","resetting env. episode 311.000000, reward total was -19.000000. running mean: -20.322749\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.329522\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.336226\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.342864\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.349435\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.355941\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.352382\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.358858\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.365269\n","resetting env. episode 320.000000, reward total was -20.000000. running mean: -20.361617\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.368000\n","resetting env. episode 322.000000, reward total was -19.000000. running mean: -20.354320\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.360777\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.367169\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.373498\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.379763\n","resetting env. episode 327.000000, reward total was -20.000000. running mean: -20.375965\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.382206\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.388383\n","resetting env. episode 330.000000, reward total was -19.000000. running mean: -20.374500\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.380755\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.386947\n","resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.383078\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.389247\n","resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.385354\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.391501\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.397586\n","resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.393610\n","resetting env. episode 339.000000, reward total was -17.000000. running mean: -20.359674\n","resetting env. episode 340.000000, reward total was -19.000000. running mean: -20.346077\n","resetting env. episode 341.000000, reward total was -18.000000. running mean: -20.322616\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.329390\n","resetting env. episode 343.000000, reward total was -19.000000. running mean: -20.316096\n","resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.312935\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.319806\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.326608\n","resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.323342\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.330108\n","resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.326807\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.333539\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.340204\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.346802\n","resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.343334\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.349900\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.356401\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.362837\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.369209\n","resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.365517\n","resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.361862\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.358243\n","resetting env. episode 361.000000, reward total was -19.000000. running mean: -20.344661\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.351214\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.357702\n","resetting env. episode 364.000000, reward total was -20.000000. running mean: -20.354125\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.350584\n","resetting env. episode 366.000000, reward total was -20.000000. running mean: -20.347078\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.353607\n","resetting env. episode 368.000000, reward total was -20.000000. running mean: -20.350071\n","resetting env. episode 369.000000, reward total was -20.000000. running mean: -20.346570\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.343105\n","resetting env. episode 371.000000, reward total was -19.000000. running mean: -20.329674\n","resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.326377\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.333113\n","resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.329782\n","resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.326484\n","resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.333219\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.339887\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.346488\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.353023\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.359493\n","resetting env. episode 381.000000, reward total was -18.000000. running mean: -20.335898\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.342539\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.339114\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.335723\n","resetting env. episode 385.000000, reward total was -19.000000. running mean: -20.322365\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.329142\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.335850\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.342492\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.349067\n","resetting env. episode 390.000000, reward total was -19.000000. running mean: -20.335576\n","resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.332221\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.338898\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.345509\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.352054\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.358534\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.364948\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.371299\n","resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.367586\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.373910\n","resetting env. episode 400.000000, reward total was -19.000000. running mean: -20.360171\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.366569\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.372904\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.379175\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.385383\n","resetting env. episode 405.000000, reward total was -19.000000. running mean: -20.371529\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.377814\n","resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.374036\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.380295\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.386492\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.392627\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.398701\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.404714\n","resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.400667\n","resetting env. episode 414.000000, reward total was -20.000000. running mean: -20.396660\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.392694\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.398767\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.404779\n","resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.400731\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.406724\n","resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.402657\n","resetting env. episode 421.000000, reward total was -20.000000. running mean: -20.398630\n","resetting env. episode 422.000000, reward total was -18.000000. running mean: -20.374644\n","resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.380897\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.387088\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.383217\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.389385\n","resetting env. episode 427.000000, reward total was -17.000000. running mean: -20.355491\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.361937\n","resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.358317\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.364734\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.371087\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.377376\n","resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.373602\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.379866\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.386067\n","resetting env. episode 436.000000, reward total was -20.000000. running mean: -20.382207\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.388385\n","resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.384501\n","resetting env. episode 439.000000, reward total was -20.000000. running mean: -20.380656\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.386849\n","resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.382981\n","resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.379151\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.385359\n","resetting env. episode 444.000000, reward total was -20.000000. running mean: -20.381506\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.387691\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.393814\n","resetting env. episode 447.000000, reward total was -18.000000. running mean: -20.369876\n","resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.366177\n","resetting env. episode 449.000000, reward total was -19.000000. running mean: -20.352515\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.358990\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.365400\n","resetting env. episode 452.000000, reward total was -19.000000. running mean: -20.351746\n","resetting env. episode 453.000000, reward total was -20.000000. running mean: -20.348229\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.354746\n","resetting env. episode 455.000000, reward total was -19.000000. running mean: -20.341199\n","resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.337787\n","resetting env. episode 457.000000, reward total was -19.000000. running mean: -20.324409\n","resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.321165\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.327953\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.324674\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.331427\n","resetting env. episode 462.000000, reward total was -18.000000. running mean: -20.308113\n","resetting env. episode 463.000000, reward total was -19.000000. running mean: -20.295032\n","resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.292081\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.299161\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.306169\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.313107\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.319976\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.326776\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.333509\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.340174\n","resetting env. episode 472.000000, reward total was -20.000000. running mean: -20.336772\n","resetting env. episode 473.000000, reward total was -20.000000. running mean: -20.333404\n","resetting env. episode 474.000000, reward total was -20.000000. running mean: -20.330070\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.336769\n","resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.333402\n","resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.330068\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.326767\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.323499\n","resetting env. episode 480.000000, reward total was -19.000000. running mean: -20.310264\n","resetting env. episode 481.000000, reward total was -20.000000. running mean: -20.307162\n","resetting env. episode 482.000000, reward total was -18.000000. running mean: -20.284090\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.291249\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.298337\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.305353\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.312300\n","resetting env. episode 487.000000, reward total was -18.000000. running mean: -20.289177\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.286285\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.293422\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.290488\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.297583\n","resetting env. episode 492.000000, reward total was -19.000000. running mean: -20.284607\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.291761\n","resetting env. episode 494.000000, reward total was -18.000000. running mean: -20.268844\n","resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.266155\n","resetting env. episode 496.000000, reward total was -19.000000. running mean: -20.253494\n","resetting env. episode 497.000000, reward total was -20.000000. running mean: -20.250959\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.258449\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.265865\n","resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.273206\n","CPU times: user 47min 48s, sys: 13min 48s, total: 1h 1min 37s\n","Wall time: 31min 51s\n"]}]},{"metadata":{"id":"8fheN9DRlWXQ","outputId":"a72e87d8-2984-4aa4-c1dc-d84598892dd0","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1660635597258,"user_tz":-330,"elapsed":41537,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -10.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"id":"9AxOcQhIsKow","outputId":"27684472-2086-4d4d-8bd7-ed605409b5e6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660641970206,"user_tz":-330,"elapsed":6372969,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist3 = train_model(env, model, total_episodes=1500)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -19.000000. running mean: -19.000000\n","resetting env. episode 2.000000, reward total was -20.000000. running mean: -19.010000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -19.029900\n","resetting env. episode 4.000000, reward total was -20.000000. running mean: -19.039601\n","resetting env. episode 5.000000, reward total was -20.000000. running mean: -19.049205\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -19.068713\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -19.078026\n","resetting env. episode 8.000000, reward total was -20.000000. running mean: -19.087246\n","resetting env. episode 9.000000, reward total was -19.000000. running mean: -19.086373\n","resetting env. episode 10.000000, reward total was -20.000000. running mean: -19.095509\n","resetting env. episode 11.000000, reward total was -19.000000. running mean: -19.094554\n","resetting env. episode 12.000000, reward total was -19.000000. running mean: -19.093609\n","resetting env. episode 13.000000, reward total was -20.000000. running mean: -19.102673\n","resetting env. episode 14.000000, reward total was -19.000000. running mean: -19.101646\n","resetting env. episode 15.000000, reward total was -20.000000. running mean: -19.110629\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -19.129523\n","resetting env. episode 17.000000, reward total was -20.000000. running mean: -19.138228\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -19.156846\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -19.175277\n","resetting env. episode 20.000000, reward total was -20.000000. running mean: -19.183524\n","resetting env. episode 21.000000, reward total was -20.000000. running mean: -19.191689\n","resetting env. episode 22.000000, reward total was -18.000000. running mean: -19.179772\n","resetting env. episode 23.000000, reward total was -20.000000. running mean: -19.187975\n","resetting env. episode 24.000000, reward total was -20.000000. running mean: -19.196095\n","resetting env. episode 25.000000, reward total was -20.000000. running mean: -19.204134\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -19.222093\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -19.239872\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -19.257473\n","resetting env. episode 29.000000, reward total was -18.000000. running mean: -19.244898\n","resetting env. episode 30.000000, reward total was -20.000000. running mean: -19.252449\n","resetting env. episode 31.000000, reward total was -19.000000. running mean: -19.249925\n","resetting env. episode 32.000000, reward total was -19.000000. running mean: -19.247425\n","resetting env. episode 33.000000, reward total was -17.000000. running mean: -19.224951\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -19.242702\n","resetting env. episode 35.000000, reward total was -18.000000. running mean: -19.230275\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -19.247972\n","resetting env. episode 37.000000, reward total was -19.000000. running mean: -19.245492\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -19.263037\n","resetting env. episode 39.000000, reward total was -19.000000. running mean: -19.260407\n","resetting env. episode 40.000000, reward total was -20.000000. running mean: -19.267803\n","resetting env. episode 41.000000, reward total was -19.000000. running mean: -19.265125\n","resetting env. episode 42.000000, reward total was -20.000000. running mean: -19.272474\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -19.289749\n","resetting env. episode 44.000000, reward total was -19.000000. running mean: -19.286851\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -19.303983\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -19.320943\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -19.337734\n","resetting env. episode 48.000000, reward total was -20.000000. running mean: -19.344356\n","resetting env. episode 49.000000, reward total was -20.000000. running mean: -19.350913\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -19.357404\n","resetting env. episode 51.000000, reward total was -19.000000. running mean: -19.353829\n","resetting env. episode 52.000000, reward total was -20.000000. running mean: -19.360291\n","resetting env. episode 53.000000, reward total was -19.000000. running mean: -19.356688\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -19.373121\n","resetting env. episode 55.000000, reward total was -20.000000. running mean: -19.379390\n","resetting env. episode 56.000000, reward total was -20.000000. running mean: -19.385596\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -19.401740\n","resetting env. episode 58.000000, reward total was -20.000000. running mean: -19.407723\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -19.423646\n","resetting env. episode 60.000000, reward total was -20.000000. running mean: -19.429409\n","resetting env. episode 61.000000, reward total was -20.000000. running mean: -19.435115\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -19.450764\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -19.466256\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -19.481594\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -19.496778\n","resetting env. episode 66.000000, reward total was -20.000000. running mean: -19.501810\n","resetting env. episode 67.000000, reward total was -19.000000. running mean: -19.496792\n","resetting env. episode 68.000000, reward total was -20.000000. running mean: -19.501824\n","resetting env. episode 69.000000, reward total was -18.000000. running mean: -19.486806\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -19.501938\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -19.506918\n","resetting env. episode 72.000000, reward total was -20.000000. running mean: -19.511849\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -19.526731\n","resetting env. episode 74.000000, reward total was -19.000000. running mean: -19.521463\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -19.536249\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -19.550886\n","resetting env. episode 77.000000, reward total was -20.000000. running mean: -19.555377\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -19.569824\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -19.584125\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -19.598284\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -19.612301\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -19.616178\n","resetting env. episode 83.000000, reward total was -19.000000. running mean: -19.610017\n","resetting env. episode 84.000000, reward total was -20.000000. running mean: -19.613916\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -19.617777\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -19.631599\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -19.645283\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -19.658831\n","resetting env. episode 89.000000, reward total was -17.000000. running mean: -19.632242\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -19.645920\n","resetting env. episode 91.000000, reward total was -19.000000. running mean: -19.639461\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -19.653066\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -19.666535\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -19.679870\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -19.693071\n","resetting env. episode 96.000000, reward total was -20.000000. running mean: -19.696141\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -19.709179\n","resetting env. episode 98.000000, reward total was -18.000000. running mean: -19.692087\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -19.705167\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -19.718115\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -19.720934\n","resetting env. episode 102.000000, reward total was -19.000000. running mean: -19.713724\n","resetting env. episode 103.000000, reward total was -20.000000. running mean: -19.716587\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -19.729421\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -19.742127\n","resetting env. episode 106.000000, reward total was -20.000000. running mean: -19.744706\n","resetting env. episode 107.000000, reward total was -20.000000. running mean: -19.747259\n","resetting env. episode 108.000000, reward total was -18.000000. running mean: -19.729786\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -19.742488\n","resetting env. episode 110.000000, reward total was -20.000000. running mean: -19.745063\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -19.757613\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -19.770037\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -19.782336\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -19.794513\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -19.806568\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -19.818502\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -19.830317\n","resetting env. episode 118.000000, reward total was -20.000000. running mean: -19.832014\n","resetting env. episode 119.000000, reward total was -19.000000. running mean: -19.823694\n","resetting env. episode 120.000000, reward total was -18.000000. running mean: -19.805457\n","resetting env. episode 121.000000, reward total was -19.000000. running mean: -19.797402\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -19.809428\n","resetting env. episode 123.000000, reward total was -20.000000. running mean: -19.811334\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -19.823221\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -19.834988\n","resetting env. episode 126.000000, reward total was -17.000000. running mean: -19.806639\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -19.818572\n","resetting env. episode 128.000000, reward total was -20.000000. running mean: -19.820386\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -19.832183\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -19.843861\n","resetting env. episode 131.000000, reward total was -19.000000. running mean: -19.835422\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -19.837068\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -19.848697\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -19.860210\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -19.871608\n","resetting env. episode 136.000000, reward total was -20.000000. running mean: -19.872892\n","resetting env. episode 137.000000, reward total was -19.000000. running mean: -19.864163\n","resetting env. episode 138.000000, reward total was -20.000000. running mean: -19.865522\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -19.876866\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -19.888098\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -19.899217\n","resetting env. episode 142.000000, reward total was -20.000000. running mean: -19.900225\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -19.911222\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -19.922110\n","resetting env. episode 145.000000, reward total was -19.000000. running mean: -19.912889\n","resetting env. episode 146.000000, reward total was -21.000000. running mean: -19.923760\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -19.934522\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -19.945177\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -19.955725\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -19.966168\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -19.976507\n","resetting env. episode 152.000000, reward total was -19.000000. running mean: -19.966741\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -19.977074\n","resetting env. episode 154.000000, reward total was -19.000000. running mean: -19.967303\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -19.977630\n","resetting env. episode 156.000000, reward total was -19.000000. running mean: -19.967854\n","resetting env. episode 157.000000, reward total was -17.000000. running mean: -19.938175\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -19.948794\n","resetting env. episode 159.000000, reward total was -20.000000. running mean: -19.949306\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -19.959813\n","resetting env. episode 161.000000, reward total was -19.000000. running mean: -19.950215\n","resetting env. episode 162.000000, reward total was -19.000000. running mean: -19.940712\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -19.951305\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -19.961792\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -19.972174\n","resetting env. episode 166.000000, reward total was -20.000000. running mean: -19.972453\n","resetting env. episode 167.000000, reward total was -18.000000. running mean: -19.952728\n","resetting env. episode 168.000000, reward total was -20.000000. running mean: -19.953201\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -19.963669\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -19.974032\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -19.984292\n","resetting env. episode 172.000000, reward total was -20.000000. running mean: -19.984449\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -19.984604\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -19.994758\n","resetting env. episode 175.000000, reward total was -20.000000. running mean: -19.994811\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.004863\n","resetting env. episode 177.000000, reward total was -20.000000. running mean: -20.004814\n","resetting env. episode 178.000000, reward total was -20.000000. running mean: -20.004766\n","resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.004718\n","resetting env. episode 180.000000, reward total was -19.000000. running mean: -19.994671\n","resetting env. episode 181.000000, reward total was -18.000000. running mean: -19.974724\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -19.984977\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -19.995127\n","resetting env. episode 184.000000, reward total was -20.000000. running mean: -19.995176\n","resetting env. episode 185.000000, reward total was -20.000000. running mean: -19.995224\n","resetting env. episode 186.000000, reward total was -19.000000. running mean: -19.985272\n","resetting env. episode 187.000000, reward total was -20.000000. running mean: -19.985419\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -19.985565\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -19.995709\n","resetting env. episode 190.000000, reward total was -20.000000. running mean: -19.995752\n","resetting env. episode 191.000000, reward total was -20.000000. running mean: -19.995795\n","resetting env. episode 192.000000, reward total was -20.000000. running mean: -19.995837\n","resetting env. episode 193.000000, reward total was -19.000000. running mean: -19.985878\n","resetting env. episode 194.000000, reward total was -20.000000. running mean: -19.986020\n","resetting env. episode 195.000000, reward total was -20.000000. running mean: -19.986160\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -19.996298\n","resetting env. episode 197.000000, reward total was -20.000000. running mean: -19.996335\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.006372\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.016308\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.026145\n","resetting env. episode 201.000000, reward total was -19.000000. running mean: -20.015883\n","resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.015725\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.015567\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.025412\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.035157\n","resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.034806\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.044458\n","resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.044013\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.053573\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.063037\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.072407\n","resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.071683\n","resetting env. episode 213.000000, reward total was -19.000000. running mean: -20.060966\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.070356\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.079653\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.088856\n","resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.087968\n","resetting env. episode 218.000000, reward total was -19.000000. running mean: -20.077088\n","resetting env. episode 219.000000, reward total was -19.000000. running mean: -20.066317\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.075654\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.084898\n","resetting env. episode 222.000000, reward total was -19.000000. running mean: -20.074049\n","resetting env. episode 223.000000, reward total was -18.000000. running mean: -20.053308\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.062775\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.062147\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.071526\n","resetting env. episode 227.000000, reward total was -19.000000. running mean: -20.060811\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.060202\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.069600\n","resetting env. episode 230.000000, reward total was -19.000000. running mean: -20.058904\n","resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.058315\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.057732\n","resetting env. episode 233.000000, reward total was -18.000000. running mean: -20.037155\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.036783\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.046415\n","resetting env. episode 236.000000, reward total was -18.000000. running mean: -20.025951\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.035692\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.045335\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.054882\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.064333\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.073689\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.082953\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.092123\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.101202\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.110190\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.119088\n","resetting env. episode 247.000000, reward total was -19.000000. running mean: -20.107897\n","resetting env. episode 248.000000, reward total was -19.000000. running mean: -20.096818\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.105850\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.114791\n","resetting env. episode 251.000000, reward total was -18.000000. running mean: -20.093643\n","resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.092707\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.101780\n","resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.100762\n","resetting env. episode 255.000000, reward total was -20.000000. running mean: -20.099754\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.108757\n","resetting env. episode 257.000000, reward total was -19.000000. running mean: -20.097669\n","resetting env. episode 258.000000, reward total was -19.000000. running mean: -20.086693\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.095826\n","resetting env. episode 260.000000, reward total was -20.000000. running mean: -20.094867\n","resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.103919\n","resetting env. episode 262.000000, reward total was -19.000000. running mean: -20.092880\n","resetting env. episode 263.000000, reward total was -20.000000. running mean: -20.091951\n","resetting env. episode 264.000000, reward total was -20.000000. running mean: -20.091031\n","resetting env. episode 265.000000, reward total was -18.000000. running mean: -20.070121\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.069420\n","resetting env. episode 267.000000, reward total was -18.000000. running mean: -20.048726\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.058238\n","resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.057656\n","resetting env. episode 270.000000, reward total was -20.000000. running mean: -20.057079\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.056509\n","resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.055944\n","resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.055384\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.064830\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.074182\n","resetting env. episode 276.000000, reward total was -19.000000. running mean: -20.063440\n","resetting env. episode 277.000000, reward total was -20.000000. running mean: -20.062806\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.072178\n","resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.071456\n","resetting env. episode 280.000000, reward total was -18.000000. running mean: -20.050741\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.060234\n","resetting env. episode 282.000000, reward total was -19.000000. running mean: -20.049632\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.059135\n","resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.058544\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.067958\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.077279\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.086506\n","resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.085641\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.094785\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.093837\n","resetting env. episode 291.000000, reward total was -19.000000. running mean: -20.082898\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.082069\n","resetting env. episode 293.000000, reward total was -18.000000. running mean: -20.061249\n","resetting env. episode 294.000000, reward total was -18.000000. running mean: -20.040636\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.050230\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.059728\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.069130\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.078439\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.087655\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.086778\n","resetting env. episode 301.000000, reward total was -18.000000. running mean: -20.065910\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.075251\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.084499\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.093654\n","resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.092717\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.101790\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.110772\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.109664\n","resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.108568\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.117482\n","resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.116307\n","resetting env. episode 312.000000, reward total was -19.000000. running mean: -20.105144\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.104093\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.113052\n","resetting env. episode 315.000000, reward total was -20.000000. running mean: -20.111921\n","resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.110802\n","resetting env. episode 317.000000, reward total was -19.000000. running mean: -20.099694\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.108697\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.117610\n","resetting env. episode 320.000000, reward total was -19.000000. running mean: -20.106434\n","resetting env. episode 321.000000, reward total was -19.000000. running mean: -20.095370\n","resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.094416\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.103472\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.112437\n","resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.111313\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.120200\n","resetting env. episode 327.000000, reward total was -20.000000. running mean: -20.118998\n","resetting env. episode 328.000000, reward total was -20.000000. running mean: -20.117808\n","resetting env. episode 329.000000, reward total was -20.000000. running mean: -20.116630\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.125463\n","resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.124209\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.132967\n","resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.131637\n","resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.130321\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.139017\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.147627\n","resetting env. episode 337.000000, reward total was -19.000000. running mean: -20.136151\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.144789\n","resetting env. episode 339.000000, reward total was -19.000000. running mean: -20.133341\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.142008\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.150588\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.159082\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.167491\n","resetting env. episode 344.000000, reward total was -19.000000. running mean: -20.155816\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.164258\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.172616\n","resetting env. episode 347.000000, reward total was -19.000000. running mean: -20.160889\n","resetting env. episode 348.000000, reward total was -19.000000. running mean: -20.149281\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.157788\n","resetting env. episode 350.000000, reward total was -19.000000. running mean: -20.146210\n","resetting env. episode 351.000000, reward total was -19.000000. running mean: -20.134748\n","resetting env. episode 352.000000, reward total was -18.000000. running mean: -20.113400\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.122266\n","resetting env. episode 354.000000, reward total was -20.000000. running mean: -20.121044\n","resetting env. episode 355.000000, reward total was -20.000000. running mean: -20.119833\n","resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.118635\n","resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.117449\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.126274\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.135011\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.143661\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.142225\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.150802\n","resetting env. episode 363.000000, reward total was -18.000000. running mean: -20.129294\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.138001\n","resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.146621\n","resetting env. episode 366.000000, reward total was -19.000000. running mean: -20.135155\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.143804\n","resetting env. episode 368.000000, reward total was -19.000000. running mean: -20.132366\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.141042\n","resetting env. episode 370.000000, reward total was -18.000000. running mean: -20.119631\n","resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.118435\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.127251\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.135978\n","resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.134618\n","resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.133272\n","resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.131940\n","resetting env. episode 377.000000, reward total was -19.000000. running mean: -20.120620\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.129414\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.138120\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.146739\n","resetting env. episode 381.000000, reward total was -19.000000. running mean: -20.135271\n","resetting env. episode 382.000000, reward total was -20.000000. running mean: -20.133919\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.132579\n","resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.141254\n","resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.139841\n","resetting env. episode 386.000000, reward total was -19.000000. running mean: -20.128443\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.137158\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.145787\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.154329\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.162785\n","resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.161158\n","resetting env. episode 392.000000, reward total was -18.000000. running mean: -20.139546\n","resetting env. episode 393.000000, reward total was -18.000000. running mean: -20.118151\n","resetting env. episode 394.000000, reward total was -19.000000. running mean: -20.106969\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.105899\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.104840\n","resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.103792\n","resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.112754\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.121627\n","resetting env. episode 400.000000, reward total was -19.000000. running mean: -20.110410\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.119306\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.128113\n","resetting env. episode 403.000000, reward total was -18.000000. running mean: -20.106832\n","resetting env. episode 404.000000, reward total was -19.000000. running mean: -20.095764\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.104806\n","resetting env. episode 406.000000, reward total was -19.000000. running mean: -20.093758\n","resetting env. episode 407.000000, reward total was -18.000000. running mean: -20.072820\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.082092\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.081271\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.090459\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.099554\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.098558\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.107573\n","resetting env. episode 414.000000, reward total was -19.000000. running mean: -20.096497\n","resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.105532\n","resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.104477\n","resetting env. episode 417.000000, reward total was -20.000000. running mean: -20.103432\n","resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.102398\n","resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.101374\n","resetting env. episode 420.000000, reward total was -18.000000. running mean: -20.080360\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.089556\n","resetting env. episode 422.000000, reward total was -19.000000. running mean: -20.078661\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.077874\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.087095\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.096225\n","resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.095262\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.104310\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.113267\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.122134\n","resetting env. episode 430.000000, reward total was -19.000000. running mean: -20.110913\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.119803\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.128605\n","resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.127319\n","resetting env. episode 434.000000, reward total was -19.000000. running mean: -20.116046\n","resetting env. episode 435.000000, reward total was -20.000000. running mean: -20.114886\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.123737\n","resetting env. episode 437.000000, reward total was -19.000000. running mean: -20.112499\n","resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.121374\n","resetting env. episode 439.000000, reward total was -20.000000. running mean: -20.120161\n","resetting env. episode 440.000000, reward total was -18.000000. running mean: -20.098959\n","resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.097970\n","resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.096990\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.106020\n","resetting env. episode 444.000000, reward total was -20.000000. running mean: -20.104960\n","resetting env. episode 445.000000, reward total was -19.000000. running mean: -20.093910\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.102971\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.111941\n","resetting env. episode 448.000000, reward total was -19.000000. running mean: -20.100822\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.109814\n","resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.108716\n","resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.107628\n","resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.106552\n","resetting env. episode 453.000000, reward total was -19.000000. running mean: -20.095487\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.104532\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.113486\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.122352\n","resetting env. episode 457.000000, reward total was -18.000000. running mean: -20.101128\n","resetting env. episode 458.000000, reward total was -19.000000. running mean: -20.090117\n","resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.089216\n","resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.098323\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.107340\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.106267\n","resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.105204\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.114152\n","resetting env. episode 465.000000, reward total was -20.000000. running mean: -20.113011\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.121880\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.130662\n","resetting env. episode 468.000000, reward total was -19.000000. running mean: -20.119355\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.128161\n","resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.126880\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.135611\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.144255\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.152812\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.161284\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.169671\n","resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.167975\n","resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.166295\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.174632\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.172886\n","resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.171157\n","resetting env. episode 481.000000, reward total was -17.000000. running mean: -20.139445\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.148051\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.156570\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.165005\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.173355\n","resetting env. episode 486.000000, reward total was -20.000000. running mean: -20.171621\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.179905\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.178106\n","resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.176325\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.184561\n","resetting env. episode 491.000000, reward total was -19.000000. running mean: -20.172716\n","resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.170989\n","resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.169279\n","resetting env. episode 494.000000, reward total was -18.000000. running mean: -20.147586\n","resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.146110\n","resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.144649\n","resetting env. episode 497.000000, reward total was -19.000000. running mean: -20.133203\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.141871\n","resetting env. episode 499.000000, reward total was -19.000000. running mean: -20.130452\n","resetting env. episode 500.000000, reward total was -19.000000. running mean: -20.119147\n","resetting env. episode 501.000000, reward total was -19.000000. running mean: -20.107956\n","resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.116876\n","resetting env. episode 503.000000, reward total was -21.000000. running mean: -20.125708\n","resetting env. episode 504.000000, reward total was -20.000000. running mean: -20.124450\n","resetting env. episode 505.000000, reward total was -19.000000. running mean: -20.113206\n","resetting env. episode 506.000000, reward total was -21.000000. running mean: -20.122074\n","resetting env. episode 507.000000, reward total was -21.000000. running mean: -20.130853\n","resetting env. episode 508.000000, reward total was -20.000000. running mean: -20.129545\n","resetting env. episode 509.000000, reward total was -18.000000. running mean: -20.108249\n","resetting env. episode 510.000000, reward total was -20.000000. running mean: -20.107167\n","resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.116095\n","resetting env. episode 512.000000, reward total was -21.000000. running mean: -20.124934\n","resetting env. episode 513.000000, reward total was -21.000000. running mean: -20.133685\n","resetting env. episode 514.000000, reward total was -21.000000. running mean: -20.142348\n","resetting env. episode 515.000000, reward total was -19.000000. running mean: -20.130924\n","resetting env. episode 516.000000, reward total was -19.000000. running mean: -20.119615\n","resetting env. episode 517.000000, reward total was -18.000000. running mean: -20.098419\n","resetting env. episode 518.000000, reward total was -21.000000. running mean: -20.107435\n","resetting env. episode 519.000000, reward total was -20.000000. running mean: -20.106360\n","resetting env. episode 520.000000, reward total was -21.000000. running mean: -20.115297\n","resetting env. episode 521.000000, reward total was -21.000000. running mean: -20.124144\n","resetting env. episode 522.000000, reward total was -20.000000. running mean: -20.122902\n","resetting env. episode 523.000000, reward total was -21.000000. running mean: -20.131673\n","resetting env. episode 524.000000, reward total was -20.000000. running mean: -20.130357\n","resetting env. episode 525.000000, reward total was -19.000000. running mean: -20.119053\n","resetting env. episode 526.000000, reward total was -19.000000. running mean: -20.107863\n","resetting env. episode 527.000000, reward total was -20.000000. running mean: -20.106784\n","resetting env. episode 528.000000, reward total was -21.000000. running mean: -20.115716\n","resetting env. episode 529.000000, reward total was -18.000000. running mean: -20.094559\n","resetting env. episode 530.000000, reward total was -21.000000. running mean: -20.103613\n","resetting env. episode 531.000000, reward total was -21.000000. running mean: -20.112577\n","resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.121451\n","resetting env. episode 533.000000, reward total was -20.000000. running mean: -20.120237\n","resetting env. episode 534.000000, reward total was -20.000000. running mean: -20.119035\n","resetting env. episode 535.000000, reward total was -21.000000. running mean: -20.127844\n","resetting env. episode 536.000000, reward total was -21.000000. running mean: -20.136566\n","resetting env. episode 537.000000, reward total was -20.000000. running mean: -20.135200\n","resetting env. episode 538.000000, reward total was -19.000000. running mean: -20.123848\n","resetting env. episode 539.000000, reward total was -19.000000. running mean: -20.112610\n","resetting env. episode 540.000000, reward total was -21.000000. running mean: -20.121484\n","resetting env. episode 541.000000, reward total was -20.000000. running mean: -20.120269\n","resetting env. episode 542.000000, reward total was -17.000000. running mean: -20.089066\n","resetting env. episode 543.000000, reward total was -21.000000. running mean: -20.098175\n","resetting env. episode 544.000000, reward total was -21.000000. running mean: -20.107194\n","resetting env. episode 545.000000, reward total was -20.000000. running mean: -20.106122\n","resetting env. episode 546.000000, reward total was -18.000000. running mean: -20.085060\n","resetting env. episode 547.000000, reward total was -21.000000. running mean: -20.094210\n","resetting env. episode 548.000000, reward total was -20.000000. running mean: -20.093268\n","resetting env. episode 549.000000, reward total was -19.000000. running mean: -20.082335\n","resetting env. episode 550.000000, reward total was -21.000000. running mean: -20.091512\n","resetting env. episode 551.000000, reward total was -20.000000. running mean: -20.090597\n","resetting env. episode 552.000000, reward total was -21.000000. running mean: -20.099691\n","resetting env. episode 553.000000, reward total was -21.000000. running mean: -20.108694\n","resetting env. episode 554.000000, reward total was -21.000000. running mean: -20.117607\n","resetting env. episode 555.000000, reward total was -20.000000. running mean: -20.116431\n","resetting env. episode 556.000000, reward total was -20.000000. running mean: -20.115266\n","resetting env. episode 557.000000, reward total was -20.000000. running mean: -20.114114\n","resetting env. episode 558.000000, reward total was -21.000000. running mean: -20.122973\n","resetting env. episode 559.000000, reward total was -20.000000. running mean: -20.121743\n","resetting env. episode 560.000000, reward total was -20.000000. running mean: -20.120525\n","resetting env. episode 561.000000, reward total was -19.000000. running mean: -20.109320\n","resetting env. episode 562.000000, reward total was -21.000000. running mean: -20.118227\n","resetting env. episode 563.000000, reward total was -20.000000. running mean: -20.117045\n","resetting env. episode 564.000000, reward total was -20.000000. running mean: -20.115874\n","resetting env. episode 565.000000, reward total was -20.000000. running mean: -20.114716\n","resetting env. episode 566.000000, reward total was -18.000000. running mean: -20.093568\n","resetting env. episode 567.000000, reward total was -20.000000. running mean: -20.092633\n","resetting env. episode 568.000000, reward total was -20.000000. running mean: -20.091706\n","resetting env. episode 569.000000, reward total was -20.000000. running mean: -20.090789\n","resetting env. episode 570.000000, reward total was -20.000000. running mean: -20.089881\n","resetting env. episode 571.000000, reward total was -21.000000. running mean: -20.098983\n","resetting env. episode 572.000000, reward total was -18.000000. running mean: -20.077993\n","resetting env. episode 573.000000, reward total was -20.000000. running mean: -20.077213\n","resetting env. episode 574.000000, reward total was -21.000000. running mean: -20.086441\n","resetting env. episode 575.000000, reward total was -19.000000. running mean: -20.075576\n","resetting env. episode 576.000000, reward total was -19.000000. running mean: -20.064821\n","resetting env. episode 577.000000, reward total was -18.000000. running mean: -20.044172\n","resetting env. episode 578.000000, reward total was -17.000000. running mean: -20.013731\n","resetting env. episode 579.000000, reward total was -20.000000. running mean: -20.013593\n","resetting env. episode 580.000000, reward total was -21.000000. running mean: -20.023457\n","resetting env. episode 581.000000, reward total was -21.000000. running mean: -20.033223\n","resetting env. episode 582.000000, reward total was -21.000000. running mean: -20.042891\n","resetting env. episode 583.000000, reward total was -21.000000. running mean: -20.052462\n","resetting env. episode 584.000000, reward total was -21.000000. running mean: -20.061937\n","resetting env. episode 585.000000, reward total was -20.000000. running mean: -20.061318\n","resetting env. episode 586.000000, reward total was -21.000000. running mean: -20.070705\n","resetting env. episode 587.000000, reward total was -21.000000. running mean: -20.079997\n","resetting env. episode 588.000000, reward total was -20.000000. running mean: -20.079198\n","resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.088406\n","resetting env. episode 590.000000, reward total was -20.000000. running mean: -20.087521\n","resetting env. episode 591.000000, reward total was -21.000000. running mean: -20.096646\n","resetting env. episode 592.000000, reward total was -21.000000. running mean: -20.105680\n","resetting env. episode 593.000000, reward total was -21.000000. running mean: -20.114623\n","resetting env. episode 594.000000, reward total was -19.000000. running mean: -20.103477\n","resetting env. episode 595.000000, reward total was -19.000000. running mean: -20.092442\n","resetting env. episode 596.000000, reward total was -21.000000. running mean: -20.101518\n","resetting env. episode 597.000000, reward total was -21.000000. running mean: -20.110502\n","resetting env. episode 598.000000, reward total was -20.000000. running mean: -20.109397\n","resetting env. episode 599.000000, reward total was -19.000000. running mean: -20.098303\n","resetting env. episode 600.000000, reward total was -21.000000. running mean: -20.107320\n","resetting env. episode 601.000000, reward total was -19.000000. running mean: -20.096247\n","resetting env. episode 602.000000, reward total was -21.000000. running mean: -20.105285\n","resetting env. episode 603.000000, reward total was -21.000000. running mean: -20.114232\n","resetting env. episode 604.000000, reward total was -19.000000. running mean: -20.103090\n","resetting env. episode 605.000000, reward total was -20.000000. running mean: -20.102059\n","resetting env. episode 606.000000, reward total was -20.000000. running mean: -20.101038\n","resetting env. episode 607.000000, reward total was -19.000000. running mean: -20.090028\n","resetting env. episode 608.000000, reward total was -20.000000. running mean: -20.089127\n","resetting env. episode 609.000000, reward total was -20.000000. running mean: -20.088236\n","resetting env. episode 610.000000, reward total was -20.000000. running mean: -20.087354\n","resetting env. episode 611.000000, reward total was -21.000000. running mean: -20.096480\n","resetting env. episode 612.000000, reward total was -20.000000. running mean: -20.095515\n","resetting env. episode 613.000000, reward total was -19.000000. running mean: -20.084560\n","resetting env. episode 614.000000, reward total was -19.000000. running mean: -20.073715\n","resetting env. episode 615.000000, reward total was -21.000000. running mean: -20.082978\n","resetting env. episode 616.000000, reward total was -19.000000. running mean: -20.072148\n","resetting env. episode 617.000000, reward total was -21.000000. running mean: -20.081426\n","resetting env. episode 618.000000, reward total was -21.000000. running mean: -20.090612\n","resetting env. episode 619.000000, reward total was -20.000000. running mean: -20.089706\n","resetting env. episode 620.000000, reward total was -20.000000. running mean: -20.088809\n","resetting env. episode 621.000000, reward total was -19.000000. running mean: -20.077921\n","resetting env. episode 622.000000, reward total was -20.000000. running mean: -20.077142\n","resetting env. episode 623.000000, reward total was -21.000000. running mean: -20.086370\n","resetting env. episode 624.000000, reward total was -21.000000. running mean: -20.095506\n","resetting env. episode 625.000000, reward total was -18.000000. running mean: -20.074551\n","resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.083806\n","resetting env. episode 627.000000, reward total was -21.000000. running mean: -20.092968\n","resetting env. episode 628.000000, reward total was -20.000000. running mean: -20.092038\n","resetting env. episode 629.000000, reward total was -20.000000. running mean: -20.091118\n","resetting env. episode 630.000000, reward total was -20.000000. running mean: -20.090207\n","resetting env. episode 631.000000, reward total was -21.000000. running mean: -20.099304\n","resetting env. episode 632.000000, reward total was -20.000000. running mean: -20.098311\n","resetting env. episode 633.000000, reward total was -18.000000. running mean: -20.077328\n","resetting env. episode 634.000000, reward total was -21.000000. running mean: -20.086555\n","resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.095689\n","resetting env. episode 636.000000, reward total was -20.000000. running mean: -20.094733\n","resetting env. episode 637.000000, reward total was -19.000000. running mean: -20.083785\n","resetting env. episode 638.000000, reward total was -20.000000. running mean: -20.082947\n","resetting env. episode 639.000000, reward total was -21.000000. running mean: -20.092118\n","resetting env. episode 640.000000, reward total was -20.000000. running mean: -20.091197\n","resetting env. episode 641.000000, reward total was -20.000000. running mean: -20.090285\n","resetting env. episode 642.000000, reward total was -20.000000. running mean: -20.089382\n","resetting env. episode 643.000000, reward total was -20.000000. running mean: -20.088488\n","resetting env. episode 644.000000, reward total was -21.000000. running mean: -20.097603\n","resetting env. episode 645.000000, reward total was -20.000000. running mean: -20.096627\n","resetting env. episode 646.000000, reward total was -21.000000. running mean: -20.105661\n","resetting env. episode 647.000000, reward total was -20.000000. running mean: -20.104604\n","resetting env. episode 648.000000, reward total was -21.000000. running mean: -20.113558\n","resetting env. episode 649.000000, reward total was -19.000000. running mean: -20.102423\n","resetting env. episode 650.000000, reward total was -18.000000. running mean: -20.081398\n","resetting env. episode 651.000000, reward total was -21.000000. running mean: -20.090584\n","resetting env. episode 652.000000, reward total was -19.000000. running mean: -20.079679\n","resetting env. episode 653.000000, reward total was -18.000000. running mean: -20.058882\n","resetting env. episode 654.000000, reward total was -21.000000. running mean: -20.068293\n","resetting env. episode 655.000000, reward total was -18.000000. running mean: -20.047610\n","resetting env. episode 656.000000, reward total was -20.000000. running mean: -20.047134\n","resetting env. episode 657.000000, reward total was -21.000000. running mean: -20.056663\n","resetting env. episode 658.000000, reward total was -21.000000. running mean: -20.066096\n","resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.075435\n","resetting env. episode 660.000000, reward total was -21.000000. running mean: -20.084681\n","resetting env. episode 661.000000, reward total was -21.000000. running mean: -20.093834\n","resetting env. episode 662.000000, reward total was -20.000000. running mean: -20.092896\n","resetting env. episode 663.000000, reward total was -20.000000. running mean: -20.091967\n","resetting env. episode 664.000000, reward total was -21.000000. running mean: -20.101047\n","resetting env. episode 665.000000, reward total was -21.000000. running mean: -20.110036\n","resetting env. episode 666.000000, reward total was -20.000000. running mean: -20.108936\n","resetting env. episode 667.000000, reward total was -21.000000. running mean: -20.117847\n","resetting env. episode 668.000000, reward total was -20.000000. running mean: -20.116668\n","resetting env. episode 669.000000, reward total was -20.000000. running mean: -20.115502\n","resetting env. episode 670.000000, reward total was -21.000000. running mean: -20.124347\n","resetting env. episode 671.000000, reward total was -21.000000. running mean: -20.133103\n","resetting env. episode 672.000000, reward total was -20.000000. running mean: -20.131772\n","resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.140454\n","resetting env. episode 674.000000, reward total was -21.000000. running mean: -20.149050\n","resetting env. episode 675.000000, reward total was -19.000000. running mean: -20.137559\n","resetting env. episode 676.000000, reward total was -19.000000. running mean: -20.126184\n","resetting env. episode 677.000000, reward total was -21.000000. running mean: -20.134922\n","resetting env. episode 678.000000, reward total was -20.000000. running mean: -20.133573\n","resetting env. episode 679.000000, reward total was -21.000000. running mean: -20.142237\n","resetting env. episode 680.000000, reward total was -21.000000. running mean: -20.150815\n","resetting env. episode 681.000000, reward total was -21.000000. running mean: -20.159306\n","resetting env. episode 682.000000, reward total was -20.000000. running mean: -20.157713\n","resetting env. episode 683.000000, reward total was -20.000000. running mean: -20.156136\n","resetting env. episode 684.000000, reward total was -20.000000. running mean: -20.154575\n","resetting env. episode 685.000000, reward total was -18.000000. running mean: -20.133029\n","resetting env. episode 686.000000, reward total was -20.000000. running mean: -20.131699\n","resetting env. episode 687.000000, reward total was -21.000000. running mean: -20.140382\n","resetting env. episode 688.000000, reward total was -21.000000. running mean: -20.148978\n","resetting env. episode 689.000000, reward total was -21.000000. running mean: -20.157488\n","resetting env. episode 690.000000, reward total was -21.000000. running mean: -20.165913\n","resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.174254\n","resetting env. episode 692.000000, reward total was -21.000000. running mean: -20.182512\n","resetting env. episode 693.000000, reward total was -20.000000. running mean: -20.180687\n","resetting env. episode 694.000000, reward total was -18.000000. running mean: -20.158880\n","resetting env. episode 695.000000, reward total was -20.000000. running mean: -20.157291\n","resetting env. episode 696.000000, reward total was -19.000000. running mean: -20.145718\n","resetting env. episode 697.000000, reward total was -21.000000. running mean: -20.154261\n","resetting env. episode 698.000000, reward total was -17.000000. running mean: -20.122718\n","resetting env. episode 699.000000, reward total was -21.000000. running mean: -20.131491\n","resetting env. episode 700.000000, reward total was -19.000000. running mean: -20.120176\n","resetting env. episode 701.000000, reward total was -21.000000. running mean: -20.128974\n","resetting env. episode 702.000000, reward total was -20.000000. running mean: -20.127685\n","resetting env. episode 703.000000, reward total was -20.000000. running mean: -20.126408\n","resetting env. episode 704.000000, reward total was -20.000000. running mean: -20.125144\n","resetting env. episode 705.000000, reward total was -20.000000. running mean: -20.123892\n","resetting env. episode 706.000000, reward total was -21.000000. running mean: -20.132653\n","resetting env. episode 707.000000, reward total was -20.000000. running mean: -20.131327\n","resetting env. episode 708.000000, reward total was -21.000000. running mean: -20.140014\n","resetting env. episode 709.000000, reward total was -21.000000. running mean: -20.148613\n","resetting env. episode 710.000000, reward total was -21.000000. running mean: -20.157127\n","resetting env. episode 711.000000, reward total was -20.000000. running mean: -20.155556\n","resetting env. episode 712.000000, reward total was -21.000000. running mean: -20.164000\n","resetting env. episode 713.000000, reward total was -21.000000. running mean: -20.172360\n","resetting env. episode 714.000000, reward total was -20.000000. running mean: -20.170637\n","resetting env. episode 715.000000, reward total was -21.000000. running mean: -20.178930\n","resetting env. episode 716.000000, reward total was -21.000000. running mean: -20.187141\n","resetting env. episode 717.000000, reward total was -18.000000. running mean: -20.165270\n","resetting env. episode 718.000000, reward total was -20.000000. running mean: -20.163617\n","resetting env. episode 719.000000, reward total was -21.000000. running mean: -20.171981\n","resetting env. episode 720.000000, reward total was -20.000000. running mean: -20.170261\n","resetting env. episode 721.000000, reward total was -21.000000. running mean: -20.178558\n","resetting env. episode 722.000000, reward total was -21.000000. running mean: -20.186773\n","resetting env. episode 723.000000, reward total was -20.000000. running mean: -20.184905\n","resetting env. episode 724.000000, reward total was -21.000000. running mean: -20.193056\n","resetting env. episode 725.000000, reward total was -20.000000. running mean: -20.191126\n","resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.199214\n","resetting env. episode 727.000000, reward total was -20.000000. running mean: -20.197222\n","resetting env. episode 728.000000, reward total was -17.000000. running mean: -20.165250\n","resetting env. episode 729.000000, reward total was -20.000000. running mean: -20.163597\n","resetting env. episode 730.000000, reward total was -20.000000. running mean: -20.161961\n","resetting env. episode 731.000000, reward total was -21.000000. running mean: -20.170342\n","resetting env. episode 732.000000, reward total was -21.000000. running mean: -20.178638\n","resetting env. episode 733.000000, reward total was -20.000000. running mean: -20.176852\n","resetting env. episode 734.000000, reward total was -21.000000. running mean: -20.185083\n","resetting env. episode 735.000000, reward total was -21.000000. running mean: -20.193233\n","resetting env. episode 736.000000, reward total was -19.000000. running mean: -20.181300\n","resetting env. episode 737.000000, reward total was -19.000000. running mean: -20.169487\n","resetting env. episode 738.000000, reward total was -21.000000. running mean: -20.177792\n","resetting env. episode 739.000000, reward total was -20.000000. running mean: -20.176015\n","resetting env. episode 740.000000, reward total was -19.000000. running mean: -20.164254\n","resetting env. episode 741.000000, reward total was -19.000000. running mean: -20.152612\n","resetting env. episode 742.000000, reward total was -21.000000. running mean: -20.161086\n","resetting env. episode 743.000000, reward total was -21.000000. running mean: -20.169475\n","resetting env. episode 744.000000, reward total was -20.000000. running mean: -20.167780\n","resetting env. episode 745.000000, reward total was -21.000000. running mean: -20.176102\n","resetting env. episode 746.000000, reward total was -18.000000. running mean: -20.154341\n","resetting env. episode 747.000000, reward total was -20.000000. running mean: -20.152798\n","resetting env. episode 748.000000, reward total was -19.000000. running mean: -20.141270\n","resetting env. episode 749.000000, reward total was -20.000000. running mean: -20.139857\n","resetting env. episode 750.000000, reward total was -21.000000. running mean: -20.148459\n","resetting env. episode 751.000000, reward total was -19.000000. running mean: -20.136974\n","resetting env. episode 752.000000, reward total was -21.000000. running mean: -20.145604\n","resetting env. episode 753.000000, reward total was -20.000000. running mean: -20.144148\n","resetting env. episode 754.000000, reward total was -20.000000. running mean: -20.142707\n","resetting env. episode 755.000000, reward total was -21.000000. running mean: -20.151280\n","resetting env. episode 756.000000, reward total was -21.000000. running mean: -20.159767\n","resetting env. episode 757.000000, reward total was -19.000000. running mean: -20.148169\n","resetting env. episode 758.000000, reward total was -20.000000. running mean: -20.146688\n","resetting env. episode 759.000000, reward total was -21.000000. running mean: -20.155221\n","resetting env. episode 760.000000, reward total was -18.000000. running mean: -20.133668\n","resetting env. episode 761.000000, reward total was -19.000000. running mean: -20.122332\n","resetting env. episode 762.000000, reward total was -21.000000. running mean: -20.131108\n","resetting env. episode 763.000000, reward total was -19.000000. running mean: -20.119797\n","resetting env. episode 764.000000, reward total was -21.000000. running mean: -20.128599\n","resetting env. episode 765.000000, reward total was -20.000000. running mean: -20.127313\n","resetting env. episode 766.000000, reward total was -20.000000. running mean: -20.126040\n","resetting env. episode 767.000000, reward total was -21.000000. running mean: -20.134780\n","resetting env. episode 768.000000, reward total was -21.000000. running mean: -20.143432\n","resetting env. episode 769.000000, reward total was -20.000000. running mean: -20.141998\n","resetting env. episode 770.000000, reward total was -20.000000. running mean: -20.140578\n","resetting env. episode 771.000000, reward total was -19.000000. running mean: -20.129172\n","resetting env. episode 772.000000, reward total was -20.000000. running mean: -20.127880\n","resetting env. episode 773.000000, reward total was -21.000000. running mean: -20.136601\n","resetting env. episode 774.000000, reward total was -20.000000. running mean: -20.135235\n","resetting env. episode 775.000000, reward total was -19.000000. running mean: -20.123883\n","resetting env. episode 776.000000, reward total was -20.000000. running mean: -20.122644\n","resetting env. episode 777.000000, reward total was -20.000000. running mean: -20.121418\n","resetting env. episode 778.000000, reward total was -20.000000. running mean: -20.120204\n","resetting env. episode 779.000000, reward total was -21.000000. running mean: -20.129002\n","resetting env. episode 780.000000, reward total was -21.000000. running mean: -20.137712\n","resetting env. episode 781.000000, reward total was -19.000000. running mean: -20.126334\n","resetting env. episode 782.000000, reward total was -21.000000. running mean: -20.135071\n","resetting env. episode 783.000000, reward total was -20.000000. running mean: -20.133720\n","resetting env. episode 784.000000, reward total was -18.000000. running mean: -20.112383\n","resetting env. episode 785.000000, reward total was -21.000000. running mean: -20.121259\n","resetting env. episode 786.000000, reward total was -21.000000. running mean: -20.130047\n","resetting env. episode 787.000000, reward total was -20.000000. running mean: -20.128746\n","resetting env. episode 788.000000, reward total was -21.000000. running mean: -20.137459\n","resetting env. episode 789.000000, reward total was -20.000000. running mean: -20.136084\n","resetting env. episode 790.000000, reward total was -20.000000. running mean: -20.134723\n","resetting env. episode 791.000000, reward total was -20.000000. running mean: -20.133376\n","resetting env. episode 792.000000, reward total was -20.000000. running mean: -20.132042\n","resetting env. episode 793.000000, reward total was -21.000000. running mean: -20.140722\n","resetting env. episode 794.000000, reward total was -20.000000. running mean: -20.139315\n","resetting env. episode 795.000000, reward total was -19.000000. running mean: -20.127922\n","resetting env. episode 796.000000, reward total was -21.000000. running mean: -20.136642\n","resetting env. episode 797.000000, reward total was -21.000000. running mean: -20.145276\n","resetting env. episode 798.000000, reward total was -21.000000. running mean: -20.153823\n","resetting env. episode 799.000000, reward total was -19.000000. running mean: -20.142285\n","resetting env. episode 800.000000, reward total was -21.000000. running mean: -20.150862\n","resetting env. episode 801.000000, reward total was -21.000000. running mean: -20.159354\n","resetting env. episode 802.000000, reward total was -19.000000. running mean: -20.147760\n","resetting env. episode 803.000000, reward total was -20.000000. running mean: -20.146282\n","resetting env. episode 804.000000, reward total was -20.000000. running mean: -20.144820\n","resetting env. episode 805.000000, reward total was -17.000000. running mean: -20.113371\n","resetting env. episode 806.000000, reward total was -19.000000. running mean: -20.102238\n","resetting env. episode 807.000000, reward total was -21.000000. running mean: -20.111215\n","resetting env. episode 808.000000, reward total was -21.000000. running mean: -20.120103\n","resetting env. episode 809.000000, reward total was -21.000000. running mean: -20.128902\n","resetting env. episode 810.000000, reward total was -20.000000. running mean: -20.127613\n","resetting env. episode 811.000000, reward total was -20.000000. running mean: -20.126337\n","resetting env. episode 812.000000, reward total was -18.000000. running mean: -20.105074\n","resetting env. episode 813.000000, reward total was -18.000000. running mean: -20.084023\n","resetting env. episode 814.000000, reward total was -19.000000. running mean: -20.073183\n","resetting env. episode 815.000000, reward total was -19.000000. running mean: -20.062451\n","resetting env. episode 816.000000, reward total was -21.000000. running mean: -20.071826\n","resetting env. episode 817.000000, reward total was -21.000000. running mean: -20.081108\n","resetting env. episode 818.000000, reward total was -20.000000. running mean: -20.080297\n","resetting env. episode 819.000000, reward total was -21.000000. running mean: -20.089494\n","resetting env. episode 820.000000, reward total was -18.000000. running mean: -20.068599\n","resetting env. episode 821.000000, reward total was -20.000000. running mean: -20.067913\n","resetting env. episode 822.000000, reward total was -21.000000. running mean: -20.077234\n","resetting env. episode 823.000000, reward total was -20.000000. running mean: -20.076462\n","resetting env. episode 824.000000, reward total was -19.000000. running mean: -20.065697\n","resetting env. episode 825.000000, reward total was -20.000000. running mean: -20.065040\n","resetting env. episode 826.000000, reward total was -20.000000. running mean: -20.064390\n","resetting env. episode 827.000000, reward total was -19.000000. running mean: -20.053746\n","resetting env. episode 828.000000, reward total was -19.000000. running mean: -20.043208\n","resetting env. episode 829.000000, reward total was -21.000000. running mean: -20.052776\n","resetting env. episode 830.000000, reward total was -19.000000. running mean: -20.042248\n","resetting env. episode 831.000000, reward total was -21.000000. running mean: -20.051826\n","resetting env. episode 832.000000, reward total was -21.000000. running mean: -20.061308\n","resetting env. episode 833.000000, reward total was -20.000000. running mean: -20.060695\n","resetting env. episode 834.000000, reward total was -21.000000. running mean: -20.070088\n","resetting env. episode 835.000000, reward total was -18.000000. running mean: -20.049387\n","resetting env. episode 836.000000, reward total was -19.000000. running mean: -20.038893\n","resetting env. episode 837.000000, reward total was -19.000000. running mean: -20.028504\n","resetting env. episode 838.000000, reward total was -21.000000. running mean: -20.038219\n","resetting env. episode 839.000000, reward total was -21.000000. running mean: -20.047837\n","resetting env. episode 840.000000, reward total was -20.000000. running mean: -20.047358\n","resetting env. episode 841.000000, reward total was -21.000000. running mean: -20.056885\n","resetting env. episode 842.000000, reward total was -21.000000. running mean: -20.066316\n","resetting env. episode 843.000000, reward total was -21.000000. running mean: -20.075653\n","resetting env. episode 844.000000, reward total was -20.000000. running mean: -20.074896\n","resetting env. episode 845.000000, reward total was -21.000000. running mean: -20.084147\n","resetting env. episode 846.000000, reward total was -20.000000. running mean: -20.083306\n","resetting env. episode 847.000000, reward total was -20.000000. running mean: -20.082473\n","resetting env. episode 848.000000, reward total was -18.000000. running mean: -20.061648\n","resetting env. episode 849.000000, reward total was -21.000000. running mean: -20.071032\n","resetting env. episode 850.000000, reward total was -21.000000. running mean: -20.080321\n","resetting env. episode 851.000000, reward total was -19.000000. running mean: -20.069518\n","resetting env. episode 852.000000, reward total was -21.000000. running mean: -20.078823\n","resetting env. episode 853.000000, reward total was -20.000000. running mean: -20.078035\n","resetting env. episode 854.000000, reward total was -20.000000. running mean: -20.077254\n","resetting env. episode 855.000000, reward total was -20.000000. running mean: -20.076482\n","resetting env. episode 856.000000, reward total was -21.000000. running mean: -20.085717\n","resetting env. episode 857.000000, reward total was -18.000000. running mean: -20.064860\n","resetting env. episode 858.000000, reward total was -21.000000. running mean: -20.074211\n","resetting env. episode 859.000000, reward total was -17.000000. running mean: -20.043469\n","resetting env. episode 860.000000, reward total was -18.000000. running mean: -20.023034\n","resetting env. episode 861.000000, reward total was -21.000000. running mean: -20.032804\n","resetting env. episode 862.000000, reward total was -21.000000. running mean: -20.042476\n","resetting env. episode 863.000000, reward total was -19.000000. running mean: -20.032051\n","resetting env. episode 864.000000, reward total was -20.000000. running mean: -20.031731\n","resetting env. episode 865.000000, reward total was -21.000000. running mean: -20.041413\n","resetting env. episode 866.000000, reward total was -19.000000. running mean: -20.030999\n","resetting env. episode 867.000000, reward total was -19.000000. running mean: -20.020689\n","resetting env. episode 868.000000, reward total was -19.000000. running mean: -20.010482\n","resetting env. episode 869.000000, reward total was -20.000000. running mean: -20.010378\n","resetting env. episode 870.000000, reward total was -19.000000. running mean: -20.000274\n","resetting env. episode 871.000000, reward total was -21.000000. running mean: -20.010271\n","resetting env. episode 872.000000, reward total was -21.000000. running mean: -20.020168\n","resetting env. episode 873.000000, reward total was -21.000000. running mean: -20.029967\n","resetting env. episode 874.000000, reward total was -20.000000. running mean: -20.029667\n","resetting env. episode 875.000000, reward total was -20.000000. running mean: -20.029370\n","resetting env. episode 876.000000, reward total was -21.000000. running mean: -20.039077\n","resetting env. episode 877.000000, reward total was -21.000000. running mean: -20.048686\n","resetting env. episode 878.000000, reward total was -19.000000. running mean: -20.038199\n","resetting env. episode 879.000000, reward total was -18.000000. running mean: -20.017817\n","resetting env. episode 880.000000, reward total was -21.000000. running mean: -20.027639\n","resetting env. episode 881.000000, reward total was -21.000000. running mean: -20.037362\n","resetting env. episode 882.000000, reward total was -19.000000. running mean: -20.026989\n","resetting env. episode 883.000000, reward total was -18.000000. running mean: -20.006719\n","resetting env. episode 884.000000, reward total was -21.000000. running mean: -20.016652\n","resetting env. episode 885.000000, reward total was -19.000000. running mean: -20.006485\n","resetting env. episode 886.000000, reward total was -19.000000. running mean: -19.996420\n","resetting env. episode 887.000000, reward total was -20.000000. running mean: -19.996456\n","resetting env. episode 888.000000, reward total was -21.000000. running mean: -20.006492\n","resetting env. episode 889.000000, reward total was -20.000000. running mean: -20.006427\n","resetting env. episode 890.000000, reward total was -20.000000. running mean: -20.006362\n","resetting env. episode 891.000000, reward total was -20.000000. running mean: -20.006299\n","resetting env. episode 892.000000, reward total was -20.000000. running mean: -20.006236\n","resetting env. episode 893.000000, reward total was -21.000000. running mean: -20.016173\n","resetting env. episode 894.000000, reward total was -21.000000. running mean: -20.026012\n","resetting env. episode 895.000000, reward total was -20.000000. running mean: -20.025752\n","resetting env. episode 896.000000, reward total was -18.000000. running mean: -20.005494\n","resetting env. episode 897.000000, reward total was -21.000000. running mean: -20.015439\n","resetting env. episode 898.000000, reward total was -20.000000. running mean: -20.015285\n","resetting env. episode 899.000000, reward total was -19.000000. running mean: -20.005132\n","resetting env. episode 900.000000, reward total was -20.000000. running mean: -20.005081\n","resetting env. episode 901.000000, reward total was -20.000000. running mean: -20.005030\n","resetting env. episode 902.000000, reward total was -21.000000. running mean: -20.014979\n","resetting env. episode 903.000000, reward total was -20.000000. running mean: -20.014830\n","resetting env. episode 904.000000, reward total was -21.000000. running mean: -20.024681\n","resetting env. episode 905.000000, reward total was -21.000000. running mean: -20.034435\n","resetting env. episode 906.000000, reward total was -19.000000. running mean: -20.024090\n","resetting env. episode 907.000000, reward total was -21.000000. running mean: -20.033849\n","resetting env. episode 908.000000, reward total was -20.000000. running mean: -20.033511\n","resetting env. episode 909.000000, reward total was -21.000000. running mean: -20.043176\n","resetting env. episode 910.000000, reward total was -18.000000. running mean: -20.022744\n","resetting env. episode 911.000000, reward total was -20.000000. running mean: -20.022517\n","resetting env. episode 912.000000, reward total was -21.000000. running mean: -20.032291\n","resetting env. episode 913.000000, reward total was -20.000000. running mean: -20.031968\n","resetting env. episode 914.000000, reward total was -20.000000. running mean: -20.031649\n","resetting env. episode 915.000000, reward total was -20.000000. running mean: -20.031332\n","resetting env. episode 916.000000, reward total was -21.000000. running mean: -20.041019\n","resetting env. episode 917.000000, reward total was -20.000000. running mean: -20.040609\n","resetting env. episode 918.000000, reward total was -20.000000. running mean: -20.040203\n","resetting env. episode 919.000000, reward total was -21.000000. running mean: -20.049801\n","resetting env. episode 920.000000, reward total was -17.000000. running mean: -20.019303\n","resetting env. episode 921.000000, reward total was -21.000000. running mean: -20.029110\n","resetting env. episode 922.000000, reward total was -21.000000. running mean: -20.038819\n","resetting env. episode 923.000000, reward total was -20.000000. running mean: -20.038430\n","resetting env. episode 924.000000, reward total was -21.000000. running mean: -20.048046\n","resetting env. episode 925.000000, reward total was -21.000000. running mean: -20.057566\n","resetting env. episode 926.000000, reward total was -20.000000. running mean: -20.056990\n","resetting env. episode 927.000000, reward total was -20.000000. running mean: -20.056420\n","resetting env. episode 928.000000, reward total was -21.000000. running mean: -20.065856\n","resetting env. episode 929.000000, reward total was -19.000000. running mean: -20.055197\n","resetting env. episode 930.000000, reward total was -20.000000. running mean: -20.054645\n","resetting env. episode 931.000000, reward total was -20.000000. running mean: -20.054099\n","resetting env. episode 932.000000, reward total was -20.000000. running mean: -20.053558\n","resetting env. episode 933.000000, reward total was -21.000000. running mean: -20.063022\n","resetting env. episode 934.000000, reward total was -19.000000. running mean: -20.052392\n","resetting env. episode 935.000000, reward total was -21.000000. running mean: -20.061868\n","resetting env. episode 936.000000, reward total was -21.000000. running mean: -20.071249\n","resetting env. episode 937.000000, reward total was -21.000000. running mean: -20.080537\n","resetting env. episode 938.000000, reward total was -19.000000. running mean: -20.069732\n","resetting env. episode 939.000000, reward total was -21.000000. running mean: -20.079034\n","resetting env. episode 940.000000, reward total was -20.000000. running mean: -20.078244\n","resetting env. episode 941.000000, reward total was -20.000000. running mean: -20.077461\n","resetting env. episode 942.000000, reward total was -20.000000. running mean: -20.076687\n","resetting env. episode 943.000000, reward total was -19.000000. running mean: -20.065920\n","resetting env. episode 944.000000, reward total was -19.000000. running mean: -20.055261\n","resetting env. episode 945.000000, reward total was -20.000000. running mean: -20.054708\n","resetting env. episode 946.000000, reward total was -21.000000. running mean: -20.064161\n","resetting env. episode 947.000000, reward total was -18.000000. running mean: -20.043519\n","resetting env. episode 948.000000, reward total was -19.000000. running mean: -20.033084\n","resetting env. episode 949.000000, reward total was -18.000000. running mean: -20.012753\n","resetting env. episode 950.000000, reward total was -20.000000. running mean: -20.012626\n","resetting env. episode 951.000000, reward total was -21.000000. running mean: -20.022500\n","resetting env. episode 952.000000, reward total was -21.000000. running mean: -20.032275\n","resetting env. episode 953.000000, reward total was -21.000000. running mean: -20.041952\n","resetting env. episode 954.000000, reward total was -21.000000. running mean: -20.051532\n","resetting env. episode 955.000000, reward total was -21.000000. running mean: -20.061017\n","resetting env. episode 956.000000, reward total was -19.000000. running mean: -20.050407\n","resetting env. episode 957.000000, reward total was -19.000000. running mean: -20.039903\n","resetting env. episode 958.000000, reward total was -20.000000. running mean: -20.039504\n","resetting env. episode 959.000000, reward total was -21.000000. running mean: -20.049109\n","resetting env. episode 960.000000, reward total was -19.000000. running mean: -20.038618\n","resetting env. episode 961.000000, reward total was -20.000000. running mean: -20.038231\n","resetting env. episode 962.000000, reward total was -20.000000. running mean: -20.037849\n","resetting env. episode 963.000000, reward total was -21.000000. running mean: -20.047471\n","resetting env. episode 964.000000, reward total was -20.000000. running mean: -20.046996\n","resetting env. episode 965.000000, reward total was -21.000000. running mean: -20.056526\n","resetting env. episode 966.000000, reward total was -19.000000. running mean: -20.045961\n","resetting env. episode 967.000000, reward total was -20.000000. running mean: -20.045501\n","resetting env. episode 968.000000, reward total was -20.000000. running mean: -20.045046\n","resetting env. episode 969.000000, reward total was -21.000000. running mean: -20.054596\n","resetting env. episode 970.000000, reward total was -20.000000. running mean: -20.054050\n","resetting env. episode 971.000000, reward total was -18.000000. running mean: -20.033509\n","resetting env. episode 972.000000, reward total was -20.000000. running mean: -20.033174\n","resetting env. episode 973.000000, reward total was -20.000000. running mean: -20.032842\n","resetting env. episode 974.000000, reward total was -21.000000. running mean: -20.042514\n","resetting env. episode 975.000000, reward total was -21.000000. running mean: -20.052089\n","resetting env. episode 976.000000, reward total was -20.000000. running mean: -20.051568\n","resetting env. episode 977.000000, reward total was -21.000000. running mean: -20.061052\n","resetting env. episode 978.000000, reward total was -21.000000. running mean: -20.070442\n","resetting env. episode 979.000000, reward total was -21.000000. running mean: -20.079737\n","resetting env. episode 980.000000, reward total was -19.000000. running mean: -20.068940\n","resetting env. episode 981.000000, reward total was -21.000000. running mean: -20.078251\n","resetting env. episode 982.000000, reward total was -21.000000. running mean: -20.087468\n","resetting env. episode 983.000000, reward total was -19.000000. running mean: -20.076593\n","resetting env. episode 984.000000, reward total was -21.000000. running mean: -20.085827\n","resetting env. episode 985.000000, reward total was -21.000000. running mean: -20.094969\n","resetting env. episode 986.000000, reward total was -21.000000. running mean: -20.104019\n","resetting env. episode 987.000000, reward total was -21.000000. running mean: -20.112979\n","resetting env. episode 988.000000, reward total was -21.000000. running mean: -20.121849\n","resetting env. episode 989.000000, reward total was -20.000000. running mean: -20.120631\n","resetting env. episode 990.000000, reward total was -21.000000. running mean: -20.129425\n","resetting env. episode 991.000000, reward total was -20.000000. running mean: -20.128130\n","resetting env. episode 992.000000, reward total was -20.000000. running mean: -20.126849\n","resetting env. episode 993.000000, reward total was -20.000000. running mean: -20.125581\n","resetting env. episode 994.000000, reward total was -20.000000. running mean: -20.124325\n","resetting env. episode 995.000000, reward total was -21.000000. running mean: -20.133082\n","resetting env. episode 996.000000, reward total was -20.000000. running mean: -20.131751\n","resetting env. episode 997.000000, reward total was -18.000000. running mean: -20.110433\n","resetting env. episode 998.000000, reward total was -21.000000. running mean: -20.119329\n","resetting env. episode 999.000000, reward total was -21.000000. running mean: -20.128136\n","resetting env. episode 1000.000000, reward total was -21.000000. running mean: -20.136854\n","resetting env. episode 1001.000000, reward total was -21.000000. running mean: -20.145486\n","resetting env. episode 1002.000000, reward total was -20.000000. running mean: -20.144031\n","resetting env. episode 1003.000000, reward total was -19.000000. running mean: -20.132591\n","resetting env. episode 1004.000000, reward total was -21.000000. running mean: -20.141265\n","resetting env. episode 1005.000000, reward total was -19.000000. running mean: -20.129852\n","resetting env. episode 1006.000000, reward total was -19.000000. running mean: -20.118553\n","resetting env. episode 1007.000000, reward total was -21.000000. running mean: -20.127368\n","resetting env. episode 1008.000000, reward total was -21.000000. running mean: -20.136094\n","resetting env. episode 1009.000000, reward total was -21.000000. running mean: -20.144733\n","resetting env. episode 1010.000000, reward total was -21.000000. running mean: -20.153286\n","resetting env. episode 1011.000000, reward total was -21.000000. running mean: -20.161753\n","resetting env. episode 1012.000000, reward total was -19.000000. running mean: -20.150136\n","resetting env. episode 1013.000000, reward total was -21.000000. running mean: -20.158634\n","resetting env. episode 1014.000000, reward total was -21.000000. running mean: -20.167048\n","resetting env. episode 1015.000000, reward total was -21.000000. running mean: -20.175377\n","resetting env. episode 1016.000000, reward total was -20.000000. running mean: -20.173624\n","resetting env. episode 1017.000000, reward total was -19.000000. running mean: -20.161887\n","resetting env. episode 1018.000000, reward total was -21.000000. running mean: -20.170269\n","resetting env. episode 1019.000000, reward total was -19.000000. running mean: -20.158566\n","resetting env. episode 1020.000000, reward total was -21.000000. running mean: -20.166980\n","resetting env. episode 1021.000000, reward total was -20.000000. running mean: -20.165310\n","resetting env. episode 1022.000000, reward total was -20.000000. running mean: -20.163657\n","resetting env. episode 1023.000000, reward total was -19.000000. running mean: -20.152021\n","resetting env. episode 1024.000000, reward total was -20.000000. running mean: -20.150501\n","resetting env. episode 1025.000000, reward total was -18.000000. running mean: -20.128996\n","resetting env. episode 1026.000000, reward total was -21.000000. running mean: -20.137706\n","resetting env. episode 1027.000000, reward total was -19.000000. running mean: -20.126329\n","resetting env. episode 1028.000000, reward total was -18.000000. running mean: -20.105065\n","resetting env. episode 1029.000000, reward total was -21.000000. running mean: -20.114015\n","resetting env. episode 1030.000000, reward total was -20.000000. running mean: -20.112874\n","resetting env. episode 1031.000000, reward total was -20.000000. running mean: -20.111746\n","resetting env. episode 1032.000000, reward total was -21.000000. running mean: -20.120628\n","resetting env. episode 1033.000000, reward total was -21.000000. running mean: -20.129422\n","resetting env. episode 1034.000000, reward total was -21.000000. running mean: -20.138128\n","resetting env. episode 1035.000000, reward total was -19.000000. running mean: -20.126746\n","resetting env. episode 1036.000000, reward total was -21.000000. running mean: -20.135479\n","resetting env. episode 1037.000000, reward total was -20.000000. running mean: -20.134124\n","resetting env. episode 1038.000000, reward total was -19.000000. running mean: -20.122783\n","resetting env. episode 1039.000000, reward total was -18.000000. running mean: -20.101555\n","resetting env. episode 1040.000000, reward total was -20.000000. running mean: -20.100540\n","resetting env. episode 1041.000000, reward total was -21.000000. running mean: -20.109534\n","resetting env. episode 1042.000000, reward total was -21.000000. running mean: -20.118439\n","resetting env. episode 1043.000000, reward total was -19.000000. running mean: -20.107254\n","resetting env. episode 1044.000000, reward total was -20.000000. running mean: -20.106182\n","resetting env. episode 1045.000000, reward total was -21.000000. running mean: -20.115120\n","resetting env. episode 1046.000000, reward total was -21.000000. running mean: -20.123969\n","resetting env. episode 1047.000000, reward total was -20.000000. running mean: -20.122729\n","resetting env. episode 1048.000000, reward total was -20.000000. running mean: -20.121502\n","resetting env. episode 1049.000000, reward total was -19.000000. running mean: -20.110287\n","resetting env. episode 1050.000000, reward total was -20.000000. running mean: -20.109184\n","resetting env. episode 1051.000000, reward total was -19.000000. running mean: -20.098092\n","resetting env. episode 1052.000000, reward total was -19.000000. running mean: -20.087111\n","resetting env. episode 1053.000000, reward total was -21.000000. running mean: -20.096240\n","resetting env. episode 1054.000000, reward total was -21.000000. running mean: -20.105278\n","resetting env. episode 1055.000000, reward total was -21.000000. running mean: -20.114225\n","resetting env. episode 1056.000000, reward total was -20.000000. running mean: -20.113083\n","resetting env. episode 1057.000000, reward total was -21.000000. running mean: -20.121952\n","resetting env. episode 1058.000000, reward total was -19.000000. running mean: -20.110732\n","resetting env. episode 1059.000000, reward total was -20.000000. running mean: -20.109625\n","resetting env. episode 1060.000000, reward total was -20.000000. running mean: -20.108529\n","resetting env. episode 1061.000000, reward total was -18.000000. running mean: -20.087443\n","resetting env. episode 1062.000000, reward total was -19.000000. running mean: -20.076569\n","resetting env. episode 1063.000000, reward total was -20.000000. running mean: -20.075803\n","resetting env. episode 1064.000000, reward total was -21.000000. running mean: -20.085045\n","resetting env. episode 1065.000000, reward total was -19.000000. running mean: -20.074195\n","resetting env. episode 1066.000000, reward total was -21.000000. running mean: -20.083453\n","resetting env. episode 1067.000000, reward total was -20.000000. running mean: -20.082618\n","resetting env. episode 1068.000000, reward total was -21.000000. running mean: -20.091792\n","resetting env. episode 1069.000000, reward total was -19.000000. running mean: -20.080874\n","resetting env. episode 1070.000000, reward total was -21.000000. running mean: -20.090066\n","resetting env. episode 1071.000000, reward total was -21.000000. running mean: -20.099165\n","resetting env. episode 1072.000000, reward total was -17.000000. running mean: -20.068173\n","resetting env. episode 1073.000000, reward total was -19.000000. running mean: -20.057492\n","resetting env. episode 1074.000000, reward total was -20.000000. running mean: -20.056917\n","resetting env. episode 1075.000000, reward total was -21.000000. running mean: -20.066347\n","resetting env. episode 1076.000000, reward total was -20.000000. running mean: -20.065684\n","resetting env. episode 1077.000000, reward total was -21.000000. running mean: -20.075027\n","resetting env. episode 1078.000000, reward total was -20.000000. running mean: -20.074277\n","resetting env. episode 1079.000000, reward total was -21.000000. running mean: -20.083534\n","resetting env. episode 1080.000000, reward total was -21.000000. running mean: -20.092699\n","resetting env. episode 1081.000000, reward total was -21.000000. running mean: -20.101772\n","resetting env. episode 1082.000000, reward total was -20.000000. running mean: -20.100754\n","resetting env. episode 1083.000000, reward total was -19.000000. running mean: -20.089746\n","resetting env. episode 1084.000000, reward total was -20.000000. running mean: -20.088849\n","resetting env. episode 1085.000000, reward total was -19.000000. running mean: -20.077961\n","resetting env. episode 1086.000000, reward total was -20.000000. running mean: -20.077181\n","resetting env. episode 1087.000000, reward total was -18.000000. running mean: -20.056409\n","resetting env. episode 1088.000000, reward total was -20.000000. running mean: -20.055845\n","resetting env. episode 1089.000000, reward total was -19.000000. running mean: -20.045287\n","resetting env. episode 1090.000000, reward total was -20.000000. running mean: -20.044834\n","resetting env. episode 1091.000000, reward total was -19.000000. running mean: -20.034385\n","resetting env. episode 1092.000000, reward total was -19.000000. running mean: -20.024042\n","resetting env. episode 1093.000000, reward total was -21.000000. running mean: -20.033801\n","resetting env. episode 1094.000000, reward total was -20.000000. running mean: -20.033463\n","resetting env. episode 1095.000000, reward total was -20.000000. running mean: -20.033128\n","resetting env. episode 1096.000000, reward total was -20.000000. running mean: -20.032797\n","resetting env. episode 1097.000000, reward total was -20.000000. running mean: -20.032469\n","resetting env. episode 1098.000000, reward total was -21.000000. running mean: -20.042145\n","resetting env. episode 1099.000000, reward total was -21.000000. running mean: -20.051723\n","resetting env. episode 1100.000000, reward total was -20.000000. running mean: -20.051206\n","resetting env. episode 1101.000000, reward total was -21.000000. running mean: -20.060694\n","resetting env. episode 1102.000000, reward total was -18.000000. running mean: -20.040087\n","resetting env. episode 1103.000000, reward total was -21.000000. running mean: -20.049686\n","resetting env. episode 1104.000000, reward total was -21.000000. running mean: -20.059189\n","resetting env. episode 1105.000000, reward total was -19.000000. running mean: -20.048597\n","resetting env. episode 1106.000000, reward total was -19.000000. running mean: -20.038111\n","resetting env. episode 1107.000000, reward total was -21.000000. running mean: -20.047730\n","resetting env. episode 1108.000000, reward total was -21.000000. running mean: -20.057253\n","resetting env. episode 1109.000000, reward total was -19.000000. running mean: -20.046680\n","resetting env. episode 1110.000000, reward total was -18.000000. running mean: -20.026214\n","resetting env. episode 1111.000000, reward total was -20.000000. running mean: -20.025951\n","resetting env. episode 1112.000000, reward total was -21.000000. running mean: -20.035692\n","resetting env. episode 1113.000000, reward total was -19.000000. running mean: -20.025335\n","resetting env. episode 1114.000000, reward total was -20.000000. running mean: -20.025082\n","resetting env. episode 1115.000000, reward total was -20.000000. running mean: -20.024831\n","resetting env. episode 1116.000000, reward total was -21.000000. running mean: -20.034582\n","resetting env. episode 1117.000000, reward total was -21.000000. running mean: -20.044237\n","resetting env. episode 1118.000000, reward total was -19.000000. running mean: -20.033794\n","resetting env. episode 1119.000000, reward total was -20.000000. running mean: -20.033456\n","resetting env. episode 1120.000000, reward total was -20.000000. running mean: -20.033122\n","resetting env. episode 1121.000000, reward total was -21.000000. running mean: -20.042791\n","resetting env. episode 1122.000000, reward total was -18.000000. running mean: -20.022363\n","resetting env. episode 1123.000000, reward total was -21.000000. running mean: -20.032139\n","resetting env. episode 1124.000000, reward total was -18.000000. running mean: -20.011818\n","resetting env. episode 1125.000000, reward total was -19.000000. running mean: -20.001699\n","resetting env. episode 1126.000000, reward total was -21.000000. running mean: -20.011682\n","resetting env. episode 1127.000000, reward total was -20.000000. running mean: -20.011566\n","resetting env. episode 1128.000000, reward total was -19.000000. running mean: -20.001450\n","resetting env. episode 1129.000000, reward total was -21.000000. running mean: -20.011435\n","resetting env. episode 1130.000000, reward total was -20.000000. running mean: -20.011321\n","resetting env. episode 1131.000000, reward total was -19.000000. running mean: -20.001208\n","resetting env. episode 1132.000000, reward total was -21.000000. running mean: -20.011196\n","resetting env. episode 1133.000000, reward total was -21.000000. running mean: -20.021084\n","resetting env. episode 1134.000000, reward total was -20.000000. running mean: -20.020873\n","resetting env. episode 1135.000000, reward total was -20.000000. running mean: -20.020664\n","resetting env. episode 1136.000000, reward total was -18.000000. running mean: -20.000458\n","resetting env. episode 1137.000000, reward total was -21.000000. running mean: -20.010453\n","resetting env. episode 1138.000000, reward total was -20.000000. running mean: -20.010349\n","resetting env. episode 1139.000000, reward total was -19.000000. running mean: -20.000245\n","resetting env. episode 1140.000000, reward total was -21.000000. running mean: -20.010243\n","resetting env. episode 1141.000000, reward total was -20.000000. running mean: -20.010140\n","resetting env. episode 1142.000000, reward total was -21.000000. running mean: -20.020039\n","resetting env. episode 1143.000000, reward total was -20.000000. running mean: -20.019838\n","resetting env. episode 1144.000000, reward total was -21.000000. running mean: -20.029640\n","resetting env. episode 1145.000000, reward total was -20.000000. running mean: -20.029344\n","resetting env. episode 1146.000000, reward total was -20.000000. running mean: -20.029050\n","resetting env. episode 1147.000000, reward total was -19.000000. running mean: -20.018760\n","resetting env. episode 1148.000000, reward total was -20.000000. running mean: -20.018572\n","resetting env. episode 1149.000000, reward total was -18.000000. running mean: -19.998386\n","resetting env. episode 1150.000000, reward total was -19.000000. running mean: -19.988403\n","resetting env. episode 1151.000000, reward total was -17.000000. running mean: -19.958518\n","resetting env. episode 1152.000000, reward total was -20.000000. running mean: -19.958933\n","resetting env. episode 1153.000000, reward total was -18.000000. running mean: -19.939344\n","resetting env. episode 1154.000000, reward total was -20.000000. running mean: -19.939951\n","resetting env. episode 1155.000000, reward total was -20.000000. running mean: -19.940551\n","resetting env. episode 1156.000000, reward total was -19.000000. running mean: -19.931146\n","resetting env. episode 1157.000000, reward total was -21.000000. running mean: -19.941834\n","resetting env. episode 1158.000000, reward total was -21.000000. running mean: -19.952416\n","resetting env. episode 1159.000000, reward total was -20.000000. running mean: -19.952892\n","resetting env. episode 1160.000000, reward total was -21.000000. running mean: -19.963363\n","resetting env. episode 1161.000000, reward total was -20.000000. running mean: -19.963729\n","resetting env. episode 1162.000000, reward total was -21.000000. running mean: -19.974092\n","resetting env. episode 1163.000000, reward total was -19.000000. running mean: -19.964351\n","resetting env. episode 1164.000000, reward total was -20.000000. running mean: -19.964707\n","resetting env. episode 1165.000000, reward total was -18.000000. running mean: -19.945060\n","resetting env. episode 1166.000000, reward total was -20.000000. running mean: -19.945610\n","resetting env. episode 1167.000000, reward total was -21.000000. running mean: -19.956154\n","resetting env. episode 1168.000000, reward total was -19.000000. running mean: -19.946592\n","resetting env. episode 1169.000000, reward total was -21.000000. running mean: -19.957126\n","resetting env. episode 1170.000000, reward total was -17.000000. running mean: -19.927555\n","resetting env. episode 1171.000000, reward total was -18.000000. running mean: -19.908279\n","resetting env. episode 1172.000000, reward total was -19.000000. running mean: -19.899196\n","resetting env. episode 1173.000000, reward total was -20.000000. running mean: -19.900205\n","resetting env. episode 1174.000000, reward total was -21.000000. running mean: -19.911202\n","resetting env. episode 1175.000000, reward total was -21.000000. running mean: -19.922090\n","resetting env. episode 1176.000000, reward total was -19.000000. running mean: -19.912870\n","resetting env. episode 1177.000000, reward total was -20.000000. running mean: -19.913741\n","resetting env. episode 1178.000000, reward total was -19.000000. running mean: -19.904603\n","resetting env. episode 1179.000000, reward total was -21.000000. running mean: -19.915557\n","resetting env. episode 1180.000000, reward total was -20.000000. running mean: -19.916402\n","resetting env. episode 1181.000000, reward total was -21.000000. running mean: -19.927238\n","resetting env. episode 1182.000000, reward total was -21.000000. running mean: -19.937965\n","resetting env. episode 1183.000000, reward total was -21.000000. running mean: -19.948586\n","resetting env. episode 1184.000000, reward total was -18.000000. running mean: -19.929100\n","resetting env. episode 1185.000000, reward total was -21.000000. running mean: -19.939809\n","resetting env. episode 1186.000000, reward total was -20.000000. running mean: -19.940411\n","resetting env. episode 1187.000000, reward total was -20.000000. running mean: -19.941007\n","resetting env. episode 1188.000000, reward total was -21.000000. running mean: -19.951597\n","resetting env. episode 1189.000000, reward total was -21.000000. running mean: -19.962081\n","resetting env. episode 1190.000000, reward total was -21.000000. running mean: -19.972460\n","resetting env. episode 1191.000000, reward total was -21.000000. running mean: -19.982735\n","resetting env. episode 1192.000000, reward total was -18.000000. running mean: -19.962908\n","resetting env. episode 1193.000000, reward total was -20.000000. running mean: -19.963279\n","resetting env. episode 1194.000000, reward total was -21.000000. running mean: -19.973646\n","resetting env. episode 1195.000000, reward total was -21.000000. running mean: -19.983910\n","resetting env. episode 1196.000000, reward total was -18.000000. running mean: -19.964070\n","resetting env. episode 1197.000000, reward total was -17.000000. running mean: -19.934430\n","resetting env. episode 1198.000000, reward total was -19.000000. running mean: -19.925085\n","resetting env. episode 1199.000000, reward total was -19.000000. running mean: -19.915835\n","resetting env. episode 1200.000000, reward total was -20.000000. running mean: -19.916676\n","resetting env. episode 1201.000000, reward total was -20.000000. running mean: -19.917510\n","resetting env. episode 1202.000000, reward total was -20.000000. running mean: -19.918334\n","resetting env. episode 1203.000000, reward total was -21.000000. running mean: -19.929151\n","resetting env. episode 1204.000000, reward total was -19.000000. running mean: -19.919860\n","resetting env. episode 1205.000000, reward total was -20.000000. running mean: -19.920661\n","resetting env. episode 1206.000000, reward total was -21.000000. running mean: -19.931454\n","resetting env. episode 1207.000000, reward total was -19.000000. running mean: -19.922140\n","resetting env. episode 1208.000000, reward total was -21.000000. running mean: -19.932918\n","resetting env. episode 1209.000000, reward total was -21.000000. running mean: -19.943589\n","resetting env. episode 1210.000000, reward total was -19.000000. running mean: -19.934153\n","resetting env. episode 1211.000000, reward total was -18.000000. running mean: -19.914812\n","resetting env. episode 1212.000000, reward total was -21.000000. running mean: -19.925664\n","resetting env. episode 1213.000000, reward total was -20.000000. running mean: -19.926407\n","resetting env. episode 1214.000000, reward total was -19.000000. running mean: -19.917143\n","resetting env. episode 1215.000000, reward total was -21.000000. running mean: -19.927972\n","resetting env. episode 1216.000000, reward total was -19.000000. running mean: -19.918692\n","resetting env. episode 1217.000000, reward total was -19.000000. running mean: -19.909505\n","resetting env. episode 1218.000000, reward total was -20.000000. running mean: -19.910410\n","resetting env. episode 1219.000000, reward total was -21.000000. running mean: -19.921306\n","resetting env. episode 1220.000000, reward total was -20.000000. running mean: -19.922093\n","resetting env. episode 1221.000000, reward total was -20.000000. running mean: -19.922872\n","resetting env. episode 1222.000000, reward total was -21.000000. running mean: -19.933643\n","resetting env. episode 1223.000000, reward total was -21.000000. running mean: -19.944307\n","resetting env. episode 1224.000000, reward total was -20.000000. running mean: -19.944864\n","resetting env. episode 1225.000000, reward total was -21.000000. running mean: -19.955415\n","resetting env. episode 1226.000000, reward total was -20.000000. running mean: -19.955861\n","resetting env. episode 1227.000000, reward total was -19.000000. running mean: -19.946302\n","resetting env. episode 1228.000000, reward total was -16.000000. running mean: -19.906839\n","resetting env. episode 1229.000000, reward total was -21.000000. running mean: -19.917771\n","resetting env. episode 1230.000000, reward total was -21.000000. running mean: -19.928593\n","resetting env. episode 1231.000000, reward total was -21.000000. running mean: -19.939307\n","resetting env. episode 1232.000000, reward total was -20.000000. running mean: -19.939914\n","resetting env. episode 1233.000000, reward total was -21.000000. running mean: -19.950515\n","resetting env. episode 1234.000000, reward total was -20.000000. running mean: -19.951010\n","resetting env. episode 1235.000000, reward total was -20.000000. running mean: -19.951500\n","resetting env. episode 1236.000000, reward total was -21.000000. running mean: -19.961985\n","resetting env. episode 1237.000000, reward total was -21.000000. running mean: -19.972365\n","resetting env. episode 1238.000000, reward total was -21.000000. running mean: -19.982641\n","resetting env. episode 1239.000000, reward total was -21.000000. running mean: -19.992815\n","resetting env. episode 1240.000000, reward total was -18.000000. running mean: -19.972887\n","resetting env. episode 1241.000000, reward total was -20.000000. running mean: -19.973158\n","resetting env. episode 1242.000000, reward total was -21.000000. running mean: -19.983426\n","resetting env. episode 1243.000000, reward total was -21.000000. running mean: -19.993592\n","resetting env. episode 1244.000000, reward total was -21.000000. running mean: -20.003656\n","resetting env. episode 1245.000000, reward total was -21.000000. running mean: -20.013619\n","resetting env. episode 1246.000000, reward total was -20.000000. running mean: -20.013483\n","resetting env. episode 1247.000000, reward total was -21.000000. running mean: -20.023348\n","resetting env. episode 1248.000000, reward total was -20.000000. running mean: -20.023115\n","resetting env. episode 1249.000000, reward total was -16.000000. running mean: -19.982884\n","resetting env. episode 1250.000000, reward total was -21.000000. running mean: -19.993055\n","resetting env. episode 1251.000000, reward total was -21.000000. running mean: -20.003124\n","resetting env. episode 1252.000000, reward total was -20.000000. running mean: -20.003093\n","resetting env. episode 1253.000000, reward total was -19.000000. running mean: -19.993062\n","resetting env. episode 1254.000000, reward total was -19.000000. running mean: -19.983132\n","resetting env. episode 1255.000000, reward total was -17.000000. running mean: -19.953300\n","resetting env. episode 1256.000000, reward total was -17.000000. running mean: -19.923767\n","resetting env. episode 1257.000000, reward total was -21.000000. running mean: -19.934530\n","resetting env. episode 1258.000000, reward total was -21.000000. running mean: -19.945184\n","resetting env. episode 1259.000000, reward total was -21.000000. running mean: -19.955732\n","resetting env. episode 1260.000000, reward total was -20.000000. running mean: -19.956175\n","resetting env. episode 1261.000000, reward total was -20.000000. running mean: -19.956613\n","resetting env. episode 1262.000000, reward total was -20.000000. running mean: -19.957047\n","resetting env. episode 1263.000000, reward total was -18.000000. running mean: -19.937477\n","resetting env. episode 1264.000000, reward total was -20.000000. running mean: -19.938102\n","resetting env. episode 1265.000000, reward total was -21.000000. running mean: -19.948721\n","resetting env. episode 1266.000000, reward total was -21.000000. running mean: -19.959234\n","resetting env. episode 1267.000000, reward total was -20.000000. running mean: -19.959641\n","resetting env. episode 1268.000000, reward total was -21.000000. running mean: -19.970045\n","resetting env. episode 1269.000000, reward total was -20.000000. running mean: -19.970345\n","resetting env. episode 1270.000000, reward total was -18.000000. running mean: -19.950641\n","resetting env. episode 1271.000000, reward total was -18.000000. running mean: -19.931135\n","resetting env. episode 1272.000000, reward total was -19.000000. running mean: -19.921823\n","resetting env. episode 1273.000000, reward total was -20.000000. running mean: -19.922605\n","resetting env. episode 1274.000000, reward total was -19.000000. running mean: -19.913379\n","resetting env. episode 1275.000000, reward total was -21.000000. running mean: -19.924245\n","resetting env. episode 1276.000000, reward total was -20.000000. running mean: -19.925003\n","resetting env. episode 1277.000000, reward total was -20.000000. running mean: -19.925753\n","resetting env. episode 1278.000000, reward total was -21.000000. running mean: -19.936495\n","resetting env. episode 1279.000000, reward total was -20.000000. running mean: -19.937130\n","resetting env. episode 1280.000000, reward total was -21.000000. running mean: -19.947759\n","resetting env. episode 1281.000000, reward total was -19.000000. running mean: -19.938281\n","resetting env. episode 1282.000000, reward total was -21.000000. running mean: -19.948899\n","resetting env. episode 1283.000000, reward total was -21.000000. running mean: -19.959410\n","resetting env. episode 1284.000000, reward total was -21.000000. running mean: -19.969816\n","resetting env. episode 1285.000000, reward total was -18.000000. running mean: -19.950117\n","resetting env. episode 1286.000000, reward total was -20.000000. running mean: -19.950616\n","resetting env. episode 1287.000000, reward total was -19.000000. running mean: -19.941110\n","resetting env. episode 1288.000000, reward total was -19.000000. running mean: -19.931699\n","resetting env. episode 1289.000000, reward total was -21.000000. running mean: -19.942382\n","resetting env. episode 1290.000000, reward total was -19.000000. running mean: -19.932958\n","resetting env. episode 1291.000000, reward total was -20.000000. running mean: -19.933629\n","resetting env. episode 1292.000000, reward total was -21.000000. running mean: -19.944292\n","resetting env. episode 1293.000000, reward total was -20.000000. running mean: -19.944849\n","resetting env. episode 1294.000000, reward total was -20.000000. running mean: -19.945401\n","resetting env. episode 1295.000000, reward total was -18.000000. running mean: -19.925947\n","resetting env. episode 1296.000000, reward total was -19.000000. running mean: -19.916687\n","resetting env. episode 1297.000000, reward total was -19.000000. running mean: -19.907521\n","resetting env. episode 1298.000000, reward total was -20.000000. running mean: -19.908445\n","resetting env. episode 1299.000000, reward total was -21.000000. running mean: -19.919361\n","resetting env. episode 1300.000000, reward total was -20.000000. running mean: -19.920167\n","resetting env. episode 1301.000000, reward total was -20.000000. running mean: -19.920966\n","resetting env. episode 1302.000000, reward total was -21.000000. running mean: -19.931756\n","resetting env. episode 1303.000000, reward total was -18.000000. running mean: -19.912438\n","resetting env. episode 1304.000000, reward total was -21.000000. running mean: -19.923314\n","resetting env. episode 1305.000000, reward total was -21.000000. running mean: -19.934081\n","resetting env. episode 1306.000000, reward total was -18.000000. running mean: -19.914740\n","resetting env. episode 1307.000000, reward total was -21.000000. running mean: -19.925593\n","resetting env. episode 1308.000000, reward total was -19.000000. running mean: -19.916337\n","resetting env. episode 1309.000000, reward total was -19.000000. running mean: -19.907173\n","resetting env. episode 1310.000000, reward total was -19.000000. running mean: -19.898102\n","resetting env. episode 1311.000000, reward total was -21.000000. running mean: -19.909121\n","resetting env. episode 1312.000000, reward total was -19.000000. running mean: -19.900029\n","resetting env. episode 1313.000000, reward total was -21.000000. running mean: -19.911029\n","resetting env. episode 1314.000000, reward total was -21.000000. running mean: -19.921919\n","resetting env. episode 1315.000000, reward total was -20.000000. running mean: -19.922700\n","resetting env. episode 1316.000000, reward total was -21.000000. running mean: -19.933473\n","resetting env. episode 1317.000000, reward total was -19.000000. running mean: -19.924138\n","resetting env. episode 1318.000000, reward total was -19.000000. running mean: -19.914897\n","resetting env. episode 1319.000000, reward total was -21.000000. running mean: -19.925748\n","resetting env. episode 1320.000000, reward total was -19.000000. running mean: -19.916490\n","resetting env. episode 1321.000000, reward total was -20.000000. running mean: -19.917325\n","resetting env. episode 1322.000000, reward total was -21.000000. running mean: -19.928152\n","resetting env. episode 1323.000000, reward total was -20.000000. running mean: -19.928870\n","resetting env. episode 1324.000000, reward total was -18.000000. running mean: -19.909582\n","resetting env. episode 1325.000000, reward total was -20.000000. running mean: -19.910486\n","resetting env. episode 1326.000000, reward total was -19.000000. running mean: -19.901381\n","resetting env. episode 1327.000000, reward total was -20.000000. running mean: -19.902367\n","resetting env. episode 1328.000000, reward total was -19.000000. running mean: -19.893344\n","resetting env. episode 1329.000000, reward total was -21.000000. running mean: -19.904410\n","resetting env. episode 1330.000000, reward total was -21.000000. running mean: -19.915366\n","resetting env. episode 1331.000000, reward total was -21.000000. running mean: -19.926212\n","resetting env. episode 1332.000000, reward total was -19.000000. running mean: -19.916950\n","resetting env. episode 1333.000000, reward total was -20.000000. running mean: -19.917781\n","resetting env. episode 1334.000000, reward total was -21.000000. running mean: -19.928603\n","resetting env. episode 1335.000000, reward total was -21.000000. running mean: -19.939317\n","resetting env. episode 1336.000000, reward total was -19.000000. running mean: -19.929924\n","resetting env. episode 1337.000000, reward total was -21.000000. running mean: -19.940624\n","resetting env. episode 1338.000000, reward total was -20.000000. running mean: -19.941218\n","resetting env. episode 1339.000000, reward total was -21.000000. running mean: -19.951806\n","resetting env. episode 1340.000000, reward total was -20.000000. running mean: -19.952288\n","resetting env. episode 1341.000000, reward total was -21.000000. running mean: -19.962765\n","resetting env. episode 1342.000000, reward total was -16.000000. running mean: -19.923137\n","resetting env. episode 1343.000000, reward total was -21.000000. running mean: -19.933906\n","resetting env. episode 1344.000000, reward total was -21.000000. running mean: -19.944567\n","resetting env. episode 1345.000000, reward total was -21.000000. running mean: -19.955121\n","resetting env. episode 1346.000000, reward total was -20.000000. running mean: -19.955570\n","resetting env. episode 1347.000000, reward total was -21.000000. running mean: -19.966014\n","resetting env. episode 1348.000000, reward total was -21.000000. running mean: -19.976354\n","resetting env. episode 1349.000000, reward total was -21.000000. running mean: -19.986591\n","resetting env. episode 1350.000000, reward total was -21.000000. running mean: -19.996725\n","resetting env. episode 1351.000000, reward total was -21.000000. running mean: -20.006758\n","resetting env. episode 1352.000000, reward total was -21.000000. running mean: -20.016690\n","resetting env. episode 1353.000000, reward total was -20.000000. running mean: -20.016523\n","resetting env. episode 1354.000000, reward total was -19.000000. running mean: -20.006358\n","resetting env. episode 1355.000000, reward total was -19.000000. running mean: -19.996294\n","resetting env. episode 1356.000000, reward total was -17.000000. running mean: -19.966331\n","resetting env. episode 1357.000000, reward total was -19.000000. running mean: -19.956668\n","resetting env. episode 1358.000000, reward total was -21.000000. running mean: -19.967101\n","resetting env. episode 1359.000000, reward total was -19.000000. running mean: -19.957430\n","resetting env. episode 1360.000000, reward total was -21.000000. running mean: -19.967856\n","resetting env. episode 1361.000000, reward total was -19.000000. running mean: -19.958177\n","resetting env. episode 1362.000000, reward total was -20.000000. running mean: -19.958596\n","resetting env. episode 1363.000000, reward total was -18.000000. running mean: -19.939010\n","resetting env. episode 1364.000000, reward total was -20.000000. running mean: -19.939620\n","resetting env. episode 1365.000000, reward total was -21.000000. running mean: -19.950223\n","resetting env. episode 1366.000000, reward total was -19.000000. running mean: -19.940721\n","resetting env. episode 1367.000000, reward total was -21.000000. running mean: -19.951314\n","resetting env. episode 1368.000000, reward total was -20.000000. running mean: -19.951801\n","resetting env. episode 1369.000000, reward total was -20.000000. running mean: -19.952283\n","resetting env. episode 1370.000000, reward total was -21.000000. running mean: -19.962760\n","resetting env. episode 1371.000000, reward total was -21.000000. running mean: -19.973132\n","resetting env. episode 1372.000000, reward total was -20.000000. running mean: -19.973401\n","resetting env. episode 1373.000000, reward total was -21.000000. running mean: -19.983667\n","resetting env. episode 1374.000000, reward total was -19.000000. running mean: -19.973830\n","resetting env. episode 1375.000000, reward total was -18.000000. running mean: -19.954092\n","resetting env. episode 1376.000000, reward total was -21.000000. running mean: -19.964551\n","resetting env. episode 1377.000000, reward total was -19.000000. running mean: -19.954906\n","resetting env. episode 1378.000000, reward total was -20.000000. running mean: -19.955357\n","resetting env. episode 1379.000000, reward total was -19.000000. running mean: -19.945803\n","resetting env. episode 1380.000000, reward total was -20.000000. running mean: -19.946345\n","resetting env. episode 1381.000000, reward total was -18.000000. running mean: -19.926882\n","resetting env. episode 1382.000000, reward total was -19.000000. running mean: -19.917613\n","resetting env. episode 1383.000000, reward total was -20.000000. running mean: -19.918437\n","resetting env. episode 1384.000000, reward total was -21.000000. running mean: -19.929252\n","resetting env. episode 1385.000000, reward total was -20.000000. running mean: -19.929960\n","resetting env. episode 1386.000000, reward total was -20.000000. running mean: -19.930660\n","resetting env. episode 1387.000000, reward total was -20.000000. running mean: -19.931354\n","resetting env. episode 1388.000000, reward total was -19.000000. running mean: -19.922040\n","resetting env. episode 1389.000000, reward total was -21.000000. running mean: -19.932820\n","resetting env. episode 1390.000000, reward total was -20.000000. running mean: -19.933491\n","resetting env. episode 1391.000000, reward total was -21.000000. running mean: -19.944157\n","resetting env. episode 1392.000000, reward total was -21.000000. running mean: -19.954715\n","resetting env. episode 1393.000000, reward total was -18.000000. running mean: -19.935168\n","resetting env. episode 1394.000000, reward total was -21.000000. running mean: -19.945816\n","resetting env. episode 1395.000000, reward total was -21.000000. running mean: -19.956358\n","resetting env. episode 1396.000000, reward total was -20.000000. running mean: -19.956794\n","resetting env. episode 1397.000000, reward total was -20.000000. running mean: -19.957226\n","resetting env. episode 1398.000000, reward total was -19.000000. running mean: -19.947654\n","resetting env. episode 1399.000000, reward total was -20.000000. running mean: -19.948178\n","resetting env. episode 1400.000000, reward total was -20.000000. running mean: -19.948696\n","resetting env. episode 1401.000000, reward total was -20.000000. running mean: -19.949209\n","resetting env. episode 1402.000000, reward total was -20.000000. running mean: -19.949717\n","resetting env. episode 1403.000000, reward total was -19.000000. running mean: -19.940220\n","resetting env. episode 1404.000000, reward total was -19.000000. running mean: -19.930817\n","resetting env. episode 1405.000000, reward total was -20.000000. running mean: -19.931509\n","resetting env. episode 1406.000000, reward total was -20.000000. running mean: -19.932194\n","resetting env. episode 1407.000000, reward total was -19.000000. running mean: -19.922872\n","resetting env. episode 1408.000000, reward total was -21.000000. running mean: -19.933644\n","resetting env. episode 1409.000000, reward total was -16.000000. running mean: -19.894307\n","resetting env. episode 1410.000000, reward total was -19.000000. running mean: -19.885364\n","resetting env. episode 1411.000000, reward total was -18.000000. running mean: -19.866510\n","resetting env. episode 1412.000000, reward total was -19.000000. running mean: -19.857845\n","resetting env. episode 1413.000000, reward total was -19.000000. running mean: -19.849267\n","resetting env. episode 1414.000000, reward total was -19.000000. running mean: -19.840774\n","resetting env. episode 1415.000000, reward total was -19.000000. running mean: -19.832366\n","resetting env. episode 1416.000000, reward total was -19.000000. running mean: -19.824043\n","resetting env. episode 1417.000000, reward total was -20.000000. running mean: -19.825802\n","resetting env. episode 1418.000000, reward total was -21.000000. running mean: -19.837544\n","resetting env. episode 1419.000000, reward total was -19.000000. running mean: -19.829169\n","resetting env. episode 1420.000000, reward total was -20.000000. running mean: -19.830877\n","resetting env. episode 1421.000000, reward total was -18.000000. running mean: -19.812568\n","resetting env. episode 1422.000000, reward total was -20.000000. running mean: -19.814443\n","resetting env. episode 1423.000000, reward total was -20.000000. running mean: -19.816298\n","resetting env. episode 1424.000000, reward total was -21.000000. running mean: -19.828135\n","resetting env. episode 1425.000000, reward total was -21.000000. running mean: -19.839854\n","resetting env. episode 1426.000000, reward total was -20.000000. running mean: -19.841455\n","resetting env. episode 1427.000000, reward total was -21.000000. running mean: -19.853041\n","resetting env. episode 1428.000000, reward total was -21.000000. running mean: -19.864510\n","resetting env. episode 1429.000000, reward total was -20.000000. running mean: -19.865865\n","resetting env. episode 1430.000000, reward total was -18.000000. running mean: -19.847207\n","resetting env. episode 1431.000000, reward total was -21.000000. running mean: -19.858735\n","resetting env. episode 1432.000000, reward total was -20.000000. running mean: -19.860147\n","resetting env. episode 1433.000000, reward total was -21.000000. running mean: -19.871546\n","resetting env. episode 1434.000000, reward total was -19.000000. running mean: -19.862830\n","resetting env. episode 1435.000000, reward total was -20.000000. running mean: -19.864202\n","resetting env. episode 1436.000000, reward total was -17.000000. running mean: -19.835560\n","resetting env. episode 1437.000000, reward total was -19.000000. running mean: -19.827204\n","resetting env. episode 1438.000000, reward total was -19.000000. running mean: -19.818932\n","resetting env. episode 1439.000000, reward total was -21.000000. running mean: -19.830743\n","resetting env. episode 1440.000000, reward total was -19.000000. running mean: -19.822436\n","resetting env. episode 1441.000000, reward total was -20.000000. running mean: -19.824211\n","resetting env. episode 1442.000000, reward total was -21.000000. running mean: -19.835969\n","resetting env. episode 1443.000000, reward total was -20.000000. running mean: -19.837609\n","resetting env. episode 1444.000000, reward total was -19.000000. running mean: -19.829233\n","resetting env. episode 1445.000000, reward total was -19.000000. running mean: -19.820941\n","resetting env. episode 1446.000000, reward total was -20.000000. running mean: -19.822732\n","resetting env. episode 1447.000000, reward total was -20.000000. running mean: -19.824504\n","resetting env. episode 1448.000000, reward total was -17.000000. running mean: -19.796259\n","resetting env. episode 1449.000000, reward total was -21.000000. running mean: -19.808297\n","resetting env. episode 1450.000000, reward total was -20.000000. running mean: -19.810214\n","resetting env. episode 1451.000000, reward total was -21.000000. running mean: -19.822112\n","resetting env. episode 1452.000000, reward total was -19.000000. running mean: -19.813890\n","resetting env. episode 1453.000000, reward total was -21.000000. running mean: -19.825752\n","resetting env. episode 1454.000000, reward total was -21.000000. running mean: -19.837494\n","resetting env. episode 1455.000000, reward total was -20.000000. running mean: -19.839119\n","resetting env. episode 1456.000000, reward total was -18.000000. running mean: -19.820728\n","resetting env. episode 1457.000000, reward total was -19.000000. running mean: -19.812521\n","resetting env. episode 1458.000000, reward total was -20.000000. running mean: -19.814395\n","resetting env. episode 1459.000000, reward total was -21.000000. running mean: -19.826251\n","resetting env. episode 1460.000000, reward total was -21.000000. running mean: -19.837989\n","resetting env. episode 1461.000000, reward total was -16.000000. running mean: -19.799609\n","resetting env. episode 1462.000000, reward total was -20.000000. running mean: -19.801613\n","resetting env. episode 1463.000000, reward total was -19.000000. running mean: -19.793597\n","resetting env. episode 1464.000000, reward total was -21.000000. running mean: -19.805661\n","resetting env. episode 1465.000000, reward total was -21.000000. running mean: -19.817604\n","resetting env. episode 1466.000000, reward total was -18.000000. running mean: -19.799428\n","resetting env. episode 1467.000000, reward total was -19.000000. running mean: -19.791434\n","resetting env. episode 1468.000000, reward total was -21.000000. running mean: -19.803520\n","resetting env. episode 1469.000000, reward total was -21.000000. running mean: -19.815484\n","resetting env. episode 1470.000000, reward total was -21.000000. running mean: -19.827330\n","resetting env. episode 1471.000000, reward total was -19.000000. running mean: -19.819056\n","resetting env. episode 1472.000000, reward total was -21.000000. running mean: -19.830866\n","resetting env. episode 1473.000000, reward total was -18.000000. running mean: -19.812557\n","resetting env. episode 1474.000000, reward total was -20.000000. running mean: -19.814431\n","resetting env. episode 1475.000000, reward total was -19.000000. running mean: -19.806287\n","resetting env. episode 1476.000000, reward total was -20.000000. running mean: -19.808224\n","resetting env. episode 1477.000000, reward total was -20.000000. running mean: -19.810142\n","resetting env. episode 1478.000000, reward total was -18.000000. running mean: -19.792041\n","resetting env. episode 1479.000000, reward total was -19.000000. running mean: -19.784120\n","resetting env. episode 1480.000000, reward total was -21.000000. running mean: -19.796279\n","resetting env. episode 1481.000000, reward total was -21.000000. running mean: -19.808316\n","resetting env. episode 1482.000000, reward total was -19.000000. running mean: -19.800233\n","resetting env. episode 1483.000000, reward total was -19.000000. running mean: -19.792231\n","resetting env. episode 1484.000000, reward total was -18.000000. running mean: -19.774308\n","resetting env. episode 1485.000000, reward total was -20.000000. running mean: -19.776565\n","resetting env. episode 1486.000000, reward total was -21.000000. running mean: -19.788800\n","resetting env. episode 1487.000000, reward total was -20.000000. running mean: -19.790912\n","resetting env. episode 1488.000000, reward total was -20.000000. running mean: -19.793003\n","resetting env. episode 1489.000000, reward total was -20.000000. running mean: -19.795073\n","resetting env. episode 1490.000000, reward total was -20.000000. running mean: -19.797122\n","resetting env. episode 1491.000000, reward total was -20.000000. running mean: -19.799151\n","resetting env. episode 1492.000000, reward total was -20.000000. running mean: -19.801159\n","resetting env. episode 1493.000000, reward total was -19.000000. running mean: -19.793147\n","resetting env. episode 1494.000000, reward total was -21.000000. running mean: -19.805216\n","resetting env. episode 1495.000000, reward total was -19.000000. running mean: -19.797164\n","resetting env. episode 1496.000000, reward total was -21.000000. running mean: -19.809192\n","resetting env. episode 1497.000000, reward total was -21.000000. running mean: -19.821100\n","resetting env. episode 1498.000000, reward total was -19.000000. running mean: -19.812889\n","resetting env. episode 1499.000000, reward total was -21.000000. running mean: -19.824760\n","resetting env. episode 1500.000000, reward total was -18.000000. running mean: -19.806513\n","CPU times: user 2h 40min 7s, sys: 45min 19s, total: 3h 25min 26s\n","Wall time: 1h 46min 12s\n"]}]},{"metadata":{"id":"w2NblmwDsL3y","outputId":"25c5a8e7-c9ba-4c6a-e5bb-9070ae786608","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"ok","timestamp":1660642013117,"user_tz":-330,"elapsed":42918,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -7.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}