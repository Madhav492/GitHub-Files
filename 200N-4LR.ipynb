{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"200N-4LR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"gpuClass":"standard"},"cells":[{"metadata":{"id":"cWACPRL869I4"},"cell_type":"code","source":["!pip install gym >/dev/null"],"execution_count":null,"outputs":[]},{"metadata":{"id":"2Os6feRY6ec_"},"cell_type":"code","source":["!pip install JSAnimation >/dev/null"],"execution_count":null,"outputs":[]},{"metadata":{"id":"wotUOa_e6edP"},"cell_type":"code","source":["%matplotlib inline\n","from JSAnimation.IPython_display import display_animation\n","from matplotlib import animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","\n","def display_frames_as_gif(frames):\n","    \"\"\"\n","    Displays a list of frames as a gif, with controls\n","    \"\"\"\n","    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","\n","    def animate(i):\n","        patch.set_data(frames[i])\n","\n","    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n","    HTML(anim.to_jshtml())"],"execution_count":null,"outputs":[]},{"metadata":{"id":"R66_INeZ9nYX"},"cell_type":"markdown","source":["## Step 2: Playing Pong"]},{"cell_type":"code","source":["%pip install -U gym>=0.21.0\n","%pip install -U gym[atari,accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ngMhg3fB9aA","outputId":"6736c2d7-0e8d-451a-ae1e-f7bad8c57815","executionInfo":{"status":"ok","timestamp":1660623103984,"user_tz":-330,"elapsed":34497,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n","Collecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 37.7 MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=cb58586ffa8a13e21dbd8b7183e2ded3ceae9b83004307b4cf71af664137a672\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"]}]},{"metadata":{"id":"MtT2GyK_6edc","outputId":"f0ecbe89-fdc8-48dc-c507-1cf3aea6e546","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660623105304,"user_tz":-330,"elapsed":1338,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import gym\n","env = gym.make('Pong-v0')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  f\"The environment {id} is out of date. You should consider \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}]},{"metadata":{"id":"oRE6WmXQJ1Z0","outputId":"2614462a-0569-4f0d-b00c-c5dbc5e339d7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660623105304,"user_tz":-330,"elapsed":13,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.action_space"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(6)"]},"metadata":{},"execution_count":6}]},{"metadata":{"id":"yl_9d4HFJ31W","outputId":"91aecf70-36b8-4e17-eeb8-fad79b12c057","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660623105305,"user_tz":-330,"elapsed":11,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.observation_space"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box(0, 255, (210, 160, 3), uint8)"]},"metadata":{},"execution_count":7}]},{"metadata":{"id":"trwRXI-h6eeI","outputId":"b4b3fd36-8c9a-4341-a400-7db0872354d4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660623106312,"user_tz":-330,"elapsed":1016,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# Run a demo of the environment\n","observation = env.reset()\n","cumulated_reward = 0\n","\n","frames = []\n","for t in range(1000):\n","#     print(observation)\n","    frames.append(env.render(mode = 'rgb_array'))\n","    # very stupid agent, just makes a random action within the allowd action space\n","    action = env.action_space.sample()\n","#     print(\"Action: {}\".format(t+1))    \n","    observation, reward, done, info = env.step(action)\n","#     print(reward)\n","    cumulated_reward += reward\n","    if done:\n","        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","        break\n","print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","\n","env.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -9.0\n"]}]},{"metadata":{"id":"3zZTecVWLLes"},"cell_type":"code","source":["def sigmoid(x): \n","  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n","\n","def prepro(I):\n","  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n","  I = I[35:195] # crop\n","  I = I[::2,::2,0] # downsample by factor of 2\n","  I[I == 144] = 0 # erase background (background type 1)\n","  I[I == 109] = 0 # erase background (background type 2)\n","  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n","  return I.astype(np.float).ravel()\n","\n","def policy_forward(x):\n","  h = np.dot(model['W1'], x)\n","  h[h<0] = 0 # ReLU nonlinearity\n","  logp = np.dot(model['W2'], h)\n","  p = sigmoid(logp)\n","  return p, h # return probability of taking action 2, and hidden state\n","\n","def model_step(model, observation, prev_x):\n","  # preprocess the observation, set input to network to be difference image\n","  cur_x = prepro(observation)\n","  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","  prev_x = cur_x\n","  \n","  # forward the policy network and sample an action from the returned probability\n","  aprob, _ = policy_forward(x)\n","  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n","  \n","  return action, prev_x\n","\n","def play_game(env, model):\n","  observation = env.reset()\n","\n","  frames = []\n","  cumulated_reward = 0\n","\n","  prev_x = None # used in computing the difference frame\n","\n","  for t in range(1000):\n","      frames.append(env.render(mode = 'rgb_array'))\n","      action, prev_x = model_step(model, observation, prev_x)\n","      observation, reward, done, info = env.step(action)\n","      cumulated_reward += reward\n","      if done:\n","          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","          break\n","  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","  display_frames_as_gif(frames)\n","  env.close()"],"execution_count":null,"outputs":[]},{"metadata":{"id":"6gWvZQ7AQLQt"},"cell_type":"markdown","source":["## Step 3: Policy Gradient from Scratch"]},{"metadata":{"id":"eqFm7hqcItWl"},"cell_type":"code","source":["import numpy as np\n","\n","# model initialization\n","H = 200 # number of hidden layer neurons\n","D = 80 * 80 # input dimensionality: 80x80 grid\n","model = {}\n","model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n","model['W2'] = np.random.randn(H) / np.sqrt(H)\n","\n","# import pickle\n","# model = pickle.load(open('model.pkl', 'rb'))"],"execution_count":null,"outputs":[]},{"metadata":{"id":"TwjiwKisQM19"},"cell_type":"code","source":["# hyperparameters\n","batch_size = 10 # every how many episodes to do a param update?\n","# learning_rate = 1e-4\n","learning_rate = 1e-4\n"," \n","gamma = 0.99 # discount factor for reward\n","decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n","  \n","grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n","rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n","\n","def discount_rewards(r):\n","  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n","  discounted_r = np.zeros_like(r, dtype=np.float32)\n","  running_add = 0\n","  for t in reversed(range(0, r.size)):\n","    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n","    running_add = running_add * gamma + r[t]\n","    discounted_r[t] = running_add\n","  return discounted_r\n","\n","def policy_backward(epx, eph, epdlogp):\n","  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n","  dW2 = np.dot(eph.T, epdlogp).ravel()\n","  dh = np.outer(epdlogp, model['W2'])\n","  dh[eph <= 0] = 0 # backpro prelu\n","  dW1 = np.dot(dh.T, epx)\n","  return {'W1':dW1, 'W2':dW2}\n","\n","def train_model(env, model, total_episodes = 100):\n","  hist = []\n","  observation = env.reset()\n","\n","  prev_x = None # used in computing the difference frame\n","  xs,hs,dlogps,drs = [],[],[],[]\n","  running_reward = None\n","  reward_sum = 0\n","  episode_number = 0\n","\n","  while True:\n","    # preprocess the observation, set input to network to be difference image\n","    cur_x = prepro(observation)\n","    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","    prev_x = cur_x\n","\n","    # forward the policy network and sample an action from the returned probability\n","    aprob, h = policy_forward(x)\n","    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n","\n","    # record various intermediates (needed later for backprop)\n","    xs.append(x) # observation\n","    hs.append(h) # hidden state\n","    y = 1 if action == 2 else 0 # a \"fake label\"\n","    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n","\n","    # step the environment and get new measurements\n","    observation, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n","\n","    if done: # an episode finished\n","      episode_number += 1\n","\n","      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n","      epx = np.vstack(xs)\n","      eph = np.vstack(hs)\n","      epdlogp = np.vstack(dlogps)\n","      epr = np.vstack(drs)\n","      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n","\n","      # compute the discounted reward backwards through time\n","      discounted_epr = discount_rewards(epr)\n","      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n","      discounted_epr -= np.mean(discounted_epr)\n","      discounted_epr /= np.std(discounted_epr)\n","\n","      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n","      grad = policy_backward(epx, eph, epdlogp)\n","      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n","\n","      # perform rmsprop parameter update every batch_size episodes\n","      if episode_number % batch_size == 0:\n","        for k,v in model.items():\n","          g = grad_buffer[k] # gradient\n","          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n","          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n","          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n","\n","      # boring book-keeping\n","      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n","      hist.append((episode_number, reward_sum, running_reward))\n","      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n","      reward_sum = 0\n","      observation = env.reset() # reset env\n","      prev_x = None\n","      if episode_number == total_episodes: return hist\n","\n","      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n","        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"],"execution_count":null,"outputs":[]},{"metadata":{"id":"G6Ka_5Vl9Orm","outputId":"55b06b0b-f4e8-4d7b-a10a-0c045c65eeb0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660624299858,"user_tz":-330,"elapsed":1193554,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist1 = train_model(env, model, total_episodes=500)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.980100\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.980299\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.980496\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.980691\n","resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.980884\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.981075\n","resetting env. episode 9.000000, reward total was -20.000000. running mean: -20.971265\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.971552\n","resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.961836\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.962218\n","resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.952596\n","resetting env. episode 14.000000, reward total was -20.000000. running mean: -20.943070\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.943639\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.944203\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.944761\n","resetting env. episode 18.000000, reward total was -19.000000. running mean: -20.925313\n","resetting env. episode 19.000000, reward total was -20.000000. running mean: -20.916060\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.916899\n","resetting env. episode 21.000000, reward total was -20.000000. running mean: -20.907730\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.908653\n","resetting env. episode 23.000000, reward total was -20.000000. running mean: -20.899567\n","resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.890571\n","resetting env. episode 25.000000, reward total was -18.000000. running mean: -20.861665\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.863049\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.864418\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.865774\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.867116\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.868445\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.869761\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.871063\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.872352\n","resetting env. episode 34.000000, reward total was -19.000000. running mean: -20.853629\n","resetting env. episode 35.000000, reward total was -20.000000. running mean: -20.845093\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.846642\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.848175\n","resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.839693\n","resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.831296\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.832984\n","resetting env. episode 41.000000, reward total was -20.000000. running mean: -20.824654\n","resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.816407\n","resetting env. episode 43.000000, reward total was -19.000000. running mean: -20.798243\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.800261\n","resetting env. episode 45.000000, reward total was -20.000000. running mean: -20.792258\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.794335\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.796392\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.798428\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.800444\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.802439\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.804415\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.806371\n","resetting env. episode 53.000000, reward total was -19.000000. running mean: -20.788307\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.790424\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.792520\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.794595\n","resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.786649\n","resetting env. episode 58.000000, reward total was -19.000000. running mean: -20.768782\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.771094\n","resetting env. episode 60.000000, reward total was -18.000000. running mean: -20.743383\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.745950\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.748490\n","resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.741005\n","resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.733595\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.736259\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.738897\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.741508\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.744093\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.746652\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.749185\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.741693\n","resetting env. episode 72.000000, reward total was -20.000000. running mean: -20.734276\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.726934\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.729664\n","resetting env. episode 75.000000, reward total was -19.000000. running mean: -20.712368\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.715244\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.718092\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.720911\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.723702\n","resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.716464\n","resetting env. episode 81.000000, reward total was -19.000000. running mean: -20.699300\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.692307\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.695384\n","resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.688430\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.681546\n","resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.674730\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.677983\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.681203\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.684391\n","resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.677547\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.680772\n","resetting env. episode 92.000000, reward total was -19.000000. running mean: -20.663964\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.667324\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.670651\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.663945\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.667305\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.670632\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.673926\n","resetting env. episode 99.000000, reward total was -19.000000. running mean: -20.657186\n","resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.650615\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.654108\n","resetting env. episode 102.000000, reward total was -20.000000. running mean: -20.647567\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.651092\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.654581\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.658035\n","resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.661455\n","resetting env. episode 107.000000, reward total was -19.000000. running mean: -20.644840\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.648392\n","resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.641908\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.645489\n","resetting env. episode 111.000000, reward total was -20.000000. running mean: -20.639034\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.642643\n","resetting env. episode 113.000000, reward total was -18.000000. running mean: -20.616217\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.620055\n","resetting env. episode 115.000000, reward total was -20.000000. running mean: -20.613854\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.617716\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.621539\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.625323\n","resetting env. episode 119.000000, reward total was -19.000000. running mean: -20.609070\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.612979\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.616849\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.610681\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.614574\n","resetting env. episode 124.000000, reward total was -18.000000. running mean: -20.588428\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.592544\n","resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.586619\n","resetting env. episode 127.000000, reward total was -18.000000. running mean: -20.560753\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.565145\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.569494\n","resetting env. episode 130.000000, reward total was -18.000000. running mean: -20.543799\n","resetting env. episode 131.000000, reward total was -19.000000. running mean: -20.528361\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.523077\n","resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.517846\n","resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.512668\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.517541\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.522366\n","resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.517142\n","resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.511971\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.516851\n","resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.511682\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.516566\n","resetting env. episode 142.000000, reward total was -19.000000. running mean: -20.501400\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.506386\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.511322\n","resetting env. episode 145.000000, reward total was -19.000000. running mean: -20.496209\n","resetting env. episode 146.000000, reward total was -20.000000. running mean: -20.491247\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.496334\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.501371\n","resetting env. episode 149.000000, reward total was -18.000000. running mean: -20.476357\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.481594\n","resetting env. episode 151.000000, reward total was -18.000000. running mean: -20.456778\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.462210\n","resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.457588\n","resetting env. episode 154.000000, reward total was -18.000000. running mean: -20.433012\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.438682\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.444295\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.449852\n","resetting env. episode 158.000000, reward total was -19.000000. running mean: -20.435354\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.441000\n","resetting env. episode 160.000000, reward total was -19.000000. running mean: -20.426590\n","resetting env. episode 161.000000, reward total was -20.000000. running mean: -20.422324\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.428101\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.433820\n","resetting env. episode 164.000000, reward total was -19.000000. running mean: -20.419482\n","resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.415287\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.421134\n","resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.426923\n","resetting env. episode 168.000000, reward total was -20.000000. running mean: -20.422653\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.428427\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.434143\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.439801\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.445403\n","resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.450949\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.456440\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.461875\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.467257\n","resetting env. episode 177.000000, reward total was -19.000000. running mean: -20.452584\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.458058\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.463478\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.468843\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.474154\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.479413\n","resetting env. episode 183.000000, reward total was -19.000000. running mean: -20.464619\n","resetting env. episode 184.000000, reward total was -20.000000. running mean: -20.459972\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.465373\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.470719\n","resetting env. episode 187.000000, reward total was -18.000000. running mean: -20.446012\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.451552\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.457036\n","resetting env. episode 190.000000, reward total was -20.000000. running mean: -20.452466\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.457941\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.463362\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.468728\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.474041\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.479300\n","resetting env. episode 196.000000, reward total was -20.000000. running mean: -20.474507\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.479762\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.484965\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.480115\n","resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.475314\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.480561\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.485755\n","resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.490898\n","resetting env. episode 204.000000, reward total was -20.000000. running mean: -20.485989\n","resetting env. episode 205.000000, reward total was -19.000000. running mean: -20.471129\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.476417\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.481653\n","resetting env. episode 208.000000, reward total was -19.000000. running mean: -20.466837\n","resetting env. episode 209.000000, reward total was -19.000000. running mean: -20.452168\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.457647\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.463070\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.468440\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.473755\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -20.469018\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.474327\n","resetting env. episode 216.000000, reward total was -16.000000. running mean: -20.429584\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.435288\n","resetting env. episode 218.000000, reward total was -18.000000. running mean: -20.410935\n","resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.406826\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.412758\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.418630\n","resetting env. episode 222.000000, reward total was -20.000000. running mean: -20.414444\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.420300\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.426097\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.431836\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.437517\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.443142\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.438711\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.444323\n","resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.439880\n","resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.435481\n","resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.441127\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.446715\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.442248\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.447826\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.453347\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.458814\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.464226\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.469584\n","resetting env. episode 240.000000, reward total was -19.000000. running mean: -20.454888\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.460339\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.465736\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.471078\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.476367\n","resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.471604\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.476888\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.482119\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.487298\n","resetting env. episode 249.000000, reward total was -19.000000. running mean: -20.472425\n","resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.467700\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.473023\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.478293\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.483510\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.488675\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.493788\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.498850\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.503862\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.508823\n","resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.503735\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.508698\n","resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.503611\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.508575\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.513489\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.518354\n","resetting env. episode 265.000000, reward total was -18.000000. running mean: -20.493170\n","resetting env. episode 266.000000, reward total was -19.000000. running mean: -20.478239\n","resetting env. episode 267.000000, reward total was -19.000000. running mean: -20.463456\n","resetting env. episode 268.000000, reward total was -19.000000. running mean: -20.448822\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.454334\n","resetting env. episode 270.000000, reward total was -20.000000. running mean: -20.449790\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.455292\n","resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.450739\n","resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.446232\n","resetting env. episode 274.000000, reward total was -19.000000. running mean: -20.431770\n","resetting env. episode 275.000000, reward total was -19.000000. running mean: -20.417452\n","resetting env. episode 276.000000, reward total was -20.000000. running mean: -20.413278\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.419145\n","resetting env. episode 278.000000, reward total was -20.000000. running mean: -20.414953\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.420804\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.426596\n","resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.422330\n","resetting env. episode 282.000000, reward total was -19.000000. running mean: -20.408106\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.414025\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.419885\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.425686\n","resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.421429\n","resetting env. episode 287.000000, reward total was -20.000000. running mean: -20.417215\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.423043\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.428813\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.434524\n","resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.430179\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.425877\n","resetting env. episode 293.000000, reward total was -20.000000. running mean: -20.421619\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.427402\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.433128\n","resetting env. episode 296.000000, reward total was -20.000000. running mean: -20.428797\n","resetting env. episode 297.000000, reward total was -18.000000. running mean: -20.404509\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.410464\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.406359\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.412296\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.418173\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.423991\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.429751\n","resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.425454\n","resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.421199\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.426987\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.432717\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.428390\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.434106\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.439765\n","resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.435368\n","resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.431014\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.426704\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.422437\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.428212\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.433930\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.429591\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.435295\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.440942\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.446533\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.452067\n","resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.447547\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.453071\n","resetting env. episode 324.000000, reward total was -20.000000. running mean: -20.448540\n","resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.444055\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.449614\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.455118\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.460567\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.465961\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.471302\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.476589\n","resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.471823\n","resetting env. episode 333.000000, reward total was -18.000000. running mean: -20.447105\n","resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.442634\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.448207\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.453725\n","resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.449188\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.454696\n","resetting env. episode 339.000000, reward total was -19.000000. running mean: -20.440149\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.445748\n","resetting env. episode 341.000000, reward total was -17.000000. running mean: -20.411290\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.417177\n","resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.413006\n","resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.408875\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.414787\n","resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.410639\n","resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.406532\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.412467\n","resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.408342\n","resetting env. episode 350.000000, reward total was -20.000000. running mean: -20.404259\n","resetting env. episode 351.000000, reward total was -18.000000. running mean: -20.380216\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.386414\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.392550\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.398625\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.404638\n","resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.400592\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.406586\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.412520\n","resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.408395\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.414311\n","resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.420168\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.425966\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.431707\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.437390\n","resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.443016\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.448586\n","resetting env. episode 367.000000, reward total was -20.000000. running mean: -20.444100\n","resetting env. episode 368.000000, reward total was -20.000000. running mean: -20.439659\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.445262\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.440809\n","resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.446401\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.451937\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.457418\n","resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.452844\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.458315\n","resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.453732\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.459195\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.464603\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.469957\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.475257\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.480505\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.485700\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.480843\n","resetting env. episode 384.000000, reward total was -19.000000. running mean: -20.466034\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.471374\n","resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.466660\n","resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.461994\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.467374\n","resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.462700\n","resetting env. episode 390.000000, reward total was -20.000000. running mean: -20.458073\n","resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.453492\n","resetting env. episode 392.000000, reward total was -20.000000. running mean: -20.448957\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.454468\n","resetting env. episode 394.000000, reward total was -18.000000. running mean: -20.429923\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.425624\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.421368\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.427154\n","resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.432882\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.438554\n","resetting env. episode 400.000000, reward total was -19.000000. running mean: -20.424168\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.429926\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.435627\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.441271\n","resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.436858\n","resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.432489\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.438165\n","resetting env. episode 407.000000, reward total was -17.000000. running mean: -20.403783\n","resetting env. episode 408.000000, reward total was -20.000000. running mean: -20.399745\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.395748\n","resetting env. episode 410.000000, reward total was -19.000000. running mean: -20.381790\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.387972\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.394093\n","resetting env. episode 413.000000, reward total was -19.000000. running mean: -20.380152\n","resetting env. episode 414.000000, reward total was -19.000000. running mean: -20.366350\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.362687\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.369060\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.375369\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.381615\n","resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.377799\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.384021\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.390181\n","resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.386279\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.382417\n","resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.378592\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.374806\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.381058\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.387248\n","resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.383375\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.389542\n","resetting env. episode 430.000000, reward total was -19.000000. running mean: -20.375646\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.381890\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.388071\n","resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.384190\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.390348\n","resetting env. episode 435.000000, reward total was -20.000000. running mean: -20.386445\n","resetting env. episode 436.000000, reward total was -20.000000. running mean: -20.382580\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.388754\n","resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.384867\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.391018\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.397108\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.403137\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.409106\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.415015\n","resetting env. episode 444.000000, reward total was -19.000000. running mean: -20.400864\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.406856\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.412787\n","resetting env. episode 447.000000, reward total was -20.000000. running mean: -20.408659\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.414573\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.420427\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.426223\n","resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.421960\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.427741\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.433463\n","resetting env. episode 454.000000, reward total was -19.000000. running mean: -20.419129\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.424938\n","resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.420688\n","resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.416481\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.422316\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.428093\n","resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.433812\n","resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.429474\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.435180\n","resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.430828\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.436519\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.442154\n","resetting env. episode 466.000000, reward total was -20.000000. running mean: -20.437733\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.433355\n","resetting env. episode 468.000000, reward total was -19.000000. running mean: -20.419022\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.424832\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.430583\n","resetting env. episode 471.000000, reward total was -19.000000. running mean: -20.416277\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.422115\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.427894\n","resetting env. episode 474.000000, reward total was -18.000000. running mean: -20.403615\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.409578\n","resetting env. episode 476.000000, reward total was -19.000000. running mean: -20.395483\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.401528\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.397513\n","resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.403537\n","resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.399502\n","resetting env. episode 481.000000, reward total was -20.000000. running mean: -20.395507\n","resetting env. episode 482.000000, reward total was -19.000000. running mean: -20.381552\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.387736\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.393859\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.399920\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.405921\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.411862\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.417743\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.423566\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.419330\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.425137\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.430886\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.436577\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.442211\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.447789\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.453311\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.458778\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.464190\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.469548\n","resetting env. episode 500.000000, reward total was -20.000000. running mean: -20.464853\n","CPU times: user 25min 46s, sys: 12min 6s, total: 37min 53s\n","Wall time: 19min 53s\n"]}]},{"metadata":{"id":"cHYCDYwhlVLV","outputId":"42648ec9-aca2-4572-84bd-58cd76a43fb4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660625530310,"user_tz":-330,"elapsed":1230461,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist2 = train_model(env, model, total_episodes=500)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n","resetting env. episode 2.000000, reward total was -19.000000. running mean: -19.990000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -20.000100\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.010099\n","resetting env. episode 5.000000, reward total was -19.000000. running mean: -19.999998\n","resetting env. episode 6.000000, reward total was -20.000000. running mean: -19.999998\n","resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.009998\n","resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.009898\n","resetting env. episode 9.000000, reward total was -20.000000. running mean: -20.009799\n","resetting env. episode 10.000000, reward total was -19.000000. running mean: -19.999701\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.009704\n","resetting env. episode 12.000000, reward total was -17.000000. running mean: -19.979607\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -19.989811\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -19.999913\n","resetting env. episode 15.000000, reward total was -19.000000. running mean: -19.989914\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.000015\n","resetting env. episode 17.000000, reward total was -20.000000. running mean: -20.000014\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.010014\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.019914\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.029715\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.039418\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.049024\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.058533\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.067948\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.077269\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.086496\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.095631\n","resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.094675\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.103728\n","resetting env. episode 30.000000, reward total was -20.000000. running mean: -20.102691\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.101664\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.110647\n","resetting env. episode 33.000000, reward total was -18.000000. running mean: -20.089541\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.098645\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.107659\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.116582\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.125416\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.134162\n","resetting env. episode 39.000000, reward total was -19.000000. running mean: -20.122821\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.131592\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.140276\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.148874\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.157385\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.155811\n","resetting env. episode 45.000000, reward total was -20.000000. running mean: -20.154253\n","resetting env. episode 46.000000, reward total was -18.000000. running mean: -20.132710\n","resetting env. episode 47.000000, reward total was -19.000000. running mean: -20.121383\n","resetting env. episode 48.000000, reward total was -20.000000. running mean: -20.120170\n","resetting env. episode 49.000000, reward total was -19.000000. running mean: -20.108968\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.107878\n","resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.106799\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.115731\n","resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.114574\n","resetting env. episode 54.000000, reward total was -19.000000. running mean: -20.103428\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.112394\n","resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.111270\n","resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.110157\n","resetting env. episode 58.000000, reward total was -20.000000. running mean: -20.109056\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.117965\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.126786\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.135518\n","resetting env. episode 62.000000, reward total was -19.000000. running mean: -20.124163\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.132921\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.141592\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.150176\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.158674\n","resetting env. episode 67.000000, reward total was -20.000000. running mean: -20.157087\n","resetting env. episode 68.000000, reward total was -19.000000. running mean: -20.145516\n","resetting env. episode 69.000000, reward total was -19.000000. running mean: -20.134061\n","resetting env. episode 70.000000, reward total was -20.000000. running mean: -20.132721\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.141393\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.149980\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.148480\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.156995\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.165425\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.173771\n","resetting env. episode 77.000000, reward total was -16.000000. running mean: -20.132033\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.130713\n","resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.129406\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.138112\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.146730\n","resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.155263\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.163710\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.172073\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.180353\n","resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.178549\n","resetting env. episode 87.000000, reward total was -18.000000. running mean: -20.156764\n","resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.155196\n","resetting env. episode 89.000000, reward total was -20.000000. running mean: -20.153644\n","resetting env. episode 90.000000, reward total was -18.000000. running mean: -20.132108\n","resetting env. episode 91.000000, reward total was -19.000000. running mean: -20.120787\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.129579\n","resetting env. episode 93.000000, reward total was -20.000000. running mean: -20.128283\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.137000\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.145630\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.154174\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.162632\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.171006\n","resetting env. episode 99.000000, reward total was -19.000000. running mean: -20.159296\n","resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.157703\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.156126\n","resetting env. episode 102.000000, reward total was -19.000000. running mean: -20.144564\n","resetting env. episode 103.000000, reward total was -19.000000. running mean: -20.133119\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.141788\n","resetting env. episode 105.000000, reward total was -20.000000. running mean: -20.140370\n","resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.148966\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.157476\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.165902\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.174243\n","resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.172500\n","resetting env. episode 111.000000, reward total was -20.000000. running mean: -20.170775\n","resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.169067\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.177377\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.185603\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.193747\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.201809\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.209791\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.217693\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.225516\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.233261\n","resetting env. episode 121.000000, reward total was -20.000000. running mean: -20.230929\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.228619\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.236333\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.243970\n","resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.241530\n","resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.239115\n","resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.236724\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.244356\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.251913\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.259394\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.266800\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.274132\n","resetting env. episode 133.000000, reward total was -18.000000. running mean: -20.251391\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.258877\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.266288\n","resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.263625\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.270989\n","resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.268279\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.275596\n","resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.272840\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.280112\n","resetting env. episode 142.000000, reward total was -19.000000. running mean: -20.267311\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.274637\n","resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.271891\n","resetting env. episode 145.000000, reward total was -19.000000. running mean: -20.259172\n","resetting env. episode 146.000000, reward total was -20.000000. running mean: -20.256580\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.264015\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.271375\n","resetting env. episode 149.000000, reward total was -19.000000. running mean: -20.258661\n","resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.256074\n","resetting env. episode 151.000000, reward total was -19.000000. running mean: -20.243513\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.251078\n","resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.248568\n","resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.246082\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.253621\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.261085\n","resetting env. episode 157.000000, reward total was -19.000000. running mean: -20.248474\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.255989\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.263429\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.270795\n","resetting env. episode 161.000000, reward total was -20.000000. running mean: -20.268087\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.275406\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.282652\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.289826\n","resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.286927\n","resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.284058\n","resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.291218\n","resetting env. episode 168.000000, reward total was -18.000000. running mean: -20.268305\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.275622\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.282866\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.290037\n","resetting env. episode 172.000000, reward total was -19.000000. running mean: -20.277137\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.274366\n","resetting env. episode 174.000000, reward total was -20.000000. running mean: -20.271622\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.278906\n","resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.266117\n","resetting env. episode 177.000000, reward total was -19.000000. running mean: -20.253456\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.260921\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.268312\n","resetting env. episode 180.000000, reward total was -20.000000. running mean: -20.265629\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.272972\n","resetting env. episode 182.000000, reward total was -20.000000. running mean: -20.270243\n","resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.267540\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.274865\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.282116\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.289295\n","resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.286402\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.283538\n","resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.280703\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.287896\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.295017\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.302067\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.309046\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.315955\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.322796\n","resetting env. episode 196.000000, reward total was -19.000000. running mean: -20.309568\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.316472\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.323307\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.320074\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.326874\n","resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.323605\n","resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.320369\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.317165\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.323994\n","resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.320754\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.327546\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.334271\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.340928\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.347519\n","resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.344043\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.350603\n","resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.347097\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.353626\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.360090\n","resetting env. episode 215.000000, reward total was -19.000000. running mean: -20.346489\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.353024\n","resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.349494\n","resetting env. episode 218.000000, reward total was -20.000000. running mean: -20.345999\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.352539\n","resetting env. episode 220.000000, reward total was -19.000000. running mean: -20.339013\n","resetting env. episode 221.000000, reward total was -20.000000. running mean: -20.335623\n","resetting env. episode 222.000000, reward total was -20.000000. running mean: -20.332267\n","resetting env. episode 223.000000, reward total was -19.000000. running mean: -20.318944\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.325755\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.322497\n","resetting env. episode 226.000000, reward total was -19.000000. running mean: -20.309272\n","resetting env. episode 227.000000, reward total was -20.000000. running mean: -20.306180\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.303118\n","resetting env. episode 229.000000, reward total was -19.000000. running mean: -20.290087\n","resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.287186\n","resetting env. episode 231.000000, reward total was -19.000000. running mean: -20.274314\n","resetting env. episode 232.000000, reward total was -18.000000. running mean: -20.251571\n","resetting env. episode 233.000000, reward total was -18.000000. running mean: -20.229055\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.226765\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.234497\n","resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.232152\n","resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.219830\n","resetting env. episode 238.000000, reward total was -19.000000. running mean: -20.207632\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.215556\n","resetting env. episode 240.000000, reward total was -19.000000. running mean: -20.203400\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.211366\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.219253\n","resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.217060\n","resetting env. episode 244.000000, reward total was -19.000000. running mean: -20.204889\n","resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.202841\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.210812\n","resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.208704\n","resetting env. episode 248.000000, reward total was -20.000000. running mean: -20.206617\n","resetting env. episode 249.000000, reward total was -20.000000. running mean: -20.204551\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.212505\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.220380\n","resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.218176\n","resetting env. episode 253.000000, reward total was -19.000000. running mean: -20.205995\n","resetting env. episode 254.000000, reward total was -19.000000. running mean: -20.193935\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.201995\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.209975\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.217876\n","resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.215697\n","resetting env. episode 259.000000, reward total was -19.000000. running mean: -20.203540\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.211505\n","resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.219390\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.227196\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.234924\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.242574\n","resetting env. episode 265.000000, reward total was -19.000000. running mean: -20.230149\n","resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.237847\n","resetting env. episode 267.000000, reward total was -20.000000. running mean: -20.235469\n","resetting env. episode 268.000000, reward total was -20.000000. running mean: -20.233114\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.240783\n","resetting env. episode 270.000000, reward total was -19.000000. running mean: -20.228375\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.236091\n","resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.233730\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.241393\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.248979\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.256489\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.263924\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.271285\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.278572\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.285787\n","resetting env. episode 280.000000, reward total was -20.000000. running mean: -20.282929\n","resetting env. episode 281.000000, reward total was -19.000000. running mean: -20.270100\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.277399\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.284625\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.291778\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.298861\n","resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.295872\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.302913\n","resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.299884\n","resetting env. episode 289.000000, reward total was -20.000000. running mean: -20.296885\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.303916\n","resetting env. episode 291.000000, reward total was -18.000000. running mean: -20.280877\n","resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.288068\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.295188\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.302236\n","resetting env. episode 295.000000, reward total was -20.000000. running mean: -20.299214\n","resetting env. episode 296.000000, reward total was -19.000000. running mean: -20.286221\n","resetting env. episode 297.000000, reward total was -20.000000. running mean: -20.283359\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.290526\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.297620\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.294644\n","resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.291698\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.288781\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.295893\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.302934\n","resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.299905\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.306906\n","resetting env. episode 307.000000, reward total was -20.000000. running mean: -20.303837\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.310798\n","resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.307690\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.314613\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.321467\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.328252\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.334970\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.331620\n","resetting env. episode 315.000000, reward total was -19.000000. running mean: -20.318304\n","resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.315121\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.311970\n","resetting env. episode 318.000000, reward total was -19.000000. running mean: -20.298850\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.305862\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.312803\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.309675\n","resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.306578\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.313512\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.320377\n","resetting env. episode 325.000000, reward total was -18.000000. running mean: -20.297174\n","resetting env. episode 326.000000, reward total was -20.000000. running mean: -20.294202\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.301260\n","resetting env. episode 328.000000, reward total was -19.000000. running mean: -20.288247\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.295365\n","resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.292411\n","resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.289487\n","resetting env. episode 332.000000, reward total was -19.000000. running mean: -20.276592\n","resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.273826\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.281088\n","resetting env. episode 335.000000, reward total was -18.000000. running mean: -20.258277\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.265694\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.273037\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.280307\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.287504\n","resetting env. episode 340.000000, reward total was -19.000000. running mean: -20.274629\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.281883\n","resetting env. episode 342.000000, reward total was -17.000000. running mean: -20.249064\n","resetting env. episode 343.000000, reward total was -19.000000. running mean: -20.236573\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.244207\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.251765\n","resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.249248\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.256755\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.264188\n","resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.261546\n","resetting env. episode 350.000000, reward total was -19.000000. running mean: -20.248930\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.256441\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.263877\n","resetting env. episode 353.000000, reward total was -18.000000. running mean: -20.241238\n","resetting env. episode 354.000000, reward total was -20.000000. running mean: -20.238825\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.246437\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.253973\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.261433\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.268819\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.276131\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.283369\n","resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.290536\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.297630\n","resetting env. episode 363.000000, reward total was -20.000000. running mean: -20.294654\n","resetting env. episode 364.000000, reward total was -19.000000. running mean: -20.281707\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.278890\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.286101\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.293240\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.300308\n","resetting env. episode 369.000000, reward total was -18.000000. running mean: -20.277305\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.284532\n","resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.281686\n","resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.278870\n","resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.276081\n","resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.283320\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.290487\n","resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.287582\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.294706\n","resetting env. episode 378.000000, reward total was -20.000000. running mean: -20.291759\n","resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.288842\n","resetting env. episode 380.000000, reward total was -19.000000. running mean: -20.275953\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.283194\n","resetting env. episode 382.000000, reward total was -20.000000. running mean: -20.280362\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.287558\n","resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.294682\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.301736\n","resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.298718\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.305731\n","resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.302674\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.309647\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.316551\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.323385\n","resetting env. episode 392.000000, reward total was -19.000000. running mean: -20.310151\n","resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.307050\n","resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.303979\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.300939\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.297930\n","resetting env. episode 397.000000, reward total was -18.000000. running mean: -20.274951\n","resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.282201\n","resetting env. episode 399.000000, reward total was -20.000000. running mean: -20.279379\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.286585\n","resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.283720\n","resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.280882\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.288074\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.295193\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.302241\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.309218\n","resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.306126\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.313065\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.319934\n","resetting env. episode 410.000000, reward total was -20.000000. running mean: -20.316735\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.323568\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.330332\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.337029\n","resetting env. episode 414.000000, reward total was -20.000000. running mean: -20.333658\n","resetting env. episode 415.000000, reward total was -19.000000. running mean: -20.320322\n","resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.317119\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.323947\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.330708\n","resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.327401\n","resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.324127\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.330886\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.337577\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.334201\n","resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.330859\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.337550\n","resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.334175\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.340833\n","resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.337425\n","resetting env. episode 429.000000, reward total was -19.000000. running mean: -20.324051\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -20.320810\n","resetting env. episode 431.000000, reward total was -19.000000. running mean: -20.307602\n","resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.304526\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.311481\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.318366\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.325182\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.331930\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.338611\n","resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.345225\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.351773\n","resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.348255\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.354772\n","resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.351225\n","resetting env. episode 443.000000, reward total was -20.000000. running mean: -20.347712\n","resetting env. episode 444.000000, reward total was -20.000000. running mean: -20.344235\n","resetting env. episode 445.000000, reward total was -18.000000. running mean: -20.320793\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.327585\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.334309\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.340966\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.347556\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.354081\n","resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.350540\n","resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.347035\n","resetting env. episode 453.000000, reward total was -20.000000. running mean: -20.343564\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.350129\n","resetting env. episode 455.000000, reward total was -18.000000. running mean: -20.326627\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.333361\n","resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.340028\n","resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.336627\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.343261\n","resetting env. episode 460.000000, reward total was -19.000000. running mean: -20.329828\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.336530\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.343165\n","resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.339733\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.346336\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.352872\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.359344\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.365750\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.372093\n","resetting env. episode 469.000000, reward total was -19.000000. running mean: -20.358372\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.364788\n","resetting env. episode 471.000000, reward total was -20.000000. running mean: -20.361140\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.367529\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.373854\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.380115\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.386314\n","resetting env. episode 476.000000, reward total was -18.000000. running mean: -20.362451\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.368826\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.365138\n","resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.371487\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.377772\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.383994\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.380154\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.386353\n","resetting env. episode 484.000000, reward total was -20.000000. running mean: -20.382489\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.388664\n","resetting env. episode 486.000000, reward total was -20.000000. running mean: -20.384777\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.390930\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.397020\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.403050\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.409020\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.414929\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.420780\n","resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.416572\n","resetting env. episode 494.000000, reward total was -20.000000. running mean: -20.412407\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.418283\n","resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.414100\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.419959\n","resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.415759\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.421602\n","resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.427386\n","CPU times: user 26min 59s, sys: 12min 29s, total: 39min 28s\n","Wall time: 20min 30s\n"]}]},{"metadata":{"id":"8fheN9DRlWXQ","outputId":"5cf02c16-609b-479c-c174-d5445f7f5d01","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1660625571724,"user_tz":-330,"elapsed":41423,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -10.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"id":"9AxOcQhIsKow","outputId":"a0f158d6-a223-4695-8c80-021db48b7fab","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660629289306,"user_tz":-330,"elapsed":3717589,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist3 = train_model(env, model, total_episodes=1500)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 4.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 6.000000, reward total was -20.000000. running mean: -20.980199\n","resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.980397\n","resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.970593\n","resetting env. episode 9.000000, reward total was -18.000000. running mean: -20.940887\n","resetting env. episode 10.000000, reward total was -20.000000. running mean: -20.931478\n","resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.922163\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.922942\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.923712\n","resetting env. episode 14.000000, reward total was -18.000000. running mean: -20.894475\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.895531\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.896575\n","resetting env. episode 17.000000, reward total was -20.000000. running mean: -20.887609\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.888733\n","resetting env. episode 19.000000, reward total was -19.000000. running mean: -20.869846\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.871148\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.872436\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.873712\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.874975\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.876225\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.877463\n","resetting env. episode 26.000000, reward total was -20.000000. running mean: -20.868688\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.870001\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.871301\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.872588\n","resetting env. episode 30.000000, reward total was -20.000000. running mean: -20.863862\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.855224\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.856671\n","resetting env. episode 33.000000, reward total was -19.000000. running mean: -20.838105\n","resetting env. episode 34.000000, reward total was -20.000000. running mean: -20.829724\n","resetting env. episode 35.000000, reward total was -20.000000. running mean: -20.821426\n","resetting env. episode 36.000000, reward total was -20.000000. running mean: -20.813212\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.815080\n","resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.806929\n","resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.798860\n","resetting env. episode 40.000000, reward total was -20.000000. running mean: -20.790871\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.792963\n","resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.785033\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.787183\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.779311\n","resetting env. episode 45.000000, reward total was -20.000000. running mean: -20.771518\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.773803\n","resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.766064\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.768404\n","resetting env. episode 49.000000, reward total was -18.000000. running mean: -20.740720\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.743313\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.745879\n","resetting env. episode 52.000000, reward total was -19.000000. running mean: -20.728421\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.731136\n","resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.723825\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.726587\n","resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.719321\n","resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.712128\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.715007\n","resetting env. episode 59.000000, reward total was -19.000000. running mean: -20.697856\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.700878\n","resetting env. episode 61.000000, reward total was -20.000000. running mean: -20.693869\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.696930\n","resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.689961\n","resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.683061\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.686231\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.689369\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.692475\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.695550\n","resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.688595\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.691709\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.684792\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.687944\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.681064\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.684254\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.687411\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.690537\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.693632\n","resetting env. episode 78.000000, reward total was -19.000000. running mean: -20.676695\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.679928\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.683129\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.686298\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.679435\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.682640\n","resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.675814\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.679056\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.682265\n","resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.675443\n","resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.668688\n","resetting env. episode 89.000000, reward total was -20.000000. running mean: -20.662001\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.665381\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.668728\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.672040\n","resetting env. episode 93.000000, reward total was -19.000000. running mean: -20.655320\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.658767\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.652179\n","resetting env. episode 96.000000, reward total was -20.000000. running mean: -20.645657\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.649201\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.642709\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.646282\n","resetting env. episode 100.000000, reward total was -19.000000. running mean: -20.629819\n","resetting env. episode 101.000000, reward total was -18.000000. running mean: -20.603521\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.607485\n","resetting env. episode 103.000000, reward total was -19.000000. running mean: -20.591410\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.595496\n","resetting env. episode 105.000000, reward total was -17.000000. running mean: -20.559541\n","resetting env. episode 106.000000, reward total was -19.000000. running mean: -20.543946\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.548507\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.553021\n","resetting env. episode 109.000000, reward total was -18.000000. running mean: -20.527491\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.532216\n","resetting env. episode 111.000000, reward total was -20.000000. running mean: -20.526894\n","resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.521625\n","resetting env. episode 113.000000, reward total was -20.000000. running mean: -20.516409\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.521245\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.526032\n","resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.520772\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.525564\n","resetting env. episode 118.000000, reward total was -20.000000. running mean: -20.520309\n","resetting env. episode 119.000000, reward total was -20.000000. running mean: -20.515106\n","resetting env. episode 120.000000, reward total was -19.000000. running mean: -20.499955\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.504955\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.509906\n","resetting env. episode 123.000000, reward total was -19.000000. running mean: -20.494806\n","resetting env. episode 124.000000, reward total was -18.000000. running mean: -20.469858\n","resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.465160\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.470508\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.475803\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.481045\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.486235\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.491372\n","resetting env. episode 131.000000, reward total was -20.000000. running mean: -20.486459\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.491594\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.496678\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.501711\n","resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.496694\n","resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.491727\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.496810\n","resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.491842\n","resetting env. episode 139.000000, reward total was -20.000000. running mean: -20.486923\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.492054\n","resetting env. episode 141.000000, reward total was -20.000000. running mean: -20.487134\n","resetting env. episode 142.000000, reward total was -20.000000. running mean: -20.482262\n","resetting env. episode 143.000000, reward total was -20.000000. running mean: -20.477440\n","resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.472665\n","resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.477939\n","resetting env. episode 146.000000, reward total was -18.000000. running mean: -20.453159\n","resetting env. episode 147.000000, reward total was -19.000000. running mean: -20.438628\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.444241\n","resetting env. episode 149.000000, reward total was -20.000000. running mean: -20.439799\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.445401\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.450947\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.456437\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.461873\n","resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.457254\n","resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.452682\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.458155\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.463573\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.468938\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.474248\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.479506\n","resetting env. episode 161.000000, reward total was -19.000000. running mean: -20.464711\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.470064\n","resetting env. episode 163.000000, reward total was -19.000000. running mean: -20.455363\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.460809\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.466201\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.471539\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.466824\n","resetting env. episode 168.000000, reward total was -19.000000. running mean: -20.452156\n","resetting env. episode 169.000000, reward total was -19.000000. running mean: -20.437634\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.443258\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.448825\n","resetting env. episode 172.000000, reward total was -20.000000. running mean: -20.444337\n","resetting env. episode 173.000000, reward total was -21.000000. running mean: -20.449894\n","resetting env. episode 174.000000, reward total was -20.000000. running mean: -20.445395\n","resetting env. episode 175.000000, reward total was -20.000000. running mean: -20.440941\n","resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.426531\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.432266\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.437943\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.443564\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.449128\n","resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.444637\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.450191\n","resetting env. episode 183.000000, reward total was -19.000000. running mean: -20.435689\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.441332\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.446919\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.452449\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.457925\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.453346\n","resetting env. episode 189.000000, reward total was -18.000000. running mean: -20.428812\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.434524\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.440179\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.445777\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.451319\n","resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.446806\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.452338\n","resetting env. episode 196.000000, reward total was -20.000000. running mean: -20.447815\n","resetting env. episode 197.000000, reward total was -20.000000. running mean: -20.443336\n","resetting env. episode 198.000000, reward total was -19.000000. running mean: -20.428903\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.434614\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.440268\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.445865\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.451407\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.446892\n","resetting env. episode 204.000000, reward total was -19.000000. running mean: -20.432424\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.438099\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.443718\n","resetting env. episode 207.000000, reward total was -20.000000. running mean: -20.439281\n","resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.434888\n","resetting env. episode 209.000000, reward total was -19.000000. running mean: -20.420539\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.426334\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.432071\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.437750\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.443373\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.448939\n","resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.444449\n","resetting env. episode 216.000000, reward total was -20.000000. running mean: -20.440005\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.445605\n","resetting env. episode 218.000000, reward total was -20.000000. running mean: -20.441149\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.446737\n","resetting env. episode 220.000000, reward total was -19.000000. running mean: -20.432270\n","resetting env. episode 221.000000, reward total was -20.000000. running mean: -20.427947\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.433668\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.439331\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.444938\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.450488\n","resetting env. episode 226.000000, reward total was -20.000000. running mean: -20.445984\n","resetting env. episode 227.000000, reward total was -18.000000. running mean: -20.421524\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.417308\n","resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.413135\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.419004\n","resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.414814\n","resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.420666\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.426459\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.422195\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.427973\n","resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.423693\n","resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.409456\n","resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.405361\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.411308\n","resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.407195\n","resetting env. episode 241.000000, reward total was -18.000000. running mean: -20.383123\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.389292\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.395399\n","resetting env. episode 244.000000, reward total was -20.000000. running mean: -20.391445\n","resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.387530\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.393655\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.399718\n","resetting env. episode 248.000000, reward total was -19.000000. running mean: -20.385721\n","resetting env. episode 249.000000, reward total was -19.000000. running mean: -20.371864\n","resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.368145\n","resetting env. episode 251.000000, reward total was -18.000000. running mean: -20.344464\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.351019\n","resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.347509\n","resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.344034\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.350594\n","resetting env. episode 256.000000, reward total was -18.000000. running mean: -20.327088\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.333817\n","resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.330479\n","resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.327174\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.333902\n","resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.330563\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.337257\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.343885\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.350446\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.356942\n","resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.363372\n","resetting env. episode 267.000000, reward total was -20.000000. running mean: -20.359738\n","resetting env. episode 268.000000, reward total was -20.000000. running mean: -20.356141\n","resetting env. episode 269.000000, reward total was -18.000000. running mean: -20.332580\n","resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.339254\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.335861\n","resetting env. episode 272.000000, reward total was -19.000000. running mean: -20.322503\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.329278\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.335985\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.342625\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.349199\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.355707\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.362150\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.368528\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.374843\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.381095\n","resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.377284\n","resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.373511\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.379776\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.385978\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.392118\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.398197\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.404215\n","resetting env. episode 289.000000, reward total was -20.000000. running mean: -20.400173\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.396171\n","resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.402209\n","resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.408187\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.414105\n","resetting env. episode 294.000000, reward total was -18.000000. running mean: -20.389964\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.396065\n","resetting env. episode 296.000000, reward total was -20.000000. running mean: -20.392104\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.398183\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.404201\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.410159\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.406058\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.411997\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.417877\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.423698\n","resetting env. episode 304.000000, reward total was -18.000000. running mean: -20.399461\n","resetting env. episode 305.000000, reward total was -19.000000. running mean: -20.385467\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.391612\n","resetting env. episode 307.000000, reward total was -19.000000. running mean: -20.377696\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.373919\n","resetting env. episode 309.000000, reward total was -19.000000. running mean: -20.360180\n","resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.356578\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.363012\n","resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.359382\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.355788\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.352230\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.358708\n","resetting env. episode 316.000000, reward total was -19.000000. running mean: -20.345121\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.351670\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -20.348153\n","resetting env. episode 319.000000, reward total was -18.000000. running mean: -20.324672\n","resetting env. episode 320.000000, reward total was -19.000000. running mean: -20.311425\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.318311\n","resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.325127\n","resetting env. episode 323.000000, reward total was -19.000000. running mean: -20.311876\n","resetting env. episode 324.000000, reward total was -20.000000. running mean: -20.308757\n","resetting env. episode 325.000000, reward total was -19.000000. running mean: -20.295670\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.302713\n","resetting env. episode 327.000000, reward total was -18.000000. running mean: -20.279686\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.286889\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.294020\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.301080\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.308069\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.314989\n","resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.311839\n","resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.308720\n","resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.305633\n","resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.302577\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.309551\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.316455\n","resetting env. episode 339.000000, reward total was -19.000000. running mean: -20.303291\n","resetting env. episode 340.000000, reward total was -20.000000. running mean: -20.300258\n","resetting env. episode 341.000000, reward total was -19.000000. running mean: -20.287255\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.294383\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.301439\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.308425\n","resetting env. episode 345.000000, reward total was -19.000000. running mean: -20.295340\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.302387\n","resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.299363\n","resetting env. episode 348.000000, reward total was -20.000000. running mean: -20.296370\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.303406\n","resetting env. episode 350.000000, reward total was -18.000000. running mean: -20.280372\n","resetting env. episode 351.000000, reward total was -19.000000. running mean: -20.267568\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.274892\n","resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.272143\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.279422\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.286628\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.293761\n","resetting env. episode 357.000000, reward total was -18.000000. running mean: -20.270824\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.278116\n","resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.275334\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.272581\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.269855\n","resetting env. episode 362.000000, reward total was -20.000000. running mean: -20.267157\n","resetting env. episode 363.000000, reward total was -18.000000. running mean: -20.244485\n","resetting env. episode 364.000000, reward total was -17.000000. running mean: -20.212040\n","resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.219920\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.227721\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.235444\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.243089\n","resetting env. episode 369.000000, reward total was -18.000000. running mean: -20.220658\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.228452\n","resetting env. episode 371.000000, reward total was -19.000000. running mean: -20.216167\n","resetting env. episode 372.000000, reward total was -19.000000. running mean: -20.204005\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.211965\n","resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.219846\n","resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.217647\n","resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.225471\n","resetting env. episode 377.000000, reward total was -20.000000. running mean: -20.223216\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.230984\n","resetting env. episode 379.000000, reward total was -18.000000. running mean: -20.208674\n","resetting env. episode 380.000000, reward total was -18.000000. running mean: -20.186587\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.194721\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.202774\n","resetting env. episode 383.000000, reward total was -19.000000. running mean: -20.190747\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.188839\n","resetting env. episode 385.000000, reward total was -19.000000. running mean: -20.176951\n","resetting env. episode 386.000000, reward total was -19.000000. running mean: -20.165181\n","resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.163529\n","resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.161894\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.170275\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.178572\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.186787\n","resetting env. episode 392.000000, reward total was -18.000000. running mean: -20.164919\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.173270\n","resetting env. episode 394.000000, reward total was -19.000000. running mean: -20.161537\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.159922\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.168322\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.176639\n","resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.184873\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.193024\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.201094\n","resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.199083\n","resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.197092\n","resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.195121\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.203170\n","resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.201138\n","resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.199127\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.207135\n","resetting env. episode 408.000000, reward total was -20.000000. running mean: -20.205064\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.213013\n","resetting env. episode 410.000000, reward total was -20.000000. running mean: -20.210883\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.218775\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.216587\n","resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.214421\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.222277\n","resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.230054\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.237753\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.245376\n","resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.242922\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.250493\n","resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.247988\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.255508\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.262953\n","resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.270323\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.277620\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.284844\n","resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.281996\n","resetting env. episode 427.000000, reward total was -20.000000. running mean: -20.279176\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.286384\n","resetting env. episode 429.000000, reward total was -17.000000. running mean: -20.253520\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.260985\n","resetting env. episode 431.000000, reward total was -20.000000. running mean: -20.258375\n","resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.255791\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.263233\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.270601\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.277895\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.285116\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.292265\n","resetting env. episode 438.000000, reward total was -19.000000. running mean: -20.279342\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.286549\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.293683\n","resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.290746\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.297839\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.304861\n","resetting env. episode 444.000000, reward total was -20.000000. running mean: -20.301812\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.308794\n","resetting env. episode 446.000000, reward total was -19.000000. running mean: -20.295706\n","resetting env. episode 447.000000, reward total was -19.000000. running mean: -20.282749\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.289921\n","resetting env. episode 449.000000, reward total was -19.000000. running mean: -20.277022\n","resetting env. episode 450.000000, reward total was -19.000000. running mean: -20.264252\n","resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.261609\n","resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.258993\n","resetting env. episode 453.000000, reward total was -20.000000. running mean: -20.256403\n","resetting env. episode 454.000000, reward total was -20.000000. running mean: -20.253839\n","resetting env. episode 455.000000, reward total was -20.000000. running mean: -20.251301\n","resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.248788\n","resetting env. episode 457.000000, reward total was -18.000000. running mean: -20.226300\n","resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.224037\n","resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.221797\n","resetting env. episode 460.000000, reward total was -18.000000. running mean: -20.199579\n","resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.197583\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.195607\n","resetting env. episode 463.000000, reward total was -19.000000. running mean: -20.183651\n","resetting env. episode 464.000000, reward total was -18.000000. running mean: -20.161815\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.170196\n","resetting env. episode 466.000000, reward total was -19.000000. running mean: -20.158494\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.156910\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.165340\n","resetting env. episode 469.000000, reward total was -19.000000. running mean: -20.153687\n","resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.152150\n","resetting env. episode 471.000000, reward total was -20.000000. running mean: -20.150629\n","resetting env. episode 472.000000, reward total was -20.000000. running mean: -20.149122\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.157631\n","resetting env. episode 474.000000, reward total was -19.000000. running mean: -20.146055\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.154594\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.163048\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.171418\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.169704\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.168007\n","resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.166327\n","resetting env. episode 481.000000, reward total was -19.000000. running mean: -20.154663\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.153117\n","resetting env. episode 483.000000, reward total was -20.000000. running mean: -20.151586\n","resetting env. episode 484.000000, reward total was -20.000000. running mean: -20.150070\n","resetting env. episode 485.000000, reward total was -18.000000. running mean: -20.128569\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.137283\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.145910\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.154451\n","resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.152907\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.161378\n","resetting env. episode 491.000000, reward total was -19.000000. running mean: -20.149764\n","resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.148266\n","resetting env. episode 493.000000, reward total was -19.000000. running mean: -20.136784\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.145416\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.153962\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.162422\n","resetting env. episode 497.000000, reward total was -17.000000. running mean: -20.130798\n","resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.129490\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.138195\n","resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.146813\n","resetting env. episode 501.000000, reward total was -20.000000. running mean: -20.145345\n","resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.153891\n","resetting env. episode 503.000000, reward total was -18.000000. running mean: -20.132353\n","resetting env. episode 504.000000, reward total was -17.000000. running mean: -20.101029\n","resetting env. episode 505.000000, reward total was -21.000000. running mean: -20.110019\n","resetting env. episode 506.000000, reward total was -21.000000. running mean: -20.118919\n","resetting env. episode 507.000000, reward total was -20.000000. running mean: -20.117729\n","resetting env. episode 508.000000, reward total was -21.000000. running mean: -20.126552\n","resetting env. episode 509.000000, reward total was -21.000000. running mean: -20.135287\n","resetting env. episode 510.000000, reward total was -20.000000. running mean: -20.133934\n","resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.142594\n","resetting env. episode 512.000000, reward total was -19.000000. running mean: -20.131168\n","resetting env. episode 513.000000, reward total was -19.000000. running mean: -20.119857\n","resetting env. episode 514.000000, reward total was -21.000000. running mean: -20.128658\n","resetting env. episode 515.000000, reward total was -21.000000. running mean: -20.137372\n","resetting env. episode 516.000000, reward total was -20.000000. running mean: -20.135998\n","resetting env. episode 517.000000, reward total was -20.000000. running mean: -20.134638\n","resetting env. episode 518.000000, reward total was -20.000000. running mean: -20.133291\n","resetting env. episode 519.000000, reward total was -20.000000. running mean: -20.131959\n","resetting env. episode 520.000000, reward total was -19.000000. running mean: -20.120639\n","resetting env. episode 521.000000, reward total was -19.000000. running mean: -20.109433\n","resetting env. episode 522.000000, reward total was -20.000000. running mean: -20.108338\n","resetting env. episode 523.000000, reward total was -21.000000. running mean: -20.117255\n","resetting env. episode 524.000000, reward total was -21.000000. running mean: -20.126082\n","resetting env. episode 525.000000, reward total was -21.000000. running mean: -20.134821\n","resetting env. episode 526.000000, reward total was -21.000000. running mean: -20.143473\n","resetting env. episode 527.000000, reward total was -19.000000. running mean: -20.132039\n","resetting env. episode 528.000000, reward total was -19.000000. running mean: -20.120718\n","resetting env. episode 529.000000, reward total was -21.000000. running mean: -20.129511\n","resetting env. episode 530.000000, reward total was -20.000000. running mean: -20.128216\n","resetting env. episode 531.000000, reward total was -21.000000. running mean: -20.136934\n","resetting env. episode 532.000000, reward total was -20.000000. running mean: -20.135564\n","resetting env. episode 533.000000, reward total was -20.000000. running mean: -20.134209\n","resetting env. episode 534.000000, reward total was -17.000000. running mean: -20.102867\n","resetting env. episode 535.000000, reward total was -21.000000. running mean: -20.111838\n","resetting env. episode 536.000000, reward total was -19.000000. running mean: -20.100720\n","resetting env. episode 537.000000, reward total was -21.000000. running mean: -20.109712\n","resetting env. episode 538.000000, reward total was -21.000000. running mean: -20.118615\n","resetting env. episode 539.000000, reward total was -19.000000. running mean: -20.107429\n","resetting env. episode 540.000000, reward total was -20.000000. running mean: -20.106355\n","resetting env. episode 541.000000, reward total was -21.000000. running mean: -20.115291\n","resetting env. episode 542.000000, reward total was -21.000000. running mean: -20.124138\n","resetting env. episode 543.000000, reward total was -21.000000. running mean: -20.132897\n","resetting env. episode 544.000000, reward total was -21.000000. running mean: -20.141568\n","resetting env. episode 545.000000, reward total was -21.000000. running mean: -20.150152\n","resetting env. episode 546.000000, reward total was -21.000000. running mean: -20.158651\n","resetting env. episode 547.000000, reward total was -21.000000. running mean: -20.167064\n","resetting env. episode 548.000000, reward total was -19.000000. running mean: -20.155394\n","resetting env. episode 549.000000, reward total was -21.000000. running mean: -20.163840\n","resetting env. episode 550.000000, reward total was -21.000000. running mean: -20.172201\n","resetting env. episode 551.000000, reward total was -21.000000. running mean: -20.180479\n","resetting env. episode 552.000000, reward total was -21.000000. running mean: -20.188675\n","resetting env. episode 553.000000, reward total was -20.000000. running mean: -20.186788\n","resetting env. episode 554.000000, reward total was -20.000000. running mean: -20.184920\n","resetting env. episode 555.000000, reward total was -20.000000. running mean: -20.183071\n","resetting env. episode 556.000000, reward total was -21.000000. running mean: -20.191240\n","resetting env. episode 557.000000, reward total was -18.000000. running mean: -20.169328\n","resetting env. episode 558.000000, reward total was -21.000000. running mean: -20.177634\n","resetting env. episode 559.000000, reward total was -21.000000. running mean: -20.185858\n","resetting env. episode 560.000000, reward total was -19.000000. running mean: -20.173999\n","resetting env. episode 561.000000, reward total was -20.000000. running mean: -20.172259\n","resetting env. episode 562.000000, reward total was -20.000000. running mean: -20.170537\n","resetting env. episode 563.000000, reward total was -20.000000. running mean: -20.168831\n","resetting env. episode 564.000000, reward total was -20.000000. running mean: -20.167143\n","resetting env. episode 565.000000, reward total was -18.000000. running mean: -20.145472\n","resetting env. episode 566.000000, reward total was -20.000000. running mean: -20.144017\n","resetting env. episode 567.000000, reward total was -20.000000. running mean: -20.142577\n","resetting env. episode 568.000000, reward total was -19.000000. running mean: -20.131151\n","resetting env. episode 569.000000, reward total was -21.000000. running mean: -20.139840\n","resetting env. episode 570.000000, reward total was -20.000000. running mean: -20.138441\n","resetting env. episode 571.000000, reward total was -20.000000. running mean: -20.137057\n","resetting env. episode 572.000000, reward total was -21.000000. running mean: -20.145686\n","resetting env. episode 573.000000, reward total was -21.000000. running mean: -20.154229\n","resetting env. episode 574.000000, reward total was -20.000000. running mean: -20.152687\n","resetting env. episode 575.000000, reward total was -20.000000. running mean: -20.151160\n","resetting env. episode 576.000000, reward total was -20.000000. running mean: -20.149649\n","resetting env. episode 577.000000, reward total was -21.000000. running mean: -20.158152\n","resetting env. episode 578.000000, reward total was -21.000000. running mean: -20.166571\n","resetting env. episode 579.000000, reward total was -21.000000. running mean: -20.174905\n","resetting env. episode 580.000000, reward total was -21.000000. running mean: -20.183156\n","resetting env. episode 581.000000, reward total was -20.000000. running mean: -20.181324\n","resetting env. episode 582.000000, reward total was -21.000000. running mean: -20.189511\n","resetting env. episode 583.000000, reward total was -21.000000. running mean: -20.197616\n","resetting env. episode 584.000000, reward total was -20.000000. running mean: -20.195640\n","resetting env. episode 585.000000, reward total was -20.000000. running mean: -20.193683\n","resetting env. episode 586.000000, reward total was -20.000000. running mean: -20.191746\n","resetting env. episode 587.000000, reward total was -20.000000. running mean: -20.189829\n","resetting env. episode 588.000000, reward total was -21.000000. running mean: -20.197931\n","resetting env. episode 589.000000, reward total was -20.000000. running mean: -20.195951\n","resetting env. episode 590.000000, reward total was -20.000000. running mean: -20.193992\n","resetting env. episode 591.000000, reward total was -20.000000. running mean: -20.192052\n","resetting env. episode 592.000000, reward total was -17.000000. running mean: -20.160131\n","resetting env. episode 593.000000, reward total was -21.000000. running mean: -20.168530\n","resetting env. episode 594.000000, reward total was -20.000000. running mean: -20.166845\n","resetting env. episode 595.000000, reward total was -21.000000. running mean: -20.175176\n","resetting env. episode 596.000000, reward total was -21.000000. running mean: -20.183425\n","resetting env. episode 597.000000, reward total was -19.000000. running mean: -20.171590\n","resetting env. episode 598.000000, reward total was -19.000000. running mean: -20.159874\n","resetting env. episode 599.000000, reward total was -21.000000. running mean: -20.168276\n","resetting env. episode 600.000000, reward total was -21.000000. running mean: -20.176593\n","resetting env. episode 601.000000, reward total was -19.000000. running mean: -20.164827\n","resetting env. episode 602.000000, reward total was -21.000000. running mean: -20.173179\n","resetting env. episode 603.000000, reward total was -21.000000. running mean: -20.181447\n","resetting env. episode 604.000000, reward total was -19.000000. running mean: -20.169633\n","resetting env. episode 605.000000, reward total was -21.000000. running mean: -20.177936\n","resetting env. episode 606.000000, reward total was -21.000000. running mean: -20.186157\n","resetting env. episode 607.000000, reward total was -21.000000. running mean: -20.194295\n","resetting env. episode 608.000000, reward total was -21.000000. running mean: -20.202352\n","resetting env. episode 609.000000, reward total was -19.000000. running mean: -20.190329\n","resetting env. episode 610.000000, reward total was -19.000000. running mean: -20.178425\n","resetting env. episode 611.000000, reward total was -20.000000. running mean: -20.176641\n","resetting env. episode 612.000000, reward total was -20.000000. running mean: -20.174875\n","resetting env. episode 613.000000, reward total was -20.000000. running mean: -20.173126\n","resetting env. episode 614.000000, reward total was -21.000000. running mean: -20.181395\n","resetting env. episode 615.000000, reward total was -21.000000. running mean: -20.189581\n","resetting env. episode 616.000000, reward total was -21.000000. running mean: -20.197685\n","resetting env. episode 617.000000, reward total was -19.000000. running mean: -20.185708\n","resetting env. episode 618.000000, reward total was -18.000000. running mean: -20.163851\n","resetting env. episode 619.000000, reward total was -20.000000. running mean: -20.162213\n","resetting env. episode 620.000000, reward total was -17.000000. running mean: -20.130590\n","resetting env. episode 621.000000, reward total was -19.000000. running mean: -20.119285\n","resetting env. episode 622.000000, reward total was -20.000000. running mean: -20.118092\n","resetting env. episode 623.000000, reward total was -19.000000. running mean: -20.106911\n","resetting env. episode 624.000000, reward total was -21.000000. running mean: -20.115842\n","resetting env. episode 625.000000, reward total was -20.000000. running mean: -20.114683\n","resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.123536\n","resetting env. episode 627.000000, reward total was -21.000000. running mean: -20.132301\n","resetting env. episode 628.000000, reward total was -20.000000. running mean: -20.130978\n","resetting env. episode 629.000000, reward total was -21.000000. running mean: -20.139668\n","resetting env. episode 630.000000, reward total was -19.000000. running mean: -20.128272\n","resetting env. episode 631.000000, reward total was -20.000000. running mean: -20.126989\n","resetting env. episode 632.000000, reward total was -19.000000. running mean: -20.115719\n","resetting env. episode 633.000000, reward total was -21.000000. running mean: -20.124562\n","resetting env. episode 634.000000, reward total was -19.000000. running mean: -20.113316\n","resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.122183\n","resetting env. episode 636.000000, reward total was -21.000000. running mean: -20.130961\n","resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.139652\n","resetting env. episode 638.000000, reward total was -20.000000. running mean: -20.138255\n","resetting env. episode 639.000000, reward total was -21.000000. running mean: -20.146873\n","resetting env. episode 640.000000, reward total was -21.000000. running mean: -20.155404\n","resetting env. episode 641.000000, reward total was -19.000000. running mean: -20.143850\n","resetting env. episode 642.000000, reward total was -20.000000. running mean: -20.142411\n","resetting env. episode 643.000000, reward total was -20.000000. running mean: -20.140987\n","resetting env. episode 644.000000, reward total was -21.000000. running mean: -20.149577\n","resetting env. episode 645.000000, reward total was -21.000000. running mean: -20.158082\n","resetting env. episode 646.000000, reward total was -19.000000. running mean: -20.146501\n","resetting env. episode 647.000000, reward total was -21.000000. running mean: -20.155036\n","resetting env. episode 648.000000, reward total was -21.000000. running mean: -20.163485\n","resetting env. episode 649.000000, reward total was -21.000000. running mean: -20.171850\n","resetting env. episode 650.000000, reward total was -21.000000. running mean: -20.180132\n","resetting env. episode 651.000000, reward total was -20.000000. running mean: -20.178331\n","resetting env. episode 652.000000, reward total was -21.000000. running mean: -20.186547\n","resetting env. episode 653.000000, reward total was -21.000000. running mean: -20.194682\n","resetting env. episode 654.000000, reward total was -18.000000. running mean: -20.172735\n","resetting env. episode 655.000000, reward total was -19.000000. running mean: -20.161008\n","resetting env. episode 656.000000, reward total was -20.000000. running mean: -20.159398\n","resetting env. episode 657.000000, reward total was -19.000000. running mean: -20.147804\n","resetting env. episode 658.000000, reward total was -21.000000. running mean: -20.156326\n","resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.164762\n","resetting env. episode 660.000000, reward total was -21.000000. running mean: -20.173115\n","resetting env. episode 661.000000, reward total was -21.000000. running mean: -20.181384\n","resetting env. episode 662.000000, reward total was -21.000000. running mean: -20.189570\n","resetting env. episode 663.000000, reward total was -21.000000. running mean: -20.197674\n","resetting env. episode 664.000000, reward total was -20.000000. running mean: -20.195697\n","resetting env. episode 665.000000, reward total was -19.000000. running mean: -20.183740\n","resetting env. episode 666.000000, reward total was -20.000000. running mean: -20.181903\n","resetting env. episode 667.000000, reward total was -21.000000. running mean: -20.190084\n","resetting env. episode 668.000000, reward total was -19.000000. running mean: -20.178183\n","resetting env. episode 669.000000, reward total was -20.000000. running mean: -20.176401\n","resetting env. episode 670.000000, reward total was -20.000000. running mean: -20.174637\n","resetting env. episode 671.000000, reward total was -19.000000. running mean: -20.162891\n","resetting env. episode 672.000000, reward total was -19.000000. running mean: -20.151262\n","resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.159749\n","resetting env. episode 674.000000, reward total was -20.000000. running mean: -20.158152\n","resetting env. episode 675.000000, reward total was -20.000000. running mean: -20.156570\n","resetting env. episode 676.000000, reward total was -20.000000. running mean: -20.155005\n","resetting env. episode 677.000000, reward total was -21.000000. running mean: -20.163455\n","resetting env. episode 678.000000, reward total was -20.000000. running mean: -20.161820\n","resetting env. episode 679.000000, reward total was -21.000000. running mean: -20.170202\n","resetting env. episode 680.000000, reward total was -21.000000. running mean: -20.178500\n","resetting env. episode 681.000000, reward total was -21.000000. running mean: -20.186715\n","resetting env. episode 682.000000, reward total was -19.000000. running mean: -20.174848\n","resetting env. episode 683.000000, reward total was -21.000000. running mean: -20.183099\n","resetting env. episode 684.000000, reward total was -21.000000. running mean: -20.191268\n","resetting env. episode 685.000000, reward total was -21.000000. running mean: -20.199356\n","resetting env. episode 686.000000, reward total was -20.000000. running mean: -20.197362\n","resetting env. episode 687.000000, reward total was -19.000000. running mean: -20.185388\n","resetting env. episode 688.000000, reward total was -20.000000. running mean: -20.183534\n","resetting env. episode 689.000000, reward total was -20.000000. running mean: -20.181699\n","resetting env. episode 690.000000, reward total was -21.000000. running mean: -20.189882\n","resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.197983\n","resetting env. episode 692.000000, reward total was -21.000000. running mean: -20.206003\n","resetting env. episode 693.000000, reward total was -21.000000. running mean: -20.213943\n","resetting env. episode 694.000000, reward total was -20.000000. running mean: -20.211804\n","resetting env. episode 695.000000, reward total was -19.000000. running mean: -20.199686\n","resetting env. episode 696.000000, reward total was -20.000000. running mean: -20.197689\n","resetting env. episode 697.000000, reward total was -20.000000. running mean: -20.195712\n","resetting env. episode 698.000000, reward total was -20.000000. running mean: -20.193755\n","resetting env. episode 699.000000, reward total was -21.000000. running mean: -20.201818\n","resetting env. episode 700.000000, reward total was -21.000000. running mean: -20.209799\n","resetting env. episode 701.000000, reward total was -20.000000. running mean: -20.207701\n","resetting env. episode 702.000000, reward total was -21.000000. running mean: -20.215624\n","resetting env. episode 703.000000, reward total was -19.000000. running mean: -20.203468\n","resetting env. episode 704.000000, reward total was -21.000000. running mean: -20.211433\n","resetting env. episode 705.000000, reward total was -21.000000. running mean: -20.219319\n","resetting env. episode 706.000000, reward total was -17.000000. running mean: -20.187126\n","resetting env. episode 707.000000, reward total was -21.000000. running mean: -20.195255\n","resetting env. episode 708.000000, reward total was -20.000000. running mean: -20.193302\n","resetting env. episode 709.000000, reward total was -21.000000. running mean: -20.201369\n","resetting env. episode 710.000000, reward total was -20.000000. running mean: -20.199355\n","resetting env. episode 711.000000, reward total was -20.000000. running mean: -20.197362\n","resetting env. episode 712.000000, reward total was -21.000000. running mean: -20.205388\n","resetting env. episode 713.000000, reward total was -21.000000. running mean: -20.213334\n","resetting env. episode 714.000000, reward total was -19.000000. running mean: -20.201201\n","resetting env. episode 715.000000, reward total was -20.000000. running mean: -20.199189\n","resetting env. episode 716.000000, reward total was -20.000000. running mean: -20.197197\n","resetting env. episode 717.000000, reward total was -20.000000. running mean: -20.195225\n","resetting env. episode 718.000000, reward total was -18.000000. running mean: -20.173273\n","resetting env. episode 719.000000, reward total was -20.000000. running mean: -20.171540\n","resetting env. episode 720.000000, reward total was -21.000000. running mean: -20.179825\n","resetting env. episode 721.000000, reward total was -20.000000. running mean: -20.178026\n","resetting env. episode 722.000000, reward total was -20.000000. running mean: -20.176246\n","resetting env. episode 723.000000, reward total was -21.000000. running mean: -20.184484\n","resetting env. episode 724.000000, reward total was -20.000000. running mean: -20.182639\n","resetting env. episode 725.000000, reward total was -21.000000. running mean: -20.190813\n","resetting env. episode 726.000000, reward total was -19.000000. running mean: -20.178904\n","resetting env. episode 727.000000, reward total was -20.000000. running mean: -20.177115\n","resetting env. episode 728.000000, reward total was -20.000000. running mean: -20.175344\n","resetting env. episode 729.000000, reward total was -21.000000. running mean: -20.183591\n","resetting env. episode 730.000000, reward total was -21.000000. running mean: -20.191755\n","resetting env. episode 731.000000, reward total was -21.000000. running mean: -20.199837\n","resetting env. episode 732.000000, reward total was -21.000000. running mean: -20.207839\n","resetting env. episode 733.000000, reward total was -21.000000. running mean: -20.215761\n","resetting env. episode 734.000000, reward total was -20.000000. running mean: -20.213603\n","resetting env. episode 735.000000, reward total was -21.000000. running mean: -20.221467\n","resetting env. episode 736.000000, reward total was -21.000000. running mean: -20.229252\n","resetting env. episode 737.000000, reward total was -20.000000. running mean: -20.226960\n","resetting env. episode 738.000000, reward total was -15.000000. running mean: -20.174690\n","resetting env. episode 739.000000, reward total was -20.000000. running mean: -20.172943\n","resetting env. episode 740.000000, reward total was -21.000000. running mean: -20.181214\n","resetting env. episode 741.000000, reward total was -21.000000. running mean: -20.189402\n","resetting env. episode 742.000000, reward total was -21.000000. running mean: -20.197508\n","resetting env. episode 743.000000, reward total was -21.000000. running mean: -20.205533\n","resetting env. episode 744.000000, reward total was -20.000000. running mean: -20.203477\n","resetting env. episode 745.000000, reward total was -20.000000. running mean: -20.201442\n","resetting env. episode 746.000000, reward total was -21.000000. running mean: -20.209428\n","resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.217334\n","resetting env. episode 748.000000, reward total was -21.000000. running mean: -20.225160\n","resetting env. episode 749.000000, reward total was -21.000000. running mean: -20.232909\n","resetting env. episode 750.000000, reward total was -21.000000. running mean: -20.240580\n","resetting env. episode 751.000000, reward total was -21.000000. running mean: -20.248174\n","resetting env. episode 752.000000, reward total was -18.000000. running mean: -20.225692\n","resetting env. episode 753.000000, reward total was -20.000000. running mean: -20.223435\n","resetting env. episode 754.000000, reward total was -21.000000. running mean: -20.231201\n","resetting env. episode 755.000000, reward total was -20.000000. running mean: -20.228889\n","resetting env. episode 756.000000, reward total was -21.000000. running mean: -20.236600\n","resetting env. episode 757.000000, reward total was -21.000000. running mean: -20.244234\n","resetting env. episode 758.000000, reward total was -21.000000. running mean: -20.251792\n","resetting env. episode 759.000000, reward total was -21.000000. running mean: -20.259274\n","resetting env. episode 760.000000, reward total was -20.000000. running mean: -20.256681\n","resetting env. episode 761.000000, reward total was -20.000000. running mean: -20.254114\n","resetting env. episode 762.000000, reward total was -20.000000. running mean: -20.251573\n","resetting env. episode 763.000000, reward total was -20.000000. running mean: -20.249057\n","resetting env. episode 764.000000, reward total was -19.000000. running mean: -20.236567\n","resetting env. episode 765.000000, reward total was -20.000000. running mean: -20.234201\n","resetting env. episode 766.000000, reward total was -20.000000. running mean: -20.231859\n","resetting env. episode 767.000000, reward total was -20.000000. running mean: -20.229540\n","resetting env. episode 768.000000, reward total was -19.000000. running mean: -20.217245\n","resetting env. episode 769.000000, reward total was -20.000000. running mean: -20.215073\n","resetting env. episode 770.000000, reward total was -20.000000. running mean: -20.212922\n","resetting env. episode 771.000000, reward total was -20.000000. running mean: -20.210793\n","resetting env. episode 772.000000, reward total was -21.000000. running mean: -20.218685\n","resetting env. episode 773.000000, reward total was -19.000000. running mean: -20.206498\n","resetting env. episode 774.000000, reward total was -21.000000. running mean: -20.214433\n","resetting env. episode 775.000000, reward total was -16.000000. running mean: -20.172289\n","resetting env. episode 776.000000, reward total was -20.000000. running mean: -20.170566\n","resetting env. episode 777.000000, reward total was -21.000000. running mean: -20.178860\n","resetting env. episode 778.000000, reward total was -21.000000. running mean: -20.187071\n","resetting env. episode 779.000000, reward total was -21.000000. running mean: -20.195201\n","resetting env. episode 780.000000, reward total was -19.000000. running mean: -20.183249\n","resetting env. episode 781.000000, reward total was -21.000000. running mean: -20.191416\n","resetting env. episode 782.000000, reward total was -19.000000. running mean: -20.179502\n","resetting env. episode 783.000000, reward total was -21.000000. running mean: -20.187707\n","resetting env. episode 784.000000, reward total was -21.000000. running mean: -20.195830\n","resetting env. episode 785.000000, reward total was -21.000000. running mean: -20.203872\n","resetting env. episode 786.000000, reward total was -19.000000. running mean: -20.191833\n","resetting env. episode 787.000000, reward total was -21.000000. running mean: -20.199915\n","resetting env. episode 788.000000, reward total was -21.000000. running mean: -20.207916\n","resetting env. episode 789.000000, reward total was -21.000000. running mean: -20.215836\n","resetting env. episode 790.000000, reward total was -19.000000. running mean: -20.203678\n","resetting env. episode 791.000000, reward total was -21.000000. running mean: -20.211641\n","resetting env. episode 792.000000, reward total was -19.000000. running mean: -20.199525\n","resetting env. episode 793.000000, reward total was -21.000000. running mean: -20.207530\n","resetting env. episode 794.000000, reward total was -20.000000. running mean: -20.205454\n","resetting env. episode 795.000000, reward total was -20.000000. running mean: -20.203400\n","resetting env. episode 796.000000, reward total was -19.000000. running mean: -20.191366\n","resetting env. episode 797.000000, reward total was -21.000000. running mean: -20.199452\n","resetting env. episode 798.000000, reward total was -19.000000. running mean: -20.187458\n","resetting env. episode 799.000000, reward total was -20.000000. running mean: -20.185583\n","resetting env. episode 800.000000, reward total was -21.000000. running mean: -20.193727\n","resetting env. episode 801.000000, reward total was -21.000000. running mean: -20.201790\n","resetting env. episode 802.000000, reward total was -20.000000. running mean: -20.199772\n","resetting env. episode 803.000000, reward total was -21.000000. running mean: -20.207774\n","resetting env. episode 804.000000, reward total was -21.000000. running mean: -20.215697\n","resetting env. episode 805.000000, reward total was -21.000000. running mean: -20.223540\n","resetting env. episode 806.000000, reward total was -20.000000. running mean: -20.221304\n","resetting env. episode 807.000000, reward total was -20.000000. running mean: -20.219091\n","resetting env. episode 808.000000, reward total was -20.000000. running mean: -20.216900\n","resetting env. episode 809.000000, reward total was -20.000000. running mean: -20.214731\n","resetting env. episode 810.000000, reward total was -20.000000. running mean: -20.212584\n","resetting env. episode 811.000000, reward total was -20.000000. running mean: -20.210458\n","resetting env. episode 812.000000, reward total was -20.000000. running mean: -20.208353\n","resetting env. episode 813.000000, reward total was -20.000000. running mean: -20.206270\n","resetting env. episode 814.000000, reward total was -20.000000. running mean: -20.204207\n","resetting env. episode 815.000000, reward total was -21.000000. running mean: -20.212165\n","resetting env. episode 816.000000, reward total was -20.000000. running mean: -20.210043\n","resetting env. episode 817.000000, reward total was -21.000000. running mean: -20.217943\n","resetting env. episode 818.000000, reward total was -19.000000. running mean: -20.205764\n","resetting env. episode 819.000000, reward total was -21.000000. running mean: -20.213706\n","resetting env. episode 820.000000, reward total was -20.000000. running mean: -20.211569\n","resetting env. episode 821.000000, reward total was -21.000000. running mean: -20.219453\n","resetting env. episode 822.000000, reward total was -21.000000. running mean: -20.227259\n","resetting env. episode 823.000000, reward total was -20.000000. running mean: -20.224986\n","resetting env. episode 824.000000, reward total was -21.000000. running mean: -20.232736\n","resetting env. episode 825.000000, reward total was -21.000000. running mean: -20.240409\n","resetting env. episode 826.000000, reward total was -19.000000. running mean: -20.228005\n","resetting env. episode 827.000000, reward total was -21.000000. running mean: -20.235725\n","resetting env. episode 828.000000, reward total was -21.000000. running mean: -20.243368\n","resetting env. episode 829.000000, reward total was -21.000000. running mean: -20.250934\n","resetting env. episode 830.000000, reward total was -21.000000. running mean: -20.258425\n","resetting env. episode 831.000000, reward total was -21.000000. running mean: -20.265840\n","resetting env. episode 832.000000, reward total was -20.000000. running mean: -20.263182\n","resetting env. episode 833.000000, reward total was -21.000000. running mean: -20.270550\n","resetting env. episode 834.000000, reward total was -20.000000. running mean: -20.267845\n","resetting env. episode 835.000000, reward total was -21.000000. running mean: -20.275166\n","resetting env. episode 836.000000, reward total was -21.000000. running mean: -20.282414\n","resetting env. episode 837.000000, reward total was -20.000000. running mean: -20.279590\n","resetting env. episode 838.000000, reward total was -20.000000. running mean: -20.276794\n","resetting env. episode 839.000000, reward total was -20.000000. running mean: -20.274026\n","resetting env. episode 840.000000, reward total was -21.000000. running mean: -20.281286\n","resetting env. episode 841.000000, reward total was -21.000000. running mean: -20.288473\n","resetting env. episode 842.000000, reward total was -20.000000. running mean: -20.285589\n","resetting env. episode 843.000000, reward total was -21.000000. running mean: -20.292733\n","resetting env. episode 844.000000, reward total was -21.000000. running mean: -20.299805\n","resetting env. episode 845.000000, reward total was -21.000000. running mean: -20.306807\n","resetting env. episode 846.000000, reward total was -21.000000. running mean: -20.313739\n","resetting env. episode 847.000000, reward total was -20.000000. running mean: -20.310602\n","resetting env. episode 848.000000, reward total was -20.000000. running mean: -20.307496\n","resetting env. episode 849.000000, reward total was -21.000000. running mean: -20.314421\n","resetting env. episode 850.000000, reward total was -20.000000. running mean: -20.311277\n","resetting env. episode 851.000000, reward total was -20.000000. running mean: -20.308164\n","resetting env. episode 852.000000, reward total was -21.000000. running mean: -20.315082\n","resetting env. episode 853.000000, reward total was -21.000000. running mean: -20.321931\n","resetting env. episode 854.000000, reward total was -21.000000. running mean: -20.328712\n","resetting env. episode 855.000000, reward total was -20.000000. running mean: -20.325425\n","resetting env. episode 856.000000, reward total was -21.000000. running mean: -20.332171\n","resetting env. episode 857.000000, reward total was -21.000000. running mean: -20.338849\n","resetting env. episode 858.000000, reward total was -20.000000. running mean: -20.335461\n","resetting env. episode 859.000000, reward total was -21.000000. running mean: -20.342106\n","resetting env. episode 860.000000, reward total was -20.000000. running mean: -20.338685\n","resetting env. episode 861.000000, reward total was -20.000000. running mean: -20.335298\n","resetting env. episode 862.000000, reward total was -20.000000. running mean: -20.331945\n","resetting env. episode 863.000000, reward total was -20.000000. running mean: -20.328626\n","resetting env. episode 864.000000, reward total was -19.000000. running mean: -20.315339\n","resetting env. episode 865.000000, reward total was -20.000000. running mean: -20.312186\n","resetting env. episode 866.000000, reward total was -20.000000. running mean: -20.309064\n","resetting env. episode 867.000000, reward total was -21.000000. running mean: -20.315973\n","resetting env. episode 868.000000, reward total was -19.000000. running mean: -20.302814\n","resetting env. episode 869.000000, reward total was -21.000000. running mean: -20.309786\n","resetting env. episode 870.000000, reward total was -21.000000. running mean: -20.316688\n","resetting env. episode 871.000000, reward total was -20.000000. running mean: -20.313521\n","resetting env. episode 872.000000, reward total was -19.000000. running mean: -20.300386\n","resetting env. episode 873.000000, reward total was -21.000000. running mean: -20.307382\n","resetting env. episode 874.000000, reward total was -20.000000. running mean: -20.304308\n","resetting env. episode 875.000000, reward total was -20.000000. running mean: -20.301265\n","resetting env. episode 876.000000, reward total was -17.000000. running mean: -20.268252\n","resetting env. episode 877.000000, reward total was -18.000000. running mean: -20.245570\n","resetting env. episode 878.000000, reward total was -20.000000. running mean: -20.243114\n","resetting env. episode 879.000000, reward total was -21.000000. running mean: -20.250683\n","resetting env. episode 880.000000, reward total was -19.000000. running mean: -20.238176\n","resetting env. episode 881.000000, reward total was -20.000000. running mean: -20.235794\n","resetting env. episode 882.000000, reward total was -20.000000. running mean: -20.233436\n","resetting env. episode 883.000000, reward total was -17.000000. running mean: -20.201102\n","resetting env. episode 884.000000, reward total was -21.000000. running mean: -20.209091\n","resetting env. episode 885.000000, reward total was -21.000000. running mean: -20.217000\n","resetting env. episode 886.000000, reward total was -20.000000. running mean: -20.214830\n","resetting env. episode 887.000000, reward total was -21.000000. running mean: -20.222682\n","resetting env. episode 888.000000, reward total was -21.000000. running mean: -20.230455\n","resetting env. episode 889.000000, reward total was -19.000000. running mean: -20.218150\n","resetting env. episode 890.000000, reward total was -19.000000. running mean: -20.205969\n","resetting env. episode 891.000000, reward total was -20.000000. running mean: -20.203909\n","resetting env. episode 892.000000, reward total was -21.000000. running mean: -20.211870\n","resetting env. episode 893.000000, reward total was -16.000000. running mean: -20.169751\n","resetting env. episode 894.000000, reward total was -19.000000. running mean: -20.158054\n","resetting env. episode 895.000000, reward total was -21.000000. running mean: -20.166473\n","resetting env. episode 896.000000, reward total was -21.000000. running mean: -20.174809\n","resetting env. episode 897.000000, reward total was -21.000000. running mean: -20.183061\n","resetting env. episode 898.000000, reward total was -21.000000. running mean: -20.191230\n","resetting env. episode 899.000000, reward total was -18.000000. running mean: -20.169318\n","resetting env. episode 900.000000, reward total was -21.000000. running mean: -20.177624\n","resetting env. episode 901.000000, reward total was -21.000000. running mean: -20.185848\n","resetting env. episode 902.000000, reward total was -21.000000. running mean: -20.193990\n","resetting env. episode 903.000000, reward total was -21.000000. running mean: -20.202050\n","resetting env. episode 904.000000, reward total was -21.000000. running mean: -20.210029\n","resetting env. episode 905.000000, reward total was -21.000000. running mean: -20.217929\n","resetting env. episode 906.000000, reward total was -20.000000. running mean: -20.215750\n","resetting env. episode 907.000000, reward total was -21.000000. running mean: -20.223592\n","resetting env. episode 908.000000, reward total was -21.000000. running mean: -20.231356\n","resetting env. episode 909.000000, reward total was -19.000000. running mean: -20.219043\n","resetting env. episode 910.000000, reward total was -21.000000. running mean: -20.226852\n","resetting env. episode 911.000000, reward total was -21.000000. running mean: -20.234584\n","resetting env. episode 912.000000, reward total was -20.000000. running mean: -20.232238\n","resetting env. episode 913.000000, reward total was -20.000000. running mean: -20.229916\n","resetting env. episode 914.000000, reward total was -21.000000. running mean: -20.237616\n","resetting env. episode 915.000000, reward total was -21.000000. running mean: -20.245240\n","resetting env. episode 916.000000, reward total was -21.000000. running mean: -20.252788\n","resetting env. episode 917.000000, reward total was -19.000000. running mean: -20.240260\n","resetting env. episode 918.000000, reward total was -20.000000. running mean: -20.237857\n","resetting env. episode 919.000000, reward total was -21.000000. running mean: -20.245479\n","resetting env. episode 920.000000, reward total was -21.000000. running mean: -20.253024\n","resetting env. episode 921.000000, reward total was -20.000000. running mean: -20.250494\n","resetting env. episode 922.000000, reward total was -20.000000. running mean: -20.247989\n","resetting env. episode 923.000000, reward total was -20.000000. running mean: -20.245509\n","resetting env. episode 924.000000, reward total was -21.000000. running mean: -20.253054\n","resetting env. episode 925.000000, reward total was -21.000000. running mean: -20.260523\n","resetting env. episode 926.000000, reward total was -21.000000. running mean: -20.267918\n","resetting env. episode 927.000000, reward total was -19.000000. running mean: -20.255239\n","resetting env. episode 928.000000, reward total was -21.000000. running mean: -20.262687\n","resetting env. episode 929.000000, reward total was -19.000000. running mean: -20.250060\n","resetting env. episode 930.000000, reward total was -21.000000. running mean: -20.257559\n","resetting env. episode 931.000000, reward total was -19.000000. running mean: -20.244983\n","resetting env. episode 932.000000, reward total was -21.000000. running mean: -20.252534\n","resetting env. episode 933.000000, reward total was -21.000000. running mean: -20.260008\n","resetting env. episode 934.000000, reward total was -21.000000. running mean: -20.267408\n","resetting env. episode 935.000000, reward total was -19.000000. running mean: -20.254734\n","resetting env. episode 936.000000, reward total was -21.000000. running mean: -20.262187\n","resetting env. episode 937.000000, reward total was -18.000000. running mean: -20.239565\n","resetting env. episode 938.000000, reward total was -21.000000. running mean: -20.247169\n","resetting env. episode 939.000000, reward total was -21.000000. running mean: -20.254698\n","resetting env. episode 940.000000, reward total was -20.000000. running mean: -20.252151\n","resetting env. episode 941.000000, reward total was -20.000000. running mean: -20.249629\n","resetting env. episode 942.000000, reward total was -20.000000. running mean: -20.247133\n","resetting env. episode 943.000000, reward total was -21.000000. running mean: -20.254661\n","resetting env. episode 944.000000, reward total was -21.000000. running mean: -20.262115\n","resetting env. episode 945.000000, reward total was -21.000000. running mean: -20.269494\n","resetting env. episode 946.000000, reward total was -21.000000. running mean: -20.276799\n","resetting env. episode 947.000000, reward total was -20.000000. running mean: -20.274031\n","resetting env. episode 948.000000, reward total was -20.000000. running mean: -20.271290\n","resetting env. episode 949.000000, reward total was -20.000000. running mean: -20.268578\n","resetting env. episode 950.000000, reward total was -19.000000. running mean: -20.255892\n","resetting env. episode 951.000000, reward total was -21.000000. running mean: -20.263333\n","resetting env. episode 952.000000, reward total was -21.000000. running mean: -20.270700\n","resetting env. episode 953.000000, reward total was -20.000000. running mean: -20.267993\n","resetting env. episode 954.000000, reward total was -21.000000. running mean: -20.275313\n","resetting env. episode 955.000000, reward total was -18.000000. running mean: -20.252560\n","resetting env. episode 956.000000, reward total was -20.000000. running mean: -20.250034\n","resetting env. episode 957.000000, reward total was -20.000000. running mean: -20.247534\n","resetting env. episode 958.000000, reward total was -21.000000. running mean: -20.255058\n","resetting env. episode 959.000000, reward total was -21.000000. running mean: -20.262508\n","resetting env. episode 960.000000, reward total was -21.000000. running mean: -20.269883\n","resetting env. episode 961.000000, reward total was -21.000000. running mean: -20.277184\n","resetting env. episode 962.000000, reward total was -20.000000. running mean: -20.274412\n","resetting env. episode 963.000000, reward total was -19.000000. running mean: -20.261668\n","resetting env. episode 964.000000, reward total was -21.000000. running mean: -20.269051\n","resetting env. episode 965.000000, reward total was -21.000000. running mean: -20.276361\n","resetting env. episode 966.000000, reward total was -21.000000. running mean: -20.283597\n","resetting env. episode 967.000000, reward total was -21.000000. running mean: -20.290761\n","resetting env. episode 968.000000, reward total was -20.000000. running mean: -20.287853\n","resetting env. episode 969.000000, reward total was -21.000000. running mean: -20.294975\n","resetting env. episode 970.000000, reward total was -20.000000. running mean: -20.292025\n","resetting env. episode 971.000000, reward total was -21.000000. running mean: -20.299105\n","resetting env. episode 972.000000, reward total was -20.000000. running mean: -20.296114\n","resetting env. episode 973.000000, reward total was -20.000000. running mean: -20.293153\n","resetting env. episode 974.000000, reward total was -21.000000. running mean: -20.300221\n","resetting env. episode 975.000000, reward total was -21.000000. running mean: -20.307219\n","resetting env. episode 976.000000, reward total was -21.000000. running mean: -20.314147\n","resetting env. episode 977.000000, reward total was -21.000000. running mean: -20.321005\n","resetting env. episode 978.000000, reward total was -20.000000. running mean: -20.317795\n","resetting env. episode 979.000000, reward total was -19.000000. running mean: -20.304617\n","resetting env. episode 980.000000, reward total was -18.000000. running mean: -20.281571\n","resetting env. episode 981.000000, reward total was -19.000000. running mean: -20.268755\n","resetting env. episode 982.000000, reward total was -20.000000. running mean: -20.266068\n","resetting env. episode 983.000000, reward total was -20.000000. running mean: -20.263407\n","resetting env. episode 984.000000, reward total was -19.000000. running mean: -20.250773\n","resetting env. episode 985.000000, reward total was -21.000000. running mean: -20.258265\n","resetting env. episode 986.000000, reward total was -21.000000. running mean: -20.265683\n","resetting env. episode 987.000000, reward total was -19.000000. running mean: -20.253026\n","resetting env. episode 988.000000, reward total was -20.000000. running mean: -20.250496\n","resetting env. episode 989.000000, reward total was -20.000000. running mean: -20.247991\n","resetting env. episode 990.000000, reward total was -21.000000. running mean: -20.255511\n","resetting env. episode 991.000000, reward total was -21.000000. running mean: -20.262956\n","resetting env. episode 992.000000, reward total was -19.000000. running mean: -20.250326\n","resetting env. episode 993.000000, reward total was -20.000000. running mean: -20.247823\n","resetting env. episode 994.000000, reward total was -20.000000. running mean: -20.245345\n","resetting env. episode 995.000000, reward total was -19.000000. running mean: -20.232891\n","resetting env. episode 996.000000, reward total was -19.000000. running mean: -20.220562\n","resetting env. episode 997.000000, reward total was -19.000000. running mean: -20.208357\n","resetting env. episode 998.000000, reward total was -21.000000. running mean: -20.216273\n","resetting env. episode 999.000000, reward total was -21.000000. running mean: -20.224110\n","resetting env. episode 1000.000000, reward total was -21.000000. running mean: -20.231869\n","resetting env. episode 1001.000000, reward total was -20.000000. running mean: -20.229551\n","resetting env. episode 1002.000000, reward total was -21.000000. running mean: -20.237255\n","resetting env. episode 1003.000000, reward total was -20.000000. running mean: -20.234882\n","resetting env. episode 1004.000000, reward total was -20.000000. running mean: -20.232534\n","resetting env. episode 1005.000000, reward total was -20.000000. running mean: -20.230208\n","resetting env. episode 1006.000000, reward total was -19.000000. running mean: -20.217906\n","resetting env. episode 1007.000000, reward total was -19.000000. running mean: -20.205727\n","resetting env. episode 1008.000000, reward total was -15.000000. running mean: -20.153670\n","resetting env. episode 1009.000000, reward total was -20.000000. running mean: -20.152133\n","resetting env. episode 1010.000000, reward total was -20.000000. running mean: -20.150612\n","resetting env. episode 1011.000000, reward total was -20.000000. running mean: -20.149106\n","resetting env. episode 1012.000000, reward total was -20.000000. running mean: -20.147615\n","resetting env. episode 1013.000000, reward total was -20.000000. running mean: -20.146139\n","resetting env. episode 1014.000000, reward total was -19.000000. running mean: -20.134677\n","resetting env. episode 1015.000000, reward total was -20.000000. running mean: -20.133330\n","resetting env. episode 1016.000000, reward total was -20.000000. running mean: -20.131997\n","resetting env. episode 1017.000000, reward total was -21.000000. running mean: -20.140677\n","resetting env. episode 1018.000000, reward total was -21.000000. running mean: -20.149270\n","resetting env. episode 1019.000000, reward total was -21.000000. running mean: -20.157778\n","resetting env. episode 1020.000000, reward total was -19.000000. running mean: -20.146200\n","resetting env. episode 1021.000000, reward total was -20.000000. running mean: -20.144738\n","resetting env. episode 1022.000000, reward total was -21.000000. running mean: -20.153291\n","resetting env. episode 1023.000000, reward total was -19.000000. running mean: -20.141758\n","resetting env. episode 1024.000000, reward total was -21.000000. running mean: -20.150340\n","resetting env. episode 1025.000000, reward total was -20.000000. running mean: -20.148837\n","resetting env. episode 1026.000000, reward total was -18.000000. running mean: -20.127348\n","resetting env. episode 1027.000000, reward total was -20.000000. running mean: -20.126075\n","resetting env. episode 1028.000000, reward total was -19.000000. running mean: -20.114814\n","resetting env. episode 1029.000000, reward total was -20.000000. running mean: -20.113666\n","resetting env. episode 1030.000000, reward total was -21.000000. running mean: -20.122529\n","resetting env. episode 1031.000000, reward total was -21.000000. running mean: -20.131304\n","resetting env. episode 1032.000000, reward total was -21.000000. running mean: -20.139991\n","resetting env. episode 1033.000000, reward total was -21.000000. running mean: -20.148591\n","resetting env. episode 1034.000000, reward total was -20.000000. running mean: -20.147105\n","resetting env. episode 1035.000000, reward total was -20.000000. running mean: -20.145634\n","resetting env. episode 1036.000000, reward total was -20.000000. running mean: -20.144178\n","resetting env. episode 1037.000000, reward total was -21.000000. running mean: -20.152736\n","resetting env. episode 1038.000000, reward total was -19.000000. running mean: -20.141209\n","resetting env. episode 1039.000000, reward total was -19.000000. running mean: -20.129796\n","resetting env. episode 1040.000000, reward total was -20.000000. running mean: -20.128498\n","resetting env. episode 1041.000000, reward total was -19.000000. running mean: -20.117214\n","resetting env. episode 1042.000000, reward total was -20.000000. running mean: -20.116041\n","resetting env. episode 1043.000000, reward total was -18.000000. running mean: -20.094881\n","resetting env. episode 1044.000000, reward total was -20.000000. running mean: -20.093932\n","resetting env. episode 1045.000000, reward total was -20.000000. running mean: -20.092993\n","resetting env. episode 1046.000000, reward total was -21.000000. running mean: -20.102063\n","resetting env. episode 1047.000000, reward total was -21.000000. running mean: -20.111042\n","resetting env. episode 1048.000000, reward total was -20.000000. running mean: -20.109932\n","resetting env. episode 1049.000000, reward total was -20.000000. running mean: -20.108833\n","resetting env. episode 1050.000000, reward total was -20.000000. running mean: -20.107744\n","resetting env. episode 1051.000000, reward total was -20.000000. running mean: -20.106667\n","resetting env. episode 1052.000000, reward total was -21.000000. running mean: -20.115600\n","resetting env. episode 1053.000000, reward total was -20.000000. running mean: -20.114444\n","resetting env. episode 1054.000000, reward total was -21.000000. running mean: -20.123300\n","resetting env. episode 1055.000000, reward total was -20.000000. running mean: -20.122067\n","resetting env. episode 1056.000000, reward total was -19.000000. running mean: -20.110846\n","resetting env. episode 1057.000000, reward total was -21.000000. running mean: -20.119738\n","resetting env. episode 1058.000000, reward total was -21.000000. running mean: -20.128540\n","resetting env. episode 1059.000000, reward total was -19.000000. running mean: -20.117255\n","resetting env. episode 1060.000000, reward total was -19.000000. running mean: -20.106082\n","resetting env. episode 1061.000000, reward total was -20.000000. running mean: -20.105021\n","resetting env. episode 1062.000000, reward total was -20.000000. running mean: -20.103971\n","resetting env. episode 1063.000000, reward total was -20.000000. running mean: -20.102931\n","resetting env. episode 1064.000000, reward total was -19.000000. running mean: -20.091902\n","resetting env. episode 1065.000000, reward total was -21.000000. running mean: -20.100983\n","resetting env. episode 1066.000000, reward total was -21.000000. running mean: -20.109973\n","resetting env. episode 1067.000000, reward total was -20.000000. running mean: -20.108874\n","resetting env. episode 1068.000000, reward total was -17.000000. running mean: -20.077785\n","resetting env. episode 1069.000000, reward total was -21.000000. running mean: -20.087007\n","resetting env. episode 1070.000000, reward total was -21.000000. running mean: -20.096137\n","resetting env. episode 1071.000000, reward total was -19.000000. running mean: -20.085176\n","resetting env. episode 1072.000000, reward total was -20.000000. running mean: -20.084324\n","resetting env. episode 1073.000000, reward total was -20.000000. running mean: -20.083481\n","resetting env. episode 1074.000000, reward total was -20.000000. running mean: -20.082646\n","resetting env. episode 1075.000000, reward total was -20.000000. running mean: -20.081819\n","resetting env. episode 1076.000000, reward total was -19.000000. running mean: -20.071001\n","resetting env. episode 1077.000000, reward total was -21.000000. running mean: -20.080291\n","resetting env. episode 1078.000000, reward total was -21.000000. running mean: -20.089488\n","resetting env. episode 1079.000000, reward total was -21.000000. running mean: -20.098593\n","resetting env. episode 1080.000000, reward total was -20.000000. running mean: -20.097607\n","resetting env. episode 1081.000000, reward total was -21.000000. running mean: -20.106631\n","resetting env. episode 1082.000000, reward total was -21.000000. running mean: -20.115565\n","resetting env. episode 1083.000000, reward total was -20.000000. running mean: -20.114409\n","resetting env. episode 1084.000000, reward total was -20.000000. running mean: -20.113265\n","resetting env. episode 1085.000000, reward total was -19.000000. running mean: -20.102133\n","resetting env. episode 1086.000000, reward total was -21.000000. running mean: -20.111111\n","resetting env. episode 1087.000000, reward total was -20.000000. running mean: -20.110000\n","resetting env. episode 1088.000000, reward total was -21.000000. running mean: -20.118900\n","resetting env. episode 1089.000000, reward total was -21.000000. running mean: -20.127711\n","resetting env. episode 1090.000000, reward total was -21.000000. running mean: -20.136434\n","resetting env. episode 1091.000000, reward total was -18.000000. running mean: -20.115070\n","resetting env. episode 1092.000000, reward total was -19.000000. running mean: -20.103919\n","resetting env. episode 1093.000000, reward total was -21.000000. running mean: -20.112880\n","resetting env. episode 1094.000000, reward total was -20.000000. running mean: -20.111751\n","resetting env. episode 1095.000000, reward total was -20.000000. running mean: -20.110633\n","resetting env. episode 1096.000000, reward total was -20.000000. running mean: -20.109527\n","resetting env. episode 1097.000000, reward total was -20.000000. running mean: -20.108432\n","resetting env. episode 1098.000000, reward total was -21.000000. running mean: -20.117348\n","resetting env. episode 1099.000000, reward total was -20.000000. running mean: -20.116174\n","resetting env. episode 1100.000000, reward total was -21.000000. running mean: -20.125012\n","resetting env. episode 1101.000000, reward total was -20.000000. running mean: -20.123762\n","resetting env. episode 1102.000000, reward total was -21.000000. running mean: -20.132525\n","resetting env. episode 1103.000000, reward total was -18.000000. running mean: -20.111199\n","resetting env. episode 1104.000000, reward total was -21.000000. running mean: -20.120087\n","resetting env. episode 1105.000000, reward total was -21.000000. running mean: -20.128886\n","resetting env. episode 1106.000000, reward total was -21.000000. running mean: -20.137598\n","resetting env. episode 1107.000000, reward total was -20.000000. running mean: -20.136222\n","resetting env. episode 1108.000000, reward total was -21.000000. running mean: -20.144859\n","resetting env. episode 1109.000000, reward total was -21.000000. running mean: -20.153411\n","resetting env. episode 1110.000000, reward total was -21.000000. running mean: -20.161877\n","resetting env. episode 1111.000000, reward total was -20.000000. running mean: -20.160258\n","resetting env. episode 1112.000000, reward total was -21.000000. running mean: -20.168655\n","resetting env. episode 1113.000000, reward total was -21.000000. running mean: -20.176969\n","resetting env. episode 1114.000000, reward total was -20.000000. running mean: -20.175199\n","resetting env. episode 1115.000000, reward total was -21.000000. running mean: -20.183447\n","resetting env. episode 1116.000000, reward total was -20.000000. running mean: -20.181613\n","resetting env. episode 1117.000000, reward total was -19.000000. running mean: -20.169797\n","resetting env. episode 1118.000000, reward total was -21.000000. running mean: -20.178099\n","resetting env. episode 1119.000000, reward total was -21.000000. running mean: -20.186318\n","resetting env. episode 1120.000000, reward total was -21.000000. running mean: -20.194454\n","resetting env. episode 1121.000000, reward total was -20.000000. running mean: -20.192510\n","resetting env. episode 1122.000000, reward total was -21.000000. running mean: -20.200585\n","resetting env. episode 1123.000000, reward total was -20.000000. running mean: -20.198579\n","resetting env. episode 1124.000000, reward total was -20.000000. running mean: -20.196593\n","resetting env. episode 1125.000000, reward total was -19.000000. running mean: -20.184627\n","resetting env. episode 1126.000000, reward total was -21.000000. running mean: -20.192781\n","resetting env. episode 1127.000000, reward total was -21.000000. running mean: -20.200853\n","resetting env. episode 1128.000000, reward total was -21.000000. running mean: -20.208845\n","resetting env. episode 1129.000000, reward total was -21.000000. running mean: -20.216756\n","resetting env. episode 1130.000000, reward total was -21.000000. running mean: -20.224589\n","resetting env. episode 1131.000000, reward total was -21.000000. running mean: -20.232343\n","resetting env. episode 1132.000000, reward total was -21.000000. running mean: -20.240019\n","resetting env. episode 1133.000000, reward total was -21.000000. running mean: -20.247619\n","resetting env. episode 1134.000000, reward total was -21.000000. running mean: -20.255143\n","resetting env. episode 1135.000000, reward total was -21.000000. running mean: -20.262591\n","resetting env. episode 1136.000000, reward total was -20.000000. running mean: -20.259966\n","resetting env. episode 1137.000000, reward total was -19.000000. running mean: -20.247366\n","resetting env. episode 1138.000000, reward total was -20.000000. running mean: -20.244892\n","resetting env. episode 1139.000000, reward total was -20.000000. running mean: -20.242443\n","resetting env. episode 1140.000000, reward total was -20.000000. running mean: -20.240019\n","resetting env. episode 1141.000000, reward total was -21.000000. running mean: -20.247619\n","resetting env. episode 1142.000000, reward total was -21.000000. running mean: -20.255143\n","resetting env. episode 1143.000000, reward total was -20.000000. running mean: -20.252591\n","resetting env. episode 1144.000000, reward total was -19.000000. running mean: -20.240065\n","resetting env. episode 1145.000000, reward total was -21.000000. running mean: -20.247665\n","resetting env. episode 1146.000000, reward total was -19.000000. running mean: -20.235188\n","resetting env. episode 1147.000000, reward total was -20.000000. running mean: -20.232836\n","resetting env. episode 1148.000000, reward total was -21.000000. running mean: -20.240508\n","resetting env. episode 1149.000000, reward total was -21.000000. running mean: -20.248103\n","resetting env. episode 1150.000000, reward total was -21.000000. running mean: -20.255622\n","resetting env. episode 1151.000000, reward total was -21.000000. running mean: -20.263065\n","resetting env. episode 1152.000000, reward total was -19.000000. running mean: -20.250435\n","resetting env. episode 1153.000000, reward total was -21.000000. running mean: -20.257930\n","resetting env. episode 1154.000000, reward total was -19.000000. running mean: -20.245351\n","resetting env. episode 1155.000000, reward total was -21.000000. running mean: -20.252898\n","resetting env. episode 1156.000000, reward total was -19.000000. running mean: -20.240369\n","resetting env. episode 1157.000000, reward total was -20.000000. running mean: -20.237965\n","resetting env. episode 1158.000000, reward total was -20.000000. running mean: -20.235585\n","resetting env. episode 1159.000000, reward total was -20.000000. running mean: -20.233229\n","resetting env. episode 1160.000000, reward total was -20.000000. running mean: -20.230897\n","resetting env. episode 1161.000000, reward total was -19.000000. running mean: -20.218588\n","resetting env. episode 1162.000000, reward total was -20.000000. running mean: -20.216402\n","resetting env. episode 1163.000000, reward total was -21.000000. running mean: -20.224238\n","resetting env. episode 1164.000000, reward total was -21.000000. running mean: -20.231996\n","resetting env. episode 1165.000000, reward total was -19.000000. running mean: -20.219676\n","resetting env. episode 1166.000000, reward total was -19.000000. running mean: -20.207479\n","resetting env. episode 1167.000000, reward total was -20.000000. running mean: -20.205404\n","resetting env. episode 1168.000000, reward total was -21.000000. running mean: -20.213350\n","resetting env. episode 1169.000000, reward total was -20.000000. running mean: -20.211217\n","resetting env. episode 1170.000000, reward total was -21.000000. running mean: -20.219105\n","resetting env. episode 1171.000000, reward total was -20.000000. running mean: -20.216914\n","resetting env. episode 1172.000000, reward total was -20.000000. running mean: -20.214744\n","resetting env. episode 1173.000000, reward total was -20.000000. running mean: -20.212597\n","resetting env. episode 1174.000000, reward total was -20.000000. running mean: -20.210471\n","resetting env. episode 1175.000000, reward total was -19.000000. running mean: -20.198366\n","resetting env. episode 1176.000000, reward total was -21.000000. running mean: -20.206383\n","resetting env. episode 1177.000000, reward total was -21.000000. running mean: -20.214319\n","resetting env. episode 1178.000000, reward total was -18.000000. running mean: -20.192176\n","resetting env. episode 1179.000000, reward total was -21.000000. running mean: -20.200254\n","resetting env. episode 1180.000000, reward total was -21.000000. running mean: -20.208251\n","resetting env. episode 1181.000000, reward total was -21.000000. running mean: -20.216169\n","resetting env. episode 1182.000000, reward total was -20.000000. running mean: -20.214007\n","resetting env. episode 1183.000000, reward total was -20.000000. running mean: -20.211867\n","resetting env. episode 1184.000000, reward total was -20.000000. running mean: -20.209748\n","resetting env. episode 1185.000000, reward total was -21.000000. running mean: -20.217651\n","resetting env. episode 1186.000000, reward total was -19.000000. running mean: -20.205474\n","resetting env. episode 1187.000000, reward total was -21.000000. running mean: -20.213420\n","resetting env. episode 1188.000000, reward total was -21.000000. running mean: -20.221285\n","resetting env. episode 1189.000000, reward total was -21.000000. running mean: -20.229073\n","resetting env. episode 1190.000000, reward total was -20.000000. running mean: -20.226782\n","resetting env. episode 1191.000000, reward total was -21.000000. running mean: -20.234514\n","resetting env. episode 1192.000000, reward total was -21.000000. running mean: -20.242169\n","resetting env. episode 1193.000000, reward total was -20.000000. running mean: -20.239747\n","resetting env. episode 1194.000000, reward total was -18.000000. running mean: -20.217350\n","resetting env. episode 1195.000000, reward total was -21.000000. running mean: -20.225176\n","resetting env. episode 1196.000000, reward total was -20.000000. running mean: -20.222924\n","resetting env. episode 1197.000000, reward total was -21.000000. running mean: -20.230695\n","resetting env. episode 1198.000000, reward total was -20.000000. running mean: -20.228388\n","resetting env. episode 1199.000000, reward total was -21.000000. running mean: -20.236104\n","resetting env. episode 1200.000000, reward total was -19.000000. running mean: -20.223743\n","resetting env. episode 1201.000000, reward total was -21.000000. running mean: -20.231506\n","resetting env. episode 1202.000000, reward total was -21.000000. running mean: -20.239191\n","resetting env. episode 1203.000000, reward total was -20.000000. running mean: -20.236799\n","resetting env. episode 1204.000000, reward total was -21.000000. running mean: -20.244431\n","resetting env. episode 1205.000000, reward total was -20.000000. running mean: -20.241987\n","resetting env. episode 1206.000000, reward total was -19.000000. running mean: -20.229567\n","resetting env. episode 1207.000000, reward total was -20.000000. running mean: -20.227271\n","resetting env. episode 1208.000000, reward total was -19.000000. running mean: -20.214998\n","resetting env. episode 1209.000000, reward total was -20.000000. running mean: -20.212848\n","resetting env. episode 1210.000000, reward total was -19.000000. running mean: -20.200720\n","resetting env. episode 1211.000000, reward total was -20.000000. running mean: -20.198713\n","resetting env. episode 1212.000000, reward total was -19.000000. running mean: -20.186726\n","resetting env. episode 1213.000000, reward total was -20.000000. running mean: -20.184858\n","resetting env. episode 1214.000000, reward total was -19.000000. running mean: -20.173010\n","resetting env. episode 1215.000000, reward total was -20.000000. running mean: -20.171280\n","resetting env. episode 1216.000000, reward total was -21.000000. running mean: -20.179567\n","resetting env. episode 1217.000000, reward total was -20.000000. running mean: -20.177771\n","resetting env. episode 1218.000000, reward total was -19.000000. running mean: -20.165993\n","resetting env. episode 1219.000000, reward total was -21.000000. running mean: -20.174334\n","resetting env. episode 1220.000000, reward total was -20.000000. running mean: -20.172590\n","resetting env. episode 1221.000000, reward total was -20.000000. running mean: -20.170864\n","resetting env. episode 1222.000000, reward total was -20.000000. running mean: -20.169156\n","resetting env. episode 1223.000000, reward total was -21.000000. running mean: -20.177464\n","resetting env. episode 1224.000000, reward total was -20.000000. running mean: -20.175689\n","resetting env. episode 1225.000000, reward total was -21.000000. running mean: -20.183933\n","resetting env. episode 1226.000000, reward total was -21.000000. running mean: -20.192093\n","resetting env. episode 1227.000000, reward total was -20.000000. running mean: -20.190172\n","resetting env. episode 1228.000000, reward total was -21.000000. running mean: -20.198271\n","resetting env. episode 1229.000000, reward total was -20.000000. running mean: -20.196288\n","resetting env. episode 1230.000000, reward total was -19.000000. running mean: -20.184325\n","resetting env. episode 1231.000000, reward total was -19.000000. running mean: -20.172482\n","resetting env. episode 1232.000000, reward total was -21.000000. running mean: -20.180757\n","resetting env. episode 1233.000000, reward total was -19.000000. running mean: -20.168949\n","resetting env. episode 1234.000000, reward total was -20.000000. running mean: -20.167260\n","resetting env. episode 1235.000000, reward total was -19.000000. running mean: -20.155587\n","resetting env. episode 1236.000000, reward total was -21.000000. running mean: -20.164031\n","resetting env. episode 1237.000000, reward total was -20.000000. running mean: -20.162391\n","resetting env. episode 1238.000000, reward total was -20.000000. running mean: -20.160767\n","resetting env. episode 1239.000000, reward total was -21.000000. running mean: -20.169160\n","resetting env. episode 1240.000000, reward total was -20.000000. running mean: -20.167468\n","resetting env. episode 1241.000000, reward total was -20.000000. running mean: -20.165793\n","resetting env. episode 1242.000000, reward total was -19.000000. running mean: -20.154135\n","resetting env. episode 1243.000000, reward total was -21.000000. running mean: -20.162594\n","resetting env. episode 1244.000000, reward total was -21.000000. running mean: -20.170968\n","resetting env. episode 1245.000000, reward total was -20.000000. running mean: -20.169258\n","resetting env. episode 1246.000000, reward total was -21.000000. running mean: -20.177566\n","resetting env. episode 1247.000000, reward total was -20.000000. running mean: -20.175790\n","resetting env. episode 1248.000000, reward total was -19.000000. running mean: -20.164032\n","resetting env. episode 1249.000000, reward total was -21.000000. running mean: -20.172392\n","resetting env. episode 1250.000000, reward total was -21.000000. running mean: -20.180668\n","resetting env. episode 1251.000000, reward total was -21.000000. running mean: -20.188861\n","resetting env. episode 1252.000000, reward total was -21.000000. running mean: -20.196973\n","resetting env. episode 1253.000000, reward total was -18.000000. running mean: -20.175003\n","resetting env. episode 1254.000000, reward total was -21.000000. running mean: -20.183253\n","resetting env. episode 1255.000000, reward total was -21.000000. running mean: -20.191420\n","resetting env. episode 1256.000000, reward total was -18.000000. running mean: -20.169506\n","resetting env. episode 1257.000000, reward total was -20.000000. running mean: -20.167811\n","resetting env. episode 1258.000000, reward total was -19.000000. running mean: -20.156133\n","resetting env. episode 1259.000000, reward total was -21.000000. running mean: -20.164572\n","resetting env. episode 1260.000000, reward total was -20.000000. running mean: -20.162926\n","resetting env. episode 1261.000000, reward total was -20.000000. running mean: -20.161297\n","resetting env. episode 1262.000000, reward total was -20.000000. running mean: -20.159684\n","resetting env. episode 1263.000000, reward total was -21.000000. running mean: -20.168087\n","resetting env. episode 1264.000000, reward total was -20.000000. running mean: -20.166406\n","resetting env. episode 1265.000000, reward total was -21.000000. running mean: -20.174742\n","resetting env. episode 1266.000000, reward total was -21.000000. running mean: -20.182995\n","resetting env. episode 1267.000000, reward total was -21.000000. running mean: -20.191165\n","resetting env. episode 1268.000000, reward total was -21.000000. running mean: -20.199253\n","resetting env. episode 1269.000000, reward total was -20.000000. running mean: -20.197260\n","resetting env. episode 1270.000000, reward total was -21.000000. running mean: -20.205288\n","resetting env. episode 1271.000000, reward total was -21.000000. running mean: -20.213235\n","resetting env. episode 1272.000000, reward total was -18.000000. running mean: -20.191103\n","resetting env. episode 1273.000000, reward total was -21.000000. running mean: -20.199192\n","resetting env. episode 1274.000000, reward total was -21.000000. running mean: -20.207200\n","resetting env. episode 1275.000000, reward total was -19.000000. running mean: -20.195128\n","resetting env. episode 1276.000000, reward total was -21.000000. running mean: -20.203176\n","resetting env. episode 1277.000000, reward total was -20.000000. running mean: -20.201145\n","resetting env. episode 1278.000000, reward total was -21.000000. running mean: -20.209133\n","resetting env. episode 1279.000000, reward total was -21.000000. running mean: -20.217042\n","resetting env. episode 1280.000000, reward total was -21.000000. running mean: -20.224871\n","resetting env. episode 1281.000000, reward total was -21.000000. running mean: -20.232623\n","resetting env. episode 1282.000000, reward total was -21.000000. running mean: -20.240296\n","resetting env. episode 1283.000000, reward total was -21.000000. running mean: -20.247894\n","resetting env. episode 1284.000000, reward total was -21.000000. running mean: -20.255415\n","resetting env. episode 1285.000000, reward total was -19.000000. running mean: -20.242860\n","resetting env. episode 1286.000000, reward total was -21.000000. running mean: -20.250432\n","resetting env. episode 1287.000000, reward total was -20.000000. running mean: -20.247928\n","resetting env. episode 1288.000000, reward total was -21.000000. running mean: -20.255448\n","resetting env. episode 1289.000000, reward total was -21.000000. running mean: -20.262894\n","resetting env. episode 1290.000000, reward total was -21.000000. running mean: -20.270265\n","resetting env. episode 1291.000000, reward total was -20.000000. running mean: -20.267562\n","resetting env. episode 1292.000000, reward total was -19.000000. running mean: -20.254887\n","resetting env. episode 1293.000000, reward total was -19.000000. running mean: -20.242338\n","resetting env. episode 1294.000000, reward total was -21.000000. running mean: -20.249914\n","resetting env. episode 1295.000000, reward total was -20.000000. running mean: -20.247415\n","resetting env. episode 1296.000000, reward total was -21.000000. running mean: -20.254941\n","resetting env. episode 1297.000000, reward total was -20.000000. running mean: -20.252392\n","resetting env. episode 1298.000000, reward total was -18.000000. running mean: -20.229868\n","resetting env. episode 1299.000000, reward total was -20.000000. running mean: -20.227569\n","resetting env. episode 1300.000000, reward total was -20.000000. running mean: -20.225293\n","resetting env. episode 1301.000000, reward total was -20.000000. running mean: -20.223040\n","resetting env. episode 1302.000000, reward total was -21.000000. running mean: -20.230810\n","resetting env. episode 1303.000000, reward total was -20.000000. running mean: -20.228502\n","resetting env. episode 1304.000000, reward total was -20.000000. running mean: -20.226217\n","resetting env. episode 1305.000000, reward total was -21.000000. running mean: -20.233955\n","resetting env. episode 1306.000000, reward total was -20.000000. running mean: -20.231615\n","resetting env. episode 1307.000000, reward total was -21.000000. running mean: -20.239299\n","resetting env. episode 1308.000000, reward total was -19.000000. running mean: -20.226906\n","resetting env. episode 1309.000000, reward total was -21.000000. running mean: -20.234637\n","resetting env. episode 1310.000000, reward total was -20.000000. running mean: -20.232291\n","resetting env. episode 1311.000000, reward total was -20.000000. running mean: -20.229968\n","resetting env. episode 1312.000000, reward total was -21.000000. running mean: -20.237668\n","resetting env. episode 1313.000000, reward total was -20.000000. running mean: -20.235291\n","resetting env. episode 1314.000000, reward total was -21.000000. running mean: -20.242938\n","resetting env. episode 1315.000000, reward total was -20.000000. running mean: -20.240509\n","resetting env. episode 1316.000000, reward total was -21.000000. running mean: -20.248104\n","resetting env. episode 1317.000000, reward total was -20.000000. running mean: -20.245623\n","resetting env. episode 1318.000000, reward total was -20.000000. running mean: -20.243167\n","resetting env. episode 1319.000000, reward total was -19.000000. running mean: -20.230735\n","resetting env. episode 1320.000000, reward total was -18.000000. running mean: -20.208428\n","resetting env. episode 1321.000000, reward total was -20.000000. running mean: -20.206343\n","resetting env. episode 1322.000000, reward total was -19.000000. running mean: -20.194280\n","resetting env. episode 1323.000000, reward total was -20.000000. running mean: -20.192337\n","resetting env. episode 1324.000000, reward total was -21.000000. running mean: -20.200414\n","resetting env. episode 1325.000000, reward total was -21.000000. running mean: -20.208410\n","resetting env. episode 1326.000000, reward total was -21.000000. running mean: -20.216326\n","resetting env. episode 1327.000000, reward total was -18.000000. running mean: -20.194162\n","resetting env. episode 1328.000000, reward total was -21.000000. running mean: -20.202221\n","resetting env. episode 1329.000000, reward total was -21.000000. running mean: -20.210198\n","resetting env. episode 1330.000000, reward total was -21.000000. running mean: -20.218096\n","resetting env. episode 1331.000000, reward total was -20.000000. running mean: -20.215915\n","resetting env. episode 1332.000000, reward total was -21.000000. running mean: -20.223756\n","resetting env. episode 1333.000000, reward total was -21.000000. running mean: -20.231519\n","resetting env. episode 1334.000000, reward total was -21.000000. running mean: -20.239204\n","resetting env. episode 1335.000000, reward total was -21.000000. running mean: -20.246812\n","resetting env. episode 1336.000000, reward total was -21.000000. running mean: -20.254343\n","resetting env. episode 1337.000000, reward total was -21.000000. running mean: -20.261800\n","resetting env. episode 1338.000000, reward total was -21.000000. running mean: -20.269182\n","resetting env. episode 1339.000000, reward total was -20.000000. running mean: -20.266490\n","resetting env. episode 1340.000000, reward total was -20.000000. running mean: -20.263825\n","resetting env. episode 1341.000000, reward total was -21.000000. running mean: -20.271187\n","resetting env. episode 1342.000000, reward total was -21.000000. running mean: -20.278475\n","resetting env. episode 1343.000000, reward total was -21.000000. running mean: -20.285690\n","resetting env. episode 1344.000000, reward total was -19.000000. running mean: -20.272833\n","resetting env. episode 1345.000000, reward total was -20.000000. running mean: -20.270105\n","resetting env. episode 1346.000000, reward total was -21.000000. running mean: -20.277404\n","resetting env. episode 1347.000000, reward total was -20.000000. running mean: -20.274630\n","resetting env. episode 1348.000000, reward total was -20.000000. running mean: -20.271884\n","resetting env. episode 1349.000000, reward total was -21.000000. running mean: -20.279165\n","resetting env. episode 1350.000000, reward total was -17.000000. running mean: -20.246373\n","resetting env. episode 1351.000000, reward total was -19.000000. running mean: -20.233910\n","resetting env. episode 1352.000000, reward total was -21.000000. running mean: -20.241570\n","resetting env. episode 1353.000000, reward total was -20.000000. running mean: -20.239155\n","resetting env. episode 1354.000000, reward total was -20.000000. running mean: -20.236763\n","resetting env. episode 1355.000000, reward total was -21.000000. running mean: -20.244396\n","resetting env. episode 1356.000000, reward total was -21.000000. running mean: -20.251952\n","resetting env. episode 1357.000000, reward total was -21.000000. running mean: -20.259432\n","resetting env. episode 1358.000000, reward total was -19.000000. running mean: -20.246838\n","resetting env. episode 1359.000000, reward total was -18.000000. running mean: -20.224369\n","resetting env. episode 1360.000000, reward total was -21.000000. running mean: -20.232126\n","resetting env. episode 1361.000000, reward total was -21.000000. running mean: -20.239804\n","resetting env. episode 1362.000000, reward total was -20.000000. running mean: -20.237406\n","resetting env. episode 1363.000000, reward total was -19.000000. running mean: -20.225032\n","resetting env. episode 1364.000000, reward total was -20.000000. running mean: -20.222782\n","resetting env. episode 1365.000000, reward total was -19.000000. running mean: -20.210554\n","resetting env. episode 1366.000000, reward total was -21.000000. running mean: -20.218449\n","resetting env. episode 1367.000000, reward total was -20.000000. running mean: -20.216264\n","resetting env. episode 1368.000000, reward total was -21.000000. running mean: -20.224102\n","resetting env. episode 1369.000000, reward total was -21.000000. running mean: -20.231861\n","resetting env. episode 1370.000000, reward total was -20.000000. running mean: -20.229542\n","resetting env. episode 1371.000000, reward total was -20.000000. running mean: -20.227246\n","resetting env. episode 1372.000000, reward total was -21.000000. running mean: -20.234974\n","resetting env. episode 1373.000000, reward total was -19.000000. running mean: -20.222624\n","resetting env. episode 1374.000000, reward total was -21.000000. running mean: -20.230398\n","resetting env. episode 1375.000000, reward total was -20.000000. running mean: -20.228094\n","resetting env. episode 1376.000000, reward total was -21.000000. running mean: -20.235813\n","resetting env. episode 1377.000000, reward total was -19.000000. running mean: -20.223455\n","resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.231220\n","resetting env. episode 1379.000000, reward total was -19.000000. running mean: -20.218908\n","resetting env. episode 1380.000000, reward total was -21.000000. running mean: -20.226719\n","resetting env. episode 1381.000000, reward total was -21.000000. running mean: -20.234452\n","resetting env. episode 1382.000000, reward total was -21.000000. running mean: -20.242107\n","resetting env. episode 1383.000000, reward total was -19.000000. running mean: -20.229686\n","resetting env. episode 1384.000000, reward total was -19.000000. running mean: -20.217389\n","resetting env. episode 1385.000000, reward total was -20.000000. running mean: -20.215216\n","resetting env. episode 1386.000000, reward total was -21.000000. running mean: -20.223063\n","resetting env. episode 1387.000000, reward total was -21.000000. running mean: -20.230833\n","resetting env. episode 1388.000000, reward total was -20.000000. running mean: -20.228524\n","resetting env. episode 1389.000000, reward total was -19.000000. running mean: -20.216239\n","resetting env. episode 1390.000000, reward total was -20.000000. running mean: -20.214077\n","resetting env. episode 1391.000000, reward total was -21.000000. running mean: -20.221936\n","resetting env. episode 1392.000000, reward total was -21.000000. running mean: -20.229717\n","resetting env. episode 1393.000000, reward total was -21.000000. running mean: -20.237420\n","resetting env. episode 1394.000000, reward total was -20.000000. running mean: -20.235045\n","resetting env. episode 1395.000000, reward total was -20.000000. running mean: -20.232695\n","resetting env. episode 1396.000000, reward total was -21.000000. running mean: -20.240368\n","resetting env. episode 1397.000000, reward total was -21.000000. running mean: -20.247964\n","resetting env. episode 1398.000000, reward total was -21.000000. running mean: -20.255485\n","resetting env. episode 1399.000000, reward total was -17.000000. running mean: -20.222930\n","resetting env. episode 1400.000000, reward total was -21.000000. running mean: -20.230700\n","resetting env. episode 1401.000000, reward total was -21.000000. running mean: -20.238393\n","resetting env. episode 1402.000000, reward total was -21.000000. running mean: -20.246010\n","resetting env. episode 1403.000000, reward total was -20.000000. running mean: -20.243549\n","resetting env. episode 1404.000000, reward total was -20.000000. running mean: -20.241114\n","resetting env. episode 1405.000000, reward total was -21.000000. running mean: -20.248703\n","resetting env. episode 1406.000000, reward total was -20.000000. running mean: -20.246216\n","resetting env. episode 1407.000000, reward total was -21.000000. running mean: -20.253754\n","resetting env. episode 1408.000000, reward total was -21.000000. running mean: -20.261216\n","resetting env. episode 1409.000000, reward total was -21.000000. running mean: -20.268604\n","resetting env. episode 1410.000000, reward total was -20.000000. running mean: -20.265918\n","resetting env. episode 1411.000000, reward total was -21.000000. running mean: -20.273259\n","resetting env. episode 1412.000000, reward total was -19.000000. running mean: -20.260526\n","resetting env. episode 1413.000000, reward total was -21.000000. running mean: -20.267921\n","resetting env. episode 1414.000000, reward total was -19.000000. running mean: -20.255242\n","resetting env. episode 1415.000000, reward total was -20.000000. running mean: -20.252689\n","resetting env. episode 1416.000000, reward total was -21.000000. running mean: -20.260162\n","resetting env. episode 1417.000000, reward total was -20.000000. running mean: -20.257561\n","resetting env. episode 1418.000000, reward total was -20.000000. running mean: -20.254985\n","resetting env. episode 1419.000000, reward total was -21.000000. running mean: -20.262435\n","resetting env. episode 1420.000000, reward total was -20.000000. running mean: -20.259811\n","resetting env. episode 1421.000000, reward total was -20.000000. running mean: -20.257213\n","resetting env. episode 1422.000000, reward total was -21.000000. running mean: -20.264641\n","resetting env. episode 1423.000000, reward total was -21.000000. running mean: -20.271994\n","resetting env. episode 1424.000000, reward total was -21.000000. running mean: -20.279274\n","resetting env. episode 1425.000000, reward total was -21.000000. running mean: -20.286482\n","resetting env. episode 1426.000000, reward total was -21.000000. running mean: -20.293617\n","resetting env. episode 1427.000000, reward total was -17.000000. running mean: -20.260681\n","resetting env. episode 1428.000000, reward total was -20.000000. running mean: -20.258074\n","resetting env. episode 1429.000000, reward total was -21.000000. running mean: -20.265493\n","resetting env. episode 1430.000000, reward total was -21.000000. running mean: -20.272838\n","resetting env. episode 1431.000000, reward total was -21.000000. running mean: -20.280110\n","resetting env. episode 1432.000000, reward total was -21.000000. running mean: -20.287309\n","resetting env. episode 1433.000000, reward total was -19.000000. running mean: -20.274436\n","resetting env. episode 1434.000000, reward total was -21.000000. running mean: -20.281691\n","resetting env. episode 1435.000000, reward total was -21.000000. running mean: -20.288874\n","resetting env. episode 1436.000000, reward total was -21.000000. running mean: -20.295986\n","resetting env. episode 1437.000000, reward total was -20.000000. running mean: -20.293026\n","resetting env. episode 1438.000000, reward total was -20.000000. running mean: -20.290095\n","resetting env. episode 1439.000000, reward total was -19.000000. running mean: -20.277194\n","resetting env. episode 1440.000000, reward total was -20.000000. running mean: -20.274423\n","resetting env. episode 1441.000000, reward total was -20.000000. running mean: -20.271678\n","resetting env. episode 1442.000000, reward total was -21.000000. running mean: -20.278962\n","resetting env. episode 1443.000000, reward total was -20.000000. running mean: -20.276172\n","resetting env. episode 1444.000000, reward total was -21.000000. running mean: -20.283410\n","resetting env. episode 1445.000000, reward total was -21.000000. running mean: -20.290576\n","resetting env. episode 1446.000000, reward total was -21.000000. running mean: -20.297670\n","resetting env. episode 1447.000000, reward total was -20.000000. running mean: -20.294694\n","resetting env. episode 1448.000000, reward total was -20.000000. running mean: -20.291747\n","resetting env. episode 1449.000000, reward total was -20.000000. running mean: -20.288829\n","resetting env. episode 1450.000000, reward total was -20.000000. running mean: -20.285941\n","resetting env. episode 1451.000000, reward total was -20.000000. running mean: -20.283082\n","resetting env. episode 1452.000000, reward total was -20.000000. running mean: -20.280251\n","resetting env. episode 1453.000000, reward total was -20.000000. running mean: -20.277448\n","resetting env. episode 1454.000000, reward total was -21.000000. running mean: -20.284674\n","resetting env. episode 1455.000000, reward total was -19.000000. running mean: -20.271827\n","resetting env. episode 1456.000000, reward total was -21.000000. running mean: -20.279109\n","resetting env. episode 1457.000000, reward total was -21.000000. running mean: -20.286318\n","resetting env. episode 1458.000000, reward total was -19.000000. running mean: -20.273454\n","resetting env. episode 1459.000000, reward total was -21.000000. running mean: -20.280720\n","resetting env. episode 1460.000000, reward total was -20.000000. running mean: -20.277913\n","resetting env. episode 1461.000000, reward total was -18.000000. running mean: -20.255134\n","resetting env. episode 1462.000000, reward total was -20.000000. running mean: -20.252582\n","resetting env. episode 1463.000000, reward total was -21.000000. running mean: -20.260056\n","resetting env. episode 1464.000000, reward total was -21.000000. running mean: -20.267456\n","resetting env. episode 1465.000000, reward total was -20.000000. running mean: -20.264781\n","resetting env. episode 1466.000000, reward total was -21.000000. running mean: -20.272133\n","resetting env. episode 1467.000000, reward total was -21.000000. running mean: -20.279412\n","resetting env. episode 1468.000000, reward total was -20.000000. running mean: -20.276618\n","resetting env. episode 1469.000000, reward total was -19.000000. running mean: -20.263852\n","resetting env. episode 1470.000000, reward total was -20.000000. running mean: -20.261213\n","resetting env. episode 1471.000000, reward total was -21.000000. running mean: -20.268601\n","resetting env. episode 1472.000000, reward total was -21.000000. running mean: -20.275915\n","resetting env. episode 1473.000000, reward total was -21.000000. running mean: -20.283156\n","resetting env. episode 1474.000000, reward total was -20.000000. running mean: -20.280324\n","resetting env. episode 1475.000000, reward total was -21.000000. running mean: -20.287521\n","resetting env. episode 1476.000000, reward total was -21.000000. running mean: -20.294646\n","resetting env. episode 1477.000000, reward total was -20.000000. running mean: -20.291700\n","resetting env. episode 1478.000000, reward total was -21.000000. running mean: -20.298783\n","resetting env. episode 1479.000000, reward total was -21.000000. running mean: -20.305795\n","resetting env. episode 1480.000000, reward total was -21.000000. running mean: -20.312737\n","resetting env. episode 1481.000000, reward total was -21.000000. running mean: -20.319609\n","resetting env. episode 1482.000000, reward total was -20.000000. running mean: -20.316413\n","resetting env. episode 1483.000000, reward total was -21.000000. running mean: -20.323249\n","resetting env. episode 1484.000000, reward total was -20.000000. running mean: -20.320017\n","resetting env. episode 1485.000000, reward total was -20.000000. running mean: -20.316817\n","resetting env. episode 1486.000000, reward total was -18.000000. running mean: -20.293648\n","resetting env. episode 1487.000000, reward total was -19.000000. running mean: -20.280712\n","resetting env. episode 1488.000000, reward total was -19.000000. running mean: -20.267905\n","resetting env. episode 1489.000000, reward total was -21.000000. running mean: -20.275226\n","resetting env. episode 1490.000000, reward total was -20.000000. running mean: -20.272473\n","resetting env. episode 1491.000000, reward total was -19.000000. running mean: -20.259749\n","resetting env. episode 1492.000000, reward total was -19.000000. running mean: -20.247151\n","resetting env. episode 1493.000000, reward total was -21.000000. running mean: -20.254680\n","resetting env. episode 1494.000000, reward total was -19.000000. running mean: -20.242133\n","resetting env. episode 1495.000000, reward total was -21.000000. running mean: -20.249712\n","resetting env. episode 1496.000000, reward total was -20.000000. running mean: -20.247214\n","resetting env. episode 1497.000000, reward total was -21.000000. running mean: -20.254742\n","resetting env. episode 1498.000000, reward total was -20.000000. running mean: -20.252195\n","resetting env. episode 1499.000000, reward total was -21.000000. running mean: -20.259673\n","resetting env. episode 1500.000000, reward total was -20.000000. running mean: -20.257076\n","CPU times: user 1h 21min 21s, sys: 38min, total: 1h 59min 22s\n","Wall time: 1h 1min 57s\n"]}]},{"metadata":{"id":"w2NblmwDsL3y","outputId":"a6468f92-31d2-4d8b-ef2c-07c9fbea7839","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"ok","timestamp":1660629331612,"user_tz":-330,"elapsed":42314,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -8.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAQ4AAAFZCAYAAABpOsHqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAWJQAAFiUBSVIk8AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAG8klEQVR4nO3dzW5dVxmA4XUSQxI7idM4cVVTCL8tUicgOu2ICeVOGKBeBVMkuAxuoLfAqCAkBFJRI6JIbord/DiJE1J0GFWiOS31e+J0n9TPM1zS3voyebXXklfObD6fD4Di1NQDAC8e4QAy4QAy4QAy4QAy4QAy4QAy4QAy4QAy4QAy4QAy4QAy4QCytWUf/MUPzx35Wu2p2RhvXTsz1r+x+p3aurQ5Ns9feOb33Htwf+zdvnMME3Hc7l67Mh688tIzv2f91t1x6fpHxzDRdN559+PZMs8tHY63f3Ru2UdX2talS+Pazs4zv+fmh7eEY0Xd/e72+Ohn33vm91z5yz9f+HAsa/U/AYCVIxxAJhxAJhxAtvTh6Elz5+Bg3Du4v7B+4fzGeOnixQkm4rht7N4eG7uLB9oPX94c9791eYKJVpdwHNH+7Tvjg5s3F9av7ewIx9fE5vV/jZ0/vr+w/uGb3xeOp9iqAJlwAJlwAJlwAJnD0SO6sLE+Xrl6dWH94vmNCaaBaQnHEW1vbY3tra2px4CVYKsCZMIBZMIBZMIBZA5Hj+j+w4fjweHhwvrG2XPj/Mb6BBPBdITjiG7t7X/hXZXXNq5NMBFMx1YFyIQDyIQDyIQDyByOHtG5s2fG5c3NhfX1s2cnmIbn4fHm+rj3ncVrBY8uuY/0NOE4op3t7bGzvT31GDxH+2+8OvbfeHXqMV4ItipAJhxAJhxAJhxA5nD0KY8e/3vcPTh45vccPn50DNPwPJw5OPzc30/J77m7eHfppBCOp9zY3R03dnenHoPnaPu962P7vetTj/FCEw5OnNnUA3wNOOMAMuEAsqW3Km/9+vfHOQfwApnN5/OlHtzf31/uQWBlbG1tLXXkY6sCZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZMIBZEtfq//zH357nHMAE/j5r36z1HNLX6v/3duXXauHF9w7737sWj3w1RAOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIFubeoAvsrZ2epyazRbWn3zynzGfzyeYCPjUyobjJ6//eFzYWF9Y/9Pf/j7uHBxMMBHwqZUNx+nTp8ba2mfHm8/nY/Y5XyHAV8sZB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5AJB5Ct7P9yPh/D76fAilrZcPz1/X+MU6cWP4geHh5OMA3wv1Y2HA8EAlaWMw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gEw4gW5t6ADjpnqx/cxx8e2th/fThk3Hxxt6YTTDTlxEOmNjh1oXxwS9/Osbss4nY2L0zLt7Ym2iq/89WBciEA8iEA8iEA8iEA8iEA8iEA8iEA8iEA8iEA8iW/pPzq6+9eZxzwIm18fLF8cn5Hyysn718f2y//niM+QRDfYnZfL7cVHt7eyv4zwGKK1euLHWHbukvjtlsFe/sAV8FZxxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAJhxAtvTvqgAnly8OIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIBMOIPsvVHOuS2ryN7oAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]}]}