{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"200N-3LR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"cWACPRL869I4","executionInfo":{"status":"ok","timestamp":1660738367112,"user_tz":-330,"elapsed":6407,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install gym >/dev/null"],"execution_count":1,"outputs":[]},{"metadata":{"id":"2Os6feRY6ec_","executionInfo":{"status":"ok","timestamp":1660738372346,"user_tz":-330,"elapsed":5244,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install JSAnimation >/dev/null"],"execution_count":2,"outputs":[]},{"metadata":{"id":"wotUOa_e6edP","executionInfo":{"status":"ok","timestamp":1660738372346,"user_tz":-330,"elapsed":10,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%matplotlib inline\n","from JSAnimation.IPython_display import display_animation\n","from matplotlib import animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","\n","def display_frames_as_gif(frames):\n","    \"\"\"\n","    Displays a list of frames as a gif, with controls\n","    \"\"\"\n","    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","\n","    def animate(i):\n","        patch.set_data(frames[i])\n","\n","    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n","    HTML(anim.to_jshtml())"],"execution_count":3,"outputs":[]},{"metadata":{"id":"R66_INeZ9nYX"},"cell_type":"markdown","source":["## Step 2: Playing Pong"]},{"cell_type":"code","source":["%pip install -U gym>=0.21.0\n","%pip install -U gym[atari,accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ngMhg3fB9aA","outputId":"8a9915a6-bd5d-4fea-8d39-fedd79f62831","executionInfo":{"status":"ok","timestamp":1660738405543,"user_tz":-330,"elapsed":33205,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 9.1 MB/s \n","\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=b5f4e7c2ce8577635c257a09c3fbf4faf97b23aae715656ff62ec415a6cef231\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"]}]},{"metadata":{"id":"MtT2GyK_6edc","outputId":"4308efec-e1b7-4576-d5e4-40c45855c4cb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660738406655,"user_tz":-330,"elapsed":1128,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import gym\n","env = gym.make('Pong-v0')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  f\"The environment {id} is out of date. You should consider \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}]},{"metadata":{"id":"oRE6WmXQJ1Z0","outputId":"98070ae3-15e7-4bc8-8c67-981ca83206f3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660738406656,"user_tz":-330,"elapsed":16,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.action_space"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(6)"]},"metadata":{},"execution_count":6}]},{"metadata":{"id":"yl_9d4HFJ31W","outputId":"3b5bf887-fa5c-4429-de92-e734a2df7aee","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660738406656,"user_tz":-330,"elapsed":11,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.observation_space"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box(0, 255, (210, 160, 3), uint8)"]},"metadata":{},"execution_count":7}]},{"metadata":{"id":"trwRXI-h6eeI","outputId":"bc9faf7d-83f5-4fad-8916-4dd526579ee5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660738407352,"user_tz":-330,"elapsed":704,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# Run a demo of the environment\n","observation = env.reset()\n","cumulated_reward = 0\n","\n","frames = []\n","for t in range(1000):\n","#     print(observation)\n","    frames.append(env.render(mode = 'rgb_array'))\n","    # very stupid agent, just makes a random action within the allowd action space\n","    action = env.action_space.sample()\n","#     print(\"Action: {}\".format(t+1))    \n","    observation, reward, done, info = env.step(action)\n","#     print(reward)\n","    cumulated_reward += reward\n","    if done:\n","        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","        break\n","print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","\n","env.close()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -19.0\n"]}]},{"metadata":{"id":"3zZTecVWLLes","executionInfo":{"status":"ok","timestamp":1660738407353,"user_tz":-330,"elapsed":10,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["def sigmoid(x): \n","  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n","\n","def prepro(I):\n","  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n","  I = I[35:195] # crop\n","  I = I[::2,::2,0] # downsample by factor of 2\n","  I[I == 144] = 0 # erase background (background type 1)\n","  I[I == 109] = 0 # erase background (background type 2)\n","  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n","  return I.astype(np.float).ravel()\n","\n","def policy_forward(x):\n","  h = np.dot(model['W1'], x)\n","  h[h<0] = 0 # ReLU nonlinearity\n","  logp = np.dot(model['W2'], h)\n","  p = sigmoid(logp)\n","  return p, h # return probability of taking action 2, and hidden state\n","\n","def model_step(model, observation, prev_x):\n","  # preprocess the observation, set input to network to be difference image\n","  cur_x = prepro(observation)\n","  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","  prev_x = cur_x\n","  \n","  # forward the policy network and sample an action from the returned probability\n","  aprob, _ = policy_forward(x)\n","  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n","  \n","  return action, prev_x\n","\n","def play_game(env, model):\n","  observation = env.reset()\n","\n","  frames = []\n","  cumulated_reward = 0\n","\n","  prev_x = None # used in computing the difference frame\n","\n","  for t in range(1000):\n","      frames.append(env.render(mode = 'rgb_array'))\n","      action, prev_x = model_step(model, observation, prev_x)\n","      observation, reward, done, info = env.step(action)\n","      cumulated_reward += reward\n","      if done:\n","          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","          break\n","  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","  display_frames_as_gif(frames)\n","  env.close()"],"execution_count":9,"outputs":[]},{"metadata":{"id":"6gWvZQ7AQLQt"},"cell_type":"markdown","source":["## Step 3: Policy Gradient from Scratch"]},{"metadata":{"id":"eqFm7hqcItWl","executionInfo":{"status":"ok","timestamp":1660738407353,"user_tz":-330,"elapsed":9,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import numpy as np\n","\n","# model initialization\n","H = 200 # number of hidden layer neurons\n","D = 80 * 80 # input dimensionality: 80x80 grid\n","model = {}\n","model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n","model['W2'] = np.random.randn(H) / np.sqrt(H)\n","\n","# import pickle\n","# model = pickle.load(open('model.pkl', 'rb'))"],"execution_count":10,"outputs":[]},{"metadata":{"id":"TwjiwKisQM19","executionInfo":{"status":"ok","timestamp":1660738407354,"user_tz":-330,"elapsed":10,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# hyperparameters\n","batch_size = 10 # every how many episodes to do a param update?\n","# learning_rate = 1e-3\n","learning_rate = 1e-3\n"," \n","gamma = 0.99 # discount factor for reward\n","decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n","  \n","grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n","rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n","\n","def discount_rewards(r):\n","  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n","  discounted_r = np.zeros_like(r, dtype=np.float32)\n","  running_add = 0\n","  for t in reversed(range(0, r.size)):\n","    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n","    running_add = running_add * gamma + r[t]\n","    discounted_r[t] = running_add\n","  return discounted_r\n","\n","def policy_backward(epx, eph, epdlogp):\n","  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n","  dW2 = np.dot(eph.T, epdlogp).ravel()\n","  dh = np.outer(epdlogp, model['W2'])\n","  dh[eph <= 0] = 0 # backpro prelu\n","  dW1 = np.dot(dh.T, epx)\n","  return {'W1':dW1, 'W2':dW2}\n","\n","def train_model(env, model, total_episodes = 100):\n","  hist = []\n","  observation = env.reset()\n","\n","  prev_x = None # used in computing the difference frame\n","  xs,hs,dlogps,drs = [],[],[],[]\n","  running_reward = None\n","  reward_sum = 0\n","  episode_number = 0\n","\n","  while True:\n","    # preprocess the observation, set input to network to be difference image\n","    cur_x = prepro(observation)\n","    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","    prev_x = cur_x\n","\n","    # forward the policy network and sample an action from the returned probability\n","    aprob, h = policy_forward(x)\n","    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n","\n","    # record various intermediates (needed later for backprop)\n","    xs.append(x) # observation\n","    hs.append(h) # hidden state\n","    y = 1 if action == 2 else 0 # a \"fake label\"\n","    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n","\n","    # step the environment and get new measurements\n","    observation, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n","\n","    if done: # an episode finished\n","      episode_number += 1\n","\n","      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n","      epx = np.vstack(xs)\n","      eph = np.vstack(hs)\n","      epdlogp = np.vstack(dlogps)\n","      epr = np.vstack(drs)\n","      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n","\n","      # compute the discounted reward backwards through time\n","      discounted_epr = discount_rewards(epr)\n","      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n","      discounted_epr -= np.mean(discounted_epr)\n","      discounted_epr /= np.std(discounted_epr)\n","\n","      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n","      grad = policy_backward(epx, eph, epdlogp)\n","      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n","\n","      # perform rmsprop parameter update every batch_size episodes\n","      if episode_number % batch_size == 0:\n","        for k,v in model.items():\n","          g = grad_buffer[k] # gradient\n","          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n","          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n","          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n","\n","      # boring book-keeping\n","      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n","      hist.append((episode_number, reward_sum, running_reward))\n","      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n","      reward_sum = 0\n","      observation = env.reset() # reset env\n","      prev_x = None\n","      if episode_number == total_episodes: return hist\n","\n","      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n","        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"],"execution_count":11,"outputs":[]},{"metadata":{"id":"G6Ka_5Vl9Orm","outputId":"d68ca6ec-4468-40e6-c18b-2bc1c29e51f0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660739933978,"user_tz":-330,"elapsed":1526633,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist1 = train_model(env, model, total_episodes=500)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -20.010000\n","resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.009900\n","resetting env. episode 4.000000, reward total was -20.000000. running mean: -20.009801\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.019703\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.029506\n","resetting env. episode 7.000000, reward total was -19.000000. running mean: -20.019211\n","resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.019019\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.028829\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.038540\n","resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.038155\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.047773\n","resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.047296\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.056823\n","resetting env. episode 15.000000, reward total was -19.000000. running mean: -20.046254\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.055792\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.065234\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.074582\n","resetting env. episode 19.000000, reward total was -20.000000. running mean: -20.073836\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.083097\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.092266\n","resetting env. episode 22.000000, reward total was -19.000000. running mean: -20.081344\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.090530\n","resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.089625\n","resetting env. episode 25.000000, reward total was -20.000000. running mean: -20.088729\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.097842\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.096863\n","resetting env. episode 28.000000, reward total was -18.000000. running mean: -20.075895\n","resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.075136\n","resetting env. episode 30.000000, reward total was -19.000000. running mean: -20.064384\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.063740\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.073103\n","resetting env. episode 33.000000, reward total was -19.000000. running mean: -20.062372\n","resetting env. episode 34.000000, reward total was -19.000000. running mean: -20.051748\n","resetting env. episode 35.000000, reward total was -19.000000. running mean: -20.041231\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.050818\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.060310\n","resetting env. episode 38.000000, reward total was -19.000000. running mean: -20.049707\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.059210\n","resetting env. episode 40.000000, reward total was -20.000000. running mean: -20.058618\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.068032\n","resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.067351\n","resetting env. episode 43.000000, reward total was -20.000000. running mean: -20.066678\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.066011\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.075351\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.084598\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.093752\n","resetting env. episode 48.000000, reward total was -20.000000. running mean: -20.092814\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.101886\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.100867\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.109858\n","resetting env. episode 52.000000, reward total was -20.000000. running mean: -20.108760\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.117672\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.126495\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.135231\n","resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.133878\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.142539\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.151114\n","resetting env. episode 59.000000, reward total was -18.000000. running mean: -20.129603\n","resetting env. episode 60.000000, reward total was -20.000000. running mean: -20.128307\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.137024\n","resetting env. episode 62.000000, reward total was -19.000000. running mean: -20.125654\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.134397\n","resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.133053\n","resetting env. episode 65.000000, reward total was -18.000000. running mean: -20.111723\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.120605\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.129399\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.138105\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.146724\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.155257\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.163704\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.172067\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.180347\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.188543\n","resetting env. episode 75.000000, reward total was -20.000000. running mean: -20.186658\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.194791\n","resetting env. episode 77.000000, reward total was -20.000000. running mean: -20.192843\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.190915\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.199006\n","resetting env. episode 80.000000, reward total was -19.000000. running mean: -20.187016\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.195145\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.193194\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.201262\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.209249\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.217157\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.224985\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.232736\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.240408\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.248004\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.255524\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.262969\n","resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.260339\n","resetting env. episode 93.000000, reward total was -20.000000. running mean: -20.257736\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.265158\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.272507\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.279782\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.286984\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.284114\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.291273\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.298360\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.305377\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.312323\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.319200\n","resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.316008\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.322848\n","resetting env. episode 106.000000, reward total was -18.000000. running mean: -20.299619\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.306623\n","resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.303557\n","resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.300521\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.307516\n","resetting env. episode 111.000000, reward total was -19.000000. running mean: -20.294441\n","resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.291496\n","resetting env. episode 113.000000, reward total was -19.000000. running mean: -20.278581\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.285796\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.292938\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.300008\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.307008\n","resetting env. episode 118.000000, reward total was -20.000000. running mean: -20.303938\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.310899\n","resetting env. episode 120.000000, reward total was -20.000000. running mean: -20.307790\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.314712\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.311565\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.318449\n","resetting env. episode 124.000000, reward total was -19.000000. running mean: -20.305265\n","resetting env. episode 125.000000, reward total was -19.000000. running mean: -20.292212\n","resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.289290\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.296397\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.303433\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.310399\n","resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.307295\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.314222\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.321079\n","resetting env. episode 133.000000, reward total was -19.000000. running mean: -20.307869\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.314790\n","resetting env. episode 135.000000, reward total was -18.000000. running mean: -20.291642\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.298726\n","resetting env. episode 137.000000, reward total was -18.000000. running mean: -20.275738\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.282981\n","resetting env. episode 139.000000, reward total was -20.000000. running mean: -20.280151\n","resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.277350\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.284576\n","resetting env. episode 142.000000, reward total was -20.000000. running mean: -20.281730\n","resetting env. episode 143.000000, reward total was -20.000000. running mean: -20.278913\n","resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.276124\n","resetting env. episode 145.000000, reward total was -19.000000. running mean: -20.263363\n","resetting env. episode 146.000000, reward total was -20.000000. running mean: -20.260729\n","resetting env. episode 147.000000, reward total was -19.000000. running mean: -20.248122\n","resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.245641\n","resetting env. episode 149.000000, reward total was -20.000000. running mean: -20.243184\n","resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.240752\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.248345\n","resetting env. episode 152.000000, reward total was -19.000000. running mean: -20.235861\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.243503\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.251068\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.258557\n","resetting env. episode 156.000000, reward total was -20.000000. running mean: -20.255971\n","resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.253412\n","resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.250878\n","resetting env. episode 159.000000, reward total was -20.000000. running mean: -20.248369\n","resetting env. episode 160.000000, reward total was -19.000000. running mean: -20.235885\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.243526\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.251091\n","resetting env. episode 163.000000, reward total was -19.000000. running mean: -20.238580\n","resetting env. episode 164.000000, reward total was -19.000000. running mean: -20.226194\n","resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.223932\n","resetting env. episode 166.000000, reward total was -19.000000. running mean: -20.211693\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.209576\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.217480\n","resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.215306\n","resetting env. episode 170.000000, reward total was -20.000000. running mean: -20.213153\n","resetting env. episode 171.000000, reward total was -20.000000. running mean: -20.211021\n","resetting env. episode 172.000000, reward total was -20.000000. running mean: -20.208911\n","resetting env. episode 173.000000, reward total was -18.000000. running mean: -20.186822\n","resetting env. episode 174.000000, reward total was -19.000000. running mean: -20.174953\n","resetting env. episode 175.000000, reward total was -19.000000. running mean: -20.163204\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.171572\n","resetting env. episode 177.000000, reward total was -20.000000. running mean: -20.169856\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.178158\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.186376\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.194512\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.202567\n","resetting env. episode 182.000000, reward total was -19.000000. running mean: -20.190541\n","resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.188636\n","resetting env. episode 184.000000, reward total was -18.000000. running mean: -20.166750\n","resetting env. episode 185.000000, reward total was -18.000000. running mean: -20.145082\n","resetting env. episode 186.000000, reward total was -20.000000. running mean: -20.143631\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.152195\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.150673\n","resetting env. episode 189.000000, reward total was -19.000000. running mean: -20.139166\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.147775\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.156297\n","resetting env. episode 192.000000, reward total was -20.000000. running mean: -20.154734\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.163187\n","resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.161555\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.169939\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.178240\n","resetting env. episode 197.000000, reward total was -20.000000. running mean: -20.176457\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.174693\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.172946\n","resetting env. episode 200.000000, reward total was -18.000000. running mean: -20.151217\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.159704\n","resetting env. episode 202.000000, reward total was -19.000000. running mean: -20.148107\n","resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.156626\n","resetting env. episode 204.000000, reward total was -20.000000. running mean: -20.155060\n","resetting env. episode 205.000000, reward total was -19.000000. running mean: -20.143509\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.152074\n","resetting env. episode 207.000000, reward total was -19.000000. running mean: -20.140554\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.149148\n","resetting env. episode 209.000000, reward total was -20.000000. running mean: -20.147657\n","resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.146180\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.154718\n","resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.153171\n","resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.151639\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.160123\n","resetting env. episode 215.000000, reward total was -19.000000. running mean: -20.148522\n","resetting env. episode 216.000000, reward total was -19.000000. running mean: -20.137036\n","resetting env. episode 217.000000, reward total was -19.000000. running mean: -20.125666\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.134409\n","resetting env. episode 219.000000, reward total was -18.000000. running mean: -20.113065\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.121935\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.130715\n","resetting env. episode 222.000000, reward total was -19.000000. running mean: -20.119408\n","resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.118214\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.127032\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.125762\n","resetting env. episode 226.000000, reward total was -19.000000. running mean: -20.114504\n","resetting env. episode 227.000000, reward total was -20.000000. running mean: -20.113359\n","resetting env. episode 228.000000, reward total was -19.000000. running mean: -20.102225\n","resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.101203\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.110191\n","resetting env. episode 231.000000, reward total was -19.000000. running mean: -20.099089\n","resetting env. episode 232.000000, reward total was -18.000000. running mean: -20.078098\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.087317\n","resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.096444\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.105480\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.114425\n","resetting env. episode 237.000000, reward total was -20.000000. running mean: -20.113281\n","resetting env. episode 238.000000, reward total was -19.000000. running mean: -20.102148\n","resetting env. episode 239.000000, reward total was -18.000000. running mean: -20.081126\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.090315\n","resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.089412\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.088518\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.097633\n","resetting env. episode 244.000000, reward total was -18.000000. running mean: -20.076656\n","resetting env. episode 245.000000, reward total was -17.000000. running mean: -20.045890\n","resetting env. episode 246.000000, reward total was -19.000000. running mean: -20.035431\n","resetting env. episode 247.000000, reward total was -18.000000. running mean: -20.015077\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.024926\n","resetting env. episode 249.000000, reward total was -19.000000. running mean: -20.014677\n","resetting env. episode 250.000000, reward total was -19.000000. running mean: -20.004530\n","resetting env. episode 251.000000, reward total was -19.000000. running mean: -19.994484\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.004540\n","resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.004494\n","resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.004449\n","resetting env. episode 255.000000, reward total was -19.000000. running mean: -19.994405\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.004461\n","resetting env. episode 257.000000, reward total was -19.000000. running mean: -19.994416\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.004472\n","resetting env. episode 259.000000, reward total was -17.000000. running mean: -19.974427\n","resetting env. episode 260.000000, reward total was -20.000000. running mean: -19.974683\n","resetting env. episode 261.000000, reward total was -20.000000. running mean: -19.974936\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -19.985187\n","resetting env. episode 263.000000, reward total was -20.000000. running mean: -19.985335\n","resetting env. episode 264.000000, reward total was -20.000000. running mean: -19.985482\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -19.995627\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -19.995670\n","resetting env. episode 267.000000, reward total was -18.000000. running mean: -19.975714\n","resetting env. episode 268.000000, reward total was -20.000000. running mean: -19.975957\n","resetting env. episode 269.000000, reward total was -19.000000. running mean: -19.966197\n","resetting env. episode 270.000000, reward total was -19.000000. running mean: -19.956535\n","resetting env. episode 271.000000, reward total was -19.000000. running mean: -19.946970\n","resetting env. episode 272.000000, reward total was -16.000000. running mean: -19.907500\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -19.918425\n","resetting env. episode 274.000000, reward total was -20.000000. running mean: -19.919241\n","resetting env. episode 275.000000, reward total was -20.000000. running mean: -19.920048\n","resetting env. episode 276.000000, reward total was -19.000000. running mean: -19.910848\n","resetting env. episode 277.000000, reward total was -19.000000. running mean: -19.901739\n","resetting env. episode 278.000000, reward total was -20.000000. running mean: -19.902722\n","resetting env. episode 279.000000, reward total was -20.000000. running mean: -19.903695\n","resetting env. episode 280.000000, reward total was -17.000000. running mean: -19.874658\n","resetting env. episode 281.000000, reward total was -20.000000. running mean: -19.875911\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -19.887152\n","resetting env. episode 283.000000, reward total was -18.000000. running mean: -19.868281\n","resetting env. episode 284.000000, reward total was -20.000000. running mean: -19.869598\n","resetting env. episode 285.000000, reward total was -20.000000. running mean: -19.870902\n","resetting env. episode 286.000000, reward total was -20.000000. running mean: -19.872193\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -19.883471\n","resetting env. episode 288.000000, reward total was -17.000000. running mean: -19.854636\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -19.866090\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -19.867429\n","resetting env. episode 291.000000, reward total was -20.000000. running mean: -19.868755\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -19.870067\n","resetting env. episode 293.000000, reward total was -18.000000. running mean: -19.851366\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -19.862853\n","resetting env. episode 295.000000, reward total was -19.000000. running mean: -19.854224\n","resetting env. episode 296.000000, reward total was -18.000000. running mean: -19.835682\n","resetting env. episode 297.000000, reward total was -19.000000. running mean: -19.827325\n","resetting env. episode 298.000000, reward total was -19.000000. running mean: -19.819052\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -19.830861\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -19.832553\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -19.844227\n","resetting env. episode 302.000000, reward total was -18.000000. running mean: -19.825785\n","resetting env. episode 303.000000, reward total was -20.000000. running mean: -19.827527\n","resetting env. episode 304.000000, reward total was -20.000000. running mean: -19.829252\n","resetting env. episode 305.000000, reward total was -20.000000. running mean: -19.830959\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -19.842650\n","resetting env. episode 307.000000, reward total was -19.000000. running mean: -19.834223\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -19.835881\n","resetting env. episode 309.000000, reward total was -14.000000. running mean: -19.777522\n","resetting env. episode 310.000000, reward total was -20.000000. running mean: -19.779747\n","resetting env. episode 311.000000, reward total was -14.000000. running mean: -19.721950\n","resetting env. episode 312.000000, reward total was -18.000000. running mean: -19.704730\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -19.707683\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -19.710606\n","resetting env. episode 315.000000, reward total was -19.000000. running mean: -19.703500\n","resetting env. episode 316.000000, reward total was -20.000000. running mean: -19.706465\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -19.709400\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -19.712306\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -19.725183\n","resetting env. episode 320.000000, reward total was -19.000000. running mean: -19.717931\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -19.720752\n","resetting env. episode 322.000000, reward total was -20.000000. running mean: -19.723544\n","resetting env. episode 323.000000, reward total was -17.000000. running mean: -19.696309\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -19.709346\n","resetting env. episode 325.000000, reward total was -19.000000. running mean: -19.702252\n","resetting env. episode 326.000000, reward total was -19.000000. running mean: -19.695230\n","resetting env. episode 327.000000, reward total was -20.000000. running mean: -19.698278\n","resetting env. episode 328.000000, reward total was -19.000000. running mean: -19.691295\n","resetting env. episode 329.000000, reward total was -20.000000. running mean: -19.694382\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -19.707438\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -19.720364\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -19.733160\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -19.745828\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -19.758370\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -19.770787\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -19.783079\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -19.795248\n","resetting env. episode 338.000000, reward total was -19.000000. running mean: -19.787295\n","resetting env. episode 339.000000, reward total was -20.000000. running mean: -19.789422\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -19.801528\n","resetting env. episode 341.000000, reward total was -20.000000. running mean: -19.803513\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -19.815478\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -19.827323\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -19.839050\n","resetting env. episode 345.000000, reward total was -17.000000. running mean: -19.810659\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -19.822553\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -19.834327\n","resetting env. episode 348.000000, reward total was -20.000000. running mean: -19.835984\n","resetting env. episode 349.000000, reward total was -20.000000. running mean: -19.837624\n","resetting env. episode 350.000000, reward total was -19.000000. running mean: -19.829248\n","resetting env. episode 351.000000, reward total was -19.000000. running mean: -19.820955\n","resetting env. episode 352.000000, reward total was -18.000000. running mean: -19.802746\n","resetting env. episode 353.000000, reward total was -19.000000. running mean: -19.794718\n","resetting env. episode 354.000000, reward total was -20.000000. running mean: -19.796771\n","resetting env. episode 355.000000, reward total was -20.000000. running mean: -19.798803\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -19.810815\n","resetting env. episode 357.000000, reward total was -16.000000. running mean: -19.772707\n","resetting env. episode 358.000000, reward total was -20.000000. running mean: -19.774980\n","resetting env. episode 359.000000, reward total was -17.000000. running mean: -19.747230\n","resetting env. episode 360.000000, reward total was -18.000000. running mean: -19.729758\n","resetting env. episode 361.000000, reward total was -17.000000. running mean: -19.702460\n","resetting env. episode 362.000000, reward total was -20.000000. running mean: -19.705436\n","resetting env. episode 363.000000, reward total was -17.000000. running mean: -19.678382\n","resetting env. episode 364.000000, reward total was -19.000000. running mean: -19.671598\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -19.674882\n","resetting env. episode 366.000000, reward total was -20.000000. running mean: -19.678133\n","resetting env. episode 367.000000, reward total was -19.000000. running mean: -19.671352\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -19.684638\n","resetting env. episode 369.000000, reward total was -20.000000. running mean: -19.687792\n","resetting env. episode 370.000000, reward total was -19.000000. running mean: -19.680914\n","resetting env. episode 371.000000, reward total was -20.000000. running mean: -19.684105\n","resetting env. episode 372.000000, reward total was -19.000000. running mean: -19.677264\n","resetting env. episode 373.000000, reward total was -20.000000. running mean: -19.680491\n","resetting env. episode 374.000000, reward total was -21.000000. running mean: -19.693686\n","resetting env. episode 375.000000, reward total was -20.000000. running mean: -19.696749\n","resetting env. episode 376.000000, reward total was -20.000000. running mean: -19.699782\n","resetting env. episode 377.000000, reward total was -20.000000. running mean: -19.702784\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -19.715756\n","resetting env. episode 379.000000, reward total was -19.000000. running mean: -19.708598\n","resetting env. episode 380.000000, reward total was -20.000000. running mean: -19.711512\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -19.724397\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -19.737153\n","resetting env. episode 383.000000, reward total was -17.000000. running mean: -19.709782\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -19.712684\n","resetting env. episode 385.000000, reward total was -15.000000. running mean: -19.665557\n","resetting env. episode 386.000000, reward total was -19.000000. running mean: -19.658902\n","resetting env. episode 387.000000, reward total was -19.000000. running mean: -19.652313\n","resetting env. episode 388.000000, reward total was -20.000000. running mean: -19.655789\n","resetting env. episode 389.000000, reward total was -19.000000. running mean: -19.649232\n","resetting env. episode 390.000000, reward total was -18.000000. running mean: -19.632739\n","resetting env. episode 391.000000, reward total was -20.000000. running mean: -19.636412\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -19.650048\n","resetting env. episode 393.000000, reward total was -20.000000. running mean: -19.653547\n","resetting env. episode 394.000000, reward total was -20.000000. running mean: -19.657012\n","resetting env. episode 395.000000, reward total was -19.000000. running mean: -19.650442\n","resetting env. episode 396.000000, reward total was -19.000000. running mean: -19.643937\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -19.657498\n","resetting env. episode 398.000000, reward total was -20.000000. running mean: -19.660923\n","resetting env. episode 399.000000, reward total was -19.000000. running mean: -19.654314\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -19.667771\n","resetting env. episode 401.000000, reward total was -20.000000. running mean: -19.671093\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -19.684382\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -19.697538\n","resetting env. episode 404.000000, reward total was -19.000000. running mean: -19.690563\n","resetting env. episode 405.000000, reward total was -20.000000. running mean: -19.693657\n","resetting env. episode 406.000000, reward total was -20.000000. running mean: -19.696721\n","resetting env. episode 407.000000, reward total was -20.000000. running mean: -19.699753\n","resetting env. episode 408.000000, reward total was -19.000000. running mean: -19.692756\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -19.695828\n","resetting env. episode 410.000000, reward total was -20.000000. running mean: -19.698870\n","resetting env. episode 411.000000, reward total was -18.000000. running mean: -19.681881\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -19.685062\n","resetting env. episode 413.000000, reward total was -19.000000. running mean: -19.678212\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -19.691430\n","resetting env. episode 415.000000, reward total was -19.000000. running mean: -19.684515\n","resetting env. episode 416.000000, reward total was -20.000000. running mean: -19.687670\n","resetting env. episode 417.000000, reward total was -19.000000. running mean: -19.680794\n","resetting env. episode 418.000000, reward total was -20.000000. running mean: -19.683986\n","resetting env. episode 419.000000, reward total was -19.000000. running mean: -19.677146\n","resetting env. episode 420.000000, reward total was -20.000000. running mean: -19.680374\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -19.693571\n","resetting env. episode 422.000000, reward total was -20.000000. running mean: -19.696635\n","resetting env. episode 423.000000, reward total was -19.000000. running mean: -19.689668\n","resetting env. episode 424.000000, reward total was -20.000000. running mean: -19.692772\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -19.695844\n","resetting env. episode 426.000000, reward total was -20.000000. running mean: -19.698886\n","resetting env. episode 427.000000, reward total was -19.000000. running mean: -19.691897\n","resetting env. episode 428.000000, reward total was -19.000000. running mean: -19.684978\n","resetting env. episode 429.000000, reward total was -19.000000. running mean: -19.678128\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -19.681347\n","resetting env. episode 431.000000, reward total was -19.000000. running mean: -19.674533\n","resetting env. episode 432.000000, reward total was -19.000000. running mean: -19.667788\n","resetting env. episode 433.000000, reward total was -20.000000. running mean: -19.671110\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -19.684399\n","resetting env. episode 435.000000, reward total was -20.000000. running mean: -19.687555\n","resetting env. episode 436.000000, reward total was -19.000000. running mean: -19.680679\n","resetting env. episode 437.000000, reward total was -20.000000. running mean: -19.683873\n","resetting env. episode 438.000000, reward total was -21.000000. running mean: -19.697034\n","resetting env. episode 439.000000, reward total was -19.000000. running mean: -19.690064\n","resetting env. episode 440.000000, reward total was -18.000000. running mean: -19.673163\n","resetting env. episode 441.000000, reward total was -20.000000. running mean: -19.676431\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -19.689667\n","resetting env. episode 443.000000, reward total was -19.000000. running mean: -19.682770\n","resetting env. episode 444.000000, reward total was -20.000000. running mean: -19.685943\n","resetting env. episode 445.000000, reward total was -20.000000. running mean: -19.689083\n","resetting env. episode 446.000000, reward total was -17.000000. running mean: -19.662192\n","resetting env. episode 447.000000, reward total was -19.000000. running mean: -19.655570\n","resetting env. episode 448.000000, reward total was -18.000000. running mean: -19.639015\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -19.652625\n","resetting env. episode 450.000000, reward total was -18.000000. running mean: -19.636098\n","resetting env. episode 451.000000, reward total was -19.000000. running mean: -19.629737\n","resetting env. episode 452.000000, reward total was -19.000000. running mean: -19.623440\n","resetting env. episode 453.000000, reward total was -19.000000. running mean: -19.617206\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -19.631034\n","resetting env. episode 455.000000, reward total was -19.000000. running mean: -19.624723\n","resetting env. episode 456.000000, reward total was -19.000000. running mean: -19.618476\n","resetting env. episode 457.000000, reward total was -19.000000. running mean: -19.612291\n","resetting env. episode 458.000000, reward total was -18.000000. running mean: -19.596168\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -19.610207\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -19.614105\n","resetting env. episode 461.000000, reward total was -19.000000. running mean: -19.607964\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -19.621884\n","resetting env. episode 463.000000, reward total was -20.000000. running mean: -19.625665\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -19.639408\n","resetting env. episode 465.000000, reward total was -20.000000. running mean: -19.643014\n","resetting env. episode 466.000000, reward total was -20.000000. running mean: -19.646584\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -19.650118\n","resetting env. episode 468.000000, reward total was -19.000000. running mean: -19.643617\n","resetting env. episode 469.000000, reward total was -20.000000. running mean: -19.647181\n","resetting env. episode 470.000000, reward total was -13.000000. running mean: -19.580709\n","resetting env. episode 471.000000, reward total was -19.000000. running mean: -19.574902\n","resetting env. episode 472.000000, reward total was -17.000000. running mean: -19.549153\n","resetting env. episode 473.000000, reward total was -18.000000. running mean: -19.533662\n","resetting env. episode 474.000000, reward total was -20.000000. running mean: -19.538325\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -19.552942\n","resetting env. episode 476.000000, reward total was -16.000000. running mean: -19.517412\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -19.532238\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -19.546916\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -19.551447\n","resetting env. episode 480.000000, reward total was -18.000000. running mean: -19.535932\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -19.550573\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -19.565067\n","resetting env. episode 483.000000, reward total was -17.000000. running mean: -19.539416\n","resetting env. episode 484.000000, reward total was -17.000000. running mean: -19.514022\n","resetting env. episode 485.000000, reward total was -16.000000. running mean: -19.478882\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -19.494093\n","resetting env. episode 487.000000, reward total was -19.000000. running mean: -19.489152\n","resetting env. episode 488.000000, reward total was -17.000000. running mean: -19.464261\n","resetting env. episode 489.000000, reward total was -18.000000. running mean: -19.449618\n","resetting env. episode 490.000000, reward total was -18.000000. running mean: -19.435122\n","resetting env. episode 491.000000, reward total was -19.000000. running mean: -19.430771\n","resetting env. episode 492.000000, reward total was -20.000000. running mean: -19.436463\n","resetting env. episode 493.000000, reward total was -19.000000. running mean: -19.432098\n","resetting env. episode 494.000000, reward total was -20.000000. running mean: -19.437777\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -19.453400\n","resetting env. episode 496.000000, reward total was -18.000000. running mean: -19.438866\n","resetting env. episode 497.000000, reward total was -19.000000. running mean: -19.434477\n","resetting env. episode 498.000000, reward total was -19.000000. running mean: -19.430132\n","resetting env. episode 499.000000, reward total was -20.000000. running mean: -19.435831\n","resetting env. episode 500.000000, reward total was -18.000000. running mean: -19.421473\n","CPU times: user 33min 33s, sys: 15min 51s, total: 49min 25s\n","Wall time: 25min 26s\n"]}]},{"metadata":{"id":"cHYCDYwhlVLV","outputId":"e58d4aa0-ea08-4a35-e4be-45f41353297b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660742326869,"user_tz":-330,"elapsed":2392916,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist2 = train_model(env, model, total_episodes=500)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -18.000000. running mean: -18.000000\n","resetting env. episode 2.000000, reward total was -18.000000. running mean: -18.000000\n","resetting env. episode 3.000000, reward total was -19.000000. running mean: -18.010000\n","resetting env. episode 4.000000, reward total was -18.000000. running mean: -18.009900\n","resetting env. episode 5.000000, reward total was -19.000000. running mean: -18.019801\n","resetting env. episode 6.000000, reward total was -18.000000. running mean: -18.019603\n","resetting env. episode 7.000000, reward total was -17.000000. running mean: -18.009407\n","resetting env. episode 8.000000, reward total was -20.000000. running mean: -18.029313\n","resetting env. episode 9.000000, reward total was -17.000000. running mean: -18.019020\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -18.048830\n","resetting env. episode 11.000000, reward total was -19.000000. running mean: -18.058341\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -18.087758\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -18.116880\n","resetting env. episode 14.000000, reward total was -19.000000. running mean: -18.125711\n","resetting env. episode 15.000000, reward total was -20.000000. running mean: -18.144454\n","resetting env. episode 16.000000, reward total was -20.000000. running mean: -18.163010\n","resetting env. episode 17.000000, reward total was -20.000000. running mean: -18.181380\n","resetting env. episode 18.000000, reward total was -16.000000. running mean: -18.159566\n","resetting env. episode 19.000000, reward total was -18.000000. running mean: -18.157970\n","resetting env. episode 20.000000, reward total was -19.000000. running mean: -18.166391\n","resetting env. episode 21.000000, reward total was -18.000000. running mean: -18.164727\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -18.193079\n","resetting env. episode 23.000000, reward total was -19.000000. running mean: -18.201149\n","resetting env. episode 24.000000, reward total was -19.000000. running mean: -18.209137\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -18.237046\n","resetting env. episode 26.000000, reward total was -17.000000. running mean: -18.224675\n","resetting env. episode 27.000000, reward total was -18.000000. running mean: -18.222429\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -18.250204\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -18.277702\n","resetting env. episode 30.000000, reward total was -15.000000. running mean: -18.244925\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -18.262476\n","resetting env. episode 32.000000, reward total was -17.000000. running mean: -18.249851\n","resetting env. episode 33.000000, reward total was -19.000000. running mean: -18.257353\n","resetting env. episode 34.000000, reward total was -16.000000. running mean: -18.234779\n","resetting env. episode 35.000000, reward total was -15.000000. running mean: -18.202431\n","resetting env. episode 36.000000, reward total was -18.000000. running mean: -18.200407\n","resetting env. episode 37.000000, reward total was -19.000000. running mean: -18.208403\n","resetting env. episode 38.000000, reward total was -19.000000. running mean: -18.216319\n","resetting env. episode 39.000000, reward total was -18.000000. running mean: -18.214156\n","resetting env. episode 40.000000, reward total was -20.000000. running mean: -18.232014\n","resetting env. episode 41.000000, reward total was -18.000000. running mean: -18.229694\n","resetting env. episode 42.000000, reward total was -18.000000. running mean: -18.227397\n","resetting env. episode 43.000000, reward total was -19.000000. running mean: -18.235123\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -18.252772\n","resetting env. episode 45.000000, reward total was -17.000000. running mean: -18.240244\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -18.267842\n","resetting env. episode 47.000000, reward total was -19.000000. running mean: -18.275163\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -18.302412\n","resetting env. episode 49.000000, reward total was -20.000000. running mean: -18.319388\n","resetting env. episode 50.000000, reward total was -18.000000. running mean: -18.316194\n","resetting env. episode 51.000000, reward total was -16.000000. running mean: -18.293032\n","resetting env. episode 52.000000, reward total was -19.000000. running mean: -18.300101\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -18.327100\n","resetting env. episode 54.000000, reward total was -18.000000. running mean: -18.323829\n","resetting env. episode 55.000000, reward total was -19.000000. running mean: -18.330591\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -18.357285\n","resetting env. episode 57.000000, reward total was -19.000000. running mean: -18.363712\n","resetting env. episode 58.000000, reward total was -18.000000. running mean: -18.360075\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -18.386474\n","resetting env. episode 60.000000, reward total was -19.000000. running mean: -18.392610\n","resetting env. episode 61.000000, reward total was -18.000000. running mean: -18.388684\n","resetting env. episode 62.000000, reward total was -20.000000. running mean: -18.404797\n","resetting env. episode 63.000000, reward total was -17.000000. running mean: -18.390749\n","resetting env. episode 64.000000, reward total was -20.000000. running mean: -18.406841\n","resetting env. episode 65.000000, reward total was -19.000000. running mean: -18.412773\n","resetting env. episode 66.000000, reward total was -18.000000. running mean: -18.408645\n","resetting env. episode 67.000000, reward total was -20.000000. running mean: -18.424559\n","resetting env. episode 68.000000, reward total was -20.000000. running mean: -18.440313\n","resetting env. episode 69.000000, reward total was -20.000000. running mean: -18.455910\n","resetting env. episode 70.000000, reward total was -17.000000. running mean: -18.441351\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -18.466937\n","resetting env. episode 72.000000, reward total was -20.000000. running mean: -18.482268\n","resetting env. episode 73.000000, reward total was -19.000000. running mean: -18.487445\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -18.512571\n","resetting env. episode 75.000000, reward total was -18.000000. running mean: -18.507445\n","resetting env. episode 76.000000, reward total was -16.000000. running mean: -18.482371\n","resetting env. episode 77.000000, reward total was -18.000000. running mean: -18.477547\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -18.492772\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -18.517844\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -18.542665\n","resetting env. episode 81.000000, reward total was -17.000000. running mean: -18.527239\n","resetting env. episode 82.000000, reward total was -17.000000. running mean: -18.511966\n","resetting env. episode 83.000000, reward total was -17.000000. running mean: -18.496847\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -18.521878\n","resetting env. episode 85.000000, reward total was -16.000000. running mean: -18.496659\n","resetting env. episode 86.000000, reward total was -17.000000. running mean: -18.481693\n","resetting env. episode 87.000000, reward total was -19.000000. running mean: -18.486876\n","resetting env. episode 88.000000, reward total was -14.000000. running mean: -18.442007\n","resetting env. episode 89.000000, reward total was -17.000000. running mean: -18.427587\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -18.453311\n","resetting env. episode 91.000000, reward total was -19.000000. running mean: -18.458778\n","resetting env. episode 92.000000, reward total was -18.000000. running mean: -18.454190\n","resetting env. episode 93.000000, reward total was -20.000000. running mean: -18.469648\n","resetting env. episode 94.000000, reward total was -16.000000. running mean: -18.444952\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -18.460502\n","resetting env. episode 96.000000, reward total was -16.000000. running mean: -18.435897\n","resetting env. episode 97.000000, reward total was -19.000000. running mean: -18.441538\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -18.467123\n","resetting env. episode 99.000000, reward total was -17.000000. running mean: -18.452452\n","resetting env. episode 100.000000, reward total was -16.000000. running mean: -18.427927\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -18.443648\n","resetting env. episode 102.000000, reward total was -15.000000. running mean: -18.409212\n","resetting env. episode 103.000000, reward total was -17.000000. running mean: -18.395119\n","resetting env. episode 104.000000, reward total was -17.000000. running mean: -18.381168\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -18.407357\n","resetting env. episode 106.000000, reward total was -18.000000. running mean: -18.403283\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -18.429250\n","resetting env. episode 108.000000, reward total was -18.000000. running mean: -18.424958\n","resetting env. episode 109.000000, reward total was -19.000000. running mean: -18.430708\n","resetting env. episode 110.000000, reward total was -20.000000. running mean: -18.446401\n","resetting env. episode 111.000000, reward total was -17.000000. running mean: -18.431937\n","resetting env. episode 112.000000, reward total was -20.000000. running mean: -18.447618\n","resetting env. episode 113.000000, reward total was -19.000000. running mean: -18.453141\n","resetting env. episode 114.000000, reward total was -15.000000. running mean: -18.418610\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -18.444424\n","resetting env. episode 116.000000, reward total was -17.000000. running mean: -18.429980\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -18.455680\n","resetting env. episode 118.000000, reward total was -19.000000. running mean: -18.461123\n","resetting env. episode 119.000000, reward total was -20.000000. running mean: -18.476512\n","resetting env. episode 120.000000, reward total was -18.000000. running mean: -18.471747\n","resetting env. episode 121.000000, reward total was -20.000000. running mean: -18.487029\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -18.512159\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -18.537037\n","resetting env. episode 124.000000, reward total was -17.000000. running mean: -18.521667\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -18.546450\n","resetting env. episode 126.000000, reward total was -17.000000. running mean: -18.530986\n","resetting env. episode 127.000000, reward total was -20.000000. running mean: -18.545676\n","resetting env. episode 128.000000, reward total was -18.000000. running mean: -18.540219\n","resetting env. episode 129.000000, reward total was -18.000000. running mean: -18.534817\n","resetting env. episode 130.000000, reward total was -18.000000. running mean: -18.529469\n","resetting env. episode 131.000000, reward total was -13.000000. running mean: -18.474174\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -18.489432\n","resetting env. episode 133.000000, reward total was -19.000000. running mean: -18.494538\n","resetting env. episode 134.000000, reward total was -20.000000. running mean: -18.509593\n","resetting env. episode 135.000000, reward total was -19.000000. running mean: -18.514497\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -18.539352\n","resetting env. episode 137.000000, reward total was -19.000000. running mean: -18.543958\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -18.568519\n","resetting env. episode 139.000000, reward total was -16.000000. running mean: -18.542834\n","resetting env. episode 140.000000, reward total was -19.000000. running mean: -18.547405\n","resetting env. episode 141.000000, reward total was -15.000000. running mean: -18.511931\n","resetting env. episode 142.000000, reward total was -17.000000. running mean: -18.496812\n","resetting env. episode 143.000000, reward total was -17.000000. running mean: -18.481844\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -18.507025\n","resetting env. episode 145.000000, reward total was -18.000000. running mean: -18.501955\n","resetting env. episode 146.000000, reward total was -18.000000. running mean: -18.496935\n","resetting env. episode 147.000000, reward total was -19.000000. running mean: -18.501966\n","resetting env. episode 148.000000, reward total was -19.000000. running mean: -18.506946\n","resetting env. episode 149.000000, reward total was -16.000000. running mean: -18.481877\n","resetting env. episode 150.000000, reward total was -19.000000. running mean: -18.487058\n","resetting env. episode 151.000000, reward total was -16.000000. running mean: -18.462188\n","resetting env. episode 152.000000, reward total was -19.000000. running mean: -18.467566\n","resetting env. episode 153.000000, reward total was -19.000000. running mean: -18.472890\n","resetting env. episode 154.000000, reward total was -19.000000. running mean: -18.478161\n","resetting env. episode 155.000000, reward total was -18.000000. running mean: -18.473380\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -18.498646\n","resetting env. episode 157.000000, reward total was -19.000000. running mean: -18.503659\n","resetting env. episode 158.000000, reward total was -19.000000. running mean: -18.508623\n","resetting env. episode 159.000000, reward total was -18.000000. running mean: -18.503537\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -18.528501\n","resetting env. episode 161.000000, reward total was -17.000000. running mean: -18.513216\n","resetting env. episode 162.000000, reward total was -16.000000. running mean: -18.488084\n","resetting env. episode 163.000000, reward total was -19.000000. running mean: -18.493203\n","resetting env. episode 164.000000, reward total was -19.000000. running mean: -18.498271\n","resetting env. episode 165.000000, reward total was -17.000000. running mean: -18.483288\n","resetting env. episode 166.000000, reward total was -19.000000. running mean: -18.488456\n","resetting env. episode 167.000000, reward total was -18.000000. running mean: -18.483571\n","resetting env. episode 168.000000, reward total was -19.000000. running mean: -18.488735\n","resetting env. episode 169.000000, reward total was -17.000000. running mean: -18.473848\n","resetting env. episode 170.000000, reward total was -19.000000. running mean: -18.479109\n","resetting env. episode 171.000000, reward total was -19.000000. running mean: -18.484318\n","resetting env. episode 172.000000, reward total was -19.000000. running mean: -18.489475\n","resetting env. episode 173.000000, reward total was -19.000000. running mean: -18.494580\n","resetting env. episode 174.000000, reward total was -17.000000. running mean: -18.479635\n","resetting env. episode 175.000000, reward total was -17.000000. running mean: -18.464838\n","resetting env. episode 176.000000, reward total was -16.000000. running mean: -18.440190\n","resetting env. episode 177.000000, reward total was -19.000000. running mean: -18.445788\n","resetting env. episode 178.000000, reward total was -19.000000. running mean: -18.451330\n","resetting env. episode 179.000000, reward total was -17.000000. running mean: -18.436817\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -18.462449\n","resetting env. episode 181.000000, reward total was -19.000000. running mean: -18.467824\n","resetting env. episode 182.000000, reward total was -16.000000. running mean: -18.443146\n","resetting env. episode 183.000000, reward total was -17.000000. running mean: -18.428714\n","resetting env. episode 184.000000, reward total was -19.000000. running mean: -18.434427\n","resetting env. episode 185.000000, reward total was -18.000000. running mean: -18.430083\n","resetting env. episode 186.000000, reward total was -19.000000. running mean: -18.435782\n","resetting env. episode 187.000000, reward total was -18.000000. running mean: -18.431424\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -18.447110\n","resetting env. episode 189.000000, reward total was -19.000000. running mean: -18.452639\n","resetting env. episode 190.000000, reward total was -17.000000. running mean: -18.438113\n","resetting env. episode 191.000000, reward total was -19.000000. running mean: -18.443732\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -18.469294\n","resetting env. episode 193.000000, reward total was -20.000000. running mean: -18.484601\n","resetting env. episode 194.000000, reward total was -19.000000. running mean: -18.489755\n","resetting env. episode 195.000000, reward total was -15.000000. running mean: -18.454858\n","resetting env. episode 196.000000, reward total was -19.000000. running mean: -18.460309\n","resetting env. episode 197.000000, reward total was -19.000000. running mean: -18.465706\n","resetting env. episode 198.000000, reward total was -17.000000. running mean: -18.451049\n","resetting env. episode 199.000000, reward total was -17.000000. running mean: -18.436538\n","resetting env. episode 200.000000, reward total was -19.000000. running mean: -18.442173\n","resetting env. episode 201.000000, reward total was -19.000000. running mean: -18.447751\n","resetting env. episode 202.000000, reward total was -19.000000. running mean: -18.453274\n","resetting env. episode 203.000000, reward total was -19.000000. running mean: -18.458741\n","resetting env. episode 204.000000, reward total was -15.000000. running mean: -18.424154\n","resetting env. episode 205.000000, reward total was -16.000000. running mean: -18.399912\n","resetting env. episode 206.000000, reward total was -17.000000. running mean: -18.385913\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -18.412054\n","resetting env. episode 208.000000, reward total was -19.000000. running mean: -18.417933\n","resetting env. episode 209.000000, reward total was -16.000000. running mean: -18.393754\n","resetting env. episode 210.000000, reward total was -19.000000. running mean: -18.399816\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -18.425818\n","resetting env. episode 212.000000, reward total was -19.000000. running mean: -18.431560\n","resetting env. episode 213.000000, reward total was -20.000000. running mean: -18.447245\n","resetting env. episode 214.000000, reward total was -19.000000. running mean: -18.452772\n","resetting env. episode 215.000000, reward total was -15.000000. running mean: -18.418244\n","resetting env. episode 216.000000, reward total was -20.000000. running mean: -18.434062\n","resetting env. episode 217.000000, reward total was -18.000000. running mean: -18.429721\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -18.455424\n","resetting env. episode 219.000000, reward total was -17.000000. running mean: -18.440870\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -18.466461\n","resetting env. episode 221.000000, reward total was -17.000000. running mean: -18.451797\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -18.477279\n","resetting env. episode 223.000000, reward total was -19.000000. running mean: -18.482506\n","resetting env. episode 224.000000, reward total was -18.000000. running mean: -18.477681\n","resetting env. episode 225.000000, reward total was -19.000000. running mean: -18.482904\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -18.508075\n","resetting env. episode 227.000000, reward total was -17.000000. running mean: -18.492994\n","resetting env. episode 228.000000, reward total was -21.000000. running mean: -18.518064\n","resetting env. episode 229.000000, reward total was -19.000000. running mean: -18.522884\n","resetting env. episode 230.000000, reward total was -17.000000. running mean: -18.507655\n","resetting env. episode 231.000000, reward total was -20.000000. running mean: -18.522578\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -18.537352\n","resetting env. episode 233.000000, reward total was -19.000000. running mean: -18.541979\n","resetting env. episode 234.000000, reward total was -19.000000. running mean: -18.546559\n","resetting env. episode 235.000000, reward total was -19.000000. running mean: -18.551093\n","resetting env. episode 236.000000, reward total was -16.000000. running mean: -18.525583\n","resetting env. episode 237.000000, reward total was -19.000000. running mean: -18.530327\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -18.555023\n","resetting env. episode 239.000000, reward total was -19.000000. running mean: -18.559473\n","resetting env. episode 240.000000, reward total was -20.000000. running mean: -18.573878\n","resetting env. episode 241.000000, reward total was -17.000000. running mean: -18.558140\n","resetting env. episode 242.000000, reward total was -18.000000. running mean: -18.552558\n","resetting env. episode 243.000000, reward total was -18.000000. running mean: -18.547033\n","resetting env. episode 244.000000, reward total was -19.000000. running mean: -18.551562\n","resetting env. episode 245.000000, reward total was -19.000000. running mean: -18.556047\n","resetting env. episode 246.000000, reward total was -14.000000. running mean: -18.510486\n","resetting env. episode 247.000000, reward total was -18.000000. running mean: -18.505381\n","resetting env. episode 248.000000, reward total was -20.000000. running mean: -18.520328\n","resetting env. episode 249.000000, reward total was -20.000000. running mean: -18.535124\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -18.559773\n","resetting env. episode 251.000000, reward total was -17.000000. running mean: -18.544175\n","resetting env. episode 252.000000, reward total was -20.000000. running mean: -18.558734\n","resetting env. episode 253.000000, reward total was -14.000000. running mean: -18.513146\n","resetting env. episode 254.000000, reward total was -16.000000. running mean: -18.488015\n","resetting env. episode 255.000000, reward total was -19.000000. running mean: -18.493135\n","resetting env. episode 256.000000, reward total was -18.000000. running mean: -18.488203\n","resetting env. episode 257.000000, reward total was -19.000000. running mean: -18.493321\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -18.518388\n","resetting env. episode 259.000000, reward total was -15.000000. running mean: -18.483204\n","resetting env. episode 260.000000, reward total was -17.000000. running mean: -18.468372\n","resetting env. episode 261.000000, reward total was -16.000000. running mean: -18.443688\n","resetting env. episode 262.000000, reward total was -19.000000. running mean: -18.449252\n","resetting env. episode 263.000000, reward total was -19.000000. running mean: -18.454759\n","resetting env. episode 264.000000, reward total was -19.000000. running mean: -18.460211\n","resetting env. episode 265.000000, reward total was -19.000000. running mean: -18.465609\n","resetting env. episode 266.000000, reward total was -17.000000. running mean: -18.450953\n","resetting env. episode 267.000000, reward total was -20.000000. running mean: -18.466444\n","resetting env. episode 268.000000, reward total was -16.000000. running mean: -18.441779\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -18.467361\n","resetting env. episode 270.000000, reward total was -16.000000. running mean: -18.442688\n","resetting env. episode 271.000000, reward total was -17.000000. running mean: -18.428261\n","resetting env. episode 272.000000, reward total was -16.000000. running mean: -18.403978\n","resetting env. episode 273.000000, reward total was -15.000000. running mean: -18.369939\n","resetting env. episode 274.000000, reward total was -16.000000. running mean: -18.346239\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -18.372777\n","resetting env. episode 276.000000, reward total was -18.000000. running mean: -18.369049\n","resetting env. episode 277.000000, reward total was -19.000000. running mean: -18.375359\n","resetting env. episode 278.000000, reward total was -16.000000. running mean: -18.351605\n","resetting env. episode 279.000000, reward total was -16.000000. running mean: -18.328089\n","resetting env. episode 280.000000, reward total was -19.000000. running mean: -18.334808\n","resetting env. episode 281.000000, reward total was -16.000000. running mean: -18.311460\n","resetting env. episode 282.000000, reward total was -18.000000. running mean: -18.308345\n","resetting env. episode 283.000000, reward total was -20.000000. running mean: -18.325262\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -18.352009\n","resetting env. episode 285.000000, reward total was -18.000000. running mean: -18.348489\n","resetting env. episode 286.000000, reward total was -18.000000. running mean: -18.345004\n","resetting env. episode 287.000000, reward total was -19.000000. running mean: -18.351554\n","resetting env. episode 288.000000, reward total was -18.000000. running mean: -18.348039\n","resetting env. episode 289.000000, reward total was -19.000000. running mean: -18.354558\n","resetting env. episode 290.000000, reward total was -19.000000. running mean: -18.361013\n","resetting env. episode 291.000000, reward total was -19.000000. running mean: -18.367403\n","resetting env. episode 292.000000, reward total was -12.000000. running mean: -18.303729\n","resetting env. episode 293.000000, reward total was -17.000000. running mean: -18.290691\n","resetting env. episode 294.000000, reward total was -19.000000. running mean: -18.297784\n","resetting env. episode 295.000000, reward total was -19.000000. running mean: -18.304807\n","resetting env. episode 296.000000, reward total was -18.000000. running mean: -18.301758\n","resetting env. episode 297.000000, reward total was -19.000000. running mean: -18.308741\n","resetting env. episode 298.000000, reward total was -15.000000. running mean: -18.275653\n","resetting env. episode 299.000000, reward total was -14.000000. running mean: -18.232897\n","resetting env. episode 300.000000, reward total was -16.000000. running mean: -18.210568\n","resetting env. episode 301.000000, reward total was -19.000000. running mean: -18.218462\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -18.236278\n","resetting env. episode 303.000000, reward total was -18.000000. running mean: -18.233915\n","resetting env. episode 304.000000, reward total was -18.000000. running mean: -18.231576\n","resetting env. episode 305.000000, reward total was -19.000000. running mean: -18.239260\n","resetting env. episode 306.000000, reward total was -20.000000. running mean: -18.256867\n","resetting env. episode 307.000000, reward total was -18.000000. running mean: -18.254299\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -18.271756\n","resetting env. episode 309.000000, reward total was -14.000000. running mean: -18.229038\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -18.256748\n","resetting env. episode 311.000000, reward total was -14.000000. running mean: -18.214180\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -18.242039\n","resetting env. episode 313.000000, reward total was -19.000000. running mean: -18.249618\n","resetting env. episode 314.000000, reward total was -18.000000. running mean: -18.247122\n","resetting env. episode 315.000000, reward total was -19.000000. running mean: -18.254651\n","resetting env. episode 316.000000, reward total was -16.000000. running mean: -18.232104\n","resetting env. episode 317.000000, reward total was -17.000000. running mean: -18.219783\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -18.237585\n","resetting env. episode 319.000000, reward total was -17.000000. running mean: -18.225209\n","resetting env. episode 320.000000, reward total was -18.000000. running mean: -18.222957\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -18.240728\n","resetting env. episode 322.000000, reward total was -17.000000. running mean: -18.228321\n","resetting env. episode 323.000000, reward total was -17.000000. running mean: -18.216037\n","resetting env. episode 324.000000, reward total was -20.000000. running mean: -18.233877\n","resetting env. episode 325.000000, reward total was -18.000000. running mean: -18.231538\n","resetting env. episode 326.000000, reward total was -17.000000. running mean: -18.219223\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -18.247031\n","resetting env. episode 328.000000, reward total was -20.000000. running mean: -18.264560\n","resetting env. episode 329.000000, reward total was -17.000000. running mean: -18.251915\n","resetting env. episode 330.000000, reward total was -19.000000. running mean: -18.259396\n","resetting env. episode 331.000000, reward total was -17.000000. running mean: -18.246802\n","resetting env. episode 332.000000, reward total was -17.000000. running mean: -18.234334\n","resetting env. episode 333.000000, reward total was -12.000000. running mean: -18.171990\n","resetting env. episode 334.000000, reward total was -16.000000. running mean: -18.150270\n","resetting env. episode 335.000000, reward total was -12.000000. running mean: -18.088768\n","resetting env. episode 336.000000, reward total was -18.000000. running mean: -18.087880\n","resetting env. episode 337.000000, reward total was -16.000000. running mean: -18.067001\n","resetting env. episode 338.000000, reward total was -17.000000. running mean: -18.056331\n","resetting env. episode 339.000000, reward total was -15.000000. running mean: -18.025768\n","resetting env. episode 340.000000, reward total was -13.000000. running mean: -17.975510\n","resetting env. episode 341.000000, reward total was -19.000000. running mean: -17.985755\n","resetting env. episode 342.000000, reward total was -20.000000. running mean: -18.005897\n","resetting env. episode 343.000000, reward total was -16.000000. running mean: -17.985839\n","resetting env. episode 344.000000, reward total was -17.000000. running mean: -17.975980\n","resetting env. episode 345.000000, reward total was -16.000000. running mean: -17.956220\n","resetting env. episode 346.000000, reward total was -15.000000. running mean: -17.926658\n","resetting env. episode 347.000000, reward total was -16.000000. running mean: -17.907392\n","resetting env. episode 348.000000, reward total was -13.000000. running mean: -17.858318\n","resetting env. episode 349.000000, reward total was -17.000000. running mean: -17.849734\n","resetting env. episode 350.000000, reward total was -20.000000. running mean: -17.871237\n","resetting env. episode 351.000000, reward total was -17.000000. running mean: -17.862525\n","resetting env. episode 352.000000, reward total was -16.000000. running mean: -17.843899\n","resetting env. episode 353.000000, reward total was -17.000000. running mean: -17.835460\n","resetting env. episode 354.000000, reward total was -15.000000. running mean: -17.807106\n","resetting env. episode 355.000000, reward total was -20.000000. running mean: -17.829035\n","resetting env. episode 356.000000, reward total was -19.000000. running mean: -17.840744\n","resetting env. episode 357.000000, reward total was -17.000000. running mean: -17.832337\n","resetting env. episode 358.000000, reward total was -19.000000. running mean: -17.844014\n","resetting env. episode 359.000000, reward total was -19.000000. running mean: -17.855574\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -17.877018\n","resetting env. episode 361.000000, reward total was -18.000000. running mean: -17.878248\n","resetting env. episode 362.000000, reward total was -15.000000. running mean: -17.849465\n","resetting env. episode 363.000000, reward total was -17.000000. running mean: -17.840970\n","resetting env. episode 364.000000, reward total was -17.000000. running mean: -17.832561\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -17.854235\n","resetting env. episode 366.000000, reward total was -19.000000. running mean: -17.865693\n","resetting env. episode 367.000000, reward total was -17.000000. running mean: -17.857036\n","resetting env. episode 368.000000, reward total was -20.000000. running mean: -17.878466\n","resetting env. episode 369.000000, reward total was -19.000000. running mean: -17.889681\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -17.910784\n","resetting env. episode 371.000000, reward total was -13.000000. running mean: -17.861676\n","resetting env. episode 372.000000, reward total was -16.000000. running mean: -17.843059\n","resetting env. episode 373.000000, reward total was -19.000000. running mean: -17.854629\n","resetting env. episode 374.000000, reward total was -19.000000. running mean: -17.866083\n","resetting env. episode 375.000000, reward total was -19.000000. running mean: -17.877422\n","resetting env. episode 376.000000, reward total was -15.000000. running mean: -17.848648\n","resetting env. episode 377.000000, reward total was -16.000000. running mean: -17.830161\n","resetting env. episode 378.000000, reward total was -20.000000. running mean: -17.851859\n","resetting env. episode 379.000000, reward total was -19.000000. running mean: -17.863341\n","resetting env. episode 380.000000, reward total was -19.000000. running mean: -17.874707\n","resetting env. episode 381.000000, reward total was -17.000000. running mean: -17.865960\n","resetting env. episode 382.000000, reward total was -20.000000. running mean: -17.887301\n","resetting env. episode 383.000000, reward total was -17.000000. running mean: -17.878428\n","resetting env. episode 384.000000, reward total was -15.000000. running mean: -17.849643\n","resetting env. episode 385.000000, reward total was -18.000000. running mean: -17.851147\n","resetting env. episode 386.000000, reward total was -18.000000. running mean: -17.852636\n","resetting env. episode 387.000000, reward total was -15.000000. running mean: -17.824109\n","resetting env. episode 388.000000, reward total was -17.000000. running mean: -17.815868\n","resetting env. episode 389.000000, reward total was -15.000000. running mean: -17.787709\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -17.819832\n","resetting env. episode 391.000000, reward total was -17.000000. running mean: -17.811634\n","resetting env. episode 392.000000, reward total was -16.000000. running mean: -17.793518\n","resetting env. episode 393.000000, reward total was -17.000000. running mean: -17.785583\n","resetting env. episode 394.000000, reward total was -18.000000. running mean: -17.787727\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -17.819849\n","resetting env. episode 396.000000, reward total was -17.000000. running mean: -17.811651\n","resetting env. episode 397.000000, reward total was -18.000000. running mean: -17.813534\n","resetting env. episode 398.000000, reward total was -12.000000. running mean: -17.755399\n","resetting env. episode 399.000000, reward total was -14.000000. running mean: -17.717845\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -17.750667\n","resetting env. episode 401.000000, reward total was -16.000000. running mean: -17.733160\n","resetting env. episode 402.000000, reward total was -15.000000. running mean: -17.705828\n","resetting env. episode 403.000000, reward total was -18.000000. running mean: -17.708770\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -17.741682\n","resetting env. episode 405.000000, reward total was -17.000000. running mean: -17.734266\n","resetting env. episode 406.000000, reward total was -17.000000. running mean: -17.726923\n","resetting env. episode 407.000000, reward total was -19.000000. running mean: -17.739654\n","resetting env. episode 408.000000, reward total was -16.000000. running mean: -17.722257\n","resetting env. episode 409.000000, reward total was -17.000000. running mean: -17.715035\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -17.747884\n","resetting env. episode 411.000000, reward total was -17.000000. running mean: -17.740405\n","resetting env. episode 412.000000, reward total was -19.000000. running mean: -17.753001\n","resetting env. episode 413.000000, reward total was -19.000000. running mean: -17.765471\n","resetting env. episode 414.000000, reward total was -13.000000. running mean: -17.717817\n","resetting env. episode 415.000000, reward total was -16.000000. running mean: -17.700638\n","resetting env. episode 416.000000, reward total was -17.000000. running mean: -17.693632\n","resetting env. episode 417.000000, reward total was -15.000000. running mean: -17.666696\n","resetting env. episode 418.000000, reward total was -19.000000. running mean: -17.680029\n","resetting env. episode 419.000000, reward total was -19.000000. running mean: -17.693228\n","resetting env. episode 420.000000, reward total was -13.000000. running mean: -17.646296\n","resetting env. episode 421.000000, reward total was -16.000000. running mean: -17.629833\n","resetting env. episode 422.000000, reward total was -19.000000. running mean: -17.643535\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -17.667100\n","resetting env. episode 424.000000, reward total was -11.000000. running mean: -17.600429\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -17.624424\n","resetting env. episode 426.000000, reward total was -16.000000. running mean: -17.608180\n","resetting env. episode 427.000000, reward total was -15.000000. running mean: -17.582098\n","resetting env. episode 428.000000, reward total was -19.000000. running mean: -17.596277\n","resetting env. episode 429.000000, reward total was -15.000000. running mean: -17.570314\n","resetting env. episode 430.000000, reward total was -16.000000. running mean: -17.554611\n","resetting env. episode 431.000000, reward total was -20.000000. running mean: -17.579065\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -17.613275\n","resetting env. episode 433.000000, reward total was -19.000000. running mean: -17.627142\n","resetting env. episode 434.000000, reward total was -13.000000. running mean: -17.580870\n","resetting env. episode 435.000000, reward total was -19.000000. running mean: -17.595062\n","resetting env. episode 436.000000, reward total was -17.000000. running mean: -17.589111\n","resetting env. episode 437.000000, reward total was -16.000000. running mean: -17.573220\n","resetting env. episode 438.000000, reward total was -18.000000. running mean: -17.577488\n","resetting env. episode 439.000000, reward total was -16.000000. running mean: -17.561713\n","resetting env. episode 440.000000, reward total was -18.000000. running mean: -17.566096\n","resetting env. episode 441.000000, reward total was -16.000000. running mean: -17.550435\n","resetting env. episode 442.000000, reward total was -19.000000. running mean: -17.564930\n","resetting env. episode 443.000000, reward total was -14.000000. running mean: -17.529281\n","resetting env. episode 444.000000, reward total was -18.000000. running mean: -17.533988\n","resetting env. episode 445.000000, reward total was -19.000000. running mean: -17.548648\n","resetting env. episode 446.000000, reward total was -13.000000. running mean: -17.503162\n","resetting env. episode 447.000000, reward total was -18.000000. running mean: -17.508130\n","resetting env. episode 448.000000, reward total was -19.000000. running mean: -17.523049\n","resetting env. episode 449.000000, reward total was -17.000000. running mean: -17.517819\n","resetting env. episode 450.000000, reward total was -14.000000. running mean: -17.482640\n","resetting env. episode 451.000000, reward total was -19.000000. running mean: -17.497814\n","resetting env. episode 452.000000, reward total was -14.000000. running mean: -17.462836\n","resetting env. episode 453.000000, reward total was -17.000000. running mean: -17.458207\n","resetting env. episode 454.000000, reward total was -18.000000. running mean: -17.463625\n","resetting env. episode 455.000000, reward total was -17.000000. running mean: -17.458989\n","resetting env. episode 456.000000, reward total was -18.000000. running mean: -17.464399\n","resetting env. episode 457.000000, reward total was -18.000000. running mean: -17.469755\n","resetting env. episode 458.000000, reward total was -16.000000. running mean: -17.455058\n","resetting env. episode 459.000000, reward total was -16.000000. running mean: -17.440507\n","resetting env. episode 460.000000, reward total was -13.000000. running mean: -17.396102\n","resetting env. episode 461.000000, reward total was -16.000000. running mean: -17.382141\n","resetting env. episode 462.000000, reward total was -17.000000. running mean: -17.378320\n","resetting env. episode 463.000000, reward total was -17.000000. running mean: -17.374536\n","resetting env. episode 464.000000, reward total was -20.000000. running mean: -17.400791\n","resetting env. episode 465.000000, reward total was -19.000000. running mean: -17.416783\n","resetting env. episode 466.000000, reward total was -13.000000. running mean: -17.372615\n","resetting env. episode 467.000000, reward total was -11.000000. running mean: -17.308889\n","resetting env. episode 468.000000, reward total was -19.000000. running mean: -17.325800\n","resetting env. episode 469.000000, reward total was -17.000000. running mean: -17.322542\n","resetting env. episode 470.000000, reward total was -14.000000. running mean: -17.289317\n","resetting env. episode 471.000000, reward total was -18.000000. running mean: -17.296424\n","resetting env. episode 472.000000, reward total was -16.000000. running mean: -17.283459\n","resetting env. episode 473.000000, reward total was -15.000000. running mean: -17.260625\n","resetting env. episode 474.000000, reward total was -17.000000. running mean: -17.258019\n","resetting env. episode 475.000000, reward total was -12.000000. running mean: -17.205438\n","resetting env. episode 476.000000, reward total was -14.000000. running mean: -17.173384\n","resetting env. episode 477.000000, reward total was -13.000000. running mean: -17.131650\n","resetting env. episode 478.000000, reward total was -18.000000. running mean: -17.140334\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -17.168930\n","resetting env. episode 480.000000, reward total was -19.000000. running mean: -17.187241\n","resetting env. episode 481.000000, reward total was -17.000000. running mean: -17.185369\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -17.213515\n","resetting env. episode 483.000000, reward total was -14.000000. running mean: -17.181380\n","resetting env. episode 484.000000, reward total was -20.000000. running mean: -17.209566\n","resetting env. episode 485.000000, reward total was -15.000000. running mean: -17.187470\n","resetting env. episode 486.000000, reward total was -15.000000. running mean: -17.165596\n","resetting env. episode 487.000000, reward total was -16.000000. running mean: -17.153940\n","resetting env. episode 488.000000, reward total was -19.000000. running mean: -17.172400\n","resetting env. episode 489.000000, reward total was -17.000000. running mean: -17.170676\n","resetting env. episode 490.000000, reward total was -17.000000. running mean: -17.168970\n","resetting env. episode 491.000000, reward total was -18.000000. running mean: -17.177280\n","resetting env. episode 492.000000, reward total was -20.000000. running mean: -17.205507\n","resetting env. episode 493.000000, reward total was -16.000000. running mean: -17.193452\n","resetting env. episode 494.000000, reward total was -19.000000. running mean: -17.211517\n","resetting env. episode 495.000000, reward total was -16.000000. running mean: -17.199402\n","resetting env. episode 496.000000, reward total was -16.000000. running mean: -17.187408\n","resetting env. episode 497.000000, reward total was -16.000000. running mean: -17.175534\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -17.213779\n","resetting env. episode 499.000000, reward total was -18.000000. running mean: -17.221641\n","resetting env. episode 500.000000, reward total was -17.000000. running mean: -17.219425\n","CPU times: user 52min 53s, sys: 24min 44s, total: 1h 17min 37s\n","Wall time: 39min 52s\n"]}]},{"metadata":{"id":"8fheN9DRlWXQ","outputId":"b8c94d5e-0555-4e72-a748-8e4307f45501","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1660742367835,"user_tz":-330,"elapsed":40996,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -3.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"id":"9AxOcQhIsKow","outputId":"9967521c-0d59-4f55-b8c2-b2ee6f3cf1c1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660754244046,"user_tz":-330,"elapsed":11876221,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist3 = train_model(env, model, total_episodes=1500)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -12.000000. running mean: -12.000000\n","resetting env. episode 2.000000, reward total was -17.000000. running mean: -12.050000\n","resetting env. episode 3.000000, reward total was -17.000000. running mean: -12.099500\n","resetting env. episode 4.000000, reward total was -15.000000. running mean: -12.128505\n","resetting env. episode 5.000000, reward total was -19.000000. running mean: -12.197220\n","resetting env. episode 6.000000, reward total was -12.000000. running mean: -12.195248\n","resetting env. episode 7.000000, reward total was -19.000000. running mean: -12.263295\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -12.350662\n","resetting env. episode 9.000000, reward total was -16.000000. running mean: -12.387156\n","resetting env. episode 10.000000, reward total was -17.000000. running mean: -12.433284\n","resetting env. episode 11.000000, reward total was -17.000000. running mean: -12.478951\n","resetting env. episode 12.000000, reward total was -16.000000. running mean: -12.514162\n","resetting env. episode 13.000000, reward total was -13.000000. running mean: -12.519020\n","resetting env. episode 14.000000, reward total was -15.000000. running mean: -12.543830\n","resetting env. episode 15.000000, reward total was -13.000000. running mean: -12.548392\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -12.632908\n","resetting env. episode 17.000000, reward total was -16.000000. running mean: -12.666579\n","resetting env. episode 18.000000, reward total was -17.000000. running mean: -12.709913\n","resetting env. episode 19.000000, reward total was -17.000000. running mean: -12.752814\n","resetting env. episode 20.000000, reward total was -16.000000. running mean: -12.785286\n","resetting env. episode 21.000000, reward total was -19.000000. running mean: -12.847433\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -12.928958\n","resetting env. episode 23.000000, reward total was -16.000000. running mean: -12.959669\n","resetting env. episode 24.000000, reward total was -15.000000. running mean: -12.980072\n","resetting env. episode 25.000000, reward total was -19.000000. running mean: -13.040271\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -13.119869\n","resetting env. episode 27.000000, reward total was -19.000000. running mean: -13.178670\n","resetting env. episode 28.000000, reward total was -16.000000. running mean: -13.206883\n","resetting env. episode 29.000000, reward total was -18.000000. running mean: -13.254815\n","resetting env. episode 30.000000, reward total was -19.000000. running mean: -13.312266\n","resetting env. episode 31.000000, reward total was -12.000000. running mean: -13.299144\n","resetting env. episode 32.000000, reward total was -20.000000. running mean: -13.366152\n","resetting env. episode 33.000000, reward total was -20.000000. running mean: -13.432491\n","resetting env. episode 34.000000, reward total was -15.000000. running mean: -13.448166\n","resetting env. episode 35.000000, reward total was -19.000000. running mean: -13.503684\n","resetting env. episode 36.000000, reward total was -17.000000. running mean: -13.538647\n","resetting env. episode 37.000000, reward total was -19.000000. running mean: -13.593261\n","resetting env. episode 38.000000, reward total was -12.000000. running mean: -13.577328\n","resetting env. episode 39.000000, reward total was -17.000000. running mean: -13.611555\n","resetting env. episode 40.000000, reward total was -19.000000. running mean: -13.665439\n","resetting env. episode 41.000000, reward total was -18.000000. running mean: -13.708785\n","resetting env. episode 42.000000, reward total was -18.000000. running mean: -13.751697\n","resetting env. episode 43.000000, reward total was -17.000000. running mean: -13.784180\n","resetting env. episode 44.000000, reward total was -17.000000. running mean: -13.816338\n","resetting env. episode 45.000000, reward total was -15.000000. running mean: -13.828175\n","resetting env. episode 46.000000, reward total was -14.000000. running mean: -13.829893\n","resetting env. episode 47.000000, reward total was -13.000000. running mean: -13.821594\n","resetting env. episode 48.000000, reward total was -18.000000. running mean: -13.863378\n","resetting env. episode 49.000000, reward total was -17.000000. running mean: -13.894745\n","resetting env. episode 50.000000, reward total was -17.000000. running mean: -13.925797\n","resetting env. episode 51.000000, reward total was -18.000000. running mean: -13.966539\n","resetting env. episode 52.000000, reward total was -19.000000. running mean: -14.016874\n","resetting env. episode 53.000000, reward total was -17.000000. running mean: -14.046705\n","resetting env. episode 54.000000, reward total was -15.000000. running mean: -14.056238\n","resetting env. episode 55.000000, reward total was -13.000000. running mean: -14.045676\n","resetting env. episode 56.000000, reward total was -18.000000. running mean: -14.085219\n","resetting env. episode 57.000000, reward total was -18.000000. running mean: -14.124367\n","resetting env. episode 58.000000, reward total was -18.000000. running mean: -14.163123\n","resetting env. episode 59.000000, reward total was -15.000000. running mean: -14.171492\n","resetting env. episode 60.000000, reward total was -19.000000. running mean: -14.219777\n","resetting env. episode 61.000000, reward total was -13.000000. running mean: -14.207579\n","resetting env. episode 62.000000, reward total was -18.000000. running mean: -14.245503\n","resetting env. episode 63.000000, reward total was -9.000000. running mean: -14.193048\n","resetting env. episode 64.000000, reward total was -14.000000. running mean: -14.191118\n","resetting env. episode 65.000000, reward total was -18.000000. running mean: -14.229207\n","resetting env. episode 66.000000, reward total was -18.000000. running mean: -14.266915\n","resetting env. episode 67.000000, reward total was -19.000000. running mean: -14.314245\n","resetting env. episode 68.000000, reward total was -19.000000. running mean: -14.361103\n","resetting env. episode 69.000000, reward total was -16.000000. running mean: -14.377492\n","resetting env. episode 70.000000, reward total was -19.000000. running mean: -14.423717\n","resetting env. episode 71.000000, reward total was -14.000000. running mean: -14.419480\n","resetting env. episode 72.000000, reward total was -17.000000. running mean: -14.445285\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -14.500832\n","resetting env. episode 74.000000, reward total was -13.000000. running mean: -14.485824\n","resetting env. episode 75.000000, reward total was -13.000000. running mean: -14.470966\n","resetting env. episode 76.000000, reward total was -17.000000. running mean: -14.496256\n","resetting env. episode 77.000000, reward total was -16.000000. running mean: -14.511293\n","resetting env. episode 78.000000, reward total was -14.000000. running mean: -14.506180\n","resetting env. episode 79.000000, reward total was -17.000000. running mean: -14.531119\n","resetting env. episode 80.000000, reward total was -19.000000. running mean: -14.575807\n","resetting env. episode 81.000000, reward total was -15.000000. running mean: -14.580049\n","resetting env. episode 82.000000, reward total was -19.000000. running mean: -14.624249\n","resetting env. episode 83.000000, reward total was -13.000000. running mean: -14.608006\n","resetting env. episode 84.000000, reward total was -13.000000. running mean: -14.591926\n","resetting env. episode 85.000000, reward total was -18.000000. running mean: -14.626007\n","resetting env. episode 86.000000, reward total was -17.000000. running mean: -14.649747\n","resetting env. episode 87.000000, reward total was -15.000000. running mean: -14.653250\n","resetting env. episode 88.000000, reward total was -9.000000. running mean: -14.596717\n","resetting env. episode 89.000000, reward total was -15.000000. running mean: -14.600750\n","resetting env. episode 90.000000, reward total was -9.000000. running mean: -14.544742\n","resetting env. episode 91.000000, reward total was -10.000000. running mean: -14.499295\n","resetting env. episode 92.000000, reward total was -16.000000. running mean: -14.514302\n","resetting env. episode 93.000000, reward total was -13.000000. running mean: -14.499159\n","resetting env. episode 94.000000, reward total was -19.000000. running mean: -14.544167\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -14.608726\n","resetting env. episode 96.000000, reward total was -17.000000. running mean: -14.632638\n","resetting env. episode 97.000000, reward total was -15.000000. running mean: -14.636312\n","resetting env. episode 98.000000, reward total was -17.000000. running mean: -14.659949\n","resetting env. episode 99.000000, reward total was -17.000000. running mean: -14.683349\n","resetting env. episode 100.000000, reward total was -18.000000. running mean: -14.716516\n","resetting env. episode 101.000000, reward total was -14.000000. running mean: -14.709351\n","resetting env. episode 102.000000, reward total was -13.000000. running mean: -14.692257\n","resetting env. episode 103.000000, reward total was -19.000000. running mean: -14.735335\n","resetting env. episode 104.000000, reward total was -18.000000. running mean: -14.767981\n","resetting env. episode 105.000000, reward total was -17.000000. running mean: -14.790302\n","resetting env. episode 106.000000, reward total was -16.000000. running mean: -14.802399\n","resetting env. episode 107.000000, reward total was -18.000000. running mean: -14.834375\n","resetting env. episode 108.000000, reward total was -16.000000. running mean: -14.846031\n","resetting env. episode 109.000000, reward total was -19.000000. running mean: -14.887571\n","resetting env. episode 110.000000, reward total was -17.000000. running mean: -14.908695\n","resetting env. episode 111.000000, reward total was -17.000000. running mean: -14.929608\n","resetting env. episode 112.000000, reward total was -18.000000. running mean: -14.960312\n","resetting env. episode 113.000000, reward total was -15.000000. running mean: -14.960709\n","resetting env. episode 114.000000, reward total was -17.000000. running mean: -14.981102\n","resetting env. episode 115.000000, reward total was -16.000000. running mean: -14.991291\n","resetting env. episode 116.000000, reward total was -14.000000. running mean: -14.981378\n","resetting env. episode 117.000000, reward total was -17.000000. running mean: -15.001564\n","resetting env. episode 118.000000, reward total was -19.000000. running mean: -15.041548\n","resetting env. episode 119.000000, reward total was -18.000000. running mean: -15.071133\n","resetting env. episode 120.000000, reward total was -19.000000. running mean: -15.110421\n","resetting env. episode 121.000000, reward total was -15.000000. running mean: -15.109317\n","resetting env. episode 122.000000, reward total was -17.000000. running mean: -15.128224\n","resetting env. episode 123.000000, reward total was -17.000000. running mean: -15.146942\n","resetting env. episode 124.000000, reward total was -13.000000. running mean: -15.125472\n","resetting env. episode 125.000000, reward total was -10.000000. running mean: -15.074218\n","resetting env. episode 126.000000, reward total was -17.000000. running mean: -15.093475\n","resetting env. episode 127.000000, reward total was -19.000000. running mean: -15.132541\n","resetting env. episode 128.000000, reward total was -16.000000. running mean: -15.141215\n","resetting env. episode 129.000000, reward total was -15.000000. running mean: -15.139803\n","resetting env. episode 130.000000, reward total was -14.000000. running mean: -15.128405\n","resetting env. episode 131.000000, reward total was -17.000000. running mean: -15.147121\n","resetting env. episode 132.000000, reward total was -10.000000. running mean: -15.095650\n","resetting env. episode 133.000000, reward total was -16.000000. running mean: -15.104693\n","resetting env. episode 134.000000, reward total was -14.000000. running mean: -15.093646\n","resetting env. episode 135.000000, reward total was -19.000000. running mean: -15.132710\n","resetting env. episode 136.000000, reward total was -7.000000. running mean: -15.051383\n","resetting env. episode 137.000000, reward total was -15.000000. running mean: -15.050869\n","resetting env. episode 138.000000, reward total was -17.000000. running mean: -15.070360\n","resetting env. episode 139.000000, reward total was -13.000000. running mean: -15.049657\n","resetting env. episode 140.000000, reward total was -16.000000. running mean: -15.059160\n","resetting env. episode 141.000000, reward total was -19.000000. running mean: -15.098569\n","resetting env. episode 142.000000, reward total was -14.000000. running mean: -15.087583\n","resetting env. episode 143.000000, reward total was -16.000000. running mean: -15.096707\n","resetting env. episode 144.000000, reward total was -18.000000. running mean: -15.125740\n","resetting env. episode 145.000000, reward total was -12.000000. running mean: -15.094483\n","resetting env. episode 146.000000, reward total was -18.000000. running mean: -15.123538\n","resetting env. episode 147.000000, reward total was -13.000000. running mean: -15.102302\n","resetting env. episode 148.000000, reward total was -17.000000. running mean: -15.121279\n","resetting env. episode 149.000000, reward total was -17.000000. running mean: -15.140067\n","resetting env. episode 150.000000, reward total was -19.000000. running mean: -15.178666\n","resetting env. episode 151.000000, reward total was -15.000000. running mean: -15.176879\n","resetting env. episode 152.000000, reward total was -19.000000. running mean: -15.215110\n","resetting env. episode 153.000000, reward total was -16.000000. running mean: -15.222959\n","resetting env. episode 154.000000, reward total was -17.000000. running mean: -15.240730\n","resetting env. episode 155.000000, reward total was -19.000000. running mean: -15.278322\n","resetting env. episode 156.000000, reward total was -13.000000. running mean: -15.255539\n","resetting env. episode 157.000000, reward total was -11.000000. running mean: -15.212984\n","resetting env. episode 158.000000, reward total was -13.000000. running mean: -15.190854\n","resetting env. episode 159.000000, reward total was -19.000000. running mean: -15.228945\n","resetting env. episode 160.000000, reward total was -14.000000. running mean: -15.216656\n","resetting env. episode 161.000000, reward total was -20.000000. running mean: -15.264489\n","resetting env. episode 162.000000, reward total was -14.000000. running mean: -15.251845\n","resetting env. episode 163.000000, reward total was -17.000000. running mean: -15.269326\n","resetting env. episode 164.000000, reward total was -17.000000. running mean: -15.286633\n","resetting env. episode 165.000000, reward total was -17.000000. running mean: -15.303767\n","resetting env. episode 166.000000, reward total was -17.000000. running mean: -15.320729\n","resetting env. episode 167.000000, reward total was -17.000000. running mean: -15.337522\n","resetting env. episode 168.000000, reward total was -15.000000. running mean: -15.334146\n","resetting env. episode 169.000000, reward total was -19.000000. running mean: -15.370805\n","resetting env. episode 170.000000, reward total was -17.000000. running mean: -15.387097\n","resetting env. episode 171.000000, reward total was -19.000000. running mean: -15.423226\n","resetting env. episode 172.000000, reward total was -13.000000. running mean: -15.398994\n","resetting env. episode 173.000000, reward total was -17.000000. running mean: -15.415004\n","resetting env. episode 174.000000, reward total was -16.000000. running mean: -15.420854\n","resetting env. episode 175.000000, reward total was -17.000000. running mean: -15.436645\n","resetting env. episode 176.000000, reward total was -12.000000. running mean: -15.402279\n","resetting env. episode 177.000000, reward total was -13.000000. running mean: -15.378256\n","resetting env. episode 178.000000, reward total was -19.000000. running mean: -15.414473\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -15.470329\n","resetting env. episode 180.000000, reward total was -16.000000. running mean: -15.475625\n","resetting env. episode 181.000000, reward total was -16.000000. running mean: -15.480869\n","resetting env. episode 182.000000, reward total was -15.000000. running mean: -15.476060\n","resetting env. episode 183.000000, reward total was -17.000000. running mean: -15.491300\n","resetting env. episode 184.000000, reward total was -18.000000. running mean: -15.516387\n","resetting env. episode 185.000000, reward total was -13.000000. running mean: -15.491223\n","resetting env. episode 186.000000, reward total was -15.000000. running mean: -15.486311\n","resetting env. episode 187.000000, reward total was -19.000000. running mean: -15.521448\n","resetting env. episode 188.000000, reward total was -17.000000. running mean: -15.536233\n","resetting env. episode 189.000000, reward total was -19.000000. running mean: -15.570871\n","resetting env. episode 190.000000, reward total was -16.000000. running mean: -15.575162\n","resetting env. episode 191.000000, reward total was -20.000000. running mean: -15.619410\n","resetting env. episode 192.000000, reward total was -17.000000. running mean: -15.633216\n","resetting env. episode 193.000000, reward total was -17.000000. running mean: -15.646884\n","resetting env. episode 194.000000, reward total was -13.000000. running mean: -15.620415\n","resetting env. episode 195.000000, reward total was -9.000000. running mean: -15.554211\n","resetting env. episode 196.000000, reward total was -16.000000. running mean: -15.558669\n","resetting env. episode 197.000000, reward total was -14.000000. running mean: -15.543082\n","resetting env. episode 198.000000, reward total was -12.000000. running mean: -15.507652\n","resetting env. episode 199.000000, reward total was -17.000000. running mean: -15.522575\n","resetting env. episode 200.000000, reward total was -19.000000. running mean: -15.557349\n","resetting env. episode 201.000000, reward total was -14.000000. running mean: -15.541776\n","resetting env. episode 202.000000, reward total was -19.000000. running mean: -15.576358\n","resetting env. episode 203.000000, reward total was -12.000000. running mean: -15.540594\n","resetting env. episode 204.000000, reward total was -17.000000. running mean: -15.555188\n","resetting env. episode 205.000000, reward total was -10.000000. running mean: -15.499637\n","resetting env. episode 206.000000, reward total was -15.000000. running mean: -15.494640\n","resetting env. episode 207.000000, reward total was -15.000000. running mean: -15.489694\n","resetting env. episode 208.000000, reward total was -17.000000. running mean: -15.504797\n","resetting env. episode 209.000000, reward total was -12.000000. running mean: -15.469749\n","resetting env. episode 210.000000, reward total was -16.000000. running mean: -15.475051\n","resetting env. episode 211.000000, reward total was -17.000000. running mean: -15.490301\n","resetting env. episode 212.000000, reward total was -19.000000. running mean: -15.525398\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -15.580144\n","resetting env. episode 214.000000, reward total was -13.000000. running mean: -15.554342\n","resetting env. episode 215.000000, reward total was -14.000000. running mean: -15.538799\n","resetting env. episode 216.000000, reward total was -14.000000. running mean: -15.523411\n","resetting env. episode 217.000000, reward total was -17.000000. running mean: -15.538177\n","resetting env. episode 218.000000, reward total was -15.000000. running mean: -15.532795\n","resetting env. episode 219.000000, reward total was -11.000000. running mean: -15.487467\n","resetting env. episode 220.000000, reward total was -16.000000. running mean: -15.492593\n","resetting env. episode 221.000000, reward total was -17.000000. running mean: -15.507667\n","resetting env. episode 222.000000, reward total was -13.000000. running mean: -15.482590\n","resetting env. episode 223.000000, reward total was -15.000000. running mean: -15.477764\n","resetting env. episode 224.000000, reward total was -18.000000. running mean: -15.502986\n","resetting env. episode 225.000000, reward total was -14.000000. running mean: -15.487957\n","resetting env. episode 226.000000, reward total was -17.000000. running mean: -15.503077\n","resetting env. episode 227.000000, reward total was -16.000000. running mean: -15.508046\n","resetting env. episode 228.000000, reward total was -15.000000. running mean: -15.502966\n","resetting env. episode 229.000000, reward total was -13.000000. running mean: -15.477936\n","resetting env. episode 230.000000, reward total was -14.000000. running mean: -15.463157\n","resetting env. episode 231.000000, reward total was -17.000000. running mean: -15.478525\n","resetting env. episode 232.000000, reward total was -19.000000. running mean: -15.513740\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -15.568603\n","resetting env. episode 234.000000, reward total was -14.000000. running mean: -15.552917\n","resetting env. episode 235.000000, reward total was -14.000000. running mean: -15.537387\n","resetting env. episode 236.000000, reward total was -17.000000. running mean: -15.552013\n","resetting env. episode 237.000000, reward total was -13.000000. running mean: -15.526493\n","resetting env. episode 238.000000, reward total was -19.000000. running mean: -15.561228\n","resetting env. episode 239.000000, reward total was -16.000000. running mean: -15.565616\n","resetting env. episode 240.000000, reward total was -17.000000. running mean: -15.579960\n","resetting env. episode 241.000000, reward total was -17.000000. running mean: -15.594160\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -15.638219\n","resetting env. episode 243.000000, reward total was -17.000000. running mean: -15.651837\n","resetting env. episode 244.000000, reward total was -13.000000. running mean: -15.625318\n","resetting env. episode 245.000000, reward total was -17.000000. running mean: -15.639065\n","resetting env. episode 246.000000, reward total was -15.000000. running mean: -15.632674\n","resetting env. episode 247.000000, reward total was -19.000000. running mean: -15.666348\n","resetting env. episode 248.000000, reward total was -12.000000. running mean: -15.629684\n","resetting env. episode 249.000000, reward total was -13.000000. running mean: -15.603387\n","resetting env. episode 250.000000, reward total was -13.000000. running mean: -15.577353\n","resetting env. episode 251.000000, reward total was -14.000000. running mean: -15.561580\n","resetting env. episode 252.000000, reward total was -17.000000. running mean: -15.575964\n","resetting env. episode 253.000000, reward total was -18.000000. running mean: -15.600204\n","resetting env. episode 254.000000, reward total was -11.000000. running mean: -15.554202\n","resetting env. episode 255.000000, reward total was -19.000000. running mean: -15.588660\n","resetting env. episode 256.000000, reward total was -18.000000. running mean: -15.612774\n","resetting env. episode 257.000000, reward total was -15.000000. running mean: -15.606646\n","resetting env. episode 258.000000, reward total was -15.000000. running mean: -15.600580\n","resetting env. episode 259.000000, reward total was -15.000000. running mean: -15.594574\n","resetting env. episode 260.000000, reward total was -11.000000. running mean: -15.548628\n","resetting env. episode 261.000000, reward total was -16.000000. running mean: -15.553142\n","resetting env. episode 262.000000, reward total was -15.000000. running mean: -15.547610\n","resetting env. episode 263.000000, reward total was -19.000000. running mean: -15.582134\n","resetting env. episode 264.000000, reward total was -14.000000. running mean: -15.566313\n","resetting env. episode 265.000000, reward total was -17.000000. running mean: -15.580650\n","resetting env. episode 266.000000, reward total was -13.000000. running mean: -15.554843\n","resetting env. episode 267.000000, reward total was -15.000000. running mean: -15.549295\n","resetting env. episode 268.000000, reward total was -16.000000. running mean: -15.553802\n","resetting env. episode 269.000000, reward total was -19.000000. running mean: -15.588264\n","resetting env. episode 270.000000, reward total was -17.000000. running mean: -15.602381\n","resetting env. episode 271.000000, reward total was -12.000000. running mean: -15.566357\n","resetting env. episode 272.000000, reward total was -15.000000. running mean: -15.560694\n","resetting env. episode 273.000000, reward total was -19.000000. running mean: -15.595087\n","resetting env. episode 274.000000, reward total was -12.000000. running mean: -15.559136\n","resetting env. episode 275.000000, reward total was -14.000000. running mean: -15.543545\n","resetting env. episode 276.000000, reward total was -15.000000. running mean: -15.538109\n","resetting env. episode 277.000000, reward total was -12.000000. running mean: -15.502728\n","resetting env. episode 278.000000, reward total was -19.000000. running mean: -15.537701\n","resetting env. episode 279.000000, reward total was -19.000000. running mean: -15.572324\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -15.626601\n","resetting env. episode 281.000000, reward total was -14.000000. running mean: -15.610335\n","resetting env. episode 282.000000, reward total was -18.000000. running mean: -15.634231\n","resetting env. episode 283.000000, reward total was -13.000000. running mean: -15.607889\n","resetting env. episode 284.000000, reward total was -18.000000. running mean: -15.631810\n","resetting env. episode 285.000000, reward total was -18.000000. running mean: -15.655492\n","resetting env. episode 286.000000, reward total was -15.000000. running mean: -15.648937\n","resetting env. episode 287.000000, reward total was -13.000000. running mean: -15.622448\n","resetting env. episode 288.000000, reward total was -16.000000. running mean: -15.626223\n","resetting env. episode 289.000000, reward total was -16.000000. running mean: -15.629961\n","resetting env. episode 290.000000, reward total was -16.000000. running mean: -15.633661\n","resetting env. episode 291.000000, reward total was -13.000000. running mean: -15.607325\n","resetting env. episode 292.000000, reward total was -17.000000. running mean: -15.621252\n","resetting env. episode 293.000000, reward total was -14.000000. running mean: -15.605039\n","resetting env. episode 294.000000, reward total was -18.000000. running mean: -15.628989\n","resetting env. episode 295.000000, reward total was -19.000000. running mean: -15.662699\n","resetting env. episode 296.000000, reward total was -18.000000. running mean: -15.686072\n","resetting env. episode 297.000000, reward total was -17.000000. running mean: -15.699211\n","resetting env. episode 298.000000, reward total was -19.000000. running mean: -15.732219\n","resetting env. episode 299.000000, reward total was -19.000000. running mean: -15.764897\n","resetting env. episode 300.000000, reward total was -17.000000. running mean: -15.777248\n","resetting env. episode 301.000000, reward total was -15.000000. running mean: -15.769475\n","resetting env. episode 302.000000, reward total was -19.000000. running mean: -15.801781\n","resetting env. episode 303.000000, reward total was -15.000000. running mean: -15.793763\n","resetting env. episode 304.000000, reward total was -17.000000. running mean: -15.805825\n","resetting env. episode 305.000000, reward total was -18.000000. running mean: -15.827767\n","resetting env. episode 306.000000, reward total was -16.000000. running mean: -15.829489\n","resetting env. episode 307.000000, reward total was -15.000000. running mean: -15.821194\n","resetting env. episode 308.000000, reward total was -17.000000. running mean: -15.832982\n","resetting env. episode 309.000000, reward total was -16.000000. running mean: -15.834653\n","resetting env. episode 310.000000, reward total was -13.000000. running mean: -15.806306\n","resetting env. episode 311.000000, reward total was -11.000000. running mean: -15.758243\n","resetting env. episode 312.000000, reward total was -10.000000. running mean: -15.700660\n","resetting env. episode 313.000000, reward total was -13.000000. running mean: -15.673654\n","resetting env. episode 314.000000, reward total was -15.000000. running mean: -15.666917\n","resetting env. episode 315.000000, reward total was -19.000000. running mean: -15.700248\n","resetting env. episode 316.000000, reward total was -17.000000. running mean: -15.713246\n","resetting env. episode 317.000000, reward total was -17.000000. running mean: -15.726113\n","resetting env. episode 318.000000, reward total was -17.000000. running mean: -15.738852\n","resetting env. episode 319.000000, reward total was -19.000000. running mean: -15.771464\n","resetting env. episode 320.000000, reward total was -18.000000. running mean: -15.793749\n","resetting env. episode 321.000000, reward total was -16.000000. running mean: -15.795811\n","resetting env. episode 322.000000, reward total was -21.000000. running mean: -15.847853\n","resetting env. episode 323.000000, reward total was -13.000000. running mean: -15.819375\n","resetting env. episode 324.000000, reward total was -16.000000. running mean: -15.821181\n","resetting env. episode 325.000000, reward total was -19.000000. running mean: -15.852969\n","resetting env. episode 326.000000, reward total was -14.000000. running mean: -15.834440\n","resetting env. episode 327.000000, reward total was -11.000000. running mean: -15.786095\n","resetting env. episode 328.000000, reward total was -12.000000. running mean: -15.748234\n","resetting env. episode 329.000000, reward total was -19.000000. running mean: -15.780752\n","resetting env. episode 330.000000, reward total was -16.000000. running mean: -15.782944\n","resetting env. episode 331.000000, reward total was -13.000000. running mean: -15.755115\n","resetting env. episode 332.000000, reward total was -12.000000. running mean: -15.717564\n","resetting env. episode 333.000000, reward total was -16.000000. running mean: -15.720388\n","resetting env. episode 334.000000, reward total was -15.000000. running mean: -15.713184\n","resetting env. episode 335.000000, reward total was -12.000000. running mean: -15.676052\n","resetting env. episode 336.000000, reward total was -11.000000. running mean: -15.629292\n","resetting env. episode 337.000000, reward total was -13.000000. running mean: -15.602999\n","resetting env. episode 338.000000, reward total was -17.000000. running mean: -15.616969\n","resetting env. episode 339.000000, reward total was -14.000000. running mean: -15.600799\n","resetting env. episode 340.000000, reward total was -16.000000. running mean: -15.604791\n","resetting env. episode 341.000000, reward total was -16.000000. running mean: -15.608743\n","resetting env. episode 342.000000, reward total was -18.000000. running mean: -15.632656\n","resetting env. episode 343.000000, reward total was -17.000000. running mean: -15.646329\n","resetting env. episode 344.000000, reward total was -12.000000. running mean: -15.609866\n","resetting env. episode 345.000000, reward total was -18.000000. running mean: -15.633767\n","resetting env. episode 346.000000, reward total was -8.000000. running mean: -15.557430\n","resetting env. episode 347.000000, reward total was -19.000000. running mean: -15.591855\n","resetting env. episode 348.000000, reward total was -20.000000. running mean: -15.635937\n","resetting env. episode 349.000000, reward total was -13.000000. running mean: -15.609578\n","resetting env. episode 350.000000, reward total was -9.000000. running mean: -15.543482\n","resetting env. episode 351.000000, reward total was -19.000000. running mean: -15.578047\n","resetting env. episode 352.000000, reward total was -13.000000. running mean: -15.552266\n","resetting env. episode 353.000000, reward total was -17.000000. running mean: -15.566744\n","resetting env. episode 354.000000, reward total was -16.000000. running mean: -15.571076\n","resetting env. episode 355.000000, reward total was -19.000000. running mean: -15.605366\n","resetting env. episode 356.000000, reward total was -18.000000. running mean: -15.629312\n","resetting env. episode 357.000000, reward total was -16.000000. running mean: -15.633019\n","resetting env. episode 358.000000, reward total was -17.000000. running mean: -15.646689\n","resetting env. episode 359.000000, reward total was -16.000000. running mean: -15.650222\n","resetting env. episode 360.000000, reward total was -15.000000. running mean: -15.643720\n","resetting env. episode 361.000000, reward total was -15.000000. running mean: -15.637282\n","resetting env. episode 362.000000, reward total was -13.000000. running mean: -15.610910\n","resetting env. episode 363.000000, reward total was -9.000000. running mean: -15.544800\n","resetting env. episode 364.000000, reward total was -13.000000. running mean: -15.519352\n","resetting env. episode 365.000000, reward total was -19.000000. running mean: -15.554159\n","resetting env. episode 366.000000, reward total was -18.000000. running mean: -15.578617\n","resetting env. episode 367.000000, reward total was -13.000000. running mean: -15.552831\n","resetting env. episode 368.000000, reward total was -18.000000. running mean: -15.577303\n","resetting env. episode 369.000000, reward total was -17.000000. running mean: -15.591530\n","resetting env. episode 370.000000, reward total was -12.000000. running mean: -15.555614\n","resetting env. episode 371.000000, reward total was -16.000000. running mean: -15.560058\n","resetting env. episode 372.000000, reward total was -19.000000. running mean: -15.594458\n","resetting env. episode 373.000000, reward total was -15.000000. running mean: -15.588513\n","resetting env. episode 374.000000, reward total was -16.000000. running mean: -15.592628\n","resetting env. episode 375.000000, reward total was -14.000000. running mean: -15.576702\n","resetting env. episode 376.000000, reward total was -15.000000. running mean: -15.570935\n","resetting env. episode 377.000000, reward total was -16.000000. running mean: -15.575225\n","resetting env. episode 378.000000, reward total was -17.000000. running mean: -15.589473\n","resetting env. episode 379.000000, reward total was -15.000000. running mean: -15.583578\n","resetting env. episode 380.000000, reward total was -17.000000. running mean: -15.597743\n","resetting env. episode 381.000000, reward total was -15.000000. running mean: -15.591765\n","resetting env. episode 382.000000, reward total was -13.000000. running mean: -15.565848\n","resetting env. episode 383.000000, reward total was -14.000000. running mean: -15.550189\n","resetting env. episode 384.000000, reward total was -15.000000. running mean: -15.544687\n","resetting env. episode 385.000000, reward total was -10.000000. running mean: -15.489240\n","resetting env. episode 386.000000, reward total was -15.000000. running mean: -15.484348\n","resetting env. episode 387.000000, reward total was -19.000000. running mean: -15.519504\n","resetting env. episode 388.000000, reward total was -13.000000. running mean: -15.494309\n","resetting env. episode 389.000000, reward total was -15.000000. running mean: -15.489366\n","resetting env. episode 390.000000, reward total was -18.000000. running mean: -15.514473\n","resetting env. episode 391.000000, reward total was -15.000000. running mean: -15.509328\n","resetting env. episode 392.000000, reward total was -11.000000. running mean: -15.464235\n","resetting env. episode 393.000000, reward total was -13.000000. running mean: -15.439592\n","resetting env. episode 394.000000, reward total was -16.000000. running mean: -15.445196\n","resetting env. episode 395.000000, reward total was -15.000000. running mean: -15.440744\n","resetting env. episode 396.000000, reward total was -15.000000. running mean: -15.436337\n","resetting env. episode 397.000000, reward total was -14.000000. running mean: -15.421974\n","resetting env. episode 398.000000, reward total was -13.000000. running mean: -15.397754\n","resetting env. episode 399.000000, reward total was -17.000000. running mean: -15.413776\n","resetting env. episode 400.000000, reward total was -13.000000. running mean: -15.389639\n","resetting env. episode 401.000000, reward total was -17.000000. running mean: -15.405742\n","resetting env. episode 402.000000, reward total was -14.000000. running mean: -15.391685\n","resetting env. episode 403.000000, reward total was -13.000000. running mean: -15.367768\n","resetting env. episode 404.000000, reward total was -10.000000. running mean: -15.314090\n","resetting env. episode 405.000000, reward total was -15.000000. running mean: -15.310949\n","resetting env. episode 406.000000, reward total was -11.000000. running mean: -15.267840\n","resetting env. episode 407.000000, reward total was -19.000000. running mean: -15.305161\n","resetting env. episode 408.000000, reward total was -13.000000. running mean: -15.282110\n","resetting env. episode 409.000000, reward total was -17.000000. running mean: -15.299289\n","resetting env. episode 410.000000, reward total was -15.000000. running mean: -15.296296\n","resetting env. episode 411.000000, reward total was -15.000000. running mean: -15.293333\n","resetting env. episode 412.000000, reward total was -15.000000. running mean: -15.290400\n","resetting env. episode 413.000000, reward total was -15.000000. running mean: -15.287496\n","resetting env. episode 414.000000, reward total was -11.000000. running mean: -15.244621\n","resetting env. episode 415.000000, reward total was -13.000000. running mean: -15.222174\n","resetting env. episode 416.000000, reward total was -16.000000. running mean: -15.229953\n","resetting env. episode 417.000000, reward total was -14.000000. running mean: -15.217653\n","resetting env. episode 418.000000, reward total was -17.000000. running mean: -15.235477\n","resetting env. episode 419.000000, reward total was -16.000000. running mean: -15.243122\n","resetting env. episode 420.000000, reward total was -16.000000. running mean: -15.250691\n","resetting env. episode 421.000000, reward total was -17.000000. running mean: -15.268184\n","resetting env. episode 422.000000, reward total was -18.000000. running mean: -15.295502\n","resetting env. episode 423.000000, reward total was -16.000000. running mean: -15.302547\n","resetting env. episode 424.000000, reward total was -10.000000. running mean: -15.249521\n","resetting env. episode 425.000000, reward total was -14.000000. running mean: -15.237026\n","resetting env. episode 426.000000, reward total was -13.000000. running mean: -15.214656\n","resetting env. episode 427.000000, reward total was -15.000000. running mean: -15.212509\n","resetting env. episode 428.000000, reward total was -15.000000. running mean: -15.210384\n","resetting env. episode 429.000000, reward total was -18.000000. running mean: -15.238280\n","resetting env. episode 430.000000, reward total was -12.000000. running mean: -15.205898\n","resetting env. episode 431.000000, reward total was -17.000000. running mean: -15.223839\n","resetting env. episode 432.000000, reward total was -17.000000. running mean: -15.241600\n","resetting env. episode 433.000000, reward total was -13.000000. running mean: -15.219184\n","resetting env. episode 434.000000, reward total was -6.000000. running mean: -15.126992\n","resetting env. episode 435.000000, reward total was -20.000000. running mean: -15.175722\n","resetting env. episode 436.000000, reward total was -12.000000. running mean: -15.143965\n","resetting env. episode 437.000000, reward total was -9.000000. running mean: -15.082526\n","resetting env. episode 438.000000, reward total was -11.000000. running mean: -15.041700\n","resetting env. episode 439.000000, reward total was -14.000000. running mean: -15.031283\n","resetting env. episode 440.000000, reward total was -17.000000. running mean: -15.050970\n","resetting env. episode 441.000000, reward total was -17.000000. running mean: -15.070461\n","resetting env. episode 442.000000, reward total was -15.000000. running mean: -15.069756\n","resetting env. episode 443.000000, reward total was -13.000000. running mean: -15.049059\n","resetting env. episode 444.000000, reward total was -19.000000. running mean: -15.088568\n","resetting env. episode 445.000000, reward total was -12.000000. running mean: -15.057682\n","resetting env. episode 446.000000, reward total was -16.000000. running mean: -15.067106\n","resetting env. episode 447.000000, reward total was -15.000000. running mean: -15.066434\n","resetting env. episode 448.000000, reward total was -15.000000. running mean: -15.065770\n","resetting env. episode 449.000000, reward total was -17.000000. running mean: -15.085112\n","resetting env. episode 450.000000, reward total was -17.000000. running mean: -15.104261\n","resetting env. episode 451.000000, reward total was -8.000000. running mean: -15.033219\n","resetting env. episode 452.000000, reward total was -14.000000. running mean: -15.022886\n","resetting env. episode 453.000000, reward total was -17.000000. running mean: -15.042658\n","resetting env. episode 454.000000, reward total was -17.000000. running mean: -15.062231\n","resetting env. episode 455.000000, reward total was -13.000000. running mean: -15.041609\n","resetting env. episode 456.000000, reward total was -15.000000. running mean: -15.041193\n","resetting env. episode 457.000000, reward total was -12.000000. running mean: -15.010781\n","resetting env. episode 458.000000, reward total was -17.000000. running mean: -15.030673\n","resetting env. episode 459.000000, reward total was -11.000000. running mean: -14.990366\n","resetting env. episode 460.000000, reward total was -12.000000. running mean: -14.960463\n","resetting env. episode 461.000000, reward total was -13.000000. running mean: -14.940858\n","resetting env. episode 462.000000, reward total was -9.000000. running mean: -14.881449\n","resetting env. episode 463.000000, reward total was -13.000000. running mean: -14.862635\n","resetting env. episode 464.000000, reward total was -12.000000. running mean: -14.834008\n","resetting env. episode 465.000000, reward total was -8.000000. running mean: -14.765668\n","resetting env. episode 466.000000, reward total was -20.000000. running mean: -14.818012\n","resetting env. episode 467.000000, reward total was -15.000000. running mean: -14.819832\n","resetting env. episode 468.000000, reward total was -14.000000. running mean: -14.811633\n","resetting env. episode 469.000000, reward total was -13.000000. running mean: -14.793517\n","resetting env. episode 470.000000, reward total was -19.000000. running mean: -14.835582\n","resetting env. episode 471.000000, reward total was -9.000000. running mean: -14.777226\n","resetting env. episode 472.000000, reward total was -7.000000. running mean: -14.699454\n","resetting env. episode 473.000000, reward total was -9.000000. running mean: -14.642459\n","resetting env. episode 474.000000, reward total was -9.000000. running mean: -14.586035\n","resetting env. episode 475.000000, reward total was -4.000000. running mean: -14.480174\n","resetting env. episode 476.000000, reward total was -15.000000. running mean: -14.485372\n","resetting env. episode 477.000000, reward total was -17.000000. running mean: -14.510519\n","resetting env. episode 478.000000, reward total was -18.000000. running mean: -14.545414\n","resetting env. episode 479.000000, reward total was -14.000000. running mean: -14.539959\n","resetting env. episode 480.000000, reward total was -13.000000. running mean: -14.524560\n","resetting env. episode 481.000000, reward total was -13.000000. running mean: -14.509314\n","resetting env. episode 482.000000, reward total was -15.000000. running mean: -14.514221\n","resetting env. episode 483.000000, reward total was -15.000000. running mean: -14.519079\n","resetting env. episode 484.000000, reward total was -14.000000. running mean: -14.513888\n","resetting env. episode 485.000000, reward total was -17.000000. running mean: -14.538749\n","resetting env. episode 486.000000, reward total was -14.000000. running mean: -14.533362\n","resetting env. episode 487.000000, reward total was -9.000000. running mean: -14.478028\n","resetting env. episode 488.000000, reward total was -15.000000. running mean: -14.483248\n","resetting env. episode 489.000000, reward total was -8.000000. running mean: -14.418415\n","resetting env. episode 490.000000, reward total was -12.000000. running mean: -14.394231\n","resetting env. episode 491.000000, reward total was -19.000000. running mean: -14.440289\n","resetting env. episode 492.000000, reward total was -13.000000. running mean: -14.425886\n","resetting env. episode 493.000000, reward total was -17.000000. running mean: -14.451627\n","resetting env. episode 494.000000, reward total was -15.000000. running mean: -14.457111\n","resetting env. episode 495.000000, reward total was -16.000000. running mean: -14.472540\n","resetting env. episode 496.000000, reward total was -15.000000. running mean: -14.477814\n","resetting env. episode 497.000000, reward total was -15.000000. running mean: -14.483036\n","resetting env. episode 498.000000, reward total was -12.000000. running mean: -14.458206\n","resetting env. episode 499.000000, reward total was -17.000000. running mean: -14.483624\n","resetting env. episode 500.000000, reward total was -6.000000. running mean: -14.398788\n","resetting env. episode 501.000000, reward total was -9.000000. running mean: -14.344800\n","resetting env. episode 502.000000, reward total was -11.000000. running mean: -14.311352\n","resetting env. episode 503.000000, reward total was -13.000000. running mean: -14.298238\n","resetting env. episode 504.000000, reward total was -17.000000. running mean: -14.325256\n","resetting env. episode 505.000000, reward total was -19.000000. running mean: -14.372003\n","resetting env. episode 506.000000, reward total was -14.000000. running mean: -14.368283\n","resetting env. episode 507.000000, reward total was -9.000000. running mean: -14.314600\n","resetting env. episode 508.000000, reward total was -15.000000. running mean: -14.321454\n","resetting env. episode 509.000000, reward total was -17.000000. running mean: -14.348240\n","resetting env. episode 510.000000, reward total was -15.000000. running mean: -14.354757\n","resetting env. episode 511.000000, reward total was -11.000000. running mean: -14.321210\n","resetting env. episode 512.000000, reward total was -9.000000. running mean: -14.267998\n","resetting env. episode 513.000000, reward total was -9.000000. running mean: -14.215318\n","resetting env. episode 514.000000, reward total was -13.000000. running mean: -14.203165\n","resetting env. episode 515.000000, reward total was -10.000000. running mean: -14.161133\n","resetting env. episode 516.000000, reward total was -19.000000. running mean: -14.209522\n","resetting env. episode 517.000000, reward total was -15.000000. running mean: -14.217426\n","resetting env. episode 518.000000, reward total was -15.000000. running mean: -14.225252\n","resetting env. episode 519.000000, reward total was -13.000000. running mean: -14.213000\n","resetting env. episode 520.000000, reward total was -15.000000. running mean: -14.220870\n","resetting env. episode 521.000000, reward total was -12.000000. running mean: -14.198661\n","resetting env. episode 522.000000, reward total was -11.000000. running mean: -14.166674\n","resetting env. episode 523.000000, reward total was -10.000000. running mean: -14.125008\n","resetting env. episode 524.000000, reward total was -10.000000. running mean: -14.083757\n","resetting env. episode 525.000000, reward total was -19.000000. running mean: -14.132920\n","resetting env. episode 526.000000, reward total was -12.000000. running mean: -14.111591\n","resetting env. episode 527.000000, reward total was -9.000000. running mean: -14.060475\n","resetting env. episode 528.000000, reward total was -8.000000. running mean: -13.999870\n","resetting env. episode 529.000000, reward total was -14.000000. running mean: -13.999871\n","resetting env. episode 530.000000, reward total was -16.000000. running mean: -14.019873\n","resetting env. episode 531.000000, reward total was -14.000000. running mean: -14.019674\n","resetting env. episode 532.000000, reward total was -19.000000. running mean: -14.069477\n","resetting env. episode 533.000000, reward total was -13.000000. running mean: -14.058782\n","resetting env. episode 534.000000, reward total was -19.000000. running mean: -14.108195\n","resetting env. episode 535.000000, reward total was -11.000000. running mean: -14.077113\n","resetting env. episode 536.000000, reward total was -11.000000. running mean: -14.046342\n","resetting env. episode 537.000000, reward total was -15.000000. running mean: -14.055878\n","resetting env. episode 538.000000, reward total was -11.000000. running mean: -14.025319\n","resetting env. episode 539.000000, reward total was -12.000000. running mean: -14.005066\n","resetting env. episode 540.000000, reward total was -16.000000. running mean: -14.025015\n","resetting env. episode 541.000000, reward total was -11.000000. running mean: -13.994765\n","resetting env. episode 542.000000, reward total was -17.000000. running mean: -14.024818\n","resetting env. episode 543.000000, reward total was -15.000000. running mean: -14.034569\n","resetting env. episode 544.000000, reward total was -10.000000. running mean: -13.994224\n","resetting env. episode 545.000000, reward total was -10.000000. running mean: -13.954282\n","resetting env. episode 546.000000, reward total was -11.000000. running mean: -13.924739\n","resetting env. episode 547.000000, reward total was -19.000000. running mean: -13.975491\n","resetting env. episode 548.000000, reward total was -15.000000. running mean: -13.985736\n","resetting env. episode 549.000000, reward total was -9.000000. running mean: -13.935879\n","resetting env. episode 550.000000, reward total was -17.000000. running mean: -13.966520\n","resetting env. episode 551.000000, reward total was -15.000000. running mean: -13.976855\n","resetting env. episode 552.000000, reward total was -14.000000. running mean: -13.977087\n","resetting env. episode 553.000000, reward total was -15.000000. running mean: -13.987316\n","resetting env. episode 554.000000, reward total was -13.000000. running mean: -13.977443\n","resetting env. episode 555.000000, reward total was -8.000000. running mean: -13.917668\n","resetting env. episode 556.000000, reward total was -14.000000. running mean: -13.918491\n","resetting env. episode 557.000000, reward total was -13.000000. running mean: -13.909306\n","resetting env. episode 558.000000, reward total was -17.000000. running mean: -13.940213\n","resetting env. episode 559.000000, reward total was -11.000000. running mean: -13.910811\n","resetting env. episode 560.000000, reward total was -14.000000. running mean: -13.911703\n","resetting env. episode 561.000000, reward total was -11.000000. running mean: -13.882586\n","resetting env. episode 562.000000, reward total was -19.000000. running mean: -13.933760\n","resetting env. episode 563.000000, reward total was -14.000000. running mean: -13.934423\n","resetting env. episode 564.000000, reward total was -10.000000. running mean: -13.895078\n","resetting env. episode 565.000000, reward total was -14.000000. running mean: -13.896128\n","resetting env. episode 566.000000, reward total was -17.000000. running mean: -13.927166\n","resetting env. episode 567.000000, reward total was -13.000000. running mean: -13.917895\n","resetting env. episode 568.000000, reward total was -12.000000. running mean: -13.898716\n","resetting env. episode 569.000000, reward total was -17.000000. running mean: -13.929729\n","resetting env. episode 570.000000, reward total was -6.000000. running mean: -13.850431\n","resetting env. episode 571.000000, reward total was -12.000000. running mean: -13.831927\n","resetting env. episode 572.000000, reward total was -19.000000. running mean: -13.883608\n","resetting env. episode 573.000000, reward total was -18.000000. running mean: -13.924772\n","resetting env. episode 574.000000, reward total was -13.000000. running mean: -13.915524\n","resetting env. episode 575.000000, reward total was -16.000000. running mean: -13.936369\n","resetting env. episode 576.000000, reward total was -7.000000. running mean: -13.867005\n","resetting env. episode 577.000000, reward total was -14.000000. running mean: -13.868335\n","resetting env. episode 578.000000, reward total was -17.000000. running mean: -13.899652\n","resetting env. episode 579.000000, reward total was -14.000000. running mean: -13.900655\n","resetting env. episode 580.000000, reward total was -16.000000. running mean: -13.921649\n","resetting env. episode 581.000000, reward total was -11.000000. running mean: -13.892432\n","resetting env. episode 582.000000, reward total was -13.000000. running mean: -13.883508\n","resetting env. episode 583.000000, reward total was -10.000000. running mean: -13.844673\n","resetting env. episode 584.000000, reward total was -11.000000. running mean: -13.816226\n","resetting env. episode 585.000000, reward total was -17.000000. running mean: -13.848064\n","resetting env. episode 586.000000, reward total was -12.000000. running mean: -13.829583\n","resetting env. episode 587.000000, reward total was -12.000000. running mean: -13.811287\n","resetting env. episode 588.000000, reward total was -17.000000. running mean: -13.843174\n","resetting env. episode 589.000000, reward total was -13.000000. running mean: -13.834743\n","resetting env. episode 590.000000, reward total was -13.000000. running mean: -13.826395\n","resetting env. episode 591.000000, reward total was -9.000000. running mean: -13.778131\n","resetting env. episode 592.000000, reward total was -17.000000. running mean: -13.810350\n","resetting env. episode 593.000000, reward total was -15.000000. running mean: -13.822246\n","resetting env. episode 594.000000, reward total was -13.000000. running mean: -13.814024\n","resetting env. episode 595.000000, reward total was -9.000000. running mean: -13.765884\n","resetting env. episode 596.000000, reward total was -13.000000. running mean: -13.758225\n","resetting env. episode 597.000000, reward total was -18.000000. running mean: -13.800643\n","resetting env. episode 598.000000, reward total was -15.000000. running mean: -13.812636\n","resetting env. episode 599.000000, reward total was -15.000000. running mean: -13.824510\n","resetting env. episode 600.000000, reward total was -12.000000. running mean: -13.806265\n","resetting env. episode 601.000000, reward total was -12.000000. running mean: -13.788202\n","resetting env. episode 602.000000, reward total was -10.000000. running mean: -13.750320\n","resetting env. episode 603.000000, reward total was -19.000000. running mean: -13.802817\n","resetting env. episode 604.000000, reward total was -15.000000. running mean: -13.814789\n","resetting env. episode 605.000000, reward total was -14.000000. running mean: -13.816641\n","resetting env. episode 606.000000, reward total was -8.000000. running mean: -13.758474\n","resetting env. episode 607.000000, reward total was -16.000000. running mean: -13.780890\n","resetting env. episode 608.000000, reward total was -12.000000. running mean: -13.763081\n","resetting env. episode 609.000000, reward total was -17.000000. running mean: -13.795450\n","resetting env. episode 610.000000, reward total was -16.000000. running mean: -13.817495\n","resetting env. episode 611.000000, reward total was -18.000000. running mean: -13.859321\n","resetting env. episode 612.000000, reward total was -17.000000. running mean: -13.890727\n","resetting env. episode 613.000000, reward total was -20.000000. running mean: -13.951820\n","resetting env. episode 614.000000, reward total was -14.000000. running mean: -13.952302\n","resetting env. episode 615.000000, reward total was -15.000000. running mean: -13.962779\n","resetting env. episode 616.000000, reward total was -13.000000. running mean: -13.953151\n","resetting env. episode 617.000000, reward total was -14.000000. running mean: -13.953620\n","resetting env. episode 618.000000, reward total was -12.000000. running mean: -13.934083\n","resetting env. episode 619.000000, reward total was -19.000000. running mean: -13.984742\n","resetting env. episode 620.000000, reward total was -16.000000. running mean: -14.004895\n","resetting env. episode 621.000000, reward total was -13.000000. running mean: -13.994846\n","resetting env. episode 622.000000, reward total was -10.000000. running mean: -13.954898\n","resetting env. episode 623.000000, reward total was -13.000000. running mean: -13.945349\n","resetting env. episode 624.000000, reward total was -15.000000. running mean: -13.955895\n","resetting env. episode 625.000000, reward total was -14.000000. running mean: -13.956336\n","resetting env. episode 626.000000, reward total was -15.000000. running mean: -13.966773\n","resetting env. episode 627.000000, reward total was -10.000000. running mean: -13.927105\n","resetting env. episode 628.000000, reward total was -11.000000. running mean: -13.897834\n","resetting env. episode 629.000000, reward total was -14.000000. running mean: -13.898856\n","resetting env. episode 630.000000, reward total was -13.000000. running mean: -13.889867\n","resetting env. episode 631.000000, reward total was -13.000000. running mean: -13.880969\n","resetting env. episode 632.000000, reward total was -16.000000. running mean: -13.902159\n","resetting env. episode 633.000000, reward total was -15.000000. running mean: -13.913137\n","resetting env. episode 634.000000, reward total was -16.000000. running mean: -13.934006\n","resetting env. episode 635.000000, reward total was -17.000000. running mean: -13.964666\n","resetting env. episode 636.000000, reward total was -17.000000. running mean: -13.995019\n","resetting env. episode 637.000000, reward total was -16.000000. running mean: -14.015069\n","resetting env. episode 638.000000, reward total was -13.000000. running mean: -14.004918\n","resetting env. episode 639.000000, reward total was -14.000000. running mean: -14.004869\n","resetting env. episode 640.000000, reward total was -17.000000. running mean: -14.034820\n","resetting env. episode 641.000000, reward total was -13.000000. running mean: -14.024472\n","resetting env. episode 642.000000, reward total was -9.000000. running mean: -13.974227\n","resetting env. episode 643.000000, reward total was -8.000000. running mean: -13.914485\n","resetting env. episode 644.000000, reward total was -15.000000. running mean: -13.925340\n","resetting env. episode 645.000000, reward total was -21.000000. running mean: -13.996087\n","resetting env. episode 646.000000, reward total was -15.000000. running mean: -14.006126\n","resetting env. episode 647.000000, reward total was -15.000000. running mean: -14.016065\n","resetting env. episode 648.000000, reward total was -16.000000. running mean: -14.035904\n","resetting env. episode 649.000000, reward total was -14.000000. running mean: -14.035545\n","resetting env. episode 650.000000, reward total was -14.000000. running mean: -14.035190\n","resetting env. episode 651.000000, reward total was -9.000000. running mean: -13.984838\n","resetting env. episode 652.000000, reward total was -16.000000. running mean: -14.004989\n","resetting env. episode 653.000000, reward total was -17.000000. running mean: -14.034940\n","resetting env. episode 654.000000, reward total was -9.000000. running mean: -13.984590\n","resetting env. episode 655.000000, reward total was -13.000000. running mean: -13.974744\n","resetting env. episode 656.000000, reward total was -19.000000. running mean: -14.024997\n","resetting env. episode 657.000000, reward total was -12.000000. running mean: -14.004747\n","resetting env. episode 658.000000, reward total was -18.000000. running mean: -14.044699\n","resetting env. episode 659.000000, reward total was -11.000000. running mean: -14.014252\n","resetting env. episode 660.000000, reward total was -7.000000. running mean: -13.944110\n","resetting env. episode 661.000000, reward total was -17.000000. running mean: -13.974669\n","resetting env. episode 662.000000, reward total was -10.000000. running mean: -13.934922\n","resetting env. episode 663.000000, reward total was -20.000000. running mean: -13.995573\n","resetting env. episode 664.000000, reward total was -7.000000. running mean: -13.925617\n","resetting env. episode 665.000000, reward total was -17.000000. running mean: -13.956361\n","resetting env. episode 666.000000, reward total was -7.000000. running mean: -13.886797\n","resetting env. episode 667.000000, reward total was -10.000000. running mean: -13.847929\n","resetting env. episode 668.000000, reward total was -10.000000. running mean: -13.809450\n","resetting env. episode 669.000000, reward total was -13.000000. running mean: -13.801356\n","resetting env. episode 670.000000, reward total was -16.000000. running mean: -13.823342\n","resetting env. episode 671.000000, reward total was -12.000000. running mean: -13.805109\n","resetting env. episode 672.000000, reward total was -17.000000. running mean: -13.837057\n","resetting env. episode 673.000000, reward total was -16.000000. running mean: -13.858687\n","resetting env. episode 674.000000, reward total was -11.000000. running mean: -13.830100\n","resetting env. episode 675.000000, reward total was -17.000000. running mean: -13.861799\n","resetting env. episode 676.000000, reward total was -12.000000. running mean: -13.843181\n","resetting env. episode 677.000000, reward total was -8.000000. running mean: -13.784749\n","resetting env. episode 678.000000, reward total was -13.000000. running mean: -13.776902\n","resetting env. episode 679.000000, reward total was -17.000000. running mean: -13.809133\n","resetting env. episode 680.000000, reward total was -17.000000. running mean: -13.841041\n","resetting env. episode 681.000000, reward total was -5.000000. running mean: -13.752631\n","resetting env. episode 682.000000, reward total was -15.000000. running mean: -13.765105\n","resetting env. episode 683.000000, reward total was -13.000000. running mean: -13.757454\n","resetting env. episode 684.000000, reward total was -13.000000. running mean: -13.749879\n","resetting env. episode 685.000000, reward total was -11.000000. running mean: -13.722380\n","resetting env. episode 686.000000, reward total was -13.000000. running mean: -13.715156\n","resetting env. episode 687.000000, reward total was -13.000000. running mean: -13.708005\n","resetting env. episode 688.000000, reward total was -5.000000. running mean: -13.620925\n","resetting env. episode 689.000000, reward total was -10.000000. running mean: -13.584716\n","resetting env. episode 690.000000, reward total was -14.000000. running mean: -13.588868\n","resetting env. episode 691.000000, reward total was -19.000000. running mean: -13.642980\n","resetting env. episode 692.000000, reward total was -13.000000. running mean: -13.636550\n","resetting env. episode 693.000000, reward total was -13.000000. running mean: -13.630184\n","resetting env. episode 694.000000, reward total was -19.000000. running mean: -13.683883\n","resetting env. episode 695.000000, reward total was -13.000000. running mean: -13.677044\n","resetting env. episode 696.000000, reward total was -11.000000. running mean: -13.650273\n","resetting env. episode 697.000000, reward total was -21.000000. running mean: -13.723771\n","resetting env. episode 698.000000, reward total was -15.000000. running mean: -13.736533\n","resetting env. episode 699.000000, reward total was -13.000000. running mean: -13.729168\n","resetting env. episode 700.000000, reward total was -8.000000. running mean: -13.671876\n","resetting env. episode 701.000000, reward total was -3.000000. running mean: -13.565157\n","resetting env. episode 702.000000, reward total was -13.000000. running mean: -13.559506\n","resetting env. episode 703.000000, reward total was -11.000000. running mean: -13.533911\n","resetting env. episode 704.000000, reward total was -15.000000. running mean: -13.548571\n","resetting env. episode 705.000000, reward total was -9.000000. running mean: -13.503086\n","resetting env. episode 706.000000, reward total was -10.000000. running mean: -13.468055\n","resetting env. episode 707.000000, reward total was -16.000000. running mean: -13.493374\n","resetting env. episode 708.000000, reward total was -12.000000. running mean: -13.478441\n","resetting env. episode 709.000000, reward total was -16.000000. running mean: -13.503656\n","resetting env. episode 710.000000, reward total was -17.000000. running mean: -13.538620\n","resetting env. episode 711.000000, reward total was -17.000000. running mean: -13.573233\n","resetting env. episode 712.000000, reward total was -10.000000. running mean: -13.537501\n","resetting env. episode 713.000000, reward total was -15.000000. running mean: -13.552126\n","resetting env. episode 714.000000, reward total was -13.000000. running mean: -13.546605\n","resetting env. episode 715.000000, reward total was -9.000000. running mean: -13.501139\n","resetting env. episode 716.000000, reward total was -6.000000. running mean: -13.426127\n","resetting env. episode 717.000000, reward total was -19.000000. running mean: -13.481866\n","resetting env. episode 718.000000, reward total was -14.000000. running mean: -13.487047\n","resetting env. episode 719.000000, reward total was -14.000000. running mean: -13.492177\n","resetting env. episode 720.000000, reward total was -19.000000. running mean: -13.547255\n","resetting env. episode 721.000000, reward total was -11.000000. running mean: -13.521783\n","resetting env. episode 722.000000, reward total was -13.000000. running mean: -13.516565\n","resetting env. episode 723.000000, reward total was -11.000000. running mean: -13.491399\n","resetting env. episode 724.000000, reward total was -10.000000. running mean: -13.456485\n","resetting env. episode 725.000000, reward total was -12.000000. running mean: -13.441920\n","resetting env. episode 726.000000, reward total was -9.000000. running mean: -13.397501\n","resetting env. episode 727.000000, reward total was -9.000000. running mean: -13.353526\n","resetting env. episode 728.000000, reward total was -2.000000. running mean: -13.239991\n","resetting env. episode 729.000000, reward total was -11.000000. running mean: -13.217591\n","resetting env. episode 730.000000, reward total was -17.000000. running mean: -13.255415\n","resetting env. episode 731.000000, reward total was -17.000000. running mean: -13.292861\n","resetting env. episode 732.000000, reward total was -13.000000. running mean: -13.289932\n","resetting env. episode 733.000000, reward total was -15.000000. running mean: -13.307033\n","resetting env. episode 734.000000, reward total was -4.000000. running mean: -13.213963\n","resetting env. episode 735.000000, reward total was -15.000000. running mean: -13.231823\n","resetting env. episode 736.000000, reward total was -13.000000. running mean: -13.229505\n","resetting env. episode 737.000000, reward total was -15.000000. running mean: -13.247210\n","resetting env. episode 738.000000, reward total was -17.000000. running mean: -13.284738\n","resetting env. episode 739.000000, reward total was -14.000000. running mean: -13.291890\n","resetting env. episode 740.000000, reward total was -15.000000. running mean: -13.308971\n","resetting env. episode 741.000000, reward total was -8.000000. running mean: -13.255882\n","resetting env. episode 742.000000, reward total was -6.000000. running mean: -13.183323\n","resetting env. episode 743.000000, reward total was -16.000000. running mean: -13.211490\n","resetting env. episode 744.000000, reward total was -12.000000. running mean: -13.199375\n","resetting env. episode 745.000000, reward total was -11.000000. running mean: -13.177381\n","resetting env. episode 746.000000, reward total was -11.000000. running mean: -13.155607\n","resetting env. episode 747.000000, reward total was -15.000000. running mean: -13.174051\n","resetting env. episode 748.000000, reward total was -9.000000. running mean: -13.132311\n","resetting env. episode 749.000000, reward total was -19.000000. running mean: -13.190987\n","resetting env. episode 750.000000, reward total was -14.000000. running mean: -13.199078\n","resetting env. episode 751.000000, reward total was -9.000000. running mean: -13.157087\n","resetting env. episode 752.000000, reward total was -9.000000. running mean: -13.115516\n","resetting env. episode 753.000000, reward total was -10.000000. running mean: -13.084361\n","resetting env. episode 754.000000, reward total was -15.000000. running mean: -13.103517\n","resetting env. episode 755.000000, reward total was -12.000000. running mean: -13.092482\n","resetting env. episode 756.000000, reward total was -15.000000. running mean: -13.111557\n","resetting env. episode 757.000000, reward total was -11.000000. running mean: -13.090442\n","resetting env. episode 758.000000, reward total was -15.000000. running mean: -13.109537\n","resetting env. episode 759.000000, reward total was -15.000000. running mean: -13.128442\n","resetting env. episode 760.000000, reward total was -8.000000. running mean: -13.077157\n","resetting env. episode 761.000000, reward total was -17.000000. running mean: -13.116386\n","resetting env. episode 762.000000, reward total was -12.000000. running mean: -13.105222\n","resetting env. episode 763.000000, reward total was -14.000000. running mean: -13.114170\n","resetting env. episode 764.000000, reward total was -15.000000. running mean: -13.133028\n","resetting env. episode 765.000000, reward total was -2.000000. running mean: -13.021698\n","resetting env. episode 766.000000, reward total was -12.000000. running mean: -13.011481\n","resetting env. episode 767.000000, reward total was -14.000000. running mean: -13.021366\n","resetting env. episode 768.000000, reward total was -15.000000. running mean: -13.041152\n","resetting env. episode 769.000000, reward total was -13.000000. running mean: -13.040741\n","resetting env. episode 770.000000, reward total was -15.000000. running mean: -13.060333\n","resetting env. episode 771.000000, reward total was -10.000000. running mean: -13.029730\n","resetting env. episode 772.000000, reward total was -14.000000. running mean: -13.039433\n","resetting env. episode 773.000000, reward total was -17.000000. running mean: -13.079038\n","resetting env. episode 774.000000, reward total was -8.000000. running mean: -13.028248\n","resetting env. episode 775.000000, reward total was -3.000000. running mean: -12.927966\n","resetting env. episode 776.000000, reward total was -12.000000. running mean: -12.918686\n","resetting env. episode 777.000000, reward total was -14.000000. running mean: -12.929499\n","resetting env. episode 778.000000, reward total was -9.000000. running mean: -12.890204\n","resetting env. episode 779.000000, reward total was -19.000000. running mean: -12.951302\n","resetting env. episode 780.000000, reward total was -16.000000. running mean: -12.981789\n","resetting env. episode 781.000000, reward total was -10.000000. running mean: -12.951971\n","resetting env. episode 782.000000, reward total was -15.000000. running mean: -12.972451\n","resetting env. episode 783.000000, reward total was -14.000000. running mean: -12.982727\n","resetting env. episode 784.000000, reward total was -18.000000. running mean: -13.032900\n","resetting env. episode 785.000000, reward total was -9.000000. running mean: -12.992571\n","resetting env. episode 786.000000, reward total was -5.000000. running mean: -12.912645\n","resetting env. episode 787.000000, reward total was -7.000000. running mean: -12.853518\n","resetting env. episode 788.000000, reward total was -16.000000. running mean: -12.884983\n","resetting env. episode 789.000000, reward total was -12.000000. running mean: -12.876133\n","resetting env. episode 790.000000, reward total was -15.000000. running mean: -12.897372\n","resetting env. episode 791.000000, reward total was -3.000000. running mean: -12.798398\n","resetting env. episode 792.000000, reward total was -15.000000. running mean: -12.820414\n","resetting env. episode 793.000000, reward total was -17.000000. running mean: -12.862210\n","resetting env. episode 794.000000, reward total was -15.000000. running mean: -12.883588\n","resetting env. episode 795.000000, reward total was -15.000000. running mean: -12.904752\n","resetting env. episode 796.000000, reward total was -18.000000. running mean: -12.955705\n","resetting env. episode 797.000000, reward total was -20.000000. running mean: -13.026148\n","resetting env. episode 798.000000, reward total was -15.000000. running mean: -13.045886\n","resetting env. episode 799.000000, reward total was -14.000000. running mean: -13.055427\n","resetting env. episode 800.000000, reward total was -9.000000. running mean: -13.014873\n","resetting env. episode 801.000000, reward total was -14.000000. running mean: -13.024724\n","resetting env. episode 802.000000, reward total was -12.000000. running mean: -13.014477\n","resetting env. episode 803.000000, reward total was -3.000000. running mean: -12.914332\n","resetting env. episode 804.000000, reward total was -17.000000. running mean: -12.955189\n","resetting env. episode 805.000000, reward total was -11.000000. running mean: -12.935637\n","resetting env. episode 806.000000, reward total was -15.000000. running mean: -12.956281\n","resetting env. episode 807.000000, reward total was -6.000000. running mean: -12.886718\n","resetting env. episode 808.000000, reward total was -13.000000. running mean: -12.887851\n","resetting env. episode 809.000000, reward total was -7.000000. running mean: -12.828972\n","resetting env. episode 810.000000, reward total was -17.000000. running mean: -12.870683\n","resetting env. episode 811.000000, reward total was -13.000000. running mean: -12.871976\n","resetting env. episode 812.000000, reward total was -12.000000. running mean: -12.863256\n","resetting env. episode 813.000000, reward total was -16.000000. running mean: -12.894623\n","resetting env. episode 814.000000, reward total was -18.000000. running mean: -12.945677\n","resetting env. episode 815.000000, reward total was -15.000000. running mean: -12.966220\n","resetting env. episode 816.000000, reward total was -10.000000. running mean: -12.936558\n","resetting env. episode 817.000000, reward total was -15.000000. running mean: -12.957193\n","resetting env. episode 818.000000, reward total was -12.000000. running mean: -12.947621\n","resetting env. episode 819.000000, reward total was -15.000000. running mean: -12.968144\n","resetting env. episode 820.000000, reward total was -17.000000. running mean: -13.008463\n","resetting env. episode 821.000000, reward total was -13.000000. running mean: -13.008378\n","resetting env. episode 822.000000, reward total was -16.000000. running mean: -13.038295\n","resetting env. episode 823.000000, reward total was -8.000000. running mean: -12.987912\n","resetting env. episode 824.000000, reward total was -9.000000. running mean: -12.948033\n","resetting env. episode 825.000000, reward total was -15.000000. running mean: -12.968552\n","resetting env. episode 826.000000, reward total was -10.000000. running mean: -12.938867\n","resetting env. episode 827.000000, reward total was -12.000000. running mean: -12.929478\n","resetting env. episode 828.000000, reward total was -12.000000. running mean: -12.920183\n","resetting env. episode 829.000000, reward total was -13.000000. running mean: -12.920981\n","resetting env. episode 830.000000, reward total was -10.000000. running mean: -12.891772\n","resetting env. episode 831.000000, reward total was -12.000000. running mean: -12.882854\n","resetting env. episode 832.000000, reward total was -15.000000. running mean: -12.904025\n","resetting env. episode 833.000000, reward total was -15.000000. running mean: -12.924985\n","resetting env. episode 834.000000, reward total was -18.000000. running mean: -12.975735\n","resetting env. episode 835.000000, reward total was -5.000000. running mean: -12.895978\n","resetting env. episode 836.000000, reward total was -17.000000. running mean: -12.937018\n","resetting env. episode 837.000000, reward total was -3.000000. running mean: -12.837648\n","resetting env. episode 838.000000, reward total was -12.000000. running mean: -12.829271\n","resetting env. episode 839.000000, reward total was -9.000000. running mean: -12.790979\n","resetting env. episode 840.000000, reward total was -15.000000. running mean: -12.813069\n","resetting env. episode 841.000000, reward total was -16.000000. running mean: -12.844938\n","resetting env. episode 842.000000, reward total was -11.000000. running mean: -12.826489\n","resetting env. episode 843.000000, reward total was -11.000000. running mean: -12.808224\n","resetting env. episode 844.000000, reward total was -15.000000. running mean: -12.830142\n","resetting env. episode 845.000000, reward total was -14.000000. running mean: -12.841840\n","resetting env. episode 846.000000, reward total was -10.000000. running mean: -12.813422\n","resetting env. episode 847.000000, reward total was -14.000000. running mean: -12.825288\n","resetting env. episode 848.000000, reward total was -8.000000. running mean: -12.777035\n","resetting env. episode 849.000000, reward total was -6.000000. running mean: -12.709264\n","resetting env. episode 850.000000, reward total was -7.000000. running mean: -12.652172\n","resetting env. episode 851.000000, reward total was -11.000000. running mean: -12.635650\n","resetting env. episode 852.000000, reward total was -11.000000. running mean: -12.619294\n","resetting env. episode 853.000000, reward total was -15.000000. running mean: -12.643101\n","resetting env. episode 854.000000, reward total was -11.000000. running mean: -12.626670\n","resetting env. episode 855.000000, reward total was -14.000000. running mean: -12.640403\n","resetting env. episode 856.000000, reward total was -8.000000. running mean: -12.593999\n","resetting env. episode 857.000000, reward total was -13.000000. running mean: -12.598059\n","resetting env. episode 858.000000, reward total was -9.000000. running mean: -12.562078\n","resetting env. episode 859.000000, reward total was -12.000000. running mean: -12.556458\n","resetting env. episode 860.000000, reward total was -10.000000. running mean: -12.530893\n","resetting env. episode 861.000000, reward total was -14.000000. running mean: -12.545584\n","resetting env. episode 862.000000, reward total was -12.000000. running mean: -12.540128\n","resetting env. episode 863.000000, reward total was -14.000000. running mean: -12.554727\n","resetting env. episode 864.000000, reward total was -11.000000. running mean: -12.539180\n","resetting env. episode 865.000000, reward total was -6.000000. running mean: -12.473788\n","resetting env. episode 866.000000, reward total was -13.000000. running mean: -12.479050\n","resetting env. episode 867.000000, reward total was -14.000000. running mean: -12.494260\n","resetting env. episode 868.000000, reward total was -12.000000. running mean: -12.489317\n","resetting env. episode 869.000000, reward total was -19.000000. running mean: -12.554424\n","resetting env. episode 870.000000, reward total was -8.000000. running mean: -12.508880\n","resetting env. episode 871.000000, reward total was -4.000000. running mean: -12.423791\n","resetting env. episode 872.000000, reward total was -12.000000. running mean: -12.419553\n","resetting env. episode 873.000000, reward total was -15.000000. running mean: -12.445357\n","resetting env. episode 874.000000, reward total was -9.000000. running mean: -12.410904\n","resetting env. episode 875.000000, reward total was 2.000000. running mean: -12.266795\n","resetting env. episode 876.000000, reward total was -17.000000. running mean: -12.314127\n","resetting env. episode 877.000000, reward total was -10.000000. running mean: -12.290985\n","resetting env. episode 878.000000, reward total was -5.000000. running mean: -12.218076\n","resetting env. episode 879.000000, reward total was -10.000000. running mean: -12.195895\n","resetting env. episode 880.000000, reward total was -11.000000. running mean: -12.183936\n","resetting env. episode 881.000000, reward total was -11.000000. running mean: -12.172097\n","resetting env. episode 882.000000, reward total was -17.000000. running mean: -12.220376\n","resetting env. episode 883.000000, reward total was -9.000000. running mean: -12.188172\n","resetting env. episode 884.000000, reward total was 1.000000. running mean: -12.056290\n","resetting env. episode 885.000000, reward total was -12.000000. running mean: -12.055727\n","resetting env. episode 886.000000, reward total was -8.000000. running mean: -12.015170\n","resetting env. episode 887.000000, reward total was -11.000000. running mean: -12.005018\n","resetting env. episode 888.000000, reward total was -13.000000. running mean: -12.014968\n","resetting env. episode 889.000000, reward total was -13.000000. running mean: -12.024818\n","resetting env. episode 890.000000, reward total was -15.000000. running mean: -12.054570\n","resetting env. episode 891.000000, reward total was 5.000000. running mean: -11.884024\n","resetting env. episode 892.000000, reward total was -9.000000. running mean: -11.855184\n","resetting env. episode 893.000000, reward total was -1.000000. running mean: -11.746632\n","resetting env. episode 894.000000, reward total was -9.000000. running mean: -11.719166\n","resetting env. episode 895.000000, reward total was -10.000000. running mean: -11.701974\n","resetting env. episode 896.000000, reward total was 2.000000. running mean: -11.564955\n","resetting env. episode 897.000000, reward total was -5.000000. running mean: -11.499305\n","resetting env. episode 898.000000, reward total was -17.000000. running mean: -11.554312\n","resetting env. episode 899.000000, reward total was -14.000000. running mean: -11.578769\n","resetting env. episode 900.000000, reward total was -9.000000. running mean: -11.552981\n","resetting env. episode 901.000000, reward total was -14.000000. running mean: -11.577451\n","resetting env. episode 902.000000, reward total was -9.000000. running mean: -11.551677\n","resetting env. episode 903.000000, reward total was -16.000000. running mean: -11.596160\n","resetting env. episode 904.000000, reward total was -16.000000. running mean: -11.640199\n","resetting env. episode 905.000000, reward total was -9.000000. running mean: -11.613797\n","resetting env. episode 906.000000, reward total was -13.000000. running mean: -11.627659\n","resetting env. episode 907.000000, reward total was -8.000000. running mean: -11.591382\n","resetting env. episode 908.000000, reward total was -16.000000. running mean: -11.635468\n","resetting env. episode 909.000000, reward total was -15.000000. running mean: -11.669114\n","resetting env. episode 910.000000, reward total was -8.000000. running mean: -11.632422\n","resetting env. episode 911.000000, reward total was -17.000000. running mean: -11.686098\n","resetting env. episode 912.000000, reward total was -18.000000. running mean: -11.749237\n","resetting env. episode 913.000000, reward total was -17.000000. running mean: -11.801745\n","resetting env. episode 914.000000, reward total was -16.000000. running mean: -11.843727\n","resetting env. episode 915.000000, reward total was -8.000000. running mean: -11.805290\n","resetting env. episode 916.000000, reward total was -9.000000. running mean: -11.777237\n","resetting env. episode 917.000000, reward total was -16.000000. running mean: -11.819465\n","resetting env. episode 918.000000, reward total was -9.000000. running mean: -11.791270\n","resetting env. episode 919.000000, reward total was -19.000000. running mean: -11.863357\n","resetting env. episode 920.000000, reward total was -17.000000. running mean: -11.914724\n","resetting env. episode 921.000000, reward total was -9.000000. running mean: -11.885577\n","resetting env. episode 922.000000, reward total was -3.000000. running mean: -11.796721\n","resetting env. episode 923.000000, reward total was -11.000000. running mean: -11.788754\n","resetting env. episode 924.000000, reward total was -12.000000. running mean: -11.790866\n","resetting env. episode 925.000000, reward total was -10.000000. running mean: -11.772957\n","resetting env. episode 926.000000, reward total was -10.000000. running mean: -11.755228\n","resetting env. episode 927.000000, reward total was -5.000000. running mean: -11.687676\n","resetting env. episode 928.000000, reward total was -5.000000. running mean: -11.620799\n","resetting env. episode 929.000000, reward total was -13.000000. running mean: -11.634591\n","resetting env. episode 930.000000, reward total was -13.000000. running mean: -11.648245\n","resetting env. episode 931.000000, reward total was -10.000000. running mean: -11.631763\n","resetting env. episode 932.000000, reward total was -9.000000. running mean: -11.605445\n","resetting env. episode 933.000000, reward total was -15.000000. running mean: -11.639390\n","resetting env. episode 934.000000, reward total was -6.000000. running mean: -11.582997\n","resetting env. episode 935.000000, reward total was -7.000000. running mean: -11.537167\n","resetting env. episode 936.000000, reward total was -19.000000. running mean: -11.611795\n","resetting env. episode 937.000000, reward total was -11.000000. running mean: -11.605677\n","resetting env. episode 938.000000, reward total was -8.000000. running mean: -11.569620\n","resetting env. episode 939.000000, reward total was -11.000000. running mean: -11.563924\n","resetting env. episode 940.000000, reward total was -17.000000. running mean: -11.618285\n","resetting env. episode 941.000000, reward total was -12.000000. running mean: -11.622102\n","resetting env. episode 942.000000, reward total was -14.000000. running mean: -11.645881\n","resetting env. episode 943.000000, reward total was -15.000000. running mean: -11.679422\n","resetting env. episode 944.000000, reward total was -14.000000. running mean: -11.702628\n","resetting env. episode 945.000000, reward total was -13.000000. running mean: -11.715602\n","resetting env. episode 946.000000, reward total was -9.000000. running mean: -11.688446\n","resetting env. episode 947.000000, reward total was -15.000000. running mean: -11.721561\n","resetting env. episode 948.000000, reward total was -11.000000. running mean: -11.714345\n","resetting env. episode 949.000000, reward total was 3.000000. running mean: -11.567202\n","resetting env. episode 950.000000, reward total was -11.000000. running mean: -11.561530\n","resetting env. episode 951.000000, reward total was -12.000000. running mean: -11.565915\n","resetting env. episode 952.000000, reward total was -1.000000. running mean: -11.460256\n","resetting env. episode 953.000000, reward total was -9.000000. running mean: -11.435653\n","resetting env. episode 954.000000, reward total was -13.000000. running mean: -11.451296\n","resetting env. episode 955.000000, reward total was -17.000000. running mean: -11.506784\n","resetting env. episode 956.000000, reward total was -16.000000. running mean: -11.551716\n","resetting env. episode 957.000000, reward total was -16.000000. running mean: -11.596199\n","resetting env. episode 958.000000, reward total was -7.000000. running mean: -11.550237\n","resetting env. episode 959.000000, reward total was -14.000000. running mean: -11.574734\n","resetting env. episode 960.000000, reward total was -12.000000. running mean: -11.578987\n","resetting env. episode 961.000000, reward total was -9.000000. running mean: -11.553197\n","resetting env. episode 962.000000, reward total was -14.000000. running mean: -11.577665\n","resetting env. episode 963.000000, reward total was -12.000000. running mean: -11.581888\n","resetting env. episode 964.000000, reward total was -17.000000. running mean: -11.636069\n","resetting env. episode 965.000000, reward total was -9.000000. running mean: -11.609709\n","resetting env. episode 966.000000, reward total was -5.000000. running mean: -11.543612\n","resetting env. episode 967.000000, reward total was -16.000000. running mean: -11.588176\n","resetting env. episode 968.000000, reward total was -9.000000. running mean: -11.562294\n","resetting env. episode 969.000000, reward total was -6.000000. running mean: -11.506671\n","resetting env. episode 970.000000, reward total was -11.000000. running mean: -11.501604\n","resetting env. episode 971.000000, reward total was -11.000000. running mean: -11.496588\n","resetting env. episode 972.000000, reward total was -14.000000. running mean: -11.521622\n","resetting env. episode 973.000000, reward total was -13.000000. running mean: -11.536406\n","resetting env. episode 974.000000, reward total was -17.000000. running mean: -11.591042\n","resetting env. episode 975.000000, reward total was -12.000000. running mean: -11.595132\n","resetting env. episode 976.000000, reward total was -18.000000. running mean: -11.659180\n","resetting env. episode 977.000000, reward total was -12.000000. running mean: -11.662588\n","resetting env. episode 978.000000, reward total was -19.000000. running mean: -11.735963\n","resetting env. episode 979.000000, reward total was -4.000000. running mean: -11.658603\n","resetting env. episode 980.000000, reward total was -19.000000. running mean: -11.732017\n","resetting env. episode 981.000000, reward total was -11.000000. running mean: -11.724697\n","resetting env. episode 982.000000, reward total was -7.000000. running mean: -11.677450\n","resetting env. episode 983.000000, reward total was -13.000000. running mean: -11.690675\n","resetting env. episode 984.000000, reward total was -13.000000. running mean: -11.703768\n","resetting env. episode 985.000000, reward total was -6.000000. running mean: -11.646731\n","resetting env. episode 986.000000, reward total was -13.000000. running mean: -11.660264\n","resetting env. episode 987.000000, reward total was 1.000000. running mean: -11.533661\n","resetting env. episode 988.000000, reward total was -15.000000. running mean: -11.568324\n","resetting env. episode 989.000000, reward total was -11.000000. running mean: -11.562641\n","resetting env. episode 990.000000, reward total was -9.000000. running mean: -11.537015\n","resetting env. episode 991.000000, reward total was -11.000000. running mean: -11.531644\n","resetting env. episode 992.000000, reward total was -1.000000. running mean: -11.426328\n","resetting env. episode 993.000000, reward total was -8.000000. running mean: -11.392065\n","resetting env. episode 994.000000, reward total was -15.000000. running mean: -11.428144\n","resetting env. episode 995.000000, reward total was -12.000000. running mean: -11.433863\n","resetting env. episode 996.000000, reward total was -16.000000. running mean: -11.479524\n","resetting env. episode 997.000000, reward total was -15.000000. running mean: -11.514729\n","resetting env. episode 998.000000, reward total was -11.000000. running mean: -11.509581\n","resetting env. episode 999.000000, reward total was -11.000000. running mean: -11.504486\n","resetting env. episode 1000.000000, reward total was -11.000000. running mean: -11.499441\n","resetting env. episode 1001.000000, reward total was -15.000000. running mean: -11.534446\n","resetting env. episode 1002.000000, reward total was -15.000000. running mean: -11.569102\n","resetting env. episode 1003.000000, reward total was -15.000000. running mean: -11.603411\n","resetting env. episode 1004.000000, reward total was -6.000000. running mean: -11.547377\n","resetting env. episode 1005.000000, reward total was -7.000000. running mean: -11.501903\n","resetting env. episode 1006.000000, reward total was -10.000000. running mean: -11.486884\n","resetting env. episode 1007.000000, reward total was -10.000000. running mean: -11.472015\n","resetting env. episode 1008.000000, reward total was -11.000000. running mean: -11.467295\n","resetting env. episode 1009.000000, reward total was -14.000000. running mean: -11.492622\n","resetting env. episode 1010.000000, reward total was -13.000000. running mean: -11.507696\n","resetting env. episode 1011.000000, reward total was -8.000000. running mean: -11.472619\n","resetting env. episode 1012.000000, reward total was -9.000000. running mean: -11.447893\n","resetting env. episode 1013.000000, reward total was -9.000000. running mean: -11.423414\n","resetting env. episode 1014.000000, reward total was -15.000000. running mean: -11.459180\n","resetting env. episode 1015.000000, reward total was -12.000000. running mean: -11.464588\n","resetting env. episode 1016.000000, reward total was -10.000000. running mean: -11.449942\n","resetting env. episode 1017.000000, reward total was -11.000000. running mean: -11.445443\n","resetting env. episode 1018.000000, reward total was -16.000000. running mean: -11.490988\n","resetting env. episode 1019.000000, reward total was -8.000000. running mean: -11.456078\n","resetting env. episode 1020.000000, reward total was -11.000000. running mean: -11.451517\n","resetting env. episode 1021.000000, reward total was -9.000000. running mean: -11.427002\n","resetting env. episode 1022.000000, reward total was -18.000000. running mean: -11.492732\n","resetting env. episode 1023.000000, reward total was -9.000000. running mean: -11.467805\n","resetting env. episode 1024.000000, reward total was -7.000000. running mean: -11.423127\n","resetting env. episode 1025.000000, reward total was -14.000000. running mean: -11.448896\n","resetting env. episode 1026.000000, reward total was -16.000000. running mean: -11.494407\n","resetting env. episode 1027.000000, reward total was -8.000000. running mean: -11.459463\n","resetting env. episode 1028.000000, reward total was -6.000000. running mean: -11.404868\n","resetting env. episode 1029.000000, reward total was -15.000000. running mean: -11.440819\n","resetting env. episode 1030.000000, reward total was -7.000000. running mean: -11.396411\n","resetting env. episode 1031.000000, reward total was -12.000000. running mean: -11.402447\n","resetting env. episode 1032.000000, reward total was -17.000000. running mean: -11.458423\n","resetting env. episode 1033.000000, reward total was -5.000000. running mean: -11.393838\n","resetting env. episode 1034.000000, reward total was -18.000000. running mean: -11.459900\n","resetting env. episode 1035.000000, reward total was -17.000000. running mean: -11.515301\n","resetting env. episode 1036.000000, reward total was -16.000000. running mean: -11.560148\n","resetting env. episode 1037.000000, reward total was -11.000000. running mean: -11.554546\n","resetting env. episode 1038.000000, reward total was -6.000000. running mean: -11.499001\n","resetting env. episode 1039.000000, reward total was -10.000000. running mean: -11.484011\n","resetting env. episode 1040.000000, reward total was -9.000000. running mean: -11.459171\n","resetting env. episode 1041.000000, reward total was -11.000000. running mean: -11.454579\n","resetting env. episode 1042.000000, reward total was -7.000000. running mean: -11.410033\n","resetting env. episode 1043.000000, reward total was -11.000000. running mean: -11.405933\n","resetting env. episode 1044.000000, reward total was -2.000000. running mean: -11.311874\n","resetting env. episode 1045.000000, reward total was -14.000000. running mean: -11.338755\n","resetting env. episode 1046.000000, reward total was -11.000000. running mean: -11.335367\n","resetting env. episode 1047.000000, reward total was -11.000000. running mean: -11.332014\n","resetting env. episode 1048.000000, reward total was -7.000000. running mean: -11.288694\n","resetting env. episode 1049.000000, reward total was -14.000000. running mean: -11.315807\n","resetting env. episode 1050.000000, reward total was -5.000000. running mean: -11.252649\n","resetting env. episode 1051.000000, reward total was -13.000000. running mean: -11.270122\n","resetting env. episode 1052.000000, reward total was -13.000000. running mean: -11.287421\n","resetting env. episode 1053.000000, reward total was -16.000000. running mean: -11.334547\n","resetting env. episode 1054.000000, reward total was -12.000000. running mean: -11.341201\n","resetting env. episode 1055.000000, reward total was -13.000000. running mean: -11.357789\n","resetting env. episode 1056.000000, reward total was -9.000000. running mean: -11.334211\n","resetting env. episode 1057.000000, reward total was -6.000000. running mean: -11.280869\n","resetting env. episode 1058.000000, reward total was -19.000000. running mean: -11.358060\n","resetting env. episode 1059.000000, reward total was -8.000000. running mean: -11.324480\n","resetting env. episode 1060.000000, reward total was -10.000000. running mean: -11.311235\n","resetting env. episode 1061.000000, reward total was -11.000000. running mean: -11.308123\n","resetting env. episode 1062.000000, reward total was -8.000000. running mean: -11.275042\n","resetting env. episode 1063.000000, reward total was -10.000000. running mean: -11.262291\n","resetting env. episode 1064.000000, reward total was -11.000000. running mean: -11.259668\n","resetting env. episode 1065.000000, reward total was -8.000000. running mean: -11.227071\n","resetting env. episode 1066.000000, reward total was -14.000000. running mean: -11.254801\n","resetting env. episode 1067.000000, reward total was -6.000000. running mean: -11.202253\n","resetting env. episode 1068.000000, reward total was -9.000000. running mean: -11.180230\n","resetting env. episode 1069.000000, reward total was -15.000000. running mean: -11.218428\n","resetting env. episode 1070.000000, reward total was -13.000000. running mean: -11.236244\n","resetting env. episode 1071.000000, reward total was -12.000000. running mean: -11.243881\n","resetting env. episode 1072.000000, reward total was -5.000000. running mean: -11.181442\n","resetting env. episode 1073.000000, reward total was -8.000000. running mean: -11.149628\n","resetting env. episode 1074.000000, reward total was -12.000000. running mean: -11.158132\n","resetting env. episode 1075.000000, reward total was -12.000000. running mean: -11.166550\n","resetting env. episode 1076.000000, reward total was -4.000000. running mean: -11.094885\n","resetting env. episode 1077.000000, reward total was -13.000000. running mean: -11.113936\n","resetting env. episode 1078.000000, reward total was -15.000000. running mean: -11.152797\n","resetting env. episode 1079.000000, reward total was -19.000000. running mean: -11.231269\n","resetting env. episode 1080.000000, reward total was -16.000000. running mean: -11.278956\n","resetting env. episode 1081.000000, reward total was -9.000000. running mean: -11.256166\n","resetting env. episode 1082.000000, reward total was -11.000000. running mean: -11.253605\n","resetting env. episode 1083.000000, reward total was -3.000000. running mean: -11.171069\n","resetting env. episode 1084.000000, reward total was -2.000000. running mean: -11.079358\n","resetting env. episode 1085.000000, reward total was -14.000000. running mean: -11.108564\n","resetting env. episode 1086.000000, reward total was -8.000000. running mean: -11.077479\n","resetting env. episode 1087.000000, reward total was -7.000000. running mean: -11.036704\n","resetting env. episode 1088.000000, reward total was -14.000000. running mean: -11.066337\n","resetting env. episode 1089.000000, reward total was -5.000000. running mean: -11.005674\n","resetting env. episode 1090.000000, reward total was -16.000000. running mean: -11.055617\n","resetting env. episode 1091.000000, reward total was -6.000000. running mean: -11.005061\n","resetting env. episode 1092.000000, reward total was -15.000000. running mean: -11.045010\n","resetting env. episode 1093.000000, reward total was -3.000000. running mean: -10.964560\n","resetting env. episode 1094.000000, reward total was -8.000000. running mean: -10.934914\n","resetting env. episode 1095.000000, reward total was -8.000000. running mean: -10.905565\n","resetting env. episode 1096.000000, reward total was -6.000000. running mean: -10.856510\n","resetting env. episode 1097.000000, reward total was -15.000000. running mean: -10.897945\n","resetting env. episode 1098.000000, reward total was -15.000000. running mean: -10.938965\n","resetting env. episode 1099.000000, reward total was -17.000000. running mean: -10.999575\n","resetting env. episode 1100.000000, reward total was -16.000000. running mean: -11.049580\n","resetting env. episode 1101.000000, reward total was -13.000000. running mean: -11.069084\n","resetting env. episode 1102.000000, reward total was -9.000000. running mean: -11.048393\n","resetting env. episode 1103.000000, reward total was -15.000000. running mean: -11.087909\n","resetting env. episode 1104.000000, reward total was -16.000000. running mean: -11.137030\n","resetting env. episode 1105.000000, reward total was -9.000000. running mean: -11.115660\n","resetting env. episode 1106.000000, reward total was -8.000000. running mean: -11.084503\n","resetting env. episode 1107.000000, reward total was -6.000000. running mean: -11.033658\n","resetting env. episode 1108.000000, reward total was -8.000000. running mean: -11.003322\n","resetting env. episode 1109.000000, reward total was -19.000000. running mean: -11.083288\n","resetting env. episode 1110.000000, reward total was -2.000000. running mean: -10.992455\n","resetting env. episode 1111.000000, reward total was -17.000000. running mean: -11.052531\n","resetting env. episode 1112.000000, reward total was -11.000000. running mean: -11.052006\n","resetting env. episode 1113.000000, reward total was -7.000000. running mean: -11.011486\n","resetting env. episode 1114.000000, reward total was -15.000000. running mean: -11.051371\n","resetting env. episode 1115.000000, reward total was -9.000000. running mean: -11.030857\n","resetting env. episode 1116.000000, reward total was -10.000000. running mean: -11.020548\n","resetting env. episode 1117.000000, reward total was -13.000000. running mean: -11.040343\n","resetting env. episode 1118.000000, reward total was -3.000000. running mean: -10.959939\n","resetting env. episode 1119.000000, reward total was -15.000000. running mean: -11.000340\n","resetting env. episode 1120.000000, reward total was -6.000000. running mean: -10.950337\n","resetting env. episode 1121.000000, reward total was -10.000000. running mean: -10.940833\n","resetting env. episode 1122.000000, reward total was -17.000000. running mean: -11.001425\n","resetting env. episode 1123.000000, reward total was -11.000000. running mean: -11.001411\n","resetting env. episode 1124.000000, reward total was -16.000000. running mean: -11.051397\n","resetting env. episode 1125.000000, reward total was -10.000000. running mean: -11.040883\n","resetting env. episode 1126.000000, reward total was -7.000000. running mean: -11.000474\n","resetting env. episode 1127.000000, reward total was -14.000000. running mean: -11.030469\n","resetting env. episode 1128.000000, reward total was -11.000000. running mean: -11.030164\n","resetting env. episode 1129.000000, reward total was -5.000000. running mean: -10.969863\n","resetting env. episode 1130.000000, reward total was -7.000000. running mean: -10.930164\n","resetting env. episode 1131.000000, reward total was -15.000000. running mean: -10.970862\n","resetting env. episode 1132.000000, reward total was -17.000000. running mean: -11.031154\n","resetting env. episode 1133.000000, reward total was -9.000000. running mean: -11.010842\n","resetting env. episode 1134.000000, reward total was -10.000000. running mean: -11.000734\n","resetting env. episode 1135.000000, reward total was -9.000000. running mean: -10.980727\n","resetting env. episode 1136.000000, reward total was -7.000000. running mean: -10.940919\n","resetting env. episode 1137.000000, reward total was -8.000000. running mean: -10.911510\n","resetting env. episode 1138.000000, reward total was -11.000000. running mean: -10.912395\n","resetting env. episode 1139.000000, reward total was -15.000000. running mean: -10.953271\n","resetting env. episode 1140.000000, reward total was -10.000000. running mean: -10.943738\n","resetting env. episode 1141.000000, reward total was -11.000000. running mean: -10.944301\n","resetting env. episode 1142.000000, reward total was -12.000000. running mean: -10.954858\n","resetting env. episode 1143.000000, reward total was -11.000000. running mean: -10.955309\n","resetting env. episode 1144.000000, reward total was -3.000000. running mean: -10.875756\n","resetting env. episode 1145.000000, reward total was -3.000000. running mean: -10.796999\n","resetting env. episode 1146.000000, reward total was -6.000000. running mean: -10.749029\n","resetting env. episode 1147.000000, reward total was -16.000000. running mean: -10.801538\n","resetting env. episode 1148.000000, reward total was -15.000000. running mean: -10.843523\n","resetting env. episode 1149.000000, reward total was -3.000000. running mean: -10.765088\n","resetting env. episode 1150.000000, reward total was -12.000000. running mean: -10.777437\n","resetting env. episode 1151.000000, reward total was -6.000000. running mean: -10.729663\n","resetting env. episode 1152.000000, reward total was -11.000000. running mean: -10.732366\n","resetting env. episode 1153.000000, reward total was -11.000000. running mean: -10.735042\n","resetting env. episode 1154.000000, reward total was -13.000000. running mean: -10.757692\n","resetting env. episode 1155.000000, reward total was -10.000000. running mean: -10.750115\n","resetting env. episode 1156.000000, reward total was -7.000000. running mean: -10.712614\n","resetting env. episode 1157.000000, reward total was -13.000000. running mean: -10.735488\n","resetting env. episode 1158.000000, reward total was -12.000000. running mean: -10.748133\n","resetting env. episode 1159.000000, reward total was -14.000000. running mean: -10.780651\n","resetting env. episode 1160.000000, reward total was -14.000000. running mean: -10.812845\n","resetting env. episode 1161.000000, reward total was -12.000000. running mean: -10.824716\n","resetting env. episode 1162.000000, reward total was -13.000000. running mean: -10.846469\n","resetting env. episode 1163.000000, reward total was 4.000000. running mean: -10.698005\n","resetting env. episode 1164.000000, reward total was -17.000000. running mean: -10.761025\n","resetting env. episode 1165.000000, reward total was -8.000000. running mean: -10.733414\n","resetting env. episode 1166.000000, reward total was -7.000000. running mean: -10.696080\n","resetting env. episode 1167.000000, reward total was -13.000000. running mean: -10.719119\n","resetting env. episode 1168.000000, reward total was -8.000000. running mean: -10.691928\n","resetting env. episode 1169.000000, reward total was -12.000000. running mean: -10.705009\n","resetting env. episode 1170.000000, reward total was -6.000000. running mean: -10.657959\n","resetting env. episode 1171.000000, reward total was -9.000000. running mean: -10.641379\n","resetting env. episode 1172.000000, reward total was -3.000000. running mean: -10.564965\n","resetting env. episode 1173.000000, reward total was -17.000000. running mean: -10.629316\n","resetting env. episode 1174.000000, reward total was -5.000000. running mean: -10.573023\n","resetting env. episode 1175.000000, reward total was -15.000000. running mean: -10.617292\n","resetting env. episode 1176.000000, reward total was -7.000000. running mean: -10.581119\n","resetting env. episode 1177.000000, reward total was -1.000000. running mean: -10.485308\n","resetting env. episode 1178.000000, reward total was -17.000000. running mean: -10.550455\n","resetting env. episode 1179.000000, reward total was -3.000000. running mean: -10.474951\n","resetting env. episode 1180.000000, reward total was -13.000000. running mean: -10.500201\n","resetting env. episode 1181.000000, reward total was -15.000000. running mean: -10.545199\n","resetting env. episode 1182.000000, reward total was -16.000000. running mean: -10.599747\n","resetting env. episode 1183.000000, reward total was -5.000000. running mean: -10.543750\n","resetting env. episode 1184.000000, reward total was -13.000000. running mean: -10.568312\n","resetting env. episode 1185.000000, reward total was -9.000000. running mean: -10.552629\n","resetting env. episode 1186.000000, reward total was -13.000000. running mean: -10.577103\n","resetting env. episode 1187.000000, reward total was -5.000000. running mean: -10.521332\n","resetting env. episode 1188.000000, reward total was -13.000000. running mean: -10.546118\n","resetting env. episode 1189.000000, reward total was -15.000000. running mean: -10.590657\n","resetting env. episode 1190.000000, reward total was -11.000000. running mean: -10.594751\n","resetting env. episode 1191.000000, reward total was -17.000000. running mean: -10.658803\n","resetting env. episode 1192.000000, reward total was -11.000000. running mean: -10.662215\n","resetting env. episode 1193.000000, reward total was -18.000000. running mean: -10.735593\n","resetting env. episode 1194.000000, reward total was -7.000000. running mean: -10.698237\n","resetting env. episode 1195.000000, reward total was -15.000000. running mean: -10.741255\n","resetting env. episode 1196.000000, reward total was -12.000000. running mean: -10.753842\n","resetting env. episode 1197.000000, reward total was -11.000000. running mean: -10.756304\n","resetting env. episode 1198.000000, reward total was -15.000000. running mean: -10.798741\n","resetting env. episode 1199.000000, reward total was -11.000000. running mean: -10.800753\n","resetting env. episode 1200.000000, reward total was -9.000000. running mean: -10.782746\n","resetting env. episode 1201.000000, reward total was -3.000000. running mean: -10.704918\n","resetting env. episode 1202.000000, reward total was -9.000000. running mean: -10.687869\n","resetting env. episode 1203.000000, reward total was 2.000000. running mean: -10.560990\n","resetting env. episode 1204.000000, reward total was -13.000000. running mean: -10.585380\n","resetting env. episode 1205.000000, reward total was -10.000000. running mean: -10.579527\n","resetting env. episode 1206.000000, reward total was -13.000000. running mean: -10.603731\n","resetting env. episode 1207.000000, reward total was -15.000000. running mean: -10.647694\n","resetting env. episode 1208.000000, reward total was -14.000000. running mean: -10.681217\n","resetting env. episode 1209.000000, reward total was -8.000000. running mean: -10.654405\n","resetting env. episode 1210.000000, reward total was -5.000000. running mean: -10.597861\n","resetting env. episode 1211.000000, reward total was -13.000000. running mean: -10.621882\n","resetting env. episode 1212.000000, reward total was -3.000000. running mean: -10.545664\n","resetting env. episode 1213.000000, reward total was -12.000000. running mean: -10.560207\n","resetting env. episode 1214.000000, reward total was -7.000000. running mean: -10.524605\n","resetting env. episode 1215.000000, reward total was -10.000000. running mean: -10.519359\n","resetting env. episode 1216.000000, reward total was -17.000000. running mean: -10.584165\n","resetting env. episode 1217.000000, reward total was -15.000000. running mean: -10.628324\n","resetting env. episode 1218.000000, reward total was -2.000000. running mean: -10.542040\n","resetting env. episode 1219.000000, reward total was -11.000000. running mean: -10.546620\n","resetting env. episode 1220.000000, reward total was -12.000000. running mean: -10.561154\n","resetting env. episode 1221.000000, reward total was -13.000000. running mean: -10.585542\n","resetting env. episode 1222.000000, reward total was -10.000000. running mean: -10.579687\n","resetting env. episode 1223.000000, reward total was -17.000000. running mean: -10.643890\n","resetting env. episode 1224.000000, reward total was -7.000000. running mean: -10.607451\n","resetting env. episode 1225.000000, reward total was -5.000000. running mean: -10.551376\n","resetting env. episode 1226.000000, reward total was -9.000000. running mean: -10.535863\n","resetting env. episode 1227.000000, reward total was -8.000000. running mean: -10.510504\n","resetting env. episode 1228.000000, reward total was -13.000000. running mean: -10.535399\n","resetting env. episode 1229.000000, reward total was -16.000000. running mean: -10.590045\n","resetting env. episode 1230.000000, reward total was -13.000000. running mean: -10.614145\n","resetting env. episode 1231.000000, reward total was -15.000000. running mean: -10.658003\n","resetting env. episode 1232.000000, reward total was -6.000000. running mean: -10.611423\n","resetting env. episode 1233.000000, reward total was -9.000000. running mean: -10.595309\n","resetting env. episode 1234.000000, reward total was -14.000000. running mean: -10.629356\n","resetting env. episode 1235.000000, reward total was -14.000000. running mean: -10.663062\n","resetting env. episode 1236.000000, reward total was -5.000000. running mean: -10.606432\n","resetting env. episode 1237.000000, reward total was -9.000000. running mean: -10.590367\n","resetting env. episode 1238.000000, reward total was -6.000000. running mean: -10.544464\n","resetting env. episode 1239.000000, reward total was -11.000000. running mean: -10.549019\n","resetting env. episode 1240.000000, reward total was -15.000000. running mean: -10.593529\n","resetting env. episode 1241.000000, reward total was -6.000000. running mean: -10.547593\n","resetting env. episode 1242.000000, reward total was -8.000000. running mean: -10.522118\n","resetting env. episode 1243.000000, reward total was -14.000000. running mean: -10.556896\n","resetting env. episode 1244.000000, reward total was -3.000000. running mean: -10.481327\n","resetting env. episode 1245.000000, reward total was -11.000000. running mean: -10.486514\n","resetting env. episode 1246.000000, reward total was -13.000000. running mean: -10.511649\n","resetting env. episode 1247.000000, reward total was 6.000000. running mean: -10.346533\n","resetting env. episode 1248.000000, reward total was -7.000000. running mean: -10.313067\n","resetting env. episode 1249.000000, reward total was -7.000000. running mean: -10.279937\n","resetting env. episode 1250.000000, reward total was -3.000000. running mean: -10.207137\n","resetting env. episode 1251.000000, reward total was -19.000000. running mean: -10.295066\n","resetting env. episode 1252.000000, reward total was -13.000000. running mean: -10.322115\n","resetting env. episode 1253.000000, reward total was -17.000000. running mean: -10.388894\n","resetting env. episode 1254.000000, reward total was -3.000000. running mean: -10.315005\n","resetting env. episode 1255.000000, reward total was -10.000000. running mean: -10.311855\n","resetting env. episode 1256.000000, reward total was -12.000000. running mean: -10.328736\n","resetting env. episode 1257.000000, reward total was -5.000000. running mean: -10.275449\n","resetting env. episode 1258.000000, reward total was -13.000000. running mean: -10.302695\n","resetting env. episode 1259.000000, reward total was -9.000000. running mean: -10.289668\n","resetting env. episode 1260.000000, reward total was -14.000000. running mean: -10.326771\n","resetting env. episode 1261.000000, reward total was -10.000000. running mean: -10.323503\n","resetting env. episode 1262.000000, reward total was -7.000000. running mean: -10.290268\n","resetting env. episode 1263.000000, reward total was -7.000000. running mean: -10.257366\n","resetting env. episode 1264.000000, reward total was -7.000000. running mean: -10.224792\n","resetting env. episode 1265.000000, reward total was -8.000000. running mean: -10.202544\n","resetting env. episode 1266.000000, reward total was -10.000000. running mean: -10.200519\n","resetting env. episode 1267.000000, reward total was -9.000000. running mean: -10.188513\n","resetting env. episode 1268.000000, reward total was -10.000000. running mean: -10.186628\n","resetting env. episode 1269.000000, reward total was -17.000000. running mean: -10.254762\n","resetting env. episode 1270.000000, reward total was -15.000000. running mean: -10.302214\n","resetting env. episode 1271.000000, reward total was -7.000000. running mean: -10.269192\n","resetting env. episode 1272.000000, reward total was -10.000000. running mean: -10.266500\n","resetting env. episode 1273.000000, reward total was -9.000000. running mean: -10.253835\n","resetting env. episode 1274.000000, reward total was -12.000000. running mean: -10.271297\n","resetting env. episode 1275.000000, reward total was -9.000000. running mean: -10.258584\n","resetting env. episode 1276.000000, reward total was 2.000000. running mean: -10.135998\n","resetting env. episode 1277.000000, reward total was -11.000000. running mean: -10.144638\n","resetting env. episode 1278.000000, reward total was -5.000000. running mean: -10.093192\n","resetting env. episode 1279.000000, reward total was -3.000000. running mean: -10.022260\n","resetting env. episode 1280.000000, reward total was -13.000000. running mean: -10.052037\n","resetting env. episode 1281.000000, reward total was -7.000000. running mean: -10.021517\n","resetting env. episode 1282.000000, reward total was -12.000000. running mean: -10.041302\n","resetting env. episode 1283.000000, reward total was 1.000000. running mean: -9.930889\n","resetting env. episode 1284.000000, reward total was -11.000000. running mean: -9.941580\n","resetting env. episode 1285.000000, reward total was -11.000000. running mean: -9.952164\n","resetting env. episode 1286.000000, reward total was -11.000000. running mean: -9.962642\n","resetting env. episode 1287.000000, reward total was -17.000000. running mean: -10.033016\n","resetting env. episode 1288.000000, reward total was -10.000000. running mean: -10.032686\n","resetting env. episode 1289.000000, reward total was -10.000000. running mean: -10.032359\n","resetting env. episode 1290.000000, reward total was -11.000000. running mean: -10.042035\n","resetting env. episode 1291.000000, reward total was -13.000000. running mean: -10.071615\n","resetting env. episode 1292.000000, reward total was -8.000000. running mean: -10.050899\n","resetting env. episode 1293.000000, reward total was -9.000000. running mean: -10.040390\n","resetting env. episode 1294.000000, reward total was -9.000000. running mean: -10.029986\n","resetting env. episode 1295.000000, reward total was -7.000000. running mean: -9.999686\n","resetting env. episode 1296.000000, reward total was -13.000000. running mean: -10.029689\n","resetting env. episode 1297.000000, reward total was -17.000000. running mean: -10.099392\n","resetting env. episode 1298.000000, reward total was -12.000000. running mean: -10.118398\n","resetting env. episode 1299.000000, reward total was -15.000000. running mean: -10.167214\n","resetting env. episode 1300.000000, reward total was -13.000000. running mean: -10.195542\n","resetting env. episode 1301.000000, reward total was -11.000000. running mean: -10.203587\n","resetting env. episode 1302.000000, reward total was -9.000000. running mean: -10.191551\n","resetting env. episode 1303.000000, reward total was -6.000000. running mean: -10.149635\n","resetting env. episode 1304.000000, reward total was -11.000000. running mean: -10.158139\n","resetting env. episode 1305.000000, reward total was -7.000000. running mean: -10.126558\n","resetting env. episode 1306.000000, reward total was -8.000000. running mean: -10.105292\n","resetting env. episode 1307.000000, reward total was -10.000000. running mean: -10.104239\n","resetting env. episode 1308.000000, reward total was -15.000000. running mean: -10.153197\n","resetting env. episode 1309.000000, reward total was -14.000000. running mean: -10.191665\n","resetting env. episode 1310.000000, reward total was -14.000000. running mean: -10.229748\n","resetting env. episode 1311.000000, reward total was -8.000000. running mean: -10.207451\n","resetting env. episode 1312.000000, reward total was -12.000000. running mean: -10.225376\n","resetting env. episode 1313.000000, reward total was -13.000000. running mean: -10.253122\n","resetting env. episode 1314.000000, reward total was -15.000000. running mean: -10.300591\n","resetting env. episode 1315.000000, reward total was -9.000000. running mean: -10.287585\n","resetting env. episode 1316.000000, reward total was -13.000000. running mean: -10.314709\n","resetting env. episode 1317.000000, reward total was -9.000000. running mean: -10.301562\n","resetting env. episode 1318.000000, reward total was -6.000000. running mean: -10.258547\n","resetting env. episode 1319.000000, reward total was -16.000000. running mean: -10.315961\n","resetting env. episode 1320.000000, reward total was -11.000000. running mean: -10.322802\n","resetting env. episode 1321.000000, reward total was -1.000000. running mean: -10.229574\n","resetting env. episode 1322.000000, reward total was -14.000000. running mean: -10.267278\n","resetting env. episode 1323.000000, reward total was -11.000000. running mean: -10.274605\n","resetting env. episode 1324.000000, reward total was -9.000000. running mean: -10.261859\n","resetting env. episode 1325.000000, reward total was -1.000000. running mean: -10.169240\n","resetting env. episode 1326.000000, reward total was -12.000000. running mean: -10.187548\n","resetting env. episode 1327.000000, reward total was -16.000000. running mean: -10.245673\n","resetting env. episode 1328.000000, reward total was -10.000000. running mean: -10.243216\n","resetting env. episode 1329.000000, reward total was -6.000000. running mean: -10.200784\n","resetting env. episode 1330.000000, reward total was -9.000000. running mean: -10.188776\n","resetting env. episode 1331.000000, reward total was -7.000000. running mean: -10.156888\n","resetting env. episode 1332.000000, reward total was -6.000000. running mean: -10.115319\n","resetting env. episode 1333.000000, reward total was -11.000000. running mean: -10.124166\n","resetting env. episode 1334.000000, reward total was -11.000000. running mean: -10.132924\n","resetting env. episode 1335.000000, reward total was -11.000000. running mean: -10.141595\n","resetting env. episode 1336.000000, reward total was -7.000000. running mean: -10.110179\n","resetting env. episode 1337.000000, reward total was -9.000000. running mean: -10.099077\n","resetting env. episode 1338.000000, reward total was -6.000000. running mean: -10.058087\n","resetting env. episode 1339.000000, reward total was -9.000000. running mean: -10.047506\n","resetting env. episode 1340.000000, reward total was -13.000000. running mean: -10.077031\n","resetting env. episode 1341.000000, reward total was -4.000000. running mean: -10.016260\n","resetting env. episode 1342.000000, reward total was -11.000000. running mean: -10.026098\n","resetting env. episode 1343.000000, reward total was -13.000000. running mean: -10.055837\n","resetting env. episode 1344.000000, reward total was -14.000000. running mean: -10.095278\n","resetting env. episode 1345.000000, reward total was -15.000000. running mean: -10.144326\n","resetting env. episode 1346.000000, reward total was -11.000000. running mean: -10.152882\n","resetting env. episode 1347.000000, reward total was -15.000000. running mean: -10.201354\n","resetting env. episode 1348.000000, reward total was -12.000000. running mean: -10.219340\n","resetting env. episode 1349.000000, reward total was -12.000000. running mean: -10.237147\n","resetting env. episode 1350.000000, reward total was -11.000000. running mean: -10.244775\n","resetting env. episode 1351.000000, reward total was -6.000000. running mean: -10.202327\n","resetting env. episode 1352.000000, reward total was -9.000000. running mean: -10.190304\n","resetting env. episode 1353.000000, reward total was -3.000000. running mean: -10.118401\n","resetting env. episode 1354.000000, reward total was -11.000000. running mean: -10.127217\n","resetting env. episode 1355.000000, reward total was -9.000000. running mean: -10.115945\n","resetting env. episode 1356.000000, reward total was -12.000000. running mean: -10.134785\n","resetting env. episode 1357.000000, reward total was -10.000000. running mean: -10.133438\n","resetting env. episode 1358.000000, reward total was -9.000000. running mean: -10.122103\n","resetting env. episode 1359.000000, reward total was -7.000000. running mean: -10.090882\n","resetting env. episode 1360.000000, reward total was -13.000000. running mean: -10.119973\n","resetting env. episode 1361.000000, reward total was -8.000000. running mean: -10.098774\n","resetting env. episode 1362.000000, reward total was -14.000000. running mean: -10.137786\n","resetting env. episode 1363.000000, reward total was -7.000000. running mean: -10.106408\n","resetting env. episode 1364.000000, reward total was -6.000000. running mean: -10.065344\n","resetting env. episode 1365.000000, reward total was -5.000000. running mean: -10.014691\n","resetting env. episode 1366.000000, reward total was -11.000000. running mean: -10.024544\n","resetting env. episode 1367.000000, reward total was -10.000000. running mean: -10.024298\n","resetting env. episode 1368.000000, reward total was -13.000000. running mean: -10.054055\n","resetting env. episode 1369.000000, reward total was -17.000000. running mean: -10.123515\n","resetting env. episode 1370.000000, reward total was -9.000000. running mean: -10.112280\n","resetting env. episode 1371.000000, reward total was -2.000000. running mean: -10.031157\n","resetting env. episode 1372.000000, reward total was -5.000000. running mean: -9.980845\n","resetting env. episode 1373.000000, reward total was -15.000000. running mean: -10.031037\n","resetting env. episode 1374.000000, reward total was -6.000000. running mean: -9.990726\n","resetting env. episode 1375.000000, reward total was -6.000000. running mean: -9.950819\n","resetting env. episode 1376.000000, reward total was -10.000000. running mean: -9.951311\n","resetting env. episode 1377.000000, reward total was -6.000000. running mean: -9.911798\n","resetting env. episode 1378.000000, reward total was -5.000000. running mean: -9.862680\n","resetting env. episode 1379.000000, reward total was -7.000000. running mean: -9.834053\n","resetting env. episode 1380.000000, reward total was -8.000000. running mean: -9.815712\n","resetting env. episode 1381.000000, reward total was -3.000000. running mean: -9.747555\n","resetting env. episode 1382.000000, reward total was -8.000000. running mean: -9.730080\n","resetting env. episode 1383.000000, reward total was -12.000000. running mean: -9.752779\n","resetting env. episode 1384.000000, reward total was -15.000000. running mean: -9.805251\n","resetting env. episode 1385.000000, reward total was -14.000000. running mean: -9.847199\n","resetting env. episode 1386.000000, reward total was -13.000000. running mean: -9.878727\n","resetting env. episode 1387.000000, reward total was -7.000000. running mean: -9.849939\n","resetting env. episode 1388.000000, reward total was -15.000000. running mean: -9.901440\n","resetting env. episode 1389.000000, reward total was -14.000000. running mean: -9.942426\n","resetting env. episode 1390.000000, reward total was -11.000000. running mean: -9.953001\n","resetting env. episode 1391.000000, reward total was -16.000000. running mean: -10.013471\n","resetting env. episode 1392.000000, reward total was -10.000000. running mean: -10.013337\n","resetting env. episode 1393.000000, reward total was -6.000000. running mean: -9.973203\n","resetting env. episode 1394.000000, reward total was -9.000000. running mean: -9.963471\n","resetting env. episode 1395.000000, reward total was -16.000000. running mean: -10.023837\n","resetting env. episode 1396.000000, reward total was -9.000000. running mean: -10.013598\n","resetting env. episode 1397.000000, reward total was -9.000000. running mean: -10.003462\n","resetting env. episode 1398.000000, reward total was -13.000000. running mean: -10.033428\n","resetting env. episode 1399.000000, reward total was -7.000000. running mean: -10.003093\n","resetting env. episode 1400.000000, reward total was -5.000000. running mean: -9.953062\n","resetting env. episode 1401.000000, reward total was -10.000000. running mean: -9.953532\n","resetting env. episode 1402.000000, reward total was -12.000000. running mean: -9.973996\n","resetting env. episode 1403.000000, reward total was -14.000000. running mean: -10.014256\n","resetting env. episode 1404.000000, reward total was -7.000000. running mean: -9.984114\n","resetting env. episode 1405.000000, reward total was -11.000000. running mean: -9.994273\n","resetting env. episode 1406.000000, reward total was 1.000000. running mean: -9.884330\n","resetting env. episode 1407.000000, reward total was -7.000000. running mean: -9.855487\n","resetting env. episode 1408.000000, reward total was -9.000000. running mean: -9.846932\n","resetting env. episode 1409.000000, reward total was -11.000000. running mean: -9.858463\n","resetting env. episode 1410.000000, reward total was -17.000000. running mean: -9.929878\n","resetting env. episode 1411.000000, reward total was -15.000000. running mean: -9.980579\n","resetting env. episode 1412.000000, reward total was -9.000000. running mean: -9.970773\n","resetting env. episode 1413.000000, reward total was -12.000000. running mean: -9.991066\n","resetting env. episode 1414.000000, reward total was -15.000000. running mean: -10.041155\n","resetting env. episode 1415.000000, reward total was -9.000000. running mean: -10.030743\n","resetting env. episode 1416.000000, reward total was -13.000000. running mean: -10.060436\n","resetting env. episode 1417.000000, reward total was -12.000000. running mean: -10.079832\n","resetting env. episode 1418.000000, reward total was -20.000000. running mean: -10.179033\n","resetting env. episode 1419.000000, reward total was -11.000000. running mean: -10.187243\n","resetting env. episode 1420.000000, reward total was -8.000000. running mean: -10.165371\n","resetting env. episode 1421.000000, reward total was -3.000000. running mean: -10.093717\n","resetting env. episode 1422.000000, reward total was -12.000000. running mean: -10.112780\n","resetting env. episode 1423.000000, reward total was -19.000000. running mean: -10.201652\n","resetting env. episode 1424.000000, reward total was -3.000000. running mean: -10.129635\n","resetting env. episode 1425.000000, reward total was -2.000000. running mean: -10.048339\n","resetting env. episode 1426.000000, reward total was -9.000000. running mean: -10.037856\n","resetting env. episode 1427.000000, reward total was -11.000000. running mean: -10.047477\n","resetting env. episode 1428.000000, reward total was -13.000000. running mean: -10.077002\n","resetting env. episode 1429.000000, reward total was -8.000000. running mean: -10.056232\n","resetting env. episode 1430.000000, reward total was -12.000000. running mean: -10.075670\n","resetting env. episode 1431.000000, reward total was -9.000000. running mean: -10.064913\n","resetting env. episode 1432.000000, reward total was -9.000000. running mean: -10.054264\n","resetting env. episode 1433.000000, reward total was -6.000000. running mean: -10.013721\n","resetting env. episode 1434.000000, reward total was -11.000000. running mean: -10.023584\n","resetting env. episode 1435.000000, reward total was -5.000000. running mean: -9.973348\n","resetting env. episode 1436.000000, reward total was -4.000000. running mean: -9.913615\n","resetting env. episode 1437.000000, reward total was -8.000000. running mean: -9.894479\n","resetting env. episode 1438.000000, reward total was 1.000000. running mean: -9.785534\n","resetting env. episode 1439.000000, reward total was -13.000000. running mean: -9.817679\n","resetting env. episode 1440.000000, reward total was -3.000000. running mean: -9.749502\n","resetting env. episode 1441.000000, reward total was -12.000000. running mean: -9.772007\n","resetting env. episode 1442.000000, reward total was -9.000000. running mean: -9.764287\n","resetting env. episode 1443.000000, reward total was -11.000000. running mean: -9.776644\n","resetting env. episode 1444.000000, reward total was -10.000000. running mean: -9.778877\n","resetting env. episode 1445.000000, reward total was -11.000000. running mean: -9.791089\n","resetting env. episode 1446.000000, reward total was -1.000000. running mean: -9.703178\n","resetting env. episode 1447.000000, reward total was -7.000000. running mean: -9.676146\n","resetting env. episode 1448.000000, reward total was -11.000000. running mean: -9.689385\n","resetting env. episode 1449.000000, reward total was 5.000000. running mean: -9.542491\n","resetting env. episode 1450.000000, reward total was -11.000000. running mean: -9.557066\n","resetting env. episode 1451.000000, reward total was -14.000000. running mean: -9.601495\n","resetting env. episode 1452.000000, reward total was -6.000000. running mean: -9.565480\n","resetting env. episode 1453.000000, reward total was -10.000000. running mean: -9.569825\n","resetting env. episode 1454.000000, reward total was -9.000000. running mean: -9.564127\n","resetting env. episode 1455.000000, reward total was -9.000000. running mean: -9.558486\n","resetting env. episode 1456.000000, reward total was -9.000000. running mean: -9.552901\n","resetting env. episode 1457.000000, reward total was -15.000000. running mean: -9.607372\n","resetting env. episode 1458.000000, reward total was -6.000000. running mean: -9.571298\n","resetting env. episode 1459.000000, reward total was -13.000000. running mean: -9.605585\n","resetting env. episode 1460.000000, reward total was -10.000000. running mean: -9.609529\n","resetting env. episode 1461.000000, reward total was -11.000000. running mean: -9.623434\n","resetting env. episode 1462.000000, reward total was -13.000000. running mean: -9.657200\n","resetting env. episode 1463.000000, reward total was 3.000000. running mean: -9.530628\n","resetting env. episode 1464.000000, reward total was -7.000000. running mean: -9.505322\n","resetting env. episode 1465.000000, reward total was -11.000000. running mean: -9.520268\n","resetting env. episode 1466.000000, reward total was -9.000000. running mean: -9.515066\n","resetting env. episode 1467.000000, reward total was -10.000000. running mean: -9.519915\n","resetting env. episode 1468.000000, reward total was -12.000000. running mean: -9.544716\n","resetting env. episode 1469.000000, reward total was -3.000000. running mean: -9.479269\n","resetting env. episode 1470.000000, reward total was -10.000000. running mean: -9.484476\n","resetting env. episode 1471.000000, reward total was -5.000000. running mean: -9.439631\n","resetting env. episode 1472.000000, reward total was -15.000000. running mean: -9.495235\n","resetting env. episode 1473.000000, reward total was -2.000000. running mean: -9.420283\n","resetting env. episode 1474.000000, reward total was -6.000000. running mean: -9.386080\n","resetting env. episode 1475.000000, reward total was -9.000000. running mean: -9.382219\n","resetting env. episode 1476.000000, reward total was -3.000000. running mean: -9.318397\n","resetting env. episode 1477.000000, reward total was -9.000000. running mean: -9.315213\n","resetting env. episode 1478.000000, reward total was -10.000000. running mean: -9.322061\n","resetting env. episode 1479.000000, reward total was -8.000000. running mean: -9.308840\n","resetting env. episode 1480.000000, reward total was -8.000000. running mean: -9.295752\n","resetting env. episode 1481.000000, reward total was -3.000000. running mean: -9.232794\n","resetting env. episode 1482.000000, reward total was -6.000000. running mean: -9.200466\n","resetting env. episode 1483.000000, reward total was -15.000000. running mean: -9.258462\n","resetting env. episode 1484.000000, reward total was -11.000000. running mean: -9.275877\n","resetting env. episode 1485.000000, reward total was -9.000000. running mean: -9.273118\n","resetting env. episode 1486.000000, reward total was -9.000000. running mean: -9.270387\n","resetting env. episode 1487.000000, reward total was -8.000000. running mean: -9.257683\n","resetting env. episode 1488.000000, reward total was -13.000000. running mean: -9.295106\n","resetting env. episode 1489.000000, reward total was -9.000000. running mean: -9.292155\n","resetting env. episode 1490.000000, reward total was -10.000000. running mean: -9.299234\n","resetting env. episode 1491.000000, reward total was -4.000000. running mean: -9.246241\n","resetting env. episode 1492.000000, reward total was -3.000000. running mean: -9.183779\n","resetting env. episode 1493.000000, reward total was -6.000000. running mean: -9.151941\n","resetting env. episode 1494.000000, reward total was -12.000000. running mean: -9.180422\n","resetting env. episode 1495.000000, reward total was -17.000000. running mean: -9.258617\n","resetting env. episode 1496.000000, reward total was -10.000000. running mean: -9.266031\n","resetting env. episode 1497.000000, reward total was -11.000000. running mean: -9.283371\n","resetting env. episode 1498.000000, reward total was -9.000000. running mean: -9.280537\n","resetting env. episode 1499.000000, reward total was -13.000000. running mean: -9.317732\n","resetting env. episode 1500.000000, reward total was -14.000000. running mean: -9.364555\n","CPU times: user 4h 18min 51s, sys: 2h 3min 26s, total: 6h 22min 18s\n","Wall time: 3h 17min 56s\n"]}]},{"metadata":{"id":"w2NblmwDsL3y","outputId":"33a7e056-5521-4461-86b7-ed90e2818be5","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"ok","timestamp":1660754284439,"user_tz":-330,"elapsed":40403,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = 1.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}