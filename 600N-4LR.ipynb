{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"600N-4LR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"cWACPRL869I4","executionInfo":{"status":"ok","timestamp":1660642910727,"user_tz":-330,"elapsed":2773,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install gym >/dev/null"],"execution_count":1,"outputs":[]},{"metadata":{"id":"2Os6feRY6ec_","executionInfo":{"status":"ok","timestamp":1660642915482,"user_tz":-330,"elapsed":4764,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install JSAnimation >/dev/null"],"execution_count":2,"outputs":[]},{"metadata":{"id":"wotUOa_e6edP","executionInfo":{"status":"ok","timestamp":1660642915483,"user_tz":-330,"elapsed":9,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%matplotlib inline\n","from JSAnimation.IPython_display import display_animation\n","from matplotlib import animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","\n","def display_frames_as_gif(frames):\n","    \"\"\"\n","    Displays a list of frames as a gif, with controls\n","    \"\"\"\n","    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","\n","    def animate(i):\n","        patch.set_data(frames[i])\n","\n","    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n","    HTML(anim.to_jshtml())"],"execution_count":3,"outputs":[]},{"metadata":{"id":"R66_INeZ9nYX"},"cell_type":"markdown","source":["## Step 2: Playing Pong"]},{"cell_type":"code","source":["%pip install -U gym>=0.21.0\n","%pip install -U gym[atari,accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ngMhg3fB9aA","outputId":"1889ac2b-0a24-4607-bdd6-159f3383488d","executionInfo":{"status":"ok","timestamp":1660642952713,"user_tz":-330,"elapsed":37238,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 33.0 MB/s \n","\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=6ed256bd19dc2ebb89aa2082c2ac2bb96d1eb20eface0b87d52f6c89377c7278\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"]}]},{"metadata":{"id":"MtT2GyK_6edc","outputId":"151bb37e-29a9-40ae-a870-0adade372af1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660642952713,"user_tz":-330,"elapsed":26,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import gym\n","env = gym.make('Pong-v0')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  f\"The environment {id} is out of date. You should consider \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}]},{"metadata":{"id":"oRE6WmXQJ1Z0","outputId":"1566e78a-a577-43b5-f8bd-7488db80fcaf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660642953672,"user_tz":-330,"elapsed":969,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.action_space"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(6)"]},"metadata":{},"execution_count":6}]},{"metadata":{"id":"yl_9d4HFJ31W","outputId":"a2f02861-b26b-4552-d029-56783923590a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660642953672,"user_tz":-330,"elapsed":15,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.observation_space"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box(0, 255, (210, 160, 3), uint8)"]},"metadata":{},"execution_count":7}]},{"metadata":{"id":"trwRXI-h6eeI","outputId":"118373aa-dd85-48db-cb19-cb64277d6856","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660642953673,"user_tz":-330,"elapsed":14,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# Run a demo of the environment\n","observation = env.reset()\n","cumulated_reward = 0\n","\n","frames = []\n","for t in range(1000):\n","#     print(observation)\n","    frames.append(env.render(mode = 'rgb_array'))\n","    # very stupid agent, just makes a random action within the allowd action space\n","    action = env.action_space.sample()\n","#     print(\"Action: {}\".format(t+1))    \n","    observation, reward, done, info = env.step(action)\n","#     print(reward)\n","    cumulated_reward += reward\n","    if done:\n","        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","        break\n","print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","\n","env.close()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -18.0\n"]}]},{"metadata":{"id":"3zZTecVWLLes","executionInfo":{"status":"ok","timestamp":1660642953673,"user_tz":-330,"elapsed":11,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["def sigmoid(x): \n","  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n","\n","def prepro(I):\n","  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n","  I = I[35:195] # crop\n","  I = I[::2,::2,0] # downsample by factor of 2\n","  I[I == 144] = 0 # erase background (background type 1)\n","  I[I == 109] = 0 # erase background (background type 2)\n","  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n","  return I.astype(np.float).ravel()\n","\n","def policy_forward(x):\n","  h = np.dot(model['W1'], x)\n","  h[h<0] = 0 # ReLU nonlinearity\n","  logp = np.dot(model['W2'], h)\n","  p = sigmoid(logp)\n","  return p, h # return probability of taking action 2, and hidden state\n","\n","def model_step(model, observation, prev_x):\n","  # preprocess the observation, set input to network to be difference image\n","  cur_x = prepro(observation)\n","  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","  prev_x = cur_x\n","  \n","  # forward the policy network and sample an action from the returned probability\n","  aprob, _ = policy_forward(x)\n","  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n","  \n","  return action, prev_x\n","\n","def play_game(env, model):\n","  observation = env.reset()\n","\n","  frames = []\n","  cumulated_reward = 0\n","\n","  prev_x = None # used in computing the difference frame\n","\n","  for t in range(1000):\n","      frames.append(env.render(mode = 'rgb_array'))\n","      action, prev_x = model_step(model, observation, prev_x)\n","      observation, reward, done, info = env.step(action)\n","      cumulated_reward += reward\n","      if done:\n","          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","          break\n","  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","  display_frames_as_gif(frames)\n","  env.close()"],"execution_count":9,"outputs":[]},{"metadata":{"id":"6gWvZQ7AQLQt"},"cell_type":"markdown","source":["## Step 3: Policy Gradient from Scratch"]},{"metadata":{"id":"eqFm7hqcItWl","executionInfo":{"status":"ok","timestamp":1660642953674,"user_tz":-330,"elapsed":12,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import numpy as np\n","\n","# model initialization\n","H = 600 # number of hidden layer neurons\n","D = 80 * 80 # input dimensionality: 80x80 grid\n","model = {}\n","model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n","model['W2'] = np.random.randn(H) / np.sqrt(H)\n","\n","# import pickle\n","# model = pickle.load(open('model.pkl', 'rb'))"],"execution_count":10,"outputs":[]},{"metadata":{"id":"TwjiwKisQM19","executionInfo":{"status":"ok","timestamp":1660642953674,"user_tz":-330,"elapsed":11,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# hyperparameters\n","batch_size = 10 # every how many episodes to do a param update?\n","# learning_rate = 1e-4\n","learning_rate = 1e-4\n"," \n","gamma = 0.99 # discount factor for reward\n","decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n","  \n","grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n","rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n","\n","def discount_rewards(r):\n","  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n","  discounted_r = np.zeros_like(r, dtype=np.float32)\n","  running_add = 0\n","  for t in reversed(range(0, r.size)):\n","    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n","    running_add = running_add * gamma + r[t]\n","    discounted_r[t] = running_add\n","  return discounted_r\n","\n","def policy_backward(epx, eph, epdlogp):\n","  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n","  dW2 = np.dot(eph.T, epdlogp).ravel()\n","  dh = np.outer(epdlogp, model['W2'])\n","  dh[eph <= 0] = 0 # backpro prelu\n","  dW1 = np.dot(dh.T, epx)\n","  return {'W1':dW1, 'W2':dW2}\n","\n","def train_model(env, model, total_episodes = 100):\n","  hist = []\n","  observation = env.reset()\n","\n","  prev_x = None # used in computing the difference frame\n","  xs,hs,dlogps,drs = [],[],[],[]\n","  running_reward = None\n","  reward_sum = 0\n","  episode_number = 0\n","\n","  while True:\n","    # preprocess the observation, set input to network to be difference image\n","    cur_x = prepro(observation)\n","    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","    prev_x = cur_x\n","\n","    # forward the policy network and sample an action from the returned probability\n","    aprob, h = policy_forward(x)\n","    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n","\n","    # record various intermediates (needed later for backprop)\n","    xs.append(x) # observation\n","    hs.append(h) # hidden state\n","    y = 1 if action == 2 else 0 # a \"fake label\"\n","    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n","\n","    # step the environment and get new measurements\n","    observation, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n","\n","    if done: # an episode finished\n","      episode_number += 1\n","\n","      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n","      epx = np.vstack(xs)\n","      eph = np.vstack(hs)\n","      epdlogp = np.vstack(dlogps)\n","      epr = np.vstack(drs)\n","      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n","\n","      # compute the discounted reward backwards through time\n","      discounted_epr = discount_rewards(epr)\n","      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n","      discounted_epr -= np.mean(discounted_epr)\n","      discounted_epr /= np.std(discounted_epr)\n","\n","      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n","      grad = policy_backward(epx, eph, epdlogp)\n","      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n","\n","      # perform rmsprop parameter update every batch_size episodes\n","      if episode_number % batch_size == 0:\n","        for k,v in model.items():\n","          g = grad_buffer[k] # gradient\n","          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n","          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n","          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n","\n","      # boring book-keeping\n","      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n","      hist.append((episode_number, reward_sum, running_reward))\n","      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n","      reward_sum = 0\n","      observation = env.reset() # reset env\n","      prev_x = None\n","      if episode_number == total_episodes: return hist\n","\n","      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n","        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"],"execution_count":11,"outputs":[]},{"metadata":{"id":"G6Ka_5Vl9Orm","outputId":"24665acb-77d4-4979-c84c-a3e6052b5a23","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660644748939,"user_tz":-330,"elapsed":1795276,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist1 = train_model(env, model, total_episodes=500)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 7.000000, reward total was -21.000000. running mean: -20.990199\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.990297\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.990394\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.990490\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.990585\n","resetting env. episode 12.000000, reward total was -19.000000. running mean: -20.970679\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.970973\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.971263\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.971550\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.971835\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.972116\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.972395\n","resetting env. episode 19.000000, reward total was -20.000000. running mean: -20.962671\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.963045\n","resetting env. episode 21.000000, reward total was -20.000000. running mean: -20.953414\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.953880\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.954341\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.954798\n","resetting env. episode 25.000000, reward total was -20.000000. running mean: -20.945250\n","resetting env. episode 26.000000, reward total was -20.000000. running mean: -20.935797\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.936439\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.937075\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.937704\n","resetting env. episode 30.000000, reward total was -20.000000. running mean: -20.928327\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.929044\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.929753\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.930456\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.931151\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.931840\n","resetting env. episode 36.000000, reward total was -20.000000. running mean: -20.922521\n","resetting env. episode 37.000000, reward total was -20.000000. running mean: -20.913296\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.914163\n","resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.905022\n","resetting env. episode 40.000000, reward total was -19.000000. running mean: -20.885971\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.887112\n","resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.878241\n","resetting env. episode 43.000000, reward total was -20.000000. running mean: -20.869458\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.870764\n","resetting env. episode 45.000000, reward total was -19.000000. running mean: -20.852056\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.853535\n","resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.845000\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.846550\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.848084\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.839604\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.841208\n","resetting env. episode 52.000000, reward total was -20.000000. running mean: -20.832796\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.834468\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.836123\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.837762\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.839384\n","resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.830990\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.832680\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.834354\n","resetting env. episode 60.000000, reward total was -20.000000. running mean: -20.826010\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.827750\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.829472\n","resetting env. episode 63.000000, reward total was -19.000000. running mean: -20.811178\n","resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.803066\n","resetting env. episode 65.000000, reward total was -19.000000. running mean: -20.785035\n","resetting env. episode 66.000000, reward total was -19.000000. running mean: -20.767185\n","resetting env. episode 67.000000, reward total was -20.000000. running mean: -20.759513\n","resetting env. episode 68.000000, reward total was -20.000000. running mean: -20.751918\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.754399\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.756855\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.759286\n","resetting env. episode 72.000000, reward total was -20.000000. running mean: -20.751693\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.754176\n","resetting env. episode 74.000000, reward total was -20.000000. running mean: -20.746635\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.749168\n","resetting env. episode 76.000000, reward total was -20.000000. running mean: -20.741677\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.744260\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.746817\n","resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.739349\n","resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.731956\n","resetting env. episode 81.000000, reward total was -20.000000. running mean: -20.724636\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.717390\n","resetting env. episode 83.000000, reward total was -19.000000. running mean: -20.700216\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.703214\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.696181\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.699220\n","resetting env. episode 87.000000, reward total was -18.000000. running mean: -20.672227\n","resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.665505\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.668850\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.672162\n","resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.665440\n","resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.658786\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.662198\n","resetting env. episode 94.000000, reward total was -20.000000. running mean: -20.655576\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.649020\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.652530\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.656005\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.649444\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.652950\n","resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.646421\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.649956\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.653457\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.656922\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.660353\n","resetting env. episode 105.000000, reward total was -20.000000. running mean: -20.653749\n","resetting env. episode 106.000000, reward total was -19.000000. running mean: -20.637212\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.640840\n","resetting env. episode 108.000000, reward total was -18.000000. running mean: -20.614431\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.618287\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.622104\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.625883\n","resetting env. episode 112.000000, reward total was -19.000000. running mean: -20.609624\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.613528\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.617393\n","resetting env. episode 115.000000, reward total was -20.000000. running mean: -20.611219\n","resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.605107\n","resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.599056\n","resetting env. episode 118.000000, reward total was -20.000000. running mean: -20.593065\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.597134\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.601163\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.605151\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.609100\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.613009\n","resetting env. episode 124.000000, reward total was -19.000000. running mean: -20.596879\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.600910\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.604901\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.608852\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.612763\n","resetting env. episode 129.000000, reward total was -19.000000. running mean: -20.596636\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.600669\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.604663\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.598616\n","resetting env. episode 133.000000, reward total was -19.000000. running mean: -20.582630\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.586804\n","resetting env. episode 135.000000, reward total was -18.000000. running mean: -20.560936\n","resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.555326\n","resetting env. episode 137.000000, reward total was -18.000000. running mean: -20.529773\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.534475\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.539131\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.543739\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.548302\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.552819\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.557291\n","resetting env. episode 144.000000, reward total was -19.000000. running mean: -20.541718\n","resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.536301\n","resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.540938\n","resetting env. episode 147.000000, reward total was -20.000000. running mean: -20.535528\n","resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.530173\n","resetting env. episode 149.000000, reward total was -20.000000. running mean: -20.524871\n","resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.519622\n","resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.514426\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.519282\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.524089\n","resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.518848\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.523660\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.528423\n","resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.523139\n","resetting env. episode 158.000000, reward total was -20.000000. running mean: -20.517908\n","resetting env. episode 159.000000, reward total was -19.000000. running mean: -20.502728\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.507701\n","resetting env. episode 161.000000, reward total was -19.000000. running mean: -20.492624\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.497698\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.502721\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.507694\n","resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.502617\n","resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.497591\n","resetting env. episode 167.000000, reward total was -21.000000. running mean: -20.502615\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.507589\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.512513\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.517388\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.522214\n","resetting env. episode 172.000000, reward total was -20.000000. running mean: -20.516992\n","resetting env. episode 173.000000, reward total was -19.000000. running mean: -20.501822\n","resetting env. episode 174.000000, reward total was -20.000000. running mean: -20.496803\n","resetting env. episode 175.000000, reward total was -20.000000. running mean: -20.491835\n","resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.476917\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.482148\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.487326\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.492453\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.497529\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.502553\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.507528\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.512452\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.517328\n","resetting env. episode 185.000000, reward total was -20.000000. running mean: -20.512155\n","resetting env. episode 186.000000, reward total was -20.000000. running mean: -20.507033\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.511963\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.516843\n","resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.511675\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.516558\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.521392\n","resetting env. episode 192.000000, reward total was -20.000000. running mean: -20.516179\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.521017\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.525807\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.530548\n","resetting env. episode 196.000000, reward total was -19.000000. running mean: -20.515243\n","resetting env. episode 197.000000, reward total was -20.000000. running mean: -20.510091\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.504990\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.499940\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.504940\n","resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.499891\n","resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.494892\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.489943\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.495044\n","resetting env. episode 205.000000, reward total was -18.000000. running mean: -20.470093\n","resetting env. episode 206.000000, reward total was -19.000000. running mean: -20.455392\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.460838\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.466230\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.471568\n","resetting env. episode 210.000000, reward total was -19.000000. running mean: -20.456852\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.462284\n","resetting env. episode 212.000000, reward total was -18.000000. running mean: -20.437661\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.443284\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -20.438851\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.444463\n","resetting env. episode 216.000000, reward total was -20.000000. running mean: -20.440018\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.445618\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.451162\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.456650\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.462084\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.467463\n","resetting env. episode 222.000000, reward total was -19.000000. running mean: -20.452788\n","resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.448260\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.443778\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.449340\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.454847\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.460298\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.455695\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.461138\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.466527\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.471861\n","resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.477143\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.472371\n","resetting env. episode 234.000000, reward total was -19.000000. running mean: -20.457648\n","resetting env. episode 235.000000, reward total was -19.000000. running mean: -20.443071\n","resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.438641\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.444254\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.449812\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.455313\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.460760\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.466153\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.471491\n","resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.466776\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.472109\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.477387\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.482614\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.487787\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.492910\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.497980\n","resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.493001\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.498071\n","resetting env. episode 252.000000, reward total was -20.000000. running mean: -20.493090\n","resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.488159\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.493277\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.498345\n","resetting env. episode 256.000000, reward total was -19.000000. running mean: -20.483361\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.488528\n","resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.483642\n","resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.478806\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.484018\n","resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.489178\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.494286\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.499343\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.504350\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.509306\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.504213\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.509171\n","resetting env. episode 268.000000, reward total was -19.000000. running mean: -20.494079\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.499138\n","resetting env. episode 270.000000, reward total was -20.000000. running mean: -20.494147\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.499206\n","resetting env. episode 272.000000, reward total was -19.000000. running mean: -20.484214\n","resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.479371\n","resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.474578\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.479832\n","resetting env. episode 276.000000, reward total was -20.000000. running mean: -20.475034\n","resetting env. episode 277.000000, reward total was -19.000000. running mean: -20.460283\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.465680\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.471024\n","resetting env. episode 280.000000, reward total was -20.000000. running mean: -20.466313\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.471650\n","resetting env. episode 282.000000, reward total was -19.000000. running mean: -20.456934\n","resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.452364\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.457841\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.463262\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.468630\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.473943\n","resetting env. episode 288.000000, reward total was -18.000000. running mean: -20.449204\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.454712\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.460165\n","resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.465563\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.460908\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.466298\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.471635\n","resetting env. episode 295.000000, reward total was -20.000000. running mean: -20.466919\n","resetting env. episode 296.000000, reward total was -20.000000. running mean: -20.462250\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.467627\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.472951\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.478222\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.473439\n","resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.468705\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.464018\n","resetting env. episode 303.000000, reward total was -19.000000. running mean: -20.449378\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.454884\n","resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.450335\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.455832\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.461274\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.466661\n","resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.461994\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.467374\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.472700\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.477973\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.473194\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.478462\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.483677\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.488840\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.483952\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.489112\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.494221\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.499279\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.494286\n","resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.499344\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.504350\n","resetting env. episode 324.000000, reward total was -19.000000. running mean: -20.489307\n","resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.484414\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.489569\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.494674\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.499727\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.504730\n","resetting env. episode 330.000000, reward total was -19.000000. running mean: -20.489682\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.494786\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.499838\n","resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.494839\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.499891\n","resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.494892\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.499943\n","resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.494944\n","resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.489994\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.495094\n","resetting env. episode 340.000000, reward total was -20.000000. running mean: -20.490143\n","resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.485242\n","resetting env. episode 342.000000, reward total was -19.000000. running mean: -20.470389\n","resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.465686\n","resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.461029\n","resetting env. episode 345.000000, reward total was -19.000000. running mean: -20.446418\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.451954\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.457435\n","resetting env. episode 348.000000, reward total was -20.000000. running mean: -20.452860\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.458332\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.463748\n","resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.459111\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.464520\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.469875\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.475176\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.480424\n","resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.475620\n","resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.470864\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.476155\n","resetting env. episode 359.000000, reward total was -19.000000. running mean: -20.461394\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.456780\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.452212\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.457690\n","resetting env. episode 363.000000, reward total was -20.000000. running mean: -20.453113\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.458582\n","resetting env. episode 365.000000, reward total was -19.000000. running mean: -20.443996\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.449556\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.455060\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.460510\n","resetting env. episode 369.000000, reward total was -20.000000. running mean: -20.455905\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.451346\n","resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.446832\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.452364\n","resetting env. episode 373.000000, reward total was -19.000000. running mean: -20.437840\n","resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.443462\n","resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.439027\n","resetting env. episode 376.000000, reward total was -19.000000. running mean: -20.424637\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.430390\n","resetting env. episode 378.000000, reward total was -19.000000. running mean: -20.416087\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.421926\n","resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.417706\n","resetting env. episode 381.000000, reward total was -20.000000. running mean: -20.413529\n","resetting env. episode 382.000000, reward total was -19.000000. running mean: -20.399394\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.395400\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.391446\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.397532\n","resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.393556\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.399621\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.405625\n","resetting env. episode 389.000000, reward total was -19.000000. running mean: -20.391568\n","resetting env. episode 390.000000, reward total was -20.000000. running mean: -20.387653\n","resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.383776\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.389938\n","resetting env. episode 393.000000, reward total was -18.000000. running mean: -20.366039\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.372379\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.378655\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.384868\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.391020\n","resetting env. episode 398.000000, reward total was -19.000000. running mean: -20.377109\n","resetting env. episode 399.000000, reward total was -20.000000. running mean: -20.373338\n","resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.369605\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.375909\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.382150\n","resetting env. episode 403.000000, reward total was -19.000000. running mean: -20.368328\n","resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.364645\n","resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.360999\n","resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.357389\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.363815\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.370177\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.366475\n","resetting env. episode 410.000000, reward total was -20.000000. running mean: -20.362810\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.369182\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.375490\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.381735\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.387918\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.384039\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.390198\n","resetting env. episode 417.000000, reward total was -20.000000. running mean: -20.386296\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.392433\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.398509\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.404524\n","resetting env. episode 421.000000, reward total was -20.000000. running mean: -20.400479\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.406474\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.402409\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.408385\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.414301\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.420158\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.425957\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.431697\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.437380\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.443006\n","resetting env. episode 431.000000, reward total was -20.000000. running mean: -20.438576\n","resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.434190\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.439849\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.445450\n","resetting env. episode 435.000000, reward total was -18.000000. running mean: -20.420996\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.426786\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.432518\n","resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.428193\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.433911\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.439572\n","resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.435176\n","resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.430824\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.436516\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.442151\n","resetting env. episode 445.000000, reward total was -19.000000. running mean: -20.427729\n","resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.423452\n","resetting env. episode 447.000000, reward total was -19.000000. running mean: -20.409217\n","resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.405125\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.411074\n","resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.406963\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.412894\n","resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.408765\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.414677\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.420530\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.426325\n","resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.422062\n","resetting env. episode 457.000000, reward total was -19.000000. running mean: -20.407841\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.413763\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.419625\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.415429\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.421274\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.427062\n","resetting env. episode 463.000000, reward total was -19.000000. running mean: -20.412791\n","resetting env. episode 464.000000, reward total was -19.000000. running mean: -20.398663\n","resetting env. episode 465.000000, reward total was -19.000000. running mean: -20.384677\n","resetting env. episode 466.000000, reward total was -19.000000. running mean: -20.370830\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.377121\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.383350\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.389517\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.395622\n","resetting env. episode 471.000000, reward total was -19.000000. running mean: -20.381665\n","resetting env. episode 472.000000, reward total was -20.000000. running mean: -20.377849\n","resetting env. episode 473.000000, reward total was -18.000000. running mean: -20.354070\n","resetting env. episode 474.000000, reward total was -20.000000. running mean: -20.350530\n","resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.347024\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.353554\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.360018\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.356418\n","resetting env. episode 479.000000, reward total was -18.000000. running mean: -20.332854\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.339526\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.346130\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.352669\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.359142\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.365551\n","resetting env. episode 485.000000, reward total was -19.000000. running mean: -20.351895\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.358376\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.364793\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.371145\n","resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.367433\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.363759\n","resetting env. episode 491.000000, reward total was -18.000000. running mean: -20.340121\n","resetting env. episode 492.000000, reward total was -20.000000. running mean: -20.336720\n","resetting env. episode 493.000000, reward total was -19.000000. running mean: -20.323353\n","resetting env. episode 494.000000, reward total was -20.000000. running mean: -20.320119\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.326918\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.333649\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.340313\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.346909\n","resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.343440\n","resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.350006\n","CPU times: user 46min 27s, sys: 11min 19s, total: 57min 46s\n","Wall time: 29min 54s\n"]}]},{"metadata":{"id":"cHYCDYwhlVLV","outputId":"712e7cb7-0f30-41c0-f7c0-c11afe407b84","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660646601648,"user_tz":-330,"elapsed":1852733,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist2 = train_model(env, model, total_episodes=500)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.990199\n","resetting env. episode 6.000000, reward total was -19.000000. running mean: -20.970297\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.960594\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.960988\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.961378\n","resetting env. episode 10.000000, reward total was -19.000000. running mean: -20.941764\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.942347\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.942923\n","resetting env. episode 13.000000, reward total was -19.000000. running mean: -20.923494\n","resetting env. episode 14.000000, reward total was -20.000000. running mean: -20.914259\n","resetting env. episode 15.000000, reward total was -20.000000. running mean: -20.905117\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.906065\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.907005\n","resetting env. episode 18.000000, reward total was -20.000000. running mean: -20.897935\n","resetting env. episode 19.000000, reward total was -20.000000. running mean: -20.888955\n","resetting env. episode 20.000000, reward total was -20.000000. running mean: -20.880066\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.881265\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.882452\n","resetting env. episode 23.000000, reward total was -19.000000. running mean: -20.863628\n","resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.854992\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.856442\n","resetting env. episode 26.000000, reward total was -20.000000. running mean: -20.847877\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.849399\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.850905\n","resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.842396\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.843972\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.845532\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.847077\n","resetting env. episode 33.000000, reward total was -19.000000. running mean: -20.828606\n","resetting env. episode 34.000000, reward total was -19.000000. running mean: -20.810320\n","resetting env. episode 35.000000, reward total was -20.000000. running mean: -20.802217\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.804194\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.806152\n","resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.798091\n","resetting env. episode 39.000000, reward total was -20.000000. running mean: -20.790110\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.792209\n","resetting env. episode 41.000000, reward total was -19.000000. running mean: -20.774287\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.776544\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.778778\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.770991\n","resetting env. episode 45.000000, reward total was -20.000000. running mean: -20.763281\n","resetting env. episode 46.000000, reward total was -20.000000. running mean: -20.755648\n","resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.748092\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.750611\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.753104\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.755573\n","resetting env. episode 51.000000, reward total was -18.000000. running mean: -20.728018\n","resetting env. episode 52.000000, reward total was -18.000000. running mean: -20.700738\n","resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.693730\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.696793\n","resetting env. episode 55.000000, reward total was -20.000000. running mean: -20.689825\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.692927\n","resetting env. episode 57.000000, reward total was -19.000000. running mean: -20.675997\n","resetting env. episode 58.000000, reward total was -19.000000. running mean: -20.659237\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.662645\n","resetting env. episode 60.000000, reward total was -20.000000. running mean: -20.656019\n","resetting env. episode 61.000000, reward total was -20.000000. running mean: -20.649458\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.652964\n","resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.646434\n","resetting env. episode 64.000000, reward total was -18.000000. running mean: -20.619970\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.623770\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.627532\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.631257\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.634945\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.638595\n","resetting env. episode 70.000000, reward total was -20.000000. running mean: -20.632209\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.625887\n","resetting env. episode 72.000000, reward total was -20.000000. running mean: -20.619628\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.613432\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.617298\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.621125\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.624913\n","resetting env. episode 77.000000, reward total was -20.000000. running mean: -20.618664\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.622478\n","resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.616253\n","resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.610090\n","resetting env. episode 81.000000, reward total was -19.000000. running mean: -20.593989\n","resetting env. episode 82.000000, reward total was -18.000000. running mean: -20.568050\n","resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.562369\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.566745\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.561078\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.565467\n","resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.559812\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.564214\n","resetting env. episode 89.000000, reward total was -19.000000. running mean: -20.548572\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.553086\n","resetting env. episode 91.000000, reward total was -19.000000. running mean: -20.537556\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.542180\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.546758\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.551291\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.545778\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.550320\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.554817\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.559269\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.563676\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.568039\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.562359\n","resetting env. episode 102.000000, reward total was -20.000000. running mean: -20.556735\n","resetting env. episode 103.000000, reward total was -20.000000. running mean: -20.551168\n","resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.545656\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.550200\n","resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.554698\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.559151\n","resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.553559\n","resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.548023\n","resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.542543\n","resetting env. episode 111.000000, reward total was -19.000000. running mean: -20.527118\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.531847\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.536528\n","resetting env. episode 114.000000, reward total was -20.000000. running mean: -20.531163\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.535851\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.540493\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.545088\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.549637\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.554141\n","resetting env. episode 120.000000, reward total was -19.000000. running mean: -20.538599\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.543213\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.547781\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.552303\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.556780\n","resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.551212\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.555700\n","resetting env. episode 127.000000, reward total was -18.000000. running mean: -20.530143\n","resetting env. episode 128.000000, reward total was -20.000000. running mean: -20.524842\n","resetting env. episode 129.000000, reward total was -19.000000. running mean: -20.509593\n","resetting env. episode 130.000000, reward total was -18.000000. running mean: -20.484497\n","resetting env. episode 131.000000, reward total was -19.000000. running mean: -20.469653\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.474956\n","resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.470206\n","resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.465504\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.470849\n","resetting env. episode 136.000000, reward total was -20.000000. running mean: -20.466141\n","resetting env. episode 137.000000, reward total was -19.000000. running mean: -20.451479\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.456965\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.462395\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.467771\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.473093\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -20.478362\n","resetting env. episode 143.000000, reward total was -20.000000. running mean: -20.473579\n","resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.468843\n","resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.464155\n","resetting env. episode 146.000000, reward total was -19.000000. running mean: -20.449513\n","resetting env. episode 147.000000, reward total was -18.000000. running mean: -20.425018\n","resetting env. episode 148.000000, reward total was -19.000000. running mean: -20.410768\n","resetting env. episode 149.000000, reward total was -19.000000. running mean: -20.396660\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.402693\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.408666\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.414580\n","resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.410434\n","resetting env. episode 154.000000, reward total was -19.000000. running mean: -20.396330\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.402366\n","resetting env. episode 156.000000, reward total was -19.000000. running mean: -20.388343\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.394459\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.400515\n","resetting env. episode 159.000000, reward total was -20.000000. running mean: -20.396510\n","resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.392544\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.398619\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.404633\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.410586\n","resetting env. episode 164.000000, reward total was -19.000000. running mean: -20.396481\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.402516\n","resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.398491\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.394506\n","resetting env. episode 168.000000, reward total was -20.000000. running mean: -20.390561\n","resetting env. episode 169.000000, reward total was -19.000000. running mean: -20.376655\n","resetting env. episode 170.000000, reward total was -19.000000. running mean: -20.362889\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.369260\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.375567\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.371811\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.378093\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.384312\n","resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.370469\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.376765\n","resetting env. episode 178.000000, reward total was -20.000000. running mean: -20.372997\n","resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.369267\n","resetting env. episode 180.000000, reward total was -20.000000. running mean: -20.365574\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.371919\n","resetting env. episode 182.000000, reward total was -20.000000. running mean: -20.368199\n","resetting env. episode 183.000000, reward total was -19.000000. running mean: -20.354517\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.360972\n","resetting env. episode 185.000000, reward total was -20.000000. running mean: -20.357362\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.363789\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.370151\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.366449\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.372785\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.379057\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.385266\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.391414\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.397500\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.403525\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.409489\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.415395\n","resetting env. episode 197.000000, reward total was -20.000000. running mean: -20.411241\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.407128\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.403057\n","resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.399026\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.405036\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.410986\n","resetting env. episode 203.000000, reward total was -19.000000. running mean: -20.396876\n","resetting env. episode 204.000000, reward total was -20.000000. running mean: -20.392907\n","resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.388978\n","resetting env. episode 206.000000, reward total was -20.000000. running mean: -20.385088\n","resetting env. episode 207.000000, reward total was -20.000000. running mean: -20.381237\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.387425\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.393551\n","resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.389615\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.395719\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.401762\n","resetting env. episode 213.000000, reward total was -16.000000. running mean: -20.357744\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.364167\n","resetting env. episode 215.000000, reward total was -19.000000. running mean: -20.350525\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.357020\n","resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.353450\n","resetting env. episode 218.000000, reward total was -20.000000. running mean: -20.349915\n","resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.346416\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.352952\n","resetting env. episode 221.000000, reward total was -20.000000. running mean: -20.349422\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.355928\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.362369\n","resetting env. episode 224.000000, reward total was -19.000000. running mean: -20.348745\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.355258\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.361705\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.368088\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.364407\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.370763\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.377056\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.383285\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.379452\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.385658\n","resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.391801\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.397883\n","resetting env. episode 236.000000, reward total was -19.000000. running mean: -20.383904\n","resetting env. episode 237.000000, reward total was -20.000000. running mean: -20.380065\n","resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.376264\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.382502\n","resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.378677\n","resetting env. episode 241.000000, reward total was -19.000000. running mean: -20.364890\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.361241\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.367629\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.373952\n","resetting env. episode 245.000000, reward total was -17.000000. running mean: -20.340213\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.346811\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.353343\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.359809\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.366211\n","resetting env. episode 250.000000, reward total was -19.000000. running mean: -20.352549\n","resetting env. episode 251.000000, reward total was -20.000000. running mean: -20.349024\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.355533\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.361978\n","resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.358358\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.364775\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.371127\n","resetting env. episode 257.000000, reward total was -20.000000. running mean: -20.367416\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.373741\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.380004\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.386204\n","resetting env. episode 261.000000, reward total was -19.000000. running mean: -20.372342\n","resetting env. episode 262.000000, reward total was -18.000000. running mean: -20.348619\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.355132\n","resetting env. episode 264.000000, reward total was -19.000000. running mean: -20.341581\n","resetting env. episode 265.000000, reward total was -20.000000. running mean: -20.338165\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.334784\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.341436\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.348021\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.354541\n","resetting env. episode 270.000000, reward total was -19.000000. running mean: -20.340996\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.337586\n","resetting env. episode 272.000000, reward total was -19.000000. running mean: -20.324210\n","resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.320968\n","resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.317758\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.324581\n","resetting env. episode 276.000000, reward total was -18.000000. running mean: -20.301335\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.308321\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.315238\n","resetting env. episode 279.000000, reward total was -17.000000. running mean: -20.282086\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.289265\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.296372\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.303409\n","resetting env. episode 283.000000, reward total was -20.000000. running mean: -20.300375\n","resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.297371\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.304397\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.311353\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.318240\n","resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.315057\n","resetting env. episode 289.000000, reward total was -20.000000. running mean: -20.311907\n","resetting env. episode 290.000000, reward total was -19.000000. running mean: -20.298788\n","resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.305800\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.302742\n","resetting env. episode 293.000000, reward total was -20.000000. running mean: -20.299714\n","resetting env. episode 294.000000, reward total was -19.000000. running mean: -20.286717\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.293850\n","resetting env. episode 296.000000, reward total was -20.000000. running mean: -20.290911\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.298002\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.305022\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.301972\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.308952\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.315863\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.322704\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.329477\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.336182\n","resetting env. episode 305.000000, reward total was -18.000000. running mean: -20.312821\n","resetting env. episode 306.000000, reward total was -20.000000. running mean: -20.309692\n","resetting env. episode 307.000000, reward total was -20.000000. running mean: -20.306595\n","resetting env. episode 308.000000, reward total was -19.000000. running mean: -20.293529\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.300594\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.307588\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.314512\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.321367\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.328154\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.334872\n","resetting env. episode 315.000000, reward total was -19.000000. running mean: -20.321523\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.328308\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.325025\n","resetting env. episode 318.000000, reward total was -18.000000. running mean: -20.301775\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.308757\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.315669\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.312513\n","resetting env. episode 322.000000, reward total was -19.000000. running mean: -20.299388\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.306394\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.313330\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.320196\n","resetting env. episode 326.000000, reward total was -19.000000. running mean: -20.306995\n","resetting env. episode 327.000000, reward total was -19.000000. running mean: -20.293925\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.300985\n","resetting env. episode 329.000000, reward total was -19.000000. running mean: -20.287975\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.295096\n","resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.292145\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.299223\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.306231\n","resetting env. episode 334.000000, reward total was -19.000000. running mean: -20.293169\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.300237\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.307235\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.314162\n","resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.311021\n","resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.307911\n","resetting env. episode 340.000000, reward total was -19.000000. running mean: -20.294831\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.301883\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.308864\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.315776\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.322618\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.329392\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.336098\n","resetting env. episode 347.000000, reward total was -19.000000. running mean: -20.322737\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.329509\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.336214\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.342852\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.349424\n","resetting env. episode 352.000000, reward total was -20.000000. running mean: -20.345929\n","resetting env. episode 353.000000, reward total was -18.000000. running mean: -20.322470\n","resetting env. episode 354.000000, reward total was -20.000000. running mean: -20.319245\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.326053\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.332792\n","resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.329465\n","resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.326170\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.332908\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.329579\n","resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.336283\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.342920\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.349491\n","resetting env. episode 364.000000, reward total was -19.000000. running mean: -20.335996\n","resetting env. episode 365.000000, reward total was -19.000000. running mean: -20.322636\n","resetting env. episode 366.000000, reward total was -19.000000. running mean: -20.309410\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.316316\n","resetting env. episode 368.000000, reward total was -19.000000. running mean: -20.303153\n","resetting env. episode 369.000000, reward total was -19.000000. running mean: -20.290121\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.297220\n","resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.294248\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.301305\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.308292\n","resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.315209\n","resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.312057\n","resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.308937\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.315847\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.322689\n","resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.319462\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.326267\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.333005\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.339675\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.336278\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.332915\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.339586\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.346190\n","resetting env. episode 387.000000, reward total was -19.000000. running mean: -20.332728\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.339401\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.346007\n","resetting env. episode 390.000000, reward total was -20.000000. running mean: -20.342547\n","resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.339121\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.345730\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.352273\n","resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.348750\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.345263\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.351810\n","resetting env. episode 397.000000, reward total was -20.000000. running mean: -20.348292\n","resetting env. episode 398.000000, reward total was -19.000000. running mean: -20.334809\n","resetting env. episode 399.000000, reward total was -19.000000. running mean: -20.321461\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.328246\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.334964\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.341614\n","resetting env. episode 403.000000, reward total was -20.000000. running mean: -20.338198\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.344816\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.351368\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.357854\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.364276\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.370633\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.366927\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.373257\n","resetting env. episode 411.000000, reward total was -19.000000. running mean: -20.359525\n","resetting env. episode 412.000000, reward total was -19.000000. running mean: -20.345930\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.352470\n","resetting env. episode 414.000000, reward total was -17.000000. running mean: -20.318946\n","resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.325756\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.332499\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.339174\n","resetting env. episode 418.000000, reward total was -19.000000. running mean: -20.325782\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.332524\n","resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.329199\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.335907\n","resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.332548\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.329222\n","resetting env. episode 424.000000, reward total was -17.000000. running mean: -20.295930\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.292971\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.300041\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.307041\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.313970\n","resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.310830\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -20.307722\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.314645\n","resetting env. episode 432.000000, reward total was -19.000000. running mean: -20.301498\n","resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.298483\n","resetting env. episode 434.000000, reward total was -19.000000. running mean: -20.285499\n","resetting env. episode 435.000000, reward total was -17.000000. running mean: -20.252644\n","resetting env. episode 436.000000, reward total was -19.000000. running mean: -20.240117\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.247716\n","resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.255239\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.262687\n","resetting env. episode 440.000000, reward total was -19.000000. running mean: -20.250060\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.257559\n","resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.254983\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.262434\n","resetting env. episode 444.000000, reward total was -19.000000. running mean: -20.249809\n","resetting env. episode 445.000000, reward total was -19.000000. running mean: -20.237311\n","resetting env. episode 446.000000, reward total was -19.000000. running mean: -20.224938\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.232689\n","resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.230362\n","resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.228058\n","resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.225778\n","resetting env. episode 451.000000, reward total was -20.000000. running mean: -20.223520\n","resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.221285\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.229072\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.236781\n","resetting env. episode 455.000000, reward total was -19.000000. running mean: -20.224413\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.232169\n","resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.239847\n","resetting env. episode 458.000000, reward total was -19.000000. running mean: -20.227449\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.235174\n","resetting env. episode 460.000000, reward total was -18.000000. running mean: -20.212823\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.220695\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.218488\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.226303\n","resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.224040\n","resetting env. episode 465.000000, reward total was -20.000000. running mean: -20.221799\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.229581\n","resetting env. episode 467.000000, reward total was -19.000000. running mean: -20.217285\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.225113\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.232861\n","resetting env. episode 470.000000, reward total was -20.000000. running mean: -20.230533\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.238228\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.245845\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.253387\n","resetting env. episode 474.000000, reward total was -20.000000. running mean: -20.250853\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.258344\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.265761\n","resetting env. episode 477.000000, reward total was -17.000000. running mean: -20.233103\n","resetting env. episode 478.000000, reward total was -19.000000. running mean: -20.220772\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.218565\n","resetting env. episode 480.000000, reward total was -19.000000. running mean: -20.206379\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.214315\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.222172\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.229950\n","resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.217651\n","resetting env. episode 485.000000, reward total was -20.000000. running mean: -20.215474\n","resetting env. episode 486.000000, reward total was -20.000000. running mean: -20.213320\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.221186\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.218974\n","resetting env. episode 489.000000, reward total was -20.000000. running mean: -20.216785\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.224617\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.232371\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.240047\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.247647\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.255170\n","resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.252618\n","resetting env. episode 496.000000, reward total was -19.000000. running mean: -20.240092\n","resetting env. episode 497.000000, reward total was -19.000000. running mean: -20.227691\n","resetting env. episode 498.000000, reward total was -18.000000. running mean: -20.205414\n","resetting env. episode 499.000000, reward total was -18.000000. running mean: -20.183360\n","resetting env. episode 500.000000, reward total was -20.000000. running mean: -20.181527\n","CPU times: user 48min 10s, sys: 11min 36s, total: 59min 46s\n","Wall time: 30min 53s\n"]}]},{"metadata":{"id":"8fheN9DRlWXQ","outputId":"5d062412-3429-43b3-e7d9-09e416cf30f4","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1660646636476,"user_tz":-330,"elapsed":34848,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -8.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"id":"9AxOcQhIsKow","outputId":"1d03a7e1-5ace-4b37-acbd-6e740943a93b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660652682500,"user_tz":-330,"elapsed":6046033,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist3 = train_model(env, model, total_episodes=1500)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -19.000000. running mean: -19.000000\n","resetting env. episode 2.000000, reward total was -19.000000. running mean: -19.000000\n","resetting env. episode 3.000000, reward total was -19.000000. running mean: -19.000000\n","resetting env. episode 4.000000, reward total was -20.000000. running mean: -19.010000\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -19.029900\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -19.049601\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -19.059105\n","resetting env. episode 8.000000, reward total was -20.000000. running mean: -19.068514\n","resetting env. episode 9.000000, reward total was -19.000000. running mean: -19.067829\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -19.087151\n","resetting env. episode 11.000000, reward total was -20.000000. running mean: -19.096279\n","resetting env. episode 12.000000, reward total was -20.000000. running mean: -19.105316\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -19.124263\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -19.143020\n","resetting env. episode 15.000000, reward total was -20.000000. running mean: -19.151590\n","resetting env. episode 16.000000, reward total was -19.000000. running mean: -19.150074\n","resetting env. episode 17.000000, reward total was -20.000000. running mean: -19.158574\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -19.176988\n","resetting env. episode 19.000000, reward total was -20.000000. running mean: -19.185218\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -19.203366\n","resetting env. episode 21.000000, reward total was -20.000000. running mean: -19.211332\n","resetting env. episode 22.000000, reward total was -19.000000. running mean: -19.209219\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -19.227127\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -19.244855\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -19.262407\n","resetting env. episode 26.000000, reward total was -20.000000. running mean: -19.269783\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -19.287085\n","resetting env. episode 28.000000, reward total was -20.000000. running mean: -19.294214\n","resetting env. episode 29.000000, reward total was -18.000000. running mean: -19.281272\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -19.298459\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -19.315475\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -19.332320\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -19.348997\n","resetting env. episode 34.000000, reward total was -20.000000. running mean: -19.355507\n","resetting env. episode 35.000000, reward total was -20.000000. running mean: -19.361952\n","resetting env. episode 36.000000, reward total was -20.000000. running mean: -19.368332\n","resetting env. episode 37.000000, reward total was -20.000000. running mean: -19.374649\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -19.390902\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -19.406993\n","resetting env. episode 40.000000, reward total was -20.000000. running mean: -19.412923\n","resetting env. episode 41.000000, reward total was -20.000000. running mean: -19.418794\n","resetting env. episode 42.000000, reward total was -20.000000. running mean: -19.424606\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -19.440360\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -19.445957\n","resetting env. episode 45.000000, reward total was -20.000000. running mean: -19.451497\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -19.466982\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -19.482312\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -19.497489\n","resetting env. episode 49.000000, reward total was -20.000000. running mean: -19.502514\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -19.507489\n","resetting env. episode 51.000000, reward total was -20.000000. running mean: -19.512414\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -19.527290\n","resetting env. episode 53.000000, reward total was -20.000000. running mean: -19.532017\n","resetting env. episode 54.000000, reward total was -19.000000. running mean: -19.526697\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -19.541430\n","resetting env. episode 56.000000, reward total was -20.000000. running mean: -19.546016\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -19.560555\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -19.574950\n","resetting env. episode 59.000000, reward total was -20.000000. running mean: -19.579200\n","resetting env. episode 60.000000, reward total was -20.000000. running mean: -19.583408\n","resetting env. episode 61.000000, reward total was -20.000000. running mean: -19.587574\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -19.601699\n","resetting env. episode 63.000000, reward total was -19.000000. running mean: -19.595682\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -19.609725\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -19.623628\n","resetting env. episode 66.000000, reward total was -18.000000. running mean: -19.607391\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -19.621317\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -19.635104\n","resetting env. episode 69.000000, reward total was -20.000000. running mean: -19.638753\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -19.652366\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -19.665842\n","resetting env. episode 72.000000, reward total was -19.000000. running mean: -19.659184\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -19.672592\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -19.685866\n","resetting env. episode 75.000000, reward total was -20.000000. running mean: -19.689007\n","resetting env. episode 76.000000, reward total was -20.000000. running mean: -19.692117\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -19.705196\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -19.718144\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -19.730962\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -19.743653\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -19.756216\n","resetting env. episode 82.000000, reward total was -21.000000. running mean: -19.768654\n","resetting env. episode 83.000000, reward total was -20.000000. running mean: -19.770968\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -19.783258\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -19.785425\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -19.797571\n","resetting env. episode 87.000000, reward total was -18.000000. running mean: -19.779595\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -19.791799\n","resetting env. episode 89.000000, reward total was -20.000000. running mean: -19.793881\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -19.805943\n","resetting env. episode 91.000000, reward total was -18.000000. running mean: -19.787883\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -19.800004\n","resetting env. episode 93.000000, reward total was -20.000000. running mean: -19.802004\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -19.813984\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -19.815844\n","resetting env. episode 96.000000, reward total was -18.000000. running mean: -19.797686\n","resetting env. episode 97.000000, reward total was -20.000000. running mean: -19.799709\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -19.801712\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -19.813695\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -19.825558\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -19.837302\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -19.848929\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -19.860440\n","resetting env. episode 104.000000, reward total was -20.000000. running mean: -19.861836\n","resetting env. episode 105.000000, reward total was -19.000000. running mean: -19.853217\n","resetting env. episode 106.000000, reward total was -19.000000. running mean: -19.844685\n","resetting env. episode 107.000000, reward total was -20.000000. running mean: -19.846238\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -19.857776\n","resetting env. episode 109.000000, reward total was -20.000000. running mean: -19.859198\n","resetting env. episode 110.000000, reward total was -20.000000. running mean: -19.860606\n","resetting env. episode 111.000000, reward total was -17.000000. running mean: -19.832000\n","resetting env. episode 112.000000, reward total was -20.000000. running mean: -19.833680\n","resetting env. episode 113.000000, reward total was -19.000000. running mean: -19.825343\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -19.837090\n","resetting env. episode 115.000000, reward total was -19.000000. running mean: -19.828719\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -19.840432\n","resetting env. episode 117.000000, reward total was -20.000000. running mean: -19.842027\n","resetting env. episode 118.000000, reward total was -20.000000. running mean: -19.843607\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -19.855171\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -19.866619\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -19.877953\n","resetting env. episode 122.000000, reward total was -19.000000. running mean: -19.869174\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -19.880482\n","resetting env. episode 124.000000, reward total was -19.000000. running mean: -19.871677\n","resetting env. episode 125.000000, reward total was -18.000000. running mean: -19.852960\n","resetting env. episode 126.000000, reward total was -20.000000. running mean: -19.854431\n","resetting env. episode 127.000000, reward total was -20.000000. running mean: -19.855886\n","resetting env. episode 128.000000, reward total was -19.000000. running mean: -19.847328\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -19.858854\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -19.870266\n","resetting env. episode 131.000000, reward total was -19.000000. running mean: -19.861563\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -19.872947\n","resetting env. episode 133.000000, reward total was -20.000000. running mean: -19.874218\n","resetting env. episode 134.000000, reward total was -20.000000. running mean: -19.875476\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -19.886721\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -19.897854\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -19.908875\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -19.919787\n","resetting env. episode 139.000000, reward total was -19.000000. running mean: -19.910589\n","resetting env. episode 140.000000, reward total was -20.000000. running mean: -19.911483\n","resetting env. episode 141.000000, reward total was -19.000000. running mean: -19.902368\n","resetting env. episode 142.000000, reward total was -21.000000. running mean: -19.913344\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -19.924211\n","resetting env. episode 144.000000, reward total was -19.000000. running mean: -19.914969\n","resetting env. episode 145.000000, reward total was -20.000000. running mean: -19.915819\n","resetting env. episode 146.000000, reward total was -21.000000. running mean: -19.926661\n","resetting env. episode 147.000000, reward total was -20.000000. running mean: -19.927394\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -19.938120\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -19.948739\n","resetting env. episode 150.000000, reward total was -18.000000. running mean: -19.929252\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -19.939959\n","resetting env. episode 152.000000, reward total was -18.000000. running mean: -19.920560\n","resetting env. episode 153.000000, reward total was -20.000000. running mean: -19.921354\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -19.932140\n","resetting env. episode 155.000000, reward total was -19.000000. running mean: -19.922819\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -19.933591\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -19.944255\n","resetting env. episode 158.000000, reward total was -19.000000. running mean: -19.934812\n","resetting env. episode 159.000000, reward total was -20.000000. running mean: -19.935464\n","resetting env. episode 160.000000, reward total was -20.000000. running mean: -19.936110\n","resetting env. episode 161.000000, reward total was -20.000000. running mean: -19.936749\n","resetting env. episode 162.000000, reward total was -20.000000. running mean: -19.937381\n","resetting env. episode 163.000000, reward total was -20.000000. running mean: -19.938007\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -19.948627\n","resetting env. episode 165.000000, reward total was -19.000000. running mean: -19.939141\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -19.949750\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -19.950252\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -19.960749\n","resetting env. episode 169.000000, reward total was -20.000000. running mean: -19.961142\n","resetting env. episode 170.000000, reward total was -19.000000. running mean: -19.951531\n","resetting env. episode 171.000000, reward total was -20.000000. running mean: -19.952015\n","resetting env. episode 172.000000, reward total was -19.000000. running mean: -19.942495\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -19.943070\n","resetting env. episode 174.000000, reward total was -19.000000. running mean: -19.933639\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -19.944303\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -19.954860\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -19.965311\n","resetting env. episode 178.000000, reward total was -19.000000. running mean: -19.955658\n","resetting env. episode 179.000000, reward total was -20.000000. running mean: -19.956102\n","resetting env. episode 180.000000, reward total was -20.000000. running mean: -19.956541\n","resetting env. episode 181.000000, reward total was -20.000000. running mean: -19.956975\n","resetting env. episode 182.000000, reward total was -20.000000. running mean: -19.957406\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -19.967832\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -19.978153\n","resetting env. episode 185.000000, reward total was -20.000000. running mean: -19.978372\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -19.988588\n","resetting env. episode 187.000000, reward total was -19.000000. running mean: -19.978702\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -19.978915\n","resetting env. episode 189.000000, reward total was -20.000000. running mean: -19.979126\n","resetting env. episode 190.000000, reward total was -20.000000. running mean: -19.979335\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -19.989541\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -19.999646\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.009649\n","resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.009553\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.019457\n","resetting env. episode 196.000000, reward total was -18.000000. running mean: -19.999263\n","resetting env. episode 197.000000, reward total was -20.000000. running mean: -19.999270\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -19.999277\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -19.999285\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.009292\n","resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.009199\n","resetting env. episode 202.000000, reward total was -19.000000. running mean: -19.999107\n","resetting env. episode 203.000000, reward total was -19.000000. running mean: -19.989116\n","resetting env. episode 204.000000, reward total was -20.000000. running mean: -19.989225\n","resetting env. episode 205.000000, reward total was -20.000000. running mean: -19.989332\n","resetting env. episode 206.000000, reward total was -19.000000. running mean: -19.979439\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -19.989645\n","resetting env. episode 208.000000, reward total was -20.000000. running mean: -19.989748\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -19.999851\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.009852\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.019754\n","resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.019556\n","resetting env. episode 213.000000, reward total was -18.000000. running mean: -19.999361\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -19.999367\n","resetting env. episode 215.000000, reward total was -19.000000. running mean: -19.989373\n","resetting env. episode 216.000000, reward total was -19.000000. running mean: -19.979480\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -19.989685\n","resetting env. episode 218.000000, reward total was -20.000000. running mean: -19.989788\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -19.999890\n","resetting env. episode 220.000000, reward total was -19.000000. running mean: -19.989891\n","resetting env. episode 221.000000, reward total was -20.000000. running mean: -19.989992\n","resetting env. episode 222.000000, reward total was -20.000000. running mean: -19.990092\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.000192\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.000190\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.000188\n","resetting env. episode 226.000000, reward total was -20.000000. running mean: -20.000186\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.010184\n","resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.020082\n","resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.019881\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.029682\n","resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.029386\n","resetting env. episode 232.000000, reward total was -19.000000. running mean: -20.019092\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.028901\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.028612\n","resetting env. episode 235.000000, reward total was -20.000000. running mean: -20.028326\n","resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.028043\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.037762\n","resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.037384\n","resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.037011\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.046641\n","resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.046174\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.055712\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.065155\n","resetting env. episode 244.000000, reward total was -19.000000. running mean: -20.054504\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.063959\n","resetting env. episode 246.000000, reward total was -20.000000. running mean: -20.063319\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.072686\n","resetting env. episode 248.000000, reward total was -20.000000. running mean: -20.071959\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.081239\n","resetting env. episode 250.000000, reward total was -18.000000. running mean: -20.060427\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.069823\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.079125\n","resetting env. episode 253.000000, reward total was -19.000000. running mean: -20.068333\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.077650\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.086873\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.096005\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.105045\n","resetting env. episode 258.000000, reward total was -18.000000. running mean: -20.083994\n","resetting env. episode 259.000000, reward total was -19.000000. running mean: -20.073154\n","resetting env. episode 260.000000, reward total was -20.000000. running mean: -20.072423\n","resetting env. episode 261.000000, reward total was -19.000000. running mean: -20.061699\n","resetting env. episode 262.000000, reward total was -19.000000. running mean: -20.051082\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.060571\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.069965\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.079265\n","resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.088473\n","resetting env. episode 267.000000, reward total was -20.000000. running mean: -20.087588\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.096712\n","resetting env. episode 269.000000, reward total was -19.000000. running mean: -20.085745\n","resetting env. episode 270.000000, reward total was -19.000000. running mean: -20.074888\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.084139\n","resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.093297\n","resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.092364\n","resetting env. episode 274.000000, reward total was -19.000000. running mean: -20.081441\n","resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.080626\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.089820\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.098922\n","resetting env. episode 278.000000, reward total was -20.000000. running mean: -20.097933\n","resetting env. episode 279.000000, reward total was -19.000000. running mean: -20.086953\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.096084\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.105123\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.114072\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.122931\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.131702\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.140385\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.148981\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.157491\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.165916\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.174257\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.172514\n","resetting env. episode 291.000000, reward total was -19.000000. running mean: -20.160789\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.159181\n","resetting env. episode 293.000000, reward total was -20.000000. running mean: -20.157589\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.166014\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.174353\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.182610\n","resetting env. episode 297.000000, reward total was -19.000000. running mean: -20.170784\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.169076\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.167385\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.175711\n","resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.173954\n","resetting env. episode 302.000000, reward total was -18.000000. running mean: -20.152215\n","resetting env. episode 303.000000, reward total was -19.000000. running mean: -20.140693\n","resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.139286\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.147893\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.156414\n","resetting env. episode 307.000000, reward total was -20.000000. running mean: -20.154850\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.163301\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.171668\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.179952\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.188152\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.196270\n","resetting env. episode 313.000000, reward total was -18.000000. running mean: -20.174308\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.182565\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.190739\n","resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.188832\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.186943\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.195074\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.203123\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.211092\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.218981\n","resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.216791\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.224623\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.232377\n","resetting env. episode 325.000000, reward total was -18.000000. running mean: -20.210053\n","resetting env. episode 326.000000, reward total was -19.000000. running mean: -20.197953\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.205973\n","resetting env. episode 328.000000, reward total was -20.000000. running mean: -20.203913\n","resetting env. episode 329.000000, reward total was -16.000000. running mean: -20.161874\n","resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.160256\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.168653\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.176967\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.185197\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.193345\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.201411\n","resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.199397\n","resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.197403\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.205429\n","resetting env. episode 339.000000, reward total was -20.000000. running mean: -20.203375\n","resetting env. episode 340.000000, reward total was -20.000000. running mean: -20.201341\n","resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.199328\n","resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.197335\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.205361\n","resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.203308\n","resetting env. episode 345.000000, reward total was -19.000000. running mean: -20.191275\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.199362\n","resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.197368\n","resetting env. episode 348.000000, reward total was -20.000000. running mean: -20.195395\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.203441\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.211406\n","resetting env. episode 351.000000, reward total was -20.000000. running mean: -20.209292\n","resetting env. episode 352.000000, reward total was -20.000000. running mean: -20.207199\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.215127\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.222976\n","resetting env. episode 355.000000, reward total was -20.000000. running mean: -20.220746\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.228539\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.236253\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.243891\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.251452\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.248937\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.246448\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.253983\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.261444\n","resetting env. episode 364.000000, reward total was -20.000000. running mean: -20.258829\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.256241\n","resetting env. episode 366.000000, reward total was -20.000000. running mean: -20.253679\n","resetting env. episode 367.000000, reward total was -20.000000. running mean: -20.251142\n","resetting env. episode 368.000000, reward total was -20.000000. running mean: -20.248630\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.256144\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.263583\n","resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.270947\n","resetting env. episode 372.000000, reward total was -18.000000. running mean: -20.248237\n","resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.245755\n","resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.243297\n","resetting env. episode 375.000000, reward total was -18.000000. running mean: -20.220864\n","resetting env. episode 376.000000, reward total was -20.000000. running mean: -20.218656\n","resetting env. episode 377.000000, reward total was -20.000000. running mean: -20.216469\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.224304\n","resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.222061\n","resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.219841\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.227642\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.235366\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.243012\n","resetting env. episode 384.000000, reward total was -19.000000. running mean: -20.230582\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.238276\n","resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.235894\n","resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.233535\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.241199\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.248787\n","resetting env. episode 390.000000, reward total was -18.000000. running mean: -20.226299\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.234036\n","resetting env. episode 392.000000, reward total was -17.000000. running mean: -20.201696\n","resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.199679\n","resetting env. episode 394.000000, reward total was -19.000000. running mean: -20.187682\n","resetting env. episode 395.000000, reward total was -19.000000. running mean: -20.175806\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.174047\n","resetting env. episode 397.000000, reward total was -19.000000. running mean: -20.162307\n","resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.160684\n","resetting env. episode 399.000000, reward total was -20.000000. running mean: -20.159077\n","resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.157486\n","resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.155911\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.164352\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.172709\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.180982\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.189172\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.197280\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.205307\n","resetting env. episode 408.000000, reward total was -19.000000. running mean: -20.193254\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.191322\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.199409\n","resetting env. episode 411.000000, reward total was -20.000000. running mean: -20.197414\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.205440\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.213386\n","resetting env. episode 414.000000, reward total was -18.000000. running mean: -20.191252\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.189340\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.197446\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.205472\n","resetting env. episode 418.000000, reward total was -18.000000. running mean: -20.183417\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.191583\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.199667\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.207670\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.215594\n","resetting env. episode 423.000000, reward total was -19.000000. running mean: -20.203438\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.211403\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.219289\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.227096\n","resetting env. episode 427.000000, reward total was -19.000000. running mean: -20.214825\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.222677\n","resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.220450\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -20.218246\n","resetting env. episode 431.000000, reward total was -18.000000. running mean: -20.196063\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.204103\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.212062\n","resetting env. episode 434.000000, reward total was -19.000000. running mean: -20.199941\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.207942\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.215862\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.223704\n","resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.221467\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.229252\n","resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.226959\n","resetting env. episode 441.000000, reward total was -19.000000. running mean: -20.214690\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.222543\n","resetting env. episode 443.000000, reward total was -20.000000. running mean: -20.220318\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.228114\n","resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.225833\n","resetting env. episode 446.000000, reward total was -18.000000. running mean: -20.203575\n","resetting env. episode 447.000000, reward total was -20.000000. running mean: -20.201539\n","resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.199524\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.207529\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.215453\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.223299\n","resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.221066\n","resetting env. episode 453.000000, reward total was -19.000000. running mean: -20.208855\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.216766\n","resetting env. episode 455.000000, reward total was -20.000000. running mean: -20.214599\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.222453\n","resetting env. episode 457.000000, reward total was -18.000000. running mean: -20.200228\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.208226\n","resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.206144\n","resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.214082\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.221942\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.219722\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.227525\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.235250\n","resetting env. episode 465.000000, reward total was -19.000000. running mean: -20.222897\n","resetting env. episode 466.000000, reward total was -20.000000. running mean: -20.220668\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.228461\n","resetting env. episode 468.000000, reward total was -20.000000. running mean: -20.226177\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.233915\n","resetting env. episode 470.000000, reward total was -19.000000. running mean: -20.221576\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.229360\n","resetting env. episode 472.000000, reward total was -18.000000. running mean: -20.207067\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.214996\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.222846\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.230617\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.238311\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.245928\n","resetting env. episode 478.000000, reward total was -19.000000. running mean: -20.233469\n","resetting env. episode 479.000000, reward total was -19.000000. running mean: -20.221134\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.228923\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.236634\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.244267\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.251825\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.259306\n","resetting env. episode 485.000000, reward total was -20.000000. running mean: -20.256713\n","resetting env. episode 486.000000, reward total was -20.000000. running mean: -20.254146\n","resetting env. episode 487.000000, reward total was -20.000000. running mean: -20.251605\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.259089\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.266498\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.273833\n","resetting env. episode 491.000000, reward total was -20.000000. running mean: -20.271095\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.278384\n","resetting env. episode 493.000000, reward total was -17.000000. running mean: -20.245600\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.253144\n","resetting env. episode 495.000000, reward total was -17.000000. running mean: -20.220612\n","resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.218406\n","resetting env. episode 497.000000, reward total was -20.000000. running mean: -20.216222\n","resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.214060\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.221919\n","resetting env. episode 500.000000, reward total was -20.000000. running mean: -20.219700\n","resetting env. episode 501.000000, reward total was -19.000000. running mean: -20.207503\n","resetting env. episode 502.000000, reward total was -18.000000. running mean: -20.185428\n","resetting env. episode 503.000000, reward total was -18.000000. running mean: -20.163574\n","resetting env. episode 504.000000, reward total was -19.000000. running mean: -20.151938\n","resetting env. episode 505.000000, reward total was -20.000000. running mean: -20.150419\n","resetting env. episode 506.000000, reward total was -20.000000. running mean: -20.148914\n","resetting env. episode 507.000000, reward total was -21.000000. running mean: -20.157425\n","resetting env. episode 508.000000, reward total was -21.000000. running mean: -20.165851\n","resetting env. episode 509.000000, reward total was -18.000000. running mean: -20.144193\n","resetting env. episode 510.000000, reward total was -19.000000. running mean: -20.132751\n","resetting env. episode 511.000000, reward total was -19.000000. running mean: -20.121423\n","resetting env. episode 512.000000, reward total was -21.000000. running mean: -20.130209\n","resetting env. episode 513.000000, reward total was -19.000000. running mean: -20.118907\n","resetting env. episode 514.000000, reward total was -21.000000. running mean: -20.127718\n","resetting env. episode 515.000000, reward total was -19.000000. running mean: -20.116441\n","resetting env. episode 516.000000, reward total was -20.000000. running mean: -20.115276\n","resetting env. episode 517.000000, reward total was -19.000000. running mean: -20.104123\n","resetting env. episode 518.000000, reward total was -20.000000. running mean: -20.103082\n","resetting env. episode 519.000000, reward total was -19.000000. running mean: -20.092051\n","resetting env. episode 520.000000, reward total was -20.000000. running mean: -20.091131\n","resetting env. episode 521.000000, reward total was -21.000000. running mean: -20.100220\n","resetting env. episode 522.000000, reward total was -20.000000. running mean: -20.099217\n","resetting env. episode 523.000000, reward total was -21.000000. running mean: -20.108225\n","resetting env. episode 524.000000, reward total was -20.000000. running mean: -20.107143\n","resetting env. episode 525.000000, reward total was -21.000000. running mean: -20.116071\n","resetting env. episode 526.000000, reward total was -21.000000. running mean: -20.124911\n","resetting env. episode 527.000000, reward total was -20.000000. running mean: -20.123662\n","resetting env. episode 528.000000, reward total was -20.000000. running mean: -20.122425\n","resetting env. episode 529.000000, reward total was -19.000000. running mean: -20.111201\n","resetting env. episode 530.000000, reward total was -20.000000. running mean: -20.110089\n","resetting env. episode 531.000000, reward total was -21.000000. running mean: -20.118988\n","resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.127798\n","resetting env. episode 533.000000, reward total was -21.000000. running mean: -20.136520\n","resetting env. episode 534.000000, reward total was -20.000000. running mean: -20.135155\n","resetting env. episode 535.000000, reward total was -20.000000. running mean: -20.133803\n","resetting env. episode 536.000000, reward total was -20.000000. running mean: -20.132465\n","resetting env. episode 537.000000, reward total was -21.000000. running mean: -20.141141\n","resetting env. episode 538.000000, reward total was -20.000000. running mean: -20.139729\n","resetting env. episode 539.000000, reward total was -21.000000. running mean: -20.148332\n","resetting env. episode 540.000000, reward total was -21.000000. running mean: -20.156849\n","resetting env. episode 541.000000, reward total was -21.000000. running mean: -20.165280\n","resetting env. episode 542.000000, reward total was -21.000000. running mean: -20.173627\n","resetting env. episode 543.000000, reward total was -21.000000. running mean: -20.181891\n","resetting env. episode 544.000000, reward total was -19.000000. running mean: -20.170072\n","resetting env. episode 545.000000, reward total was -20.000000. running mean: -20.168371\n","resetting env. episode 546.000000, reward total was -21.000000. running mean: -20.176688\n","resetting env. episode 547.000000, reward total was -21.000000. running mean: -20.184921\n","resetting env. episode 548.000000, reward total was -17.000000. running mean: -20.153072\n","resetting env. episode 549.000000, reward total was -19.000000. running mean: -20.141541\n","resetting env. episode 550.000000, reward total was -18.000000. running mean: -20.120125\n","resetting env. episode 551.000000, reward total was -21.000000. running mean: -20.128924\n","resetting env. episode 552.000000, reward total was -19.000000. running mean: -20.117635\n","resetting env. episode 553.000000, reward total was -21.000000. running mean: -20.126459\n","resetting env. episode 554.000000, reward total was -20.000000. running mean: -20.125194\n","resetting env. episode 555.000000, reward total was -19.000000. running mean: -20.113942\n","resetting env. episode 556.000000, reward total was -19.000000. running mean: -20.102803\n","resetting env. episode 557.000000, reward total was -21.000000. running mean: -20.111775\n","resetting env. episode 558.000000, reward total was -18.000000. running mean: -20.090657\n","resetting env. episode 559.000000, reward total was -20.000000. running mean: -20.089750\n","resetting env. episode 560.000000, reward total was -21.000000. running mean: -20.098853\n","resetting env. episode 561.000000, reward total was -21.000000. running mean: -20.107864\n","resetting env. episode 562.000000, reward total was -20.000000. running mean: -20.106786\n","resetting env. episode 563.000000, reward total was -21.000000. running mean: -20.115718\n","resetting env. episode 564.000000, reward total was -20.000000. running mean: -20.114561\n","resetting env. episode 565.000000, reward total was -20.000000. running mean: -20.113415\n","resetting env. episode 566.000000, reward total was -20.000000. running mean: -20.112281\n","resetting env. episode 567.000000, reward total was -20.000000. running mean: -20.111158\n","resetting env. episode 568.000000, reward total was -20.000000. running mean: -20.110046\n","resetting env. episode 569.000000, reward total was -21.000000. running mean: -20.118946\n","resetting env. episode 570.000000, reward total was -21.000000. running mean: -20.127757\n","resetting env. episode 571.000000, reward total was -21.000000. running mean: -20.136479\n","resetting env. episode 572.000000, reward total was -21.000000. running mean: -20.145114\n","resetting env. episode 573.000000, reward total was -21.000000. running mean: -20.153663\n","resetting env. episode 574.000000, reward total was -18.000000. running mean: -20.132126\n","resetting env. episode 575.000000, reward total was -21.000000. running mean: -20.140805\n","resetting env. episode 576.000000, reward total was -21.000000. running mean: -20.149397\n","resetting env. episode 577.000000, reward total was -20.000000. running mean: -20.147903\n","resetting env. episode 578.000000, reward total was -20.000000. running mean: -20.146424\n","resetting env. episode 579.000000, reward total was -18.000000. running mean: -20.124960\n","resetting env. episode 580.000000, reward total was -21.000000. running mean: -20.133710\n","resetting env. episode 581.000000, reward total was -20.000000. running mean: -20.132373\n","resetting env. episode 582.000000, reward total was -21.000000. running mean: -20.141049\n","resetting env. episode 583.000000, reward total was -21.000000. running mean: -20.149639\n","resetting env. episode 584.000000, reward total was -21.000000. running mean: -20.158143\n","resetting env. episode 585.000000, reward total was -21.000000. running mean: -20.166561\n","resetting env. episode 586.000000, reward total was -21.000000. running mean: -20.174896\n","resetting env. episode 587.000000, reward total was -21.000000. running mean: -20.183147\n","resetting env. episode 588.000000, reward total was -21.000000. running mean: -20.191315\n","resetting env. episode 589.000000, reward total was -19.000000. running mean: -20.179402\n","resetting env. episode 590.000000, reward total was -18.000000. running mean: -20.157608\n","resetting env. episode 591.000000, reward total was -21.000000. running mean: -20.166032\n","resetting env. episode 592.000000, reward total was -19.000000. running mean: -20.154372\n","resetting env. episode 593.000000, reward total was -20.000000. running mean: -20.152828\n","resetting env. episode 594.000000, reward total was -19.000000. running mean: -20.141300\n","resetting env. episode 595.000000, reward total was -20.000000. running mean: -20.139887\n","resetting env. episode 596.000000, reward total was -20.000000. running mean: -20.138488\n","resetting env. episode 597.000000, reward total was -21.000000. running mean: -20.147103\n","resetting env. episode 598.000000, reward total was -19.000000. running mean: -20.135632\n","resetting env. episode 599.000000, reward total was -19.000000. running mean: -20.124275\n","resetting env. episode 600.000000, reward total was -20.000000. running mean: -20.123033\n","resetting env. episode 601.000000, reward total was -20.000000. running mean: -20.121802\n","resetting env. episode 602.000000, reward total was -21.000000. running mean: -20.130584\n","resetting env. episode 603.000000, reward total was -21.000000. running mean: -20.139278\n","resetting env. episode 604.000000, reward total was -19.000000. running mean: -20.127886\n","resetting env. episode 605.000000, reward total was -21.000000. running mean: -20.136607\n","resetting env. episode 606.000000, reward total was -19.000000. running mean: -20.125241\n","resetting env. episode 607.000000, reward total was -21.000000. running mean: -20.133988\n","resetting env. episode 608.000000, reward total was -20.000000. running mean: -20.132648\n","resetting env. episode 609.000000, reward total was -20.000000. running mean: -20.131322\n","resetting env. episode 610.000000, reward total was -18.000000. running mean: -20.110009\n","resetting env. episode 611.000000, reward total was -17.000000. running mean: -20.078909\n","resetting env. episode 612.000000, reward total was -21.000000. running mean: -20.088120\n","resetting env. episode 613.000000, reward total was -20.000000. running mean: -20.087238\n","resetting env. episode 614.000000, reward total was -19.000000. running mean: -20.076366\n","resetting env. episode 615.000000, reward total was -19.000000. running mean: -20.065602\n","resetting env. episode 616.000000, reward total was -20.000000. running mean: -20.064946\n","resetting env. episode 617.000000, reward total was -19.000000. running mean: -20.054297\n","resetting env. episode 618.000000, reward total was -20.000000. running mean: -20.053754\n","resetting env. episode 619.000000, reward total was -20.000000. running mean: -20.053216\n","resetting env. episode 620.000000, reward total was -20.000000. running mean: -20.052684\n","resetting env. episode 621.000000, reward total was -19.000000. running mean: -20.042157\n","resetting env. episode 622.000000, reward total was -19.000000. running mean: -20.031736\n","resetting env. episode 623.000000, reward total was -20.000000. running mean: -20.031418\n","resetting env. episode 624.000000, reward total was -21.000000. running mean: -20.041104\n","resetting env. episode 625.000000, reward total was -20.000000. running mean: -20.040693\n","resetting env. episode 626.000000, reward total was -20.000000. running mean: -20.040286\n","resetting env. episode 627.000000, reward total was -21.000000. running mean: -20.049883\n","resetting env. episode 628.000000, reward total was -21.000000. running mean: -20.059385\n","resetting env. episode 629.000000, reward total was -19.000000. running mean: -20.048791\n","resetting env. episode 630.000000, reward total was -19.000000. running mean: -20.038303\n","resetting env. episode 631.000000, reward total was -21.000000. running mean: -20.047920\n","resetting env. episode 632.000000, reward total was -20.000000. running mean: -20.047441\n","resetting env. episode 633.000000, reward total was -21.000000. running mean: -20.056966\n","resetting env. episode 634.000000, reward total was -21.000000. running mean: -20.066397\n","resetting env. episode 635.000000, reward total was -19.000000. running mean: -20.055733\n","resetting env. episode 636.000000, reward total was -19.000000. running mean: -20.045175\n","resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.054723\n","resetting env. episode 638.000000, reward total was -21.000000. running mean: -20.064176\n","resetting env. episode 639.000000, reward total was -21.000000. running mean: -20.073534\n","resetting env. episode 640.000000, reward total was -19.000000. running mean: -20.062799\n","resetting env. episode 641.000000, reward total was -21.000000. running mean: -20.072171\n","resetting env. episode 642.000000, reward total was -20.000000. running mean: -20.071449\n","resetting env. episode 643.000000, reward total was -20.000000. running mean: -20.070735\n","resetting env. episode 644.000000, reward total was -20.000000. running mean: -20.070028\n","resetting env. episode 645.000000, reward total was -20.000000. running mean: -20.069327\n","resetting env. episode 646.000000, reward total was -20.000000. running mean: -20.068634\n","resetting env. episode 647.000000, reward total was -20.000000. running mean: -20.067948\n","resetting env. episode 648.000000, reward total was -19.000000. running mean: -20.057268\n","resetting env. episode 649.000000, reward total was -19.000000. running mean: -20.046696\n","resetting env. episode 650.000000, reward total was -21.000000. running mean: -20.056229\n","resetting env. episode 651.000000, reward total was -21.000000. running mean: -20.065666\n","resetting env. episode 652.000000, reward total was -20.000000. running mean: -20.065010\n","resetting env. episode 653.000000, reward total was -21.000000. running mean: -20.074360\n","resetting env. episode 654.000000, reward total was -20.000000. running mean: -20.073616\n","resetting env. episode 655.000000, reward total was -21.000000. running mean: -20.082880\n","resetting env. episode 656.000000, reward total was -20.000000. running mean: -20.082051\n","resetting env. episode 657.000000, reward total was -21.000000. running mean: -20.091230\n","resetting env. episode 658.000000, reward total was -20.000000. running mean: -20.090318\n","resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.099415\n","resetting env. episode 660.000000, reward total was -20.000000. running mean: -20.098421\n","resetting env. episode 661.000000, reward total was -20.000000. running mean: -20.097437\n","resetting env. episode 662.000000, reward total was -21.000000. running mean: -20.106462\n","resetting env. episode 663.000000, reward total was -21.000000. running mean: -20.115398\n","resetting env. episode 664.000000, reward total was -21.000000. running mean: -20.124244\n","resetting env. episode 665.000000, reward total was -20.000000. running mean: -20.123001\n","resetting env. episode 666.000000, reward total was -20.000000. running mean: -20.121771\n","resetting env. episode 667.000000, reward total was -21.000000. running mean: -20.130554\n","resetting env. episode 668.000000, reward total was -21.000000. running mean: -20.139248\n","resetting env. episode 669.000000, reward total was -19.000000. running mean: -20.127856\n","resetting env. episode 670.000000, reward total was -21.000000. running mean: -20.136577\n","resetting env. episode 671.000000, reward total was -20.000000. running mean: -20.135211\n","resetting env. episode 672.000000, reward total was -21.000000. running mean: -20.143859\n","resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.152420\n","resetting env. episode 674.000000, reward total was -21.000000. running mean: -20.160896\n","resetting env. episode 675.000000, reward total was -21.000000. running mean: -20.169287\n","resetting env. episode 676.000000, reward total was -21.000000. running mean: -20.177594\n","resetting env. episode 677.000000, reward total was -21.000000. running mean: -20.185818\n","resetting env. episode 678.000000, reward total was -21.000000. running mean: -20.193960\n","resetting env. episode 679.000000, reward total was -18.000000. running mean: -20.172021\n","resetting env. episode 680.000000, reward total was -21.000000. running mean: -20.180300\n","resetting env. episode 681.000000, reward total was -21.000000. running mean: -20.188497\n","resetting env. episode 682.000000, reward total was -20.000000. running mean: -20.186613\n","resetting env. episode 683.000000, reward total was -19.000000. running mean: -20.174746\n","resetting env. episode 684.000000, reward total was -20.000000. running mean: -20.172999\n","resetting env. episode 685.000000, reward total was -20.000000. running mean: -20.171269\n","resetting env. episode 686.000000, reward total was -20.000000. running mean: -20.169556\n","resetting env. episode 687.000000, reward total was -21.000000. running mean: -20.177861\n","resetting env. episode 688.000000, reward total was -19.000000. running mean: -20.166082\n","resetting env. episode 689.000000, reward total was -19.000000. running mean: -20.154421\n","resetting env. episode 690.000000, reward total was -21.000000. running mean: -20.162877\n","resetting env. episode 691.000000, reward total was -20.000000. running mean: -20.161248\n","resetting env. episode 692.000000, reward total was -20.000000. running mean: -20.159636\n","resetting env. episode 693.000000, reward total was -18.000000. running mean: -20.138039\n","resetting env. episode 694.000000, reward total was -20.000000. running mean: -20.136659\n","resetting env. episode 695.000000, reward total was -21.000000. running mean: -20.145292\n","resetting env. episode 696.000000, reward total was -19.000000. running mean: -20.133840\n","resetting env. episode 697.000000, reward total was -19.000000. running mean: -20.122501\n","resetting env. episode 698.000000, reward total was -20.000000. running mean: -20.121276\n","resetting env. episode 699.000000, reward total was -21.000000. running mean: -20.130063\n","resetting env. episode 700.000000, reward total was -19.000000. running mean: -20.118763\n","resetting env. episode 701.000000, reward total was -20.000000. running mean: -20.117575\n","resetting env. episode 702.000000, reward total was -20.000000. running mean: -20.116399\n","resetting env. episode 703.000000, reward total was -21.000000. running mean: -20.125235\n","resetting env. episode 704.000000, reward total was -21.000000. running mean: -20.133983\n","resetting env. episode 705.000000, reward total was -17.000000. running mean: -20.102643\n","resetting env. episode 706.000000, reward total was -21.000000. running mean: -20.111617\n","resetting env. episode 707.000000, reward total was -20.000000. running mean: -20.110501\n","resetting env. episode 708.000000, reward total was -19.000000. running mean: -20.099396\n","resetting env. episode 709.000000, reward total was -21.000000. running mean: -20.108402\n","resetting env. episode 710.000000, reward total was -21.000000. running mean: -20.117318\n","resetting env. episode 711.000000, reward total was -21.000000. running mean: -20.126144\n","resetting env. episode 712.000000, reward total was -19.000000. running mean: -20.114883\n","resetting env. episode 713.000000, reward total was -19.000000. running mean: -20.103734\n","resetting env. episode 714.000000, reward total was -18.000000. running mean: -20.082697\n","resetting env. episode 715.000000, reward total was -21.000000. running mean: -20.091870\n","resetting env. episode 716.000000, reward total was -19.000000. running mean: -20.080951\n","resetting env. episode 717.000000, reward total was -20.000000. running mean: -20.080142\n","resetting env. episode 718.000000, reward total was -17.000000. running mean: -20.049340\n","resetting env. episode 719.000000, reward total was -21.000000. running mean: -20.058847\n","resetting env. episode 720.000000, reward total was -21.000000. running mean: -20.068258\n","resetting env. episode 721.000000, reward total was -19.000000. running mean: -20.057576\n","resetting env. episode 722.000000, reward total was -20.000000. running mean: -20.057000\n","resetting env. episode 723.000000, reward total was -17.000000. running mean: -20.026430\n","resetting env. episode 724.000000, reward total was -21.000000. running mean: -20.036166\n","resetting env. episode 725.000000, reward total was -18.000000. running mean: -20.015804\n","resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.025646\n","resetting env. episode 727.000000, reward total was -21.000000. running mean: -20.035390\n","resetting env. episode 728.000000, reward total was -20.000000. running mean: -20.035036\n","resetting env. episode 729.000000, reward total was -20.000000. running mean: -20.034685\n","resetting env. episode 730.000000, reward total was -18.000000. running mean: -20.014338\n","resetting env. episode 731.000000, reward total was -21.000000. running mean: -20.024195\n","resetting env. episode 732.000000, reward total was -21.000000. running mean: -20.033953\n","resetting env. episode 733.000000, reward total was -21.000000. running mean: -20.043614\n","resetting env. episode 734.000000, reward total was -21.000000. running mean: -20.053177\n","resetting env. episode 735.000000, reward total was -20.000000. running mean: -20.052646\n","resetting env. episode 736.000000, reward total was -21.000000. running mean: -20.062119\n","resetting env. episode 737.000000, reward total was -17.000000. running mean: -20.031498\n","resetting env. episode 738.000000, reward total was -18.000000. running mean: -20.011183\n","resetting env. episode 739.000000, reward total was -20.000000. running mean: -20.011071\n","resetting env. episode 740.000000, reward total was -20.000000. running mean: -20.010960\n","resetting env. episode 741.000000, reward total was -20.000000. running mean: -20.010851\n","resetting env. episode 742.000000, reward total was -21.000000. running mean: -20.020742\n","resetting env. episode 743.000000, reward total was -21.000000. running mean: -20.030535\n","resetting env. episode 744.000000, reward total was -19.000000. running mean: -20.020230\n","resetting env. episode 745.000000, reward total was -18.000000. running mean: -20.000027\n","resetting env. episode 746.000000, reward total was -19.000000. running mean: -19.990027\n","resetting env. episode 747.000000, reward total was -20.000000. running mean: -19.990127\n","resetting env. episode 748.000000, reward total was -21.000000. running mean: -20.000225\n","resetting env. episode 749.000000, reward total was -18.000000. running mean: -19.980223\n","resetting env. episode 750.000000, reward total was -18.000000. running mean: -19.960421\n","resetting env. episode 751.000000, reward total was -18.000000. running mean: -19.940817\n","resetting env. episode 752.000000, reward total was -21.000000. running mean: -19.951409\n","resetting env. episode 753.000000, reward total was -21.000000. running mean: -19.961895\n","resetting env. episode 754.000000, reward total was -20.000000. running mean: -19.962276\n","resetting env. episode 755.000000, reward total was -21.000000. running mean: -19.972653\n","resetting env. episode 756.000000, reward total was -20.000000. running mean: -19.972926\n","resetting env. episode 757.000000, reward total was -19.000000. running mean: -19.963197\n","resetting env. episode 758.000000, reward total was -21.000000. running mean: -19.973565\n","resetting env. episode 759.000000, reward total was -21.000000. running mean: -19.983829\n","resetting env. episode 760.000000, reward total was -19.000000. running mean: -19.973991\n","resetting env. episode 761.000000, reward total was -19.000000. running mean: -19.964251\n","resetting env. episode 762.000000, reward total was -18.000000. running mean: -19.944609\n","resetting env. episode 763.000000, reward total was -19.000000. running mean: -19.935163\n","resetting env. episode 764.000000, reward total was -19.000000. running mean: -19.925811\n","resetting env. episode 765.000000, reward total was -21.000000. running mean: -19.936553\n","resetting env. episode 766.000000, reward total was -20.000000. running mean: -19.937187\n","resetting env. episode 767.000000, reward total was -21.000000. running mean: -19.947815\n","resetting env. episode 768.000000, reward total was -19.000000. running mean: -19.938337\n","resetting env. episode 769.000000, reward total was -21.000000. running mean: -19.948954\n","resetting env. episode 770.000000, reward total was -21.000000. running mean: -19.959464\n","resetting env. episode 771.000000, reward total was -20.000000. running mean: -19.959870\n","resetting env. episode 772.000000, reward total was -19.000000. running mean: -19.950271\n","resetting env. episode 773.000000, reward total was -19.000000. running mean: -19.940768\n","resetting env. episode 774.000000, reward total was -20.000000. running mean: -19.941361\n","resetting env. episode 775.000000, reward total was -18.000000. running mean: -19.921947\n","resetting env. episode 776.000000, reward total was -18.000000. running mean: -19.902728\n","resetting env. episode 777.000000, reward total was -19.000000. running mean: -19.893700\n","resetting env. episode 778.000000, reward total was -21.000000. running mean: -19.904763\n","resetting env. episode 779.000000, reward total was -19.000000. running mean: -19.895716\n","resetting env. episode 780.000000, reward total was -21.000000. running mean: -19.906759\n","resetting env. episode 781.000000, reward total was -19.000000. running mean: -19.897691\n","resetting env. episode 782.000000, reward total was -20.000000. running mean: -19.898714\n","resetting env. episode 783.000000, reward total was -19.000000. running mean: -19.889727\n","resetting env. episode 784.000000, reward total was -21.000000. running mean: -19.900830\n","resetting env. episode 785.000000, reward total was -21.000000. running mean: -19.911821\n","resetting env. episode 786.000000, reward total was -21.000000. running mean: -19.922703\n","resetting env. episode 787.000000, reward total was -20.000000. running mean: -19.923476\n","resetting env. episode 788.000000, reward total was -19.000000. running mean: -19.914241\n","resetting env. episode 789.000000, reward total was -18.000000. running mean: -19.895099\n","resetting env. episode 790.000000, reward total was -19.000000. running mean: -19.886148\n","resetting env. episode 791.000000, reward total was -21.000000. running mean: -19.897286\n","resetting env. episode 792.000000, reward total was -20.000000. running mean: -19.898314\n","resetting env. episode 793.000000, reward total was -20.000000. running mean: -19.899330\n","resetting env. episode 794.000000, reward total was -20.000000. running mean: -19.900337\n","resetting env. episode 795.000000, reward total was -21.000000. running mean: -19.911334\n","resetting env. episode 796.000000, reward total was -20.000000. running mean: -19.912220\n","resetting env. episode 797.000000, reward total was -20.000000. running mean: -19.913098\n","resetting env. episode 798.000000, reward total was -20.000000. running mean: -19.913967\n","resetting env. episode 799.000000, reward total was -20.000000. running mean: -19.914828\n","resetting env. episode 800.000000, reward total was -20.000000. running mean: -19.915679\n","resetting env. episode 801.000000, reward total was -20.000000. running mean: -19.916523\n","resetting env. episode 802.000000, reward total was -20.000000. running mean: -19.917357\n","resetting env. episode 803.000000, reward total was -19.000000. running mean: -19.908184\n","resetting env. episode 804.000000, reward total was -18.000000. running mean: -19.889102\n","resetting env. episode 805.000000, reward total was -20.000000. running mean: -19.890211\n","resetting env. episode 806.000000, reward total was -21.000000. running mean: -19.901309\n","resetting env. episode 807.000000, reward total was -19.000000. running mean: -19.892296\n","resetting env. episode 808.000000, reward total was -20.000000. running mean: -19.893373\n","resetting env. episode 809.000000, reward total was -20.000000. running mean: -19.894439\n","resetting env. episode 810.000000, reward total was -18.000000. running mean: -19.875495\n","resetting env. episode 811.000000, reward total was -21.000000. running mean: -19.886740\n","resetting env. episode 812.000000, reward total was -21.000000. running mean: -19.897872\n","resetting env. episode 813.000000, reward total was -17.000000. running mean: -19.868894\n","resetting env. episode 814.000000, reward total was -20.000000. running mean: -19.870205\n","resetting env. episode 815.000000, reward total was -20.000000. running mean: -19.871503\n","resetting env. episode 816.000000, reward total was -21.000000. running mean: -19.882788\n","resetting env. episode 817.000000, reward total was -20.000000. running mean: -19.883960\n","resetting env. episode 818.000000, reward total was -21.000000. running mean: -19.895120\n","resetting env. episode 819.000000, reward total was -20.000000. running mean: -19.896169\n","resetting env. episode 820.000000, reward total was -21.000000. running mean: -19.907207\n","resetting env. episode 821.000000, reward total was -20.000000. running mean: -19.908135\n","resetting env. episode 822.000000, reward total was -19.000000. running mean: -19.899054\n","resetting env. episode 823.000000, reward total was -21.000000. running mean: -19.910063\n","resetting env. episode 824.000000, reward total was -19.000000. running mean: -19.900963\n","resetting env. episode 825.000000, reward total was -20.000000. running mean: -19.901953\n","resetting env. episode 826.000000, reward total was -21.000000. running mean: -19.912933\n","resetting env. episode 827.000000, reward total was -21.000000. running mean: -19.923804\n","resetting env. episode 828.000000, reward total was -20.000000. running mean: -19.924566\n","resetting env. episode 829.000000, reward total was -20.000000. running mean: -19.925320\n","resetting env. episode 830.000000, reward total was -19.000000. running mean: -19.916067\n","resetting env. episode 831.000000, reward total was -21.000000. running mean: -19.926906\n","resetting env. episode 832.000000, reward total was -18.000000. running mean: -19.907637\n","resetting env. episode 833.000000, reward total was -21.000000. running mean: -19.918561\n","resetting env. episode 834.000000, reward total was -20.000000. running mean: -19.919375\n","resetting env. episode 835.000000, reward total was -21.000000. running mean: -19.930182\n","resetting env. episode 836.000000, reward total was -20.000000. running mean: -19.930880\n","resetting env. episode 837.000000, reward total was -20.000000. running mean: -19.931571\n","resetting env. episode 838.000000, reward total was -20.000000. running mean: -19.932255\n","resetting env. episode 839.000000, reward total was -21.000000. running mean: -19.942933\n","resetting env. episode 840.000000, reward total was -21.000000. running mean: -19.953503\n","resetting env. episode 841.000000, reward total was -20.000000. running mean: -19.953968\n","resetting env. episode 842.000000, reward total was -18.000000. running mean: -19.934429\n","resetting env. episode 843.000000, reward total was -19.000000. running mean: -19.925084\n","resetting env. episode 844.000000, reward total was -19.000000. running mean: -19.915834\n","resetting env. episode 845.000000, reward total was -19.000000. running mean: -19.906675\n","resetting env. episode 846.000000, reward total was -20.000000. running mean: -19.907609\n","resetting env. episode 847.000000, reward total was -19.000000. running mean: -19.898532\n","resetting env. episode 848.000000, reward total was -21.000000. running mean: -19.909547\n","resetting env. episode 849.000000, reward total was -21.000000. running mean: -19.920452\n","resetting env. episode 850.000000, reward total was -18.000000. running mean: -19.901247\n","resetting env. episode 851.000000, reward total was -20.000000. running mean: -19.902235\n","resetting env. episode 852.000000, reward total was -20.000000. running mean: -19.903212\n","resetting env. episode 853.000000, reward total was -21.000000. running mean: -19.914180\n","resetting env. episode 854.000000, reward total was -20.000000. running mean: -19.915038\n","resetting env. episode 855.000000, reward total was -21.000000. running mean: -19.925888\n","resetting env. episode 856.000000, reward total was -19.000000. running mean: -19.916629\n","resetting env. episode 857.000000, reward total was -19.000000. running mean: -19.907463\n","resetting env. episode 858.000000, reward total was -20.000000. running mean: -19.908388\n","resetting env. episode 859.000000, reward total was -21.000000. running mean: -19.919304\n","resetting env. episode 860.000000, reward total was -18.000000. running mean: -19.900111\n","resetting env. episode 861.000000, reward total was -21.000000. running mean: -19.911110\n","resetting env. episode 862.000000, reward total was -20.000000. running mean: -19.911999\n","resetting env. episode 863.000000, reward total was -20.000000. running mean: -19.912879\n","resetting env. episode 864.000000, reward total was -18.000000. running mean: -19.893750\n","resetting env. episode 865.000000, reward total was -19.000000. running mean: -19.884813\n","resetting env. episode 866.000000, reward total was -20.000000. running mean: -19.885965\n","resetting env. episode 867.000000, reward total was -19.000000. running mean: -19.877105\n","resetting env. episode 868.000000, reward total was -21.000000. running mean: -19.888334\n","resetting env. episode 869.000000, reward total was -19.000000. running mean: -19.879451\n","resetting env. episode 870.000000, reward total was -20.000000. running mean: -19.880656\n","resetting env. episode 871.000000, reward total was -21.000000. running mean: -19.891850\n","resetting env. episode 872.000000, reward total was -19.000000. running mean: -19.882931\n","resetting env. episode 873.000000, reward total was -20.000000. running mean: -19.884102\n","resetting env. episode 874.000000, reward total was -20.000000. running mean: -19.885261\n","resetting env. episode 875.000000, reward total was -21.000000. running mean: -19.896408\n","resetting env. episode 876.000000, reward total was -21.000000. running mean: -19.907444\n","resetting env. episode 877.000000, reward total was -19.000000. running mean: -19.898370\n","resetting env. episode 878.000000, reward total was -21.000000. running mean: -19.909386\n","resetting env. episode 879.000000, reward total was -20.000000. running mean: -19.910292\n","resetting env. episode 880.000000, reward total was -19.000000. running mean: -19.901189\n","resetting env. episode 881.000000, reward total was -19.000000. running mean: -19.892177\n","resetting env. episode 882.000000, reward total was -19.000000. running mean: -19.883255\n","resetting env. episode 883.000000, reward total was -20.000000. running mean: -19.884423\n","resetting env. episode 884.000000, reward total was -21.000000. running mean: -19.895579\n","resetting env. episode 885.000000, reward total was -20.000000. running mean: -19.896623\n","resetting env. episode 886.000000, reward total was -20.000000. running mean: -19.897657\n","resetting env. episode 887.000000, reward total was -18.000000. running mean: -19.878680\n","resetting env. episode 888.000000, reward total was -21.000000. running mean: -19.889893\n","resetting env. episode 889.000000, reward total was -19.000000. running mean: -19.880994\n","resetting env. episode 890.000000, reward total was -21.000000. running mean: -19.892184\n","resetting env. episode 891.000000, reward total was -21.000000. running mean: -19.903263\n","resetting env. episode 892.000000, reward total was -21.000000. running mean: -19.914230\n","resetting env. episode 893.000000, reward total was -20.000000. running mean: -19.915088\n","resetting env. episode 894.000000, reward total was -19.000000. running mean: -19.905937\n","resetting env. episode 895.000000, reward total was -21.000000. running mean: -19.916877\n","resetting env. episode 896.000000, reward total was -21.000000. running mean: -19.927709\n","resetting env. episode 897.000000, reward total was -21.000000. running mean: -19.938432\n","resetting env. episode 898.000000, reward total was -19.000000. running mean: -19.929047\n","resetting env. episode 899.000000, reward total was -19.000000. running mean: -19.919757\n","resetting env. episode 900.000000, reward total was -18.000000. running mean: -19.900559\n","resetting env. episode 901.000000, reward total was -20.000000. running mean: -19.901554\n","resetting env. episode 902.000000, reward total was -21.000000. running mean: -19.912538\n","resetting env. episode 903.000000, reward total was -20.000000. running mean: -19.913413\n","resetting env. episode 904.000000, reward total was -21.000000. running mean: -19.924279\n","resetting env. episode 905.000000, reward total was -20.000000. running mean: -19.925036\n","resetting env. episode 906.000000, reward total was -21.000000. running mean: -19.935785\n","resetting env. episode 907.000000, reward total was -20.000000. running mean: -19.936428\n","resetting env. episode 908.000000, reward total was -19.000000. running mean: -19.927063\n","resetting env. episode 909.000000, reward total was -21.000000. running mean: -19.937793\n","resetting env. episode 910.000000, reward total was -19.000000. running mean: -19.928415\n","resetting env. episode 911.000000, reward total was -19.000000. running mean: -19.919131\n","resetting env. episode 912.000000, reward total was -21.000000. running mean: -19.929939\n","resetting env. episode 913.000000, reward total was -21.000000. running mean: -19.940640\n","resetting env. episode 914.000000, reward total was -21.000000. running mean: -19.951233\n","resetting env. episode 915.000000, reward total was -21.000000. running mean: -19.961721\n","resetting env. episode 916.000000, reward total was -21.000000. running mean: -19.972104\n","resetting env. episode 917.000000, reward total was -21.000000. running mean: -19.982383\n","resetting env. episode 918.000000, reward total was -21.000000. running mean: -19.992559\n","resetting env. episode 919.000000, reward total was -21.000000. running mean: -20.002633\n","resetting env. episode 920.000000, reward total was -21.000000. running mean: -20.012607\n","resetting env. episode 921.000000, reward total was -21.000000. running mean: -20.022481\n","resetting env. episode 922.000000, reward total was -21.000000. running mean: -20.032256\n","resetting env. episode 923.000000, reward total was -19.000000. running mean: -20.021934\n","resetting env. episode 924.000000, reward total was -20.000000. running mean: -20.021714\n","resetting env. episode 925.000000, reward total was -19.000000. running mean: -20.011497\n","resetting env. episode 926.000000, reward total was -21.000000. running mean: -20.021382\n","resetting env. episode 927.000000, reward total was -19.000000. running mean: -20.011168\n","resetting env. episode 928.000000, reward total was -19.000000. running mean: -20.001057\n","resetting env. episode 929.000000, reward total was -21.000000. running mean: -20.011046\n","resetting env. episode 930.000000, reward total was -17.000000. running mean: -19.980936\n","resetting env. episode 931.000000, reward total was -19.000000. running mean: -19.971126\n","resetting env. episode 932.000000, reward total was -20.000000. running mean: -19.971415\n","resetting env. episode 933.000000, reward total was -21.000000. running mean: -19.981701\n","resetting env. episode 934.000000, reward total was -19.000000. running mean: -19.971884\n","resetting env. episode 935.000000, reward total was -18.000000. running mean: -19.952165\n","resetting env. episode 936.000000, reward total was -21.000000. running mean: -19.962643\n","resetting env. episode 937.000000, reward total was -20.000000. running mean: -19.963017\n","resetting env. episode 938.000000, reward total was -19.000000. running mean: -19.953387\n","resetting env. episode 939.000000, reward total was -21.000000. running mean: -19.963853\n","resetting env. episode 940.000000, reward total was -19.000000. running mean: -19.954214\n","resetting env. episode 941.000000, reward total was -21.000000. running mean: -19.964672\n","resetting env. episode 942.000000, reward total was -20.000000. running mean: -19.965026\n","resetting env. episode 943.000000, reward total was -19.000000. running mean: -19.955375\n","resetting env. episode 944.000000, reward total was -19.000000. running mean: -19.945822\n","resetting env. episode 945.000000, reward total was -19.000000. running mean: -19.936363\n","resetting env. episode 946.000000, reward total was -19.000000. running mean: -19.927000\n","resetting env. episode 947.000000, reward total was -18.000000. running mean: -19.907730\n","resetting env. episode 948.000000, reward total was -20.000000. running mean: -19.908652\n","resetting env. episode 949.000000, reward total was -20.000000. running mean: -19.909566\n","resetting env. episode 950.000000, reward total was -19.000000. running mean: -19.900470\n","resetting env. episode 951.000000, reward total was -21.000000. running mean: -19.911466\n","resetting env. episode 952.000000, reward total was -19.000000. running mean: -19.902351\n","resetting env. episode 953.000000, reward total was -21.000000. running mean: -19.913327\n","resetting env. episode 954.000000, reward total was -20.000000. running mean: -19.914194\n","resetting env. episode 955.000000, reward total was -21.000000. running mean: -19.925052\n","resetting env. episode 956.000000, reward total was -18.000000. running mean: -19.905802\n","resetting env. episode 957.000000, reward total was -20.000000. running mean: -19.906744\n","resetting env. episode 958.000000, reward total was -17.000000. running mean: -19.877676\n","resetting env. episode 959.000000, reward total was -21.000000. running mean: -19.888899\n","resetting env. episode 960.000000, reward total was -20.000000. running mean: -19.890010\n","resetting env. episode 961.000000, reward total was -20.000000. running mean: -19.891110\n","resetting env. episode 962.000000, reward total was -20.000000. running mean: -19.892199\n","resetting env. episode 963.000000, reward total was -18.000000. running mean: -19.873277\n","resetting env. episode 964.000000, reward total was -18.000000. running mean: -19.854544\n","resetting env. episode 965.000000, reward total was -20.000000. running mean: -19.855999\n","resetting env. episode 966.000000, reward total was -20.000000. running mean: -19.857439\n","resetting env. episode 967.000000, reward total was -21.000000. running mean: -19.868865\n","resetting env. episode 968.000000, reward total was -19.000000. running mean: -19.860176\n","resetting env. episode 969.000000, reward total was -21.000000. running mean: -19.871574\n","resetting env. episode 970.000000, reward total was -19.000000. running mean: -19.862858\n","resetting env. episode 971.000000, reward total was -21.000000. running mean: -19.874230\n","resetting env. episode 972.000000, reward total was -21.000000. running mean: -19.885488\n","resetting env. episode 973.000000, reward total was -20.000000. running mean: -19.886633\n","resetting env. episode 974.000000, reward total was -21.000000. running mean: -19.897766\n","resetting env. episode 975.000000, reward total was -19.000000. running mean: -19.888789\n","resetting env. episode 976.000000, reward total was -21.000000. running mean: -19.899901\n","resetting env. episode 977.000000, reward total was -20.000000. running mean: -19.900902\n","resetting env. episode 978.000000, reward total was -21.000000. running mean: -19.911893\n","resetting env. episode 979.000000, reward total was -19.000000. running mean: -19.902774\n","resetting env. episode 980.000000, reward total was -20.000000. running mean: -19.903746\n","resetting env. episode 981.000000, reward total was -21.000000. running mean: -19.914709\n","resetting env. episode 982.000000, reward total was -21.000000. running mean: -19.925562\n","resetting env. episode 983.000000, reward total was -21.000000. running mean: -19.936306\n","resetting env. episode 984.000000, reward total was -21.000000. running mean: -19.946943\n","resetting env. episode 985.000000, reward total was -19.000000. running mean: -19.937473\n","resetting env. episode 986.000000, reward total was -21.000000. running mean: -19.948099\n","resetting env. episode 987.000000, reward total was -19.000000. running mean: -19.938618\n","resetting env. episode 988.000000, reward total was -19.000000. running mean: -19.929232\n","resetting env. episode 989.000000, reward total was -20.000000. running mean: -19.929939\n","resetting env. episode 990.000000, reward total was -21.000000. running mean: -19.940640\n","resetting env. episode 991.000000, reward total was -20.000000. running mean: -19.941233\n","resetting env. episode 992.000000, reward total was -21.000000. running mean: -19.951821\n","resetting env. episode 993.000000, reward total was -20.000000. running mean: -19.952303\n","resetting env. episode 994.000000, reward total was -19.000000. running mean: -19.942780\n","resetting env. episode 995.000000, reward total was -20.000000. running mean: -19.943352\n","resetting env. episode 996.000000, reward total was -20.000000. running mean: -19.943919\n","resetting env. episode 997.000000, reward total was -20.000000. running mean: -19.944479\n","resetting env. episode 998.000000, reward total was -20.000000. running mean: -19.945035\n","resetting env. episode 999.000000, reward total was -20.000000. running mean: -19.945584\n","resetting env. episode 1000.000000, reward total was -21.000000. running mean: -19.956128\n","resetting env. episode 1001.000000, reward total was -21.000000. running mean: -19.966567\n","resetting env. episode 1002.000000, reward total was -20.000000. running mean: -19.966901\n","resetting env. episode 1003.000000, reward total was -21.000000. running mean: -19.977232\n","resetting env. episode 1004.000000, reward total was -18.000000. running mean: -19.957460\n","resetting env. episode 1005.000000, reward total was -20.000000. running mean: -19.957886\n","resetting env. episode 1006.000000, reward total was -21.000000. running mean: -19.968307\n","resetting env. episode 1007.000000, reward total was -19.000000. running mean: -19.958624\n","resetting env. episode 1008.000000, reward total was -20.000000. running mean: -19.959037\n","resetting env. episode 1009.000000, reward total was -21.000000. running mean: -19.969447\n","resetting env. episode 1010.000000, reward total was -21.000000. running mean: -19.979753\n","resetting env. episode 1011.000000, reward total was -21.000000. running mean: -19.989955\n","resetting env. episode 1012.000000, reward total was -19.000000. running mean: -19.980055\n","resetting env. episode 1013.000000, reward total was -21.000000. running mean: -19.990255\n","resetting env. episode 1014.000000, reward total was -21.000000. running mean: -20.000352\n","resetting env. episode 1015.000000, reward total was -21.000000. running mean: -20.010349\n","resetting env. episode 1016.000000, reward total was -20.000000. running mean: -20.010245\n","resetting env. episode 1017.000000, reward total was -19.000000. running mean: -20.000143\n","resetting env. episode 1018.000000, reward total was -20.000000. running mean: -20.000141\n","resetting env. episode 1019.000000, reward total was -19.000000. running mean: -19.990140\n","resetting env. episode 1020.000000, reward total was -20.000000. running mean: -19.990239\n","resetting env. episode 1021.000000, reward total was -21.000000. running mean: -20.000336\n","resetting env. episode 1022.000000, reward total was -19.000000. running mean: -19.990333\n","resetting env. episode 1023.000000, reward total was -21.000000. running mean: -20.000430\n","resetting env. episode 1024.000000, reward total was -21.000000. running mean: -20.010425\n","resetting env. episode 1025.000000, reward total was -20.000000. running mean: -20.010321\n","resetting env. episode 1026.000000, reward total was -21.000000. running mean: -20.020218\n","resetting env. episode 1027.000000, reward total was -20.000000. running mean: -20.020016\n","resetting env. episode 1028.000000, reward total was -18.000000. running mean: -19.999815\n","resetting env. episode 1029.000000, reward total was -19.000000. running mean: -19.989817\n","resetting env. episode 1030.000000, reward total was -21.000000. running mean: -19.999919\n","resetting env. episode 1031.000000, reward total was -17.000000. running mean: -19.969920\n","resetting env. episode 1032.000000, reward total was -21.000000. running mean: -19.980221\n","resetting env. episode 1033.000000, reward total was -20.000000. running mean: -19.980419\n","resetting env. episode 1034.000000, reward total was -21.000000. running mean: -19.990614\n","resetting env. episode 1035.000000, reward total was -19.000000. running mean: -19.980708\n","resetting env. episode 1036.000000, reward total was -15.000000. running mean: -19.930901\n","resetting env. episode 1037.000000, reward total was -21.000000. running mean: -19.941592\n","resetting env. episode 1038.000000, reward total was -20.000000. running mean: -19.942176\n","resetting env. episode 1039.000000, reward total was -20.000000. running mean: -19.942754\n","resetting env. episode 1040.000000, reward total was -21.000000. running mean: -19.953327\n","resetting env. episode 1041.000000, reward total was -17.000000. running mean: -19.923794\n","resetting env. episode 1042.000000, reward total was -21.000000. running mean: -19.934556\n","resetting env. episode 1043.000000, reward total was -20.000000. running mean: -19.935210\n","resetting env. episode 1044.000000, reward total was -21.000000. running mean: -19.945858\n","resetting env. episode 1045.000000, reward total was -19.000000. running mean: -19.936399\n","resetting env. episode 1046.000000, reward total was -21.000000. running mean: -19.947035\n","resetting env. episode 1047.000000, reward total was -19.000000. running mean: -19.937565\n","resetting env. episode 1048.000000, reward total was -21.000000. running mean: -19.948189\n","resetting env. episode 1049.000000, reward total was -21.000000. running mean: -19.958708\n","resetting env. episode 1050.000000, reward total was -19.000000. running mean: -19.949120\n","resetting env. episode 1051.000000, reward total was -20.000000. running mean: -19.949629\n","resetting env. episode 1052.000000, reward total was -20.000000. running mean: -19.950133\n","resetting env. episode 1053.000000, reward total was -21.000000. running mean: -19.960632\n","resetting env. episode 1054.000000, reward total was -19.000000. running mean: -19.951025\n","resetting env. episode 1055.000000, reward total was -20.000000. running mean: -19.951515\n","resetting env. episode 1056.000000, reward total was -21.000000. running mean: -19.962000\n","resetting env. episode 1057.000000, reward total was -20.000000. running mean: -19.962380\n","resetting env. episode 1058.000000, reward total was -19.000000. running mean: -19.952756\n","resetting env. episode 1059.000000, reward total was -19.000000. running mean: -19.943229\n","resetting env. episode 1060.000000, reward total was -20.000000. running mean: -19.943796\n","resetting env. episode 1061.000000, reward total was -20.000000. running mean: -19.944358\n","resetting env. episode 1062.000000, reward total was -19.000000. running mean: -19.934915\n","resetting env. episode 1063.000000, reward total was -21.000000. running mean: -19.945566\n","resetting env. episode 1064.000000, reward total was -19.000000. running mean: -19.936110\n","resetting env. episode 1065.000000, reward total was -19.000000. running mean: -19.926749\n","resetting env. episode 1066.000000, reward total was -20.000000. running mean: -19.927481\n","resetting env. episode 1067.000000, reward total was -20.000000. running mean: -19.928207\n","resetting env. episode 1068.000000, reward total was -21.000000. running mean: -19.938924\n","resetting env. episode 1069.000000, reward total was -19.000000. running mean: -19.929535\n","resetting env. episode 1070.000000, reward total was -18.000000. running mean: -19.910240\n","resetting env. episode 1071.000000, reward total was -20.000000. running mean: -19.911137\n","resetting env. episode 1072.000000, reward total was -20.000000. running mean: -19.912026\n","resetting env. episode 1073.000000, reward total was -19.000000. running mean: -19.902906\n","resetting env. episode 1074.000000, reward total was -20.000000. running mean: -19.903877\n","resetting env. episode 1075.000000, reward total was -21.000000. running mean: -19.914838\n","resetting env. episode 1076.000000, reward total was -20.000000. running mean: -19.915690\n","resetting env. episode 1077.000000, reward total was -21.000000. running mean: -19.926533\n","resetting env. episode 1078.000000, reward total was -21.000000. running mean: -19.937267\n","resetting env. episode 1079.000000, reward total was -21.000000. running mean: -19.947895\n","resetting env. episode 1080.000000, reward total was -21.000000. running mean: -19.958416\n","resetting env. episode 1081.000000, reward total was -21.000000. running mean: -19.968832\n","resetting env. episode 1082.000000, reward total was -19.000000. running mean: -19.959143\n","resetting env. episode 1083.000000, reward total was -20.000000. running mean: -19.959552\n","resetting env. episode 1084.000000, reward total was -20.000000. running mean: -19.959956\n","resetting env. episode 1085.000000, reward total was -20.000000. running mean: -19.960357\n","resetting env. episode 1086.000000, reward total was -18.000000. running mean: -19.940753\n","resetting env. episode 1087.000000, reward total was -21.000000. running mean: -19.951346\n","resetting env. episode 1088.000000, reward total was -21.000000. running mean: -19.961832\n","resetting env. episode 1089.000000, reward total was -19.000000. running mean: -19.952214\n","resetting env. episode 1090.000000, reward total was -18.000000. running mean: -19.932692\n","resetting env. episode 1091.000000, reward total was -20.000000. running mean: -19.933365\n","resetting env. episode 1092.000000, reward total was -21.000000. running mean: -19.944031\n","resetting env. episode 1093.000000, reward total was -21.000000. running mean: -19.954591\n","resetting env. episode 1094.000000, reward total was -21.000000. running mean: -19.965045\n","resetting env. episode 1095.000000, reward total was -20.000000. running mean: -19.965395\n","resetting env. episode 1096.000000, reward total was -20.000000. running mean: -19.965741\n","resetting env. episode 1097.000000, reward total was -19.000000. running mean: -19.956083\n","resetting env. episode 1098.000000, reward total was -20.000000. running mean: -19.956522\n","resetting env. episode 1099.000000, reward total was -20.000000. running mean: -19.956957\n","resetting env. episode 1100.000000, reward total was -20.000000. running mean: -19.957388\n","resetting env. episode 1101.000000, reward total was -20.000000. running mean: -19.957814\n","resetting env. episode 1102.000000, reward total was -21.000000. running mean: -19.968236\n","resetting env. episode 1103.000000, reward total was -20.000000. running mean: -19.968553\n","resetting env. episode 1104.000000, reward total was -20.000000. running mean: -19.968868\n","resetting env. episode 1105.000000, reward total was -21.000000. running mean: -19.979179\n","resetting env. episode 1106.000000, reward total was -21.000000. running mean: -19.989387\n","resetting env. episode 1107.000000, reward total was -20.000000. running mean: -19.989493\n","resetting env. episode 1108.000000, reward total was -19.000000. running mean: -19.979598\n","resetting env. episode 1109.000000, reward total was -19.000000. running mean: -19.969802\n","resetting env. episode 1110.000000, reward total was -20.000000. running mean: -19.970104\n","resetting env. episode 1111.000000, reward total was -18.000000. running mean: -19.950403\n","resetting env. episode 1112.000000, reward total was -20.000000. running mean: -19.950899\n","resetting env. episode 1113.000000, reward total was -20.000000. running mean: -19.951390\n","resetting env. episode 1114.000000, reward total was -20.000000. running mean: -19.951876\n","resetting env. episode 1115.000000, reward total was -21.000000. running mean: -19.962358\n","resetting env. episode 1116.000000, reward total was -20.000000. running mean: -19.962734\n","resetting env. episode 1117.000000, reward total was -20.000000. running mean: -19.963107\n","resetting env. episode 1118.000000, reward total was -19.000000. running mean: -19.953476\n","resetting env. episode 1119.000000, reward total was -21.000000. running mean: -19.963941\n","resetting env. episode 1120.000000, reward total was -20.000000. running mean: -19.964301\n","resetting env. episode 1121.000000, reward total was -20.000000. running mean: -19.964658\n","resetting env. episode 1122.000000, reward total was -18.000000. running mean: -19.945012\n","resetting env. episode 1123.000000, reward total was -20.000000. running mean: -19.945562\n","resetting env. episode 1124.000000, reward total was -21.000000. running mean: -19.956106\n","resetting env. episode 1125.000000, reward total was -21.000000. running mean: -19.966545\n","resetting env. episode 1126.000000, reward total was -18.000000. running mean: -19.946880\n","resetting env. episode 1127.000000, reward total was -21.000000. running mean: -19.957411\n","resetting env. episode 1128.000000, reward total was -21.000000. running mean: -19.967837\n","resetting env. episode 1129.000000, reward total was -20.000000. running mean: -19.968158\n","resetting env. episode 1130.000000, reward total was -21.000000. running mean: -19.978477\n","resetting env. episode 1131.000000, reward total was -21.000000. running mean: -19.988692\n","resetting env. episode 1132.000000, reward total was -21.000000. running mean: -19.998805\n","resetting env. episode 1133.000000, reward total was -20.000000. running mean: -19.998817\n","resetting env. episode 1134.000000, reward total was -19.000000. running mean: -19.988829\n","resetting env. episode 1135.000000, reward total was -21.000000. running mean: -19.998941\n","resetting env. episode 1136.000000, reward total was -21.000000. running mean: -20.008951\n","resetting env. episode 1137.000000, reward total was -18.000000. running mean: -19.988862\n","resetting env. episode 1138.000000, reward total was -21.000000. running mean: -19.998973\n","resetting env. episode 1139.000000, reward total was -20.000000. running mean: -19.998983\n","resetting env. episode 1140.000000, reward total was -19.000000. running mean: -19.988993\n","resetting env. episode 1141.000000, reward total was -19.000000. running mean: -19.979104\n","resetting env. episode 1142.000000, reward total was -21.000000. running mean: -19.989313\n","resetting env. episode 1143.000000, reward total was -20.000000. running mean: -19.989419\n","resetting env. episode 1144.000000, reward total was -19.000000. running mean: -19.979525\n","resetting env. episode 1145.000000, reward total was -21.000000. running mean: -19.989730\n","resetting env. episode 1146.000000, reward total was -21.000000. running mean: -19.999833\n","resetting env. episode 1147.000000, reward total was -21.000000. running mean: -20.009834\n","resetting env. episode 1148.000000, reward total was -21.000000. running mean: -20.019736\n","resetting env. episode 1149.000000, reward total was -18.000000. running mean: -19.999539\n","resetting env. episode 1150.000000, reward total was -19.000000. running mean: -19.989543\n","resetting env. episode 1151.000000, reward total was -20.000000. running mean: -19.989648\n","resetting env. episode 1152.000000, reward total was -19.000000. running mean: -19.979751\n","resetting env. episode 1153.000000, reward total was -19.000000. running mean: -19.969954\n","resetting env. episode 1154.000000, reward total was -20.000000. running mean: -19.970254\n","resetting env. episode 1155.000000, reward total was -20.000000. running mean: -19.970552\n","resetting env. episode 1156.000000, reward total was -20.000000. running mean: -19.970846\n","resetting env. episode 1157.000000, reward total was -21.000000. running mean: -19.981138\n","resetting env. episode 1158.000000, reward total was -21.000000. running mean: -19.991326\n","resetting env. episode 1159.000000, reward total was -21.000000. running mean: -20.001413\n","resetting env. episode 1160.000000, reward total was -21.000000. running mean: -20.011399\n","resetting env. episode 1161.000000, reward total was -21.000000. running mean: -20.021285\n","resetting env. episode 1162.000000, reward total was -21.000000. running mean: -20.031072\n","resetting env. episode 1163.000000, reward total was -21.000000. running mean: -20.040761\n","resetting env. episode 1164.000000, reward total was -20.000000. running mean: -20.040354\n","resetting env. episode 1165.000000, reward total was -20.000000. running mean: -20.039950\n","resetting env. episode 1166.000000, reward total was -19.000000. running mean: -20.029551\n","resetting env. episode 1167.000000, reward total was -21.000000. running mean: -20.039255\n","resetting env. episode 1168.000000, reward total was -17.000000. running mean: -20.008863\n","resetting env. episode 1169.000000, reward total was -20.000000. running mean: -20.008774\n","resetting env. episode 1170.000000, reward total was -20.000000. running mean: -20.008686\n","resetting env. episode 1171.000000, reward total was -21.000000. running mean: -20.018599\n","resetting env. episode 1172.000000, reward total was -17.000000. running mean: -19.988413\n","resetting env. episode 1173.000000, reward total was -18.000000. running mean: -19.968529\n","resetting env. episode 1174.000000, reward total was -21.000000. running mean: -19.978844\n","resetting env. episode 1175.000000, reward total was -21.000000. running mean: -19.989056\n","resetting env. episode 1176.000000, reward total was -21.000000. running mean: -19.999165\n","resetting env. episode 1177.000000, reward total was -17.000000. running mean: -19.969173\n","resetting env. episode 1178.000000, reward total was -19.000000. running mean: -19.959482\n","resetting env. episode 1179.000000, reward total was -20.000000. running mean: -19.959887\n","resetting env. episode 1180.000000, reward total was -20.000000. running mean: -19.960288\n","resetting env. episode 1181.000000, reward total was -21.000000. running mean: -19.970685\n","resetting env. episode 1182.000000, reward total was -20.000000. running mean: -19.970978\n","resetting env. episode 1183.000000, reward total was -19.000000. running mean: -19.961268\n","resetting env. episode 1184.000000, reward total was -19.000000. running mean: -19.951656\n","resetting env. episode 1185.000000, reward total was -21.000000. running mean: -19.962139\n","resetting env. episode 1186.000000, reward total was -21.000000. running mean: -19.972518\n","resetting env. episode 1187.000000, reward total was -20.000000. running mean: -19.972793\n","resetting env. episode 1188.000000, reward total was -21.000000. running mean: -19.983065\n","resetting env. episode 1189.000000, reward total was -21.000000. running mean: -19.993234\n","resetting env. episode 1190.000000, reward total was -21.000000. running mean: -20.003302\n","resetting env. episode 1191.000000, reward total was -21.000000. running mean: -20.013269\n","resetting env. episode 1192.000000, reward total was -16.000000. running mean: -19.973136\n","resetting env. episode 1193.000000, reward total was -20.000000. running mean: -19.973405\n","resetting env. episode 1194.000000, reward total was -21.000000. running mean: -19.983671\n","resetting env. episode 1195.000000, reward total was -20.000000. running mean: -19.983834\n","resetting env. episode 1196.000000, reward total was -21.000000. running mean: -19.993996\n","resetting env. episode 1197.000000, reward total was -21.000000. running mean: -20.004056\n","resetting env. episode 1198.000000, reward total was -20.000000. running mean: -20.004015\n","resetting env. episode 1199.000000, reward total was -19.000000. running mean: -19.993975\n","resetting env. episode 1200.000000, reward total was -21.000000. running mean: -20.004035\n","resetting env. episode 1201.000000, reward total was -19.000000. running mean: -19.993995\n","resetting env. episode 1202.000000, reward total was -20.000000. running mean: -19.994055\n","resetting env. episode 1203.000000, reward total was -21.000000. running mean: -20.004114\n","resetting env. episode 1204.000000, reward total was -19.000000. running mean: -19.994073\n","resetting env. episode 1205.000000, reward total was -20.000000. running mean: -19.994132\n","resetting env. episode 1206.000000, reward total was -21.000000. running mean: -20.004191\n","resetting env. episode 1207.000000, reward total was -19.000000. running mean: -19.994149\n","resetting env. episode 1208.000000, reward total was -20.000000. running mean: -19.994208\n","resetting env. episode 1209.000000, reward total was -21.000000. running mean: -20.004266\n","resetting env. episode 1210.000000, reward total was -21.000000. running mean: -20.014223\n","resetting env. episode 1211.000000, reward total was -21.000000. running mean: -20.024081\n","resetting env. episode 1212.000000, reward total was -21.000000. running mean: -20.033840\n","resetting env. episode 1213.000000, reward total was -20.000000. running mean: -20.033502\n","resetting env. episode 1214.000000, reward total was -20.000000. running mean: -20.033167\n","resetting env. episode 1215.000000, reward total was -21.000000. running mean: -20.042835\n","resetting env. episode 1216.000000, reward total was -21.000000. running mean: -20.052407\n","resetting env. episode 1217.000000, reward total was -18.000000. running mean: -20.031882\n","resetting env. episode 1218.000000, reward total was -19.000000. running mean: -20.021564\n","resetting env. episode 1219.000000, reward total was -21.000000. running mean: -20.031348\n","resetting env. episode 1220.000000, reward total was -17.000000. running mean: -20.001035\n","resetting env. episode 1221.000000, reward total was -21.000000. running mean: -20.011024\n","resetting env. episode 1222.000000, reward total was -20.000000. running mean: -20.010914\n","resetting env. episode 1223.000000, reward total was -19.000000. running mean: -20.000805\n","resetting env. episode 1224.000000, reward total was -19.000000. running mean: -19.990797\n","resetting env. episode 1225.000000, reward total was -19.000000. running mean: -19.980889\n","resetting env. episode 1226.000000, reward total was -20.000000. running mean: -19.981080\n","resetting env. episode 1227.000000, reward total was -19.000000. running mean: -19.971269\n","resetting env. episode 1228.000000, reward total was -21.000000. running mean: -19.981556\n","resetting env. episode 1229.000000, reward total was -20.000000. running mean: -19.981741\n","resetting env. episode 1230.000000, reward total was -21.000000. running mean: -19.991923\n","resetting env. episode 1231.000000, reward total was -18.000000. running mean: -19.972004\n","resetting env. episode 1232.000000, reward total was -19.000000. running mean: -19.962284\n","resetting env. episode 1233.000000, reward total was -21.000000. running mean: -19.972661\n","resetting env. episode 1234.000000, reward total was -19.000000. running mean: -19.962935\n","resetting env. episode 1235.000000, reward total was -21.000000. running mean: -19.973305\n","resetting env. episode 1236.000000, reward total was -20.000000. running mean: -19.973572\n","resetting env. episode 1237.000000, reward total was -19.000000. running mean: -19.963837\n","resetting env. episode 1238.000000, reward total was -20.000000. running mean: -19.964198\n","resetting env. episode 1239.000000, reward total was -16.000000. running mean: -19.924556\n","resetting env. episode 1240.000000, reward total was -19.000000. running mean: -19.915311\n","resetting env. episode 1241.000000, reward total was -21.000000. running mean: -19.926158\n","resetting env. episode 1242.000000, reward total was -21.000000. running mean: -19.936896\n","resetting env. episode 1243.000000, reward total was -21.000000. running mean: -19.947527\n","resetting env. episode 1244.000000, reward total was -19.000000. running mean: -19.938052\n","resetting env. episode 1245.000000, reward total was -18.000000. running mean: -19.918671\n","resetting env. episode 1246.000000, reward total was -20.000000. running mean: -19.919485\n","resetting env. episode 1247.000000, reward total was -21.000000. running mean: -19.930290\n","resetting env. episode 1248.000000, reward total was -20.000000. running mean: -19.930987\n","resetting env. episode 1249.000000, reward total was -21.000000. running mean: -19.941677\n","resetting env. episode 1250.000000, reward total was -20.000000. running mean: -19.942260\n","resetting env. episode 1251.000000, reward total was -21.000000. running mean: -19.952838\n","resetting env. episode 1252.000000, reward total was -21.000000. running mean: -19.963309\n","resetting env. episode 1253.000000, reward total was -18.000000. running mean: -19.943676\n","resetting env. episode 1254.000000, reward total was -19.000000. running mean: -19.934239\n","resetting env. episode 1255.000000, reward total was -21.000000. running mean: -19.944897\n","resetting env. episode 1256.000000, reward total was -21.000000. running mean: -19.955448\n","resetting env. episode 1257.000000, reward total was -21.000000. running mean: -19.965893\n","resetting env. episode 1258.000000, reward total was -21.000000. running mean: -19.976235\n","resetting env. episode 1259.000000, reward total was -20.000000. running mean: -19.976472\n","resetting env. episode 1260.000000, reward total was -20.000000. running mean: -19.976707\n","resetting env. episode 1261.000000, reward total was -18.000000. running mean: -19.956940\n","resetting env. episode 1262.000000, reward total was -20.000000. running mean: -19.957371\n","resetting env. episode 1263.000000, reward total was -19.000000. running mean: -19.947797\n","resetting env. episode 1264.000000, reward total was -20.000000. running mean: -19.948319\n","resetting env. episode 1265.000000, reward total was -19.000000. running mean: -19.938836\n","resetting env. episode 1266.000000, reward total was -21.000000. running mean: -19.949448\n","resetting env. episode 1267.000000, reward total was -20.000000. running mean: -19.949953\n","resetting env. episode 1268.000000, reward total was -20.000000. running mean: -19.950454\n","resetting env. episode 1269.000000, reward total was -21.000000. running mean: -19.960949\n","resetting env. episode 1270.000000, reward total was -19.000000. running mean: -19.951340\n","resetting env. episode 1271.000000, reward total was -18.000000. running mean: -19.931826\n","resetting env. episode 1272.000000, reward total was -21.000000. running mean: -19.942508\n","resetting env. episode 1273.000000, reward total was -19.000000. running mean: -19.933083\n","resetting env. episode 1274.000000, reward total was -20.000000. running mean: -19.933752\n","resetting env. episode 1275.000000, reward total was -20.000000. running mean: -19.934415\n","resetting env. episode 1276.000000, reward total was -17.000000. running mean: -19.905070\n","resetting env. episode 1277.000000, reward total was -21.000000. running mean: -19.916020\n","resetting env. episode 1278.000000, reward total was -20.000000. running mean: -19.916860\n","resetting env. episode 1279.000000, reward total was -18.000000. running mean: -19.897691\n","resetting env. episode 1280.000000, reward total was -19.000000. running mean: -19.888714\n","resetting env. episode 1281.000000, reward total was -15.000000. running mean: -19.839827\n","resetting env. episode 1282.000000, reward total was -20.000000. running mean: -19.841429\n","resetting env. episode 1283.000000, reward total was -19.000000. running mean: -19.833014\n","resetting env. episode 1284.000000, reward total was -19.000000. running mean: -19.824684\n","resetting env. episode 1285.000000, reward total was -20.000000. running mean: -19.826437\n","resetting env. episode 1286.000000, reward total was -20.000000. running mean: -19.828173\n","resetting env. episode 1287.000000, reward total was -19.000000. running mean: -19.819891\n","resetting env. episode 1288.000000, reward total was -20.000000. running mean: -19.821692\n","resetting env. episode 1289.000000, reward total was -20.000000. running mean: -19.823475\n","resetting env. episode 1290.000000, reward total was -21.000000. running mean: -19.835241\n","resetting env. episode 1291.000000, reward total was -21.000000. running mean: -19.846888\n","resetting env. episode 1292.000000, reward total was -19.000000. running mean: -19.838419\n","resetting env. episode 1293.000000, reward total was -19.000000. running mean: -19.830035\n","resetting env. episode 1294.000000, reward total was -20.000000. running mean: -19.831735\n","resetting env. episode 1295.000000, reward total was -18.000000. running mean: -19.813418\n","resetting env. episode 1296.000000, reward total was -21.000000. running mean: -19.825283\n","resetting env. episode 1297.000000, reward total was -20.000000. running mean: -19.827030\n","resetting env. episode 1298.000000, reward total was -21.000000. running mean: -19.838760\n","resetting env. episode 1299.000000, reward total was -21.000000. running mean: -19.850373\n","resetting env. episode 1300.000000, reward total was -21.000000. running mean: -19.861869\n","resetting env. episode 1301.000000, reward total was -19.000000. running mean: -19.853250\n","resetting env. episode 1302.000000, reward total was -19.000000. running mean: -19.844718\n","resetting env. episode 1303.000000, reward total was -19.000000. running mean: -19.836270\n","resetting env. episode 1304.000000, reward total was -20.000000. running mean: -19.837908\n","resetting env. episode 1305.000000, reward total was -21.000000. running mean: -19.849529\n","resetting env. episode 1306.000000, reward total was -19.000000. running mean: -19.841033\n","resetting env. episode 1307.000000, reward total was -21.000000. running mean: -19.852623\n","resetting env. episode 1308.000000, reward total was -21.000000. running mean: -19.864097\n","resetting env. episode 1309.000000, reward total was -21.000000. running mean: -19.875456\n","resetting env. episode 1310.000000, reward total was -20.000000. running mean: -19.876701\n","resetting env. episode 1311.000000, reward total was -21.000000. running mean: -19.887934\n","resetting env. episode 1312.000000, reward total was -17.000000. running mean: -19.859055\n","resetting env. episode 1313.000000, reward total was -18.000000. running mean: -19.840464\n","resetting env. episode 1314.000000, reward total was -20.000000. running mean: -19.842060\n","resetting env. episode 1315.000000, reward total was -19.000000. running mean: -19.833639\n","resetting env. episode 1316.000000, reward total was -21.000000. running mean: -19.845303\n","resetting env. episode 1317.000000, reward total was -19.000000. running mean: -19.836850\n","resetting env. episode 1318.000000, reward total was -21.000000. running mean: -19.848481\n","resetting env. episode 1319.000000, reward total was -21.000000. running mean: -19.859996\n","resetting env. episode 1320.000000, reward total was -19.000000. running mean: -19.851396\n","resetting env. episode 1321.000000, reward total was -21.000000. running mean: -19.862883\n","resetting env. episode 1322.000000, reward total was -20.000000. running mean: -19.864254\n","resetting env. episode 1323.000000, reward total was -21.000000. running mean: -19.875611\n","resetting env. episode 1324.000000, reward total was -21.000000. running mean: -19.886855\n","resetting env. episode 1325.000000, reward total was -21.000000. running mean: -19.897987\n","resetting env. episode 1326.000000, reward total was -21.000000. running mean: -19.909007\n","resetting env. episode 1327.000000, reward total was -19.000000. running mean: -19.899917\n","resetting env. episode 1328.000000, reward total was -17.000000. running mean: -19.870917\n","resetting env. episode 1329.000000, reward total was -20.000000. running mean: -19.872208\n","resetting env. episode 1330.000000, reward total was -20.000000. running mean: -19.873486\n","resetting env. episode 1331.000000, reward total was -21.000000. running mean: -19.884751\n","resetting env. episode 1332.000000, reward total was -20.000000. running mean: -19.885904\n","resetting env. episode 1333.000000, reward total was -21.000000. running mean: -19.897045\n","resetting env. episode 1334.000000, reward total was -20.000000. running mean: -19.898074\n","resetting env. episode 1335.000000, reward total was -17.000000. running mean: -19.869094\n","resetting env. episode 1336.000000, reward total was -18.000000. running mean: -19.850403\n","resetting env. episode 1337.000000, reward total was -20.000000. running mean: -19.851899\n","resetting env. episode 1338.000000, reward total was -20.000000. running mean: -19.853380\n","resetting env. episode 1339.000000, reward total was -19.000000. running mean: -19.844846\n","resetting env. episode 1340.000000, reward total was -20.000000. running mean: -19.846397\n","resetting env. episode 1341.000000, reward total was -18.000000. running mean: -19.827933\n","resetting env. episode 1342.000000, reward total was -21.000000. running mean: -19.839654\n","resetting env. episode 1343.000000, reward total was -21.000000. running mean: -19.851257\n","resetting env. episode 1344.000000, reward total was -21.000000. running mean: -19.862745\n","resetting env. episode 1345.000000, reward total was -21.000000. running mean: -19.874117\n","resetting env. episode 1346.000000, reward total was -20.000000. running mean: -19.875376\n","resetting env. episode 1347.000000, reward total was -20.000000. running mean: -19.876623\n","resetting env. episode 1348.000000, reward total was -20.000000. running mean: -19.877856\n","resetting env. episode 1349.000000, reward total was -21.000000. running mean: -19.889078\n","resetting env. episode 1350.000000, reward total was -19.000000. running mean: -19.880187\n","resetting env. episode 1351.000000, reward total was -21.000000. running mean: -19.891385\n","resetting env. episode 1352.000000, reward total was -21.000000. running mean: -19.902471\n","resetting env. episode 1353.000000, reward total was -21.000000. running mean: -19.913447\n","resetting env. episode 1354.000000, reward total was -17.000000. running mean: -19.884312\n","resetting env. episode 1355.000000, reward total was -20.000000. running mean: -19.885469\n","resetting env. episode 1356.000000, reward total was -21.000000. running mean: -19.896614\n","resetting env. episode 1357.000000, reward total was -20.000000. running mean: -19.897648\n","resetting env. episode 1358.000000, reward total was -20.000000. running mean: -19.898672\n","resetting env. episode 1359.000000, reward total was -19.000000. running mean: -19.889685\n","resetting env. episode 1360.000000, reward total was -21.000000. running mean: -19.900788\n","resetting env. episode 1361.000000, reward total was -19.000000. running mean: -19.891780\n","resetting env. episode 1362.000000, reward total was -21.000000. running mean: -19.902862\n","resetting env. episode 1363.000000, reward total was -20.000000. running mean: -19.903834\n","resetting env. episode 1364.000000, reward total was -21.000000. running mean: -19.914795\n","resetting env. episode 1365.000000, reward total was -19.000000. running mean: -19.905647\n","resetting env. episode 1366.000000, reward total was -21.000000. running mean: -19.916591\n","resetting env. episode 1367.000000, reward total was -19.000000. running mean: -19.907425\n","resetting env. episode 1368.000000, reward total was -21.000000. running mean: -19.918351\n","resetting env. episode 1369.000000, reward total was -20.000000. running mean: -19.919167\n","resetting env. episode 1370.000000, reward total was -21.000000. running mean: -19.929976\n","resetting env. episode 1371.000000, reward total was -20.000000. running mean: -19.930676\n","resetting env. episode 1372.000000, reward total was -19.000000. running mean: -19.921369\n","resetting env. episode 1373.000000, reward total was -18.000000. running mean: -19.902155\n","resetting env. episode 1374.000000, reward total was -19.000000. running mean: -19.893134\n","resetting env. episode 1375.000000, reward total was -19.000000. running mean: -19.884203\n","resetting env. episode 1376.000000, reward total was -19.000000. running mean: -19.875361\n","resetting env. episode 1377.000000, reward total was -21.000000. running mean: -19.886607\n","resetting env. episode 1378.000000, reward total was -20.000000. running mean: -19.887741\n","resetting env. episode 1379.000000, reward total was -20.000000. running mean: -19.888863\n","resetting env. episode 1380.000000, reward total was -21.000000. running mean: -19.899975\n","resetting env. episode 1381.000000, reward total was -21.000000. running mean: -19.910975\n","resetting env. episode 1382.000000, reward total was -21.000000. running mean: -19.921865\n","resetting env. episode 1383.000000, reward total was -19.000000. running mean: -19.912647\n","resetting env. episode 1384.000000, reward total was -21.000000. running mean: -19.923520\n","resetting env. episode 1385.000000, reward total was -20.000000. running mean: -19.924285\n","resetting env. episode 1386.000000, reward total was -18.000000. running mean: -19.905042\n","resetting env. episode 1387.000000, reward total was -20.000000. running mean: -19.905992\n","resetting env. episode 1388.000000, reward total was -19.000000. running mean: -19.896932\n","resetting env. episode 1389.000000, reward total was -20.000000. running mean: -19.897962\n","resetting env. episode 1390.000000, reward total was -20.000000. running mean: -19.898983\n","resetting env. episode 1391.000000, reward total was -21.000000. running mean: -19.909993\n","resetting env. episode 1392.000000, reward total was -20.000000. running mean: -19.910893\n","resetting env. episode 1393.000000, reward total was -20.000000. running mean: -19.911784\n","resetting env. episode 1394.000000, reward total was -20.000000. running mean: -19.912666\n","resetting env. episode 1395.000000, reward total was -20.000000. running mean: -19.913540\n","resetting env. episode 1396.000000, reward total was -21.000000. running mean: -19.924404\n","resetting env. episode 1397.000000, reward total was -21.000000. running mean: -19.935160\n","resetting env. episode 1398.000000, reward total was -20.000000. running mean: -19.935809\n","resetting env. episode 1399.000000, reward total was -21.000000. running mean: -19.946451\n","resetting env. episode 1400.000000, reward total was -21.000000. running mean: -19.956986\n","resetting env. episode 1401.000000, reward total was -20.000000. running mean: -19.957416\n","resetting env. episode 1402.000000, reward total was -19.000000. running mean: -19.947842\n","resetting env. episode 1403.000000, reward total was -17.000000. running mean: -19.918364\n","resetting env. episode 1404.000000, reward total was -20.000000. running mean: -19.919180\n","resetting env. episode 1405.000000, reward total was -20.000000. running mean: -19.919988\n","resetting env. episode 1406.000000, reward total was -19.000000. running mean: -19.910788\n","resetting env. episode 1407.000000, reward total was -20.000000. running mean: -19.911680\n","resetting env. episode 1408.000000, reward total was -19.000000. running mean: -19.902564\n","resetting env. episode 1409.000000, reward total was -17.000000. running mean: -19.873538\n","resetting env. episode 1410.000000, reward total was -21.000000. running mean: -19.884803\n","resetting env. episode 1411.000000, reward total was -19.000000. running mean: -19.875955\n","resetting env. episode 1412.000000, reward total was -20.000000. running mean: -19.877195\n","resetting env. episode 1413.000000, reward total was -20.000000. running mean: -19.878423\n","resetting env. episode 1414.000000, reward total was -19.000000. running mean: -19.869639\n","resetting env. episode 1415.000000, reward total was -20.000000. running mean: -19.870942\n","resetting env. episode 1416.000000, reward total was -20.000000. running mean: -19.872233\n","resetting env. episode 1417.000000, reward total was -21.000000. running mean: -19.883511\n","resetting env. episode 1418.000000, reward total was -21.000000. running mean: -19.894676\n","resetting env. episode 1419.000000, reward total was -19.000000. running mean: -19.885729\n","resetting env. episode 1420.000000, reward total was -20.000000. running mean: -19.886872\n","resetting env. episode 1421.000000, reward total was -18.000000. running mean: -19.868003\n","resetting env. episode 1422.000000, reward total was -21.000000. running mean: -19.879323\n","resetting env. episode 1423.000000, reward total was -21.000000. running mean: -19.890530\n","resetting env. episode 1424.000000, reward total was -20.000000. running mean: -19.891624\n","resetting env. episode 1425.000000, reward total was -19.000000. running mean: -19.882708\n","resetting env. episode 1426.000000, reward total was -21.000000. running mean: -19.893881\n","resetting env. episode 1427.000000, reward total was -20.000000. running mean: -19.894942\n","resetting env. episode 1428.000000, reward total was -19.000000. running mean: -19.885993\n","resetting env. episode 1429.000000, reward total was -19.000000. running mean: -19.877133\n","resetting env. episode 1430.000000, reward total was -20.000000. running mean: -19.878361\n","resetting env. episode 1431.000000, reward total was -20.000000. running mean: -19.879578\n","resetting env. episode 1432.000000, reward total was -21.000000. running mean: -19.890782\n","resetting env. episode 1433.000000, reward total was -20.000000. running mean: -19.891874\n","resetting env. episode 1434.000000, reward total was -19.000000. running mean: -19.882955\n","resetting env. episode 1435.000000, reward total was -20.000000. running mean: -19.884126\n","resetting env. episode 1436.000000, reward total was -19.000000. running mean: -19.875285\n","resetting env. episode 1437.000000, reward total was -18.000000. running mean: -19.856532\n","resetting env. episode 1438.000000, reward total was -18.000000. running mean: -19.837967\n","resetting env. episode 1439.000000, reward total was -19.000000. running mean: -19.829587\n","resetting env. episode 1440.000000, reward total was -20.000000. running mean: -19.831291\n","resetting env. episode 1441.000000, reward total was -20.000000. running mean: -19.832978\n","resetting env. episode 1442.000000, reward total was -20.000000. running mean: -19.834648\n","resetting env. episode 1443.000000, reward total was -19.000000. running mean: -19.826302\n","resetting env. episode 1444.000000, reward total was -19.000000. running mean: -19.818039\n","resetting env. episode 1445.000000, reward total was -20.000000. running mean: -19.819858\n","resetting env. episode 1446.000000, reward total was -19.000000. running mean: -19.811660\n","resetting env. episode 1447.000000, reward total was -19.000000. running mean: -19.803543\n","resetting env. episode 1448.000000, reward total was -21.000000. running mean: -19.815508\n","resetting env. episode 1449.000000, reward total was -18.000000. running mean: -19.797353\n","resetting env. episode 1450.000000, reward total was -20.000000. running mean: -19.799379\n","resetting env. episode 1451.000000, reward total was -19.000000. running mean: -19.791385\n","resetting env. episode 1452.000000, reward total was -18.000000. running mean: -19.773472\n","resetting env. episode 1453.000000, reward total was -21.000000. running mean: -19.785737\n","resetting env. episode 1454.000000, reward total was -18.000000. running mean: -19.767879\n","resetting env. episode 1455.000000, reward total was -20.000000. running mean: -19.770201\n","resetting env. episode 1456.000000, reward total was -20.000000. running mean: -19.772499\n","resetting env. episode 1457.000000, reward total was -19.000000. running mean: -19.764774\n","resetting env. episode 1458.000000, reward total was -19.000000. running mean: -19.757126\n","resetting env. episode 1459.000000, reward total was -19.000000. running mean: -19.749555\n","resetting env. episode 1460.000000, reward total was -21.000000. running mean: -19.762059\n","resetting env. episode 1461.000000, reward total was -21.000000. running mean: -19.774439\n","resetting env. episode 1462.000000, reward total was -20.000000. running mean: -19.776694\n","resetting env. episode 1463.000000, reward total was -21.000000. running mean: -19.788927\n","resetting env. episode 1464.000000, reward total was -21.000000. running mean: -19.801038\n","resetting env. episode 1465.000000, reward total was -20.000000. running mean: -19.803028\n","resetting env. episode 1466.000000, reward total was -21.000000. running mean: -19.814997\n","resetting env. episode 1467.000000, reward total was -20.000000. running mean: -19.816847\n","resetting env. episode 1468.000000, reward total was -21.000000. running mean: -19.828679\n","resetting env. episode 1469.000000, reward total was -21.000000. running mean: -19.840392\n","resetting env. episode 1470.000000, reward total was -19.000000. running mean: -19.831988\n","resetting env. episode 1471.000000, reward total was -21.000000. running mean: -19.843668\n","resetting env. episode 1472.000000, reward total was -21.000000. running mean: -19.855232\n","resetting env. episode 1473.000000, reward total was -21.000000. running mean: -19.866679\n","resetting env. episode 1474.000000, reward total was -20.000000. running mean: -19.868012\n","resetting env. episode 1475.000000, reward total was -21.000000. running mean: -19.879332\n","resetting env. episode 1476.000000, reward total was -21.000000. running mean: -19.890539\n","resetting env. episode 1477.000000, reward total was -20.000000. running mean: -19.891634\n","resetting env. episode 1478.000000, reward total was -21.000000. running mean: -19.902717\n","resetting env. episode 1479.000000, reward total was -17.000000. running mean: -19.873690\n","resetting env. episode 1480.000000, reward total was -21.000000. running mean: -19.884953\n","resetting env. episode 1481.000000, reward total was -18.000000. running mean: -19.866104\n","resetting env. episode 1482.000000, reward total was -21.000000. running mean: -19.877443\n","resetting env. episode 1483.000000, reward total was -20.000000. running mean: -19.878668\n","resetting env. episode 1484.000000, reward total was -20.000000. running mean: -19.879882\n","resetting env. episode 1485.000000, reward total was -21.000000. running mean: -19.891083\n","resetting env. episode 1486.000000, reward total was -19.000000. running mean: -19.882172\n","resetting env. episode 1487.000000, reward total was -18.000000. running mean: -19.863350\n","resetting env. episode 1488.000000, reward total was -21.000000. running mean: -19.874717\n","resetting env. episode 1489.000000, reward total was -17.000000. running mean: -19.845969\n","resetting env. episode 1490.000000, reward total was -19.000000. running mean: -19.837510\n","resetting env. episode 1491.000000, reward total was -21.000000. running mean: -19.849135\n","resetting env. episode 1492.000000, reward total was -20.000000. running mean: -19.850643\n","resetting env. episode 1493.000000, reward total was -19.000000. running mean: -19.842137\n","resetting env. episode 1494.000000, reward total was -20.000000. running mean: -19.843716\n","resetting env. episode 1495.000000, reward total was -20.000000. running mean: -19.845278\n","resetting env. episode 1496.000000, reward total was -21.000000. running mean: -19.856826\n","resetting env. episode 1497.000000, reward total was -18.000000. running mean: -19.838257\n","resetting env. episode 1498.000000, reward total was -20.000000. running mean: -19.839875\n","resetting env. episode 1499.000000, reward total was -19.000000. running mean: -19.831476\n","resetting env. episode 1500.000000, reward total was -21.000000. running mean: -19.843161\n","CPU times: user 2h 39min 4s, sys: 37min 51s, total: 3h 16min 55s\n","Wall time: 1h 40min 46s\n"]}]},{"metadata":{"id":"w2NblmwDsL3y","outputId":"1be27fa3-b655-47e9-cca2-7ba1b4ea6124","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"ok","timestamp":1660652716768,"user_tz":-330,"elapsed":34278,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -6.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}