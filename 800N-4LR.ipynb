{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":3631,"status":"ok","timestamp":1660674105053,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"cWACPRL869I4"},"outputs":[],"source":["!pip install gym >/dev/null"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4823,"status":"ok","timestamp":1660674109870,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"2Os6feRY6ec_"},"outputs":[],"source":["!pip install JSAnimation >/dev/null"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1660674109870,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"wotUOa_e6edP"},"outputs":[],"source":["%matplotlib inline\n","from JSAnimation.IPython_display import display_animation\n","from matplotlib import animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","\n","def display_frames_as_gif(frames):\n","    \"\"\"\n","    Displays a list of frames as a gif, with controls\n","    \"\"\"\n","    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","\n","    def animate(i):\n","        patch.set_data(frames[i])\n","\n","    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n","    HTML(anim.to_jshtml())"]},{"cell_type":"markdown","metadata":{"id":"R66_INeZ9nYX"},"source":["## Step 2: Playing Pong"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":34371,"status":"ok","timestamp":1660674144233,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"8ngMhg3fB9aA","outputId":"d7585e92-7dab-415e-f341-1cceb10b3556"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 4.8 MB/s \n","\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=44482f006d1bc05935391ccafb8294b675eb0b0f1cf7d79558c72a88daafe898\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"]}],"source":["%pip install -U gym>=0.21.0\n","%pip install -U gym[atari,accept-rom-license]"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1148,"status":"ok","timestamp":1660674145363,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"MtT2GyK_6edc","outputId":"5896fa80-8073-4b8b-87c8-cb9a838d29ea"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  f\"The environment {id} is out of date. You should consider \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}],"source":["import gym\n","env = gym.make('Pong-v0')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1660674145364,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"oRE6WmXQJ1Z0","outputId":"6e72bb96-008a-4c59-dc54-a6862ef50d4c"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(6)"]},"metadata":{},"execution_count":6}],"source":["env.action_space"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1660674145364,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"yl_9d4HFJ31W","outputId":"bf6643f4-8064-4562-eb01-c83048b5872b"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box(0, 255, (210, 160, 3), uint8)"]},"metadata":{},"execution_count":7}],"source":["env.observation_space"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":686,"status":"ok","timestamp":1660674146040,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"trwRXI-h6eeI","outputId":"764e41ee-4c6d-484a-bd5e-a5ecea412787"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -17.0\n"]}],"source":["# Run a demo of the environment\n","observation = env.reset()\n","cumulated_reward = 0\n","\n","frames = []\n","for t in range(1000):\n","#     print(observation)\n","    frames.append(env.render(mode = 'rgb_array'))\n","    # very stupid agent, just makes a random action within the allowd action space\n","    action = env.action_space.sample()\n","#     print(\"Action: {}\".format(t+1))    \n","    observation, reward, done, info = env.step(action)\n","#     print(reward)\n","    cumulated_reward += reward\n","    if done:\n","        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","        break\n","print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","\n","env.close()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1660674146041,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"3zZTecVWLLes"},"outputs":[],"source":["def sigmoid(x): \n","  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n","\n","def prepro(I):\n","  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n","  I = I[35:195] # crop\n","  I = I[::2,::2,0] # downsample by factor of 2\n","  I[I == 144] = 0 # erase background (background type 1)\n","  I[I == 109] = 0 # erase background (background type 2)\n","  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n","  return I.astype(np.float).ravel()\n","\n","def policy_forward(x):\n","  h = np.dot(model['W1'], x)\n","  h[h<0] = 0 # ReLU nonlinearity\n","  logp = np.dot(model['W2'], h)\n","  p = sigmoid(logp)\n","  return p, h # return probability of taking action 2, and hidden state\n","\n","def model_step(model, observation, prev_x):\n","  # preprocess the observation, set input to network to be difference image\n","  cur_x = prepro(observation)\n","  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","  prev_x = cur_x\n","  \n","  # forward the policy network and sample an action from the returned probability\n","  aprob, _ = policy_forward(x)\n","  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n","  \n","  return action, prev_x\n","\n","def play_game(env, model):\n","  observation = env.reset()\n","\n","  frames = []\n","  cumulated_reward = 0\n","\n","  prev_x = None # used in computing the difference frame\n","\n","  for t in range(1000):\n","      frames.append(env.render(mode = 'rgb_array'))\n","      action, prev_x = model_step(model, observation, prev_x)\n","      observation, reward, done, info = env.step(action)\n","      cumulated_reward += reward\n","      if done:\n","          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","          break\n","  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","  display_frames_as_gif(frames)\n","  env.close()"]},{"cell_type":"markdown","metadata":{"id":"6gWvZQ7AQLQt"},"source":["## Step 3: Policy Gradient from Scratch"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":442,"status":"ok","timestamp":1660674146478,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"eqFm7hqcItWl"},"outputs":[],"source":["import numpy as np\n","\n","# model initialization\n","H = 800 # number of hidden layer neurons\n","D = 80 * 80 # input dimensionality: 80x80 grid\n","model = {}\n","model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n","model['W2'] = np.random.randn(H) / np.sqrt(H)\n","\n","# import pickle\n","# model = pickle.load(open('model.pkl', 'rb'))"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1660674146479,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"TwjiwKisQM19"},"outputs":[],"source":["# hyperparameters\n","batch_size = 10 # every how many episodes to do a param update?\n","# learning_rate = 1e-4\n","learning_rate = 1e-4\n"," \n","gamma = 0.99 # discount factor for reward\n","decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n","  \n","grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n","rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n","\n","def discount_rewards(r):\n","  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n","  discounted_r = np.zeros_like(r, dtype=np.float32)\n","  running_add = 0\n","  for t in reversed(range(0, r.size)):\n","    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n","    running_add = running_add * gamma + r[t]\n","    discounted_r[t] = running_add\n","  return discounted_r\n","\n","def policy_backward(epx, eph, epdlogp):\n","  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n","  dW2 = np.dot(eph.T, epdlogp).ravel()\n","  dh = np.outer(epdlogp, model['W2'])\n","  dh[eph <= 0] = 0 # backpro prelu\n","  dW1 = np.dot(dh.T, epx)\n","  return {'W1':dW1, 'W2':dW2}\n","\n","def train_model(env, model, total_episodes = 100):\n","  hist = []\n","  observation = env.reset()\n","\n","  prev_x = None # used in computing the difference frame\n","  xs,hs,dlogps,drs = [],[],[],[]\n","  running_reward = None\n","  reward_sum = 0\n","  episode_number = 0\n","\n","  while True:\n","    # preprocess the observation, set input to network to be difference image\n","    cur_x = prepro(observation)\n","    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","    prev_x = cur_x\n","\n","    # forward the policy network and sample an action from the returned probability\n","    aprob, h = policy_forward(x)\n","    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n","\n","    # record various intermediates (needed later for backprop)\n","    xs.append(x) # observation\n","    hs.append(h) # hidden state\n","    y = 1 if action == 2 else 0 # a \"fake label\"\n","    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n","\n","    # step the environment and get new measurements\n","    observation, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n","\n","    if done: # an episode finished\n","      episode_number += 1\n","\n","      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n","      epx = np.vstack(xs)\n","      eph = np.vstack(hs)\n","      epdlogp = np.vstack(dlogps)\n","      epr = np.vstack(drs)\n","      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n","\n","      # compute the discounted reward backwards through time\n","      discounted_epr = discount_rewards(epr)\n","      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n","      discounted_epr -= np.mean(discounted_epr)\n","      discounted_epr /= np.std(discounted_epr)\n","\n","      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n","      grad = policy_backward(epx, eph, epdlogp)\n","      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n","\n","      # perform rmsprop parameter update every batch_size episodes\n","      if episode_number % batch_size == 0:\n","        for k,v in model.items():\n","          g = grad_buffer[k] # gradient\n","          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n","          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n","          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n","\n","      # boring book-keeping\n","      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n","      hist.append((episode_number, reward_sum, running_reward))\n","      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n","      reward_sum = 0\n","      observation = env.reset() # reset env\n","      prev_x = None\n","      if episode_number == total_episodes: return hist\n","\n","      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n","        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3589055,"status":"ok","timestamp":1660677735527,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"G6Ka_5Vl9Orm","outputId":"2d4bf5be-2606-4d0c-96f4-c2bc37ab7375"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 5.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.980199\n","resetting env. episode 8.000000, reward total was -19.000000. running mean: -20.960397\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.960793\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.961185\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.961573\n","resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.951958\n","resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.942438\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.943014\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.943583\n","resetting env. episode 16.000000, reward total was -21.000000. running mean: -20.944148\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.944706\n","resetting env. episode 18.000000, reward total was -19.000000. running mean: -20.925259\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.926006\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.926746\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.927479\n","resetting env. episode 22.000000, reward total was -19.000000. running mean: -20.908204\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.909122\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.910031\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.910931\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.911821\n","resetting env. episode 27.000000, reward total was -21.000000. running mean: -20.912703\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.913576\n","resetting env. episode 29.000000, reward total was -19.000000. running mean: -20.894440\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.895496\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.886541\n","resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.877676\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.878899\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.880110\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.881309\n","resetting env. episode 36.000000, reward total was -19.000000. running mean: -20.862496\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.863871\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.865232\n","resetting env. episode 39.000000, reward total was -18.000000. running mean: -20.836580\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.838214\n","resetting env. episode 41.000000, reward total was -19.000000. running mean: -20.819832\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.821633\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.823417\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.825183\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.826931\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.828662\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.830375\n","resetting env. episode 48.000000, reward total was -20.000000. running mean: -20.822071\n","resetting env. episode 49.000000, reward total was -21.000000. running mean: -20.823851\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.815612\n","resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.807456\n","resetting env. episode 52.000000, reward total was -18.000000. running mean: -20.779381\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.781588\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.783772\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.785934\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.788075\n","resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.780194\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.782392\n","resetting env. episode 59.000000, reward total was -20.000000. running mean: -20.774568\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.776822\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.779054\n","resetting env. episode 62.000000, reward total was -21.000000. running mean: -20.781264\n","resetting env. episode 63.000000, reward total was -18.000000. running mean: -20.753451\n","resetting env. episode 64.000000, reward total was -18.000000. running mean: -20.725916\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.728657\n","resetting env. episode 66.000000, reward total was -19.000000. running mean: -20.711371\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.714257\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.717114\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.719943\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.722744\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.715516\n","resetting env. episode 72.000000, reward total was -19.000000. running mean: -20.698361\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.701378\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.704364\n","resetting env. episode 75.000000, reward total was -20.000000. running mean: -20.697320\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.700347\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.703344\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.696310\n","resetting env. episode 79.000000, reward total was -21.000000. running mean: -20.699347\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.702354\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.705330\n","resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.708277\n","resetting env. episode 83.000000, reward total was -19.000000. running mean: -20.691194\n","resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.684282\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.687439\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.690565\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.693659\n","resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.686723\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.689855\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.692957\n","resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.686027\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.689167\n","resetting env. episode 93.000000, reward total was -20.000000. running mean: -20.682275\n","resetting env. episode 94.000000, reward total was -20.000000. running mean: -20.675453\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.678698\n","resetting env. episode 96.000000, reward total was -20.000000. running mean: -20.671911\n","resetting env. episode 97.000000, reward total was -20.000000. running mean: -20.665192\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.658540\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.661955\n","resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.655335\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.648782\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.652294\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.655771\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.659213\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.662621\n","resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.655995\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.659435\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.662841\n","resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.656212\n","resetting env. episode 110.000000, reward total was -20.000000. running mean: -20.649650\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.653154\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.656622\n","resetting env. episode 113.000000, reward total was -20.000000. running mean: -20.650056\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.653555\n","resetting env. episode 115.000000, reward total was -20.000000. running mean: -20.647020\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.650550\n","resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.644044\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.647604\n","resetting env. episode 119.000000, reward total was -21.000000. running mean: -20.651128\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.654616\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.658070\n","resetting env. episode 122.000000, reward total was -18.000000. running mean: -20.631489\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.635175\n","resetting env. episode 124.000000, reward total was -20.000000. running mean: -20.628823\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.632535\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.636209\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.639847\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.643449\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.647014\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.650544\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.654039\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.647498\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.651023\n","resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.644513\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.648068\n","resetting env. episode 136.000000, reward total was -19.000000. running mean: -20.631587\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.635271\n","resetting env. episode 138.000000, reward total was -19.000000. running mean: -20.618919\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.622729\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.626502\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.630237\n","resetting env. episode 142.000000, reward total was -20.000000. running mean: -20.623935\n","resetting env. episode 143.000000, reward total was -19.000000. running mean: -20.607695\n","resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.601618\n","resetting env. episode 145.000000, reward total was -18.000000. running mean: -20.575602\n","resetting env. episode 146.000000, reward total was -19.000000. running mean: -20.559846\n","resetting env. episode 147.000000, reward total was -20.000000. running mean: -20.554248\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.558705\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.563118\n","resetting env. episode 150.000000, reward total was -20.000000. running mean: -20.557487\n","resetting env. episode 151.000000, reward total was -19.000000. running mean: -20.541912\n","resetting env. episode 152.000000, reward total was -20.000000. running mean: -20.536493\n","resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.531128\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.535817\n","resetting env. episode 155.000000, reward total was -20.000000. running mean: -20.530459\n","resetting env. episode 156.000000, reward total was -19.000000. running mean: -20.515154\n","resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.510003\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.514902\n","resetting env. episode 159.000000, reward total was -19.000000. running mean: -20.499753\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.504756\n","resetting env. episode 161.000000, reward total was -20.000000. running mean: -20.499708\n","resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.494711\n","resetting env. episode 163.000000, reward total was -20.000000. running mean: -20.489764\n","resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.484867\n","resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.480018\n","resetting env. episode 166.000000, reward total was -19.000000. running mean: -20.465218\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.460566\n","resetting env. episode 168.000000, reward total was -19.000000. running mean: -20.445960\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.451500\n","resetting env. episode 170.000000, reward total was -20.000000. running mean: -20.446985\n","resetting env. episode 171.000000, reward total was -20.000000. running mean: -20.442515\n","resetting env. episode 172.000000, reward total was -20.000000. running mean: -20.438090\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.433709\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.439372\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.444979\n","resetting env. episode 176.000000, reward total was -20.000000. running mean: -20.440529\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.446123\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.451662\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.457146\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.462574\n","resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.457948\n","resetting env. episode 182.000000, reward total was -20.000000. running mean: -20.453369\n","resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.448835\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.454347\n","resetting env. episode 185.000000, reward total was -20.000000. running mean: -20.449803\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.455305\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.460752\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.466145\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.471483\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.476769\n","resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.472001\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.477281\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.482508\n","resetting env. episode 194.000000, reward total was -20.000000. running mean: -20.477683\n","resetting env. episode 195.000000, reward total was -20.000000. running mean: -20.472906\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.478177\n","resetting env. episode 197.000000, reward total was -19.000000. running mean: -20.463395\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.468761\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.474074\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.479333\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.484540\n","resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.479694\n","resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.484897\n","resetting env. episode 204.000000, reward total was -20.000000. running mean: -20.480048\n","resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.475248\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.480495\n","resetting env. episode 207.000000, reward total was -19.000000. running mean: -20.465690\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.471034\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.476323\n","resetting env. episode 210.000000, reward total was -20.000000. running mean: -20.471560\n","resetting env. episode 211.000000, reward total was -19.000000. running mean: -20.456844\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.462276\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.467653\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.472977\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.478247\n","resetting env. episode 216.000000, reward total was -20.000000. running mean: -20.473464\n","resetting env. episode 217.000000, reward total was -20.000000. running mean: -20.468730\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.474042\n","resetting env. episode 219.000000, reward total was -19.000000. running mean: -20.459302\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.464709\n","resetting env. episode 221.000000, reward total was -20.000000. running mean: -20.460062\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.465461\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.470807\n","resetting env. episode 224.000000, reward total was -20.000000. running mean: -20.466099\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.461438\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.466823\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.472155\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.467433\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.472759\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.478032\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.483251\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.478419\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.473635\n","resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.478898\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.484109\n","resetting env. episode 236.000000, reward total was -18.000000. running mean: -20.459268\n","resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.444675\n","resetting env. episode 238.000000, reward total was -19.000000. running mean: -20.430229\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.435926\n","resetting env. episode 240.000000, reward total was -21.000000. running mean: -20.441567\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.447151\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.452680\n","resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.448153\n","resetting env. episode 244.000000, reward total was -19.000000. running mean: -20.433672\n","resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.429335\n","resetting env. episode 246.000000, reward total was -17.000000. running mean: -20.395042\n","resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.391091\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.397180\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.403208\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.409176\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.415085\n","resetting env. episode 252.000000, reward total was -19.000000. running mean: -20.400934\n","resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.396924\n","resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.392955\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.399026\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.405035\n","resetting env. episode 257.000000, reward total was -20.000000. running mean: -20.400985\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.406975\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.412905\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.418776\n","resetting env. episode 261.000000, reward total was -18.000000. running mean: -20.394589\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.400643\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.406636\n","resetting env. episode 264.000000, reward total was -17.000000. running mean: -20.372570\n","resetting env. episode 265.000000, reward total was -19.000000. running mean: -20.358844\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.355256\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.361703\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.368086\n","resetting env. episode 269.000000, reward total was -20.000000. running mean: -20.364405\n","resetting env. episode 270.000000, reward total was -20.000000. running mean: -20.360761\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.357154\n","resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.363582\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.369946\n","resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.366247\n","resetting env. episode 275.000000, reward total was -19.000000. running mean: -20.352584\n","resetting env. episode 276.000000, reward total was -20.000000. running mean: -20.349058\n","resetting env. episode 277.000000, reward total was -19.000000. running mean: -20.335568\n","resetting env. episode 278.000000, reward total was -20.000000. running mean: -20.332212\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.338890\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.345501\n","resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.342046\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.348626\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.355139\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.361588\n","resetting env. episode 285.000000, reward total was -19.000000. running mean: -20.347972\n","resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.344492\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.351048\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.357537\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.363962\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.370322\n","resetting env. episode 291.000000, reward total was -19.000000. running mean: -20.356619\n","resetting env. episode 292.000000, reward total was -20.000000. running mean: -20.353053\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.359522\n","resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.355927\n","resetting env. episode 295.000000, reward total was -17.000000. running mean: -20.322368\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.329144\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.335853\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.332494\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.339169\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.335777\n","resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.332420\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.329095\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.335804\n","resetting env. episode 304.000000, reward total was -20.000000. running mean: -20.332446\n","resetting env. episode 305.000000, reward total was -19.000000. running mean: -20.319122\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.325931\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.332671\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.339345\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.345951\n","resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.342492\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.349067\n","resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.345576\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.352120\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.348599\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.355113\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.361562\n","resetting env. episode 317.000000, reward total was -20.000000. running mean: -20.357946\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -20.354367\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.360823\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.367215\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.363543\n","resetting env. episode 322.000000, reward total was -19.000000. running mean: -20.349908\n","resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.346408\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.352944\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.359415\n","resetting env. episode 326.000000, reward total was -20.000000. running mean: -20.355821\n","resetting env. episode 327.000000, reward total was -20.000000. running mean: -20.352263\n","resetting env. episode 328.000000, reward total was -20.000000. running mean: -20.348740\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.355253\n","resetting env. episode 330.000000, reward total was -19.000000. running mean: -20.341700\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.348283\n","resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.344800\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.351352\n","resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.347839\n","resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.344360\n","resetting env. episode 336.000000, reward total was -19.000000. running mean: -20.330917\n","resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.327607\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.334331\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.340988\n","resetting env. episode 340.000000, reward total was -19.000000. running mean: -20.327578\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.334302\n","resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.330959\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.337650\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.344273\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.350831\n","resetting env. episode 346.000000, reward total was -19.000000. running mean: -20.337322\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.343949\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.350510\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.357004\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.363434\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.369800\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.376102\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.382341\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.388518\n","resetting env. episode 355.000000, reward total was -19.000000. running mean: -20.374632\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.380886\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.387077\n","resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.383207\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.389374\n","resetting env. episode 360.000000, reward total was -19.000000. running mean: -20.375481\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.371726\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.378009\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.384229\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.390386\n","resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.396482\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.402518\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.408492\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.414407\n","resetting env. episode 369.000000, reward total was -19.000000. running mean: -20.400263\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.396261\n","resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.402298\n","resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.398275\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.404292\n","resetting env. episode 374.000000, reward total was -21.000000. running mean: -20.410250\n","resetting env. episode 375.000000, reward total was -21.000000. running mean: -20.416147\n","resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.421986\n","resetting env. episode 377.000000, reward total was -19.000000. running mean: -20.407766\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.413688\n","resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.409551\n","resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.405456\n","resetting env. episode 381.000000, reward total was -20.000000. running mean: -20.401401\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.407387\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.413313\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.409180\n","resetting env. episode 385.000000, reward total was -18.000000. running mean: -20.385088\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.391237\n","resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.387325\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.393452\n","resetting env. episode 389.000000, reward total was -20.000000. running mean: -20.389517\n","resetting env. episode 390.000000, reward total was -20.000000. running mean: -20.385622\n","resetting env. episode 391.000000, reward total was -20.000000. running mean: -20.381766\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.387948\n","resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.384069\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.390228\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.386326\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.392462\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.398538\n","resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.394552\n","resetting env. episode 399.000000, reward total was -18.000000. running mean: -20.370607\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.376901\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.383132\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.389301\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.395408\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.401453\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.407439\n","resetting env. episode 406.000000, reward total was -19.000000. running mean: -20.393365\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.399431\n","resetting env. episode 408.000000, reward total was -20.000000. running mean: -20.395437\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.391482\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.397567\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.403592\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.399556\n","resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.395560\n","resetting env. episode 414.000000, reward total was -18.000000. running mean: -20.371605\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.367889\n","resetting env. episode 416.000000, reward total was -20.000000. running mean: -20.364210\n","resetting env. episode 417.000000, reward total was -20.000000. running mean: -20.360568\n","resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.356962\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.363392\n","resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.359758\n","resetting env. episode 421.000000, reward total was -19.000000. running mean: -20.346161\n","resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.342699\n","resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.349272\n","resetting env. episode 424.000000, reward total was -18.000000. running mean: -20.325780\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.332522\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.339196\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.345805\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.352346\n","resetting env. episode 429.000000, reward total was -19.000000. running mean: -20.338823\n","resetting env. episode 430.000000, reward total was -19.000000. running mean: -20.325435\n","resetting env. episode 431.000000, reward total was -20.000000. running mean: -20.322180\n","resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.318959\n","resetting env. episode 433.000000, reward total was -19.000000. running mean: -20.305769\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.312711\n","resetting env. episode 435.000000, reward total was -20.000000. running mean: -20.309584\n","resetting env. episode 436.000000, reward total was -19.000000. running mean: -20.296488\n","resetting env. episode 437.000000, reward total was -20.000000. running mean: -20.293524\n","resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.290588\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.297682\n","resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.294706\n","resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.291759\n","resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.288841\n","resetting env. episode 443.000000, reward total was -19.000000. running mean: -20.275953\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.283193\n","resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.280361\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.287557\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.294682\n","resetting env. episode 448.000000, reward total was -18.000000. running mean: -20.271735\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.279018\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.286228\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.293365\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.300432\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.307427\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.314353\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.321209\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.327997\n","resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.324717\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.331470\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.338156\n","resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.344774\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.351326\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.357813\n","resetting env. episode 463.000000, reward total was -20.000000. running mean: -20.354235\n","resetting env. episode 464.000000, reward total was -20.000000. running mean: -20.350693\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.357186\n","resetting env. episode 466.000000, reward total was -20.000000. running mean: -20.353614\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.350078\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.356577\n","resetting env. episode 469.000000, reward total was -20.000000. running mean: -20.353011\n","resetting env. episode 470.000000, reward total was -19.000000. running mean: -20.339481\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.346086\n","resetting env. episode 472.000000, reward total was -20.000000. running mean: -20.342625\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.349199\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.355707\n","resetting env. episode 475.000000, reward total was -19.000000. running mean: -20.342150\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.348728\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.355241\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.351689\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.348172\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.354690\n","resetting env. episode 481.000000, reward total was -19.000000. running mean: -20.341143\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.347732\n","resetting env. episode 483.000000, reward total was -20.000000. running mean: -20.344254\n","resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.330812\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.337504\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.344129\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.350688\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.357181\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.363609\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.369973\n","resetting env. episode 491.000000, reward total was -17.000000. running mean: -20.336273\n","resetting env. episode 492.000000, reward total was -19.000000. running mean: -20.322910\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.329681\n","resetting env. episode 494.000000, reward total was -20.000000. running mean: -20.326384\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.333121\n","resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.329789\n","resetting env. episode 497.000000, reward total was -18.000000. running mean: -20.306491\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.313427\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.320292\n","resetting env. episode 500.000000, reward total was -18.000000. running mean: -20.297089\n","CPU times: user 1h 39min 10s, sys: 16min 10s, total: 1h 55min 21s\n","Wall time: 59min 49s\n"]}],"source":["%time hist1 = train_model(env, model, total_episodes=500)"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3793199,"status":"ok","timestamp":1660681528706,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"cHYCDYwhlVLV","outputId":"5cde8b10-3331-4b9e-b0a7-4573c52060e6"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 4.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 6.000000, reward total was -20.000000. running mean: -20.980199\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.970397\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.970693\n","resetting env. episode 9.000000, reward total was -20.000000. running mean: -20.960986\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.961376\n","resetting env. episode 11.000000, reward total was -20.000000. running mean: -20.951762\n","resetting env. episode 12.000000, reward total was -19.000000. running mean: -20.932245\n","resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.922922\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.923693\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.924456\n","resetting env. episode 16.000000, reward total was -19.000000. running mean: -20.905212\n","resetting env. episode 17.000000, reward total was -18.000000. running mean: -20.876160\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.877398\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.878624\n","resetting env. episode 20.000000, reward total was -20.000000. running mean: -20.869838\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.871139\n","resetting env. episode 22.000000, reward total was -20.000000. running mean: -20.862428\n","resetting env. episode 23.000000, reward total was -19.000000. running mean: -20.843804\n","resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.835366\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.837012\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.838642\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.830255\n","resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.821953\n","resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.813733\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.815596\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.817440\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.819266\n","resetting env. episode 33.000000, reward total was -20.000000. running mean: -20.811073\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.812962\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.814833\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.816684\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.818518\n","resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.810332\n","resetting env. episode 39.000000, reward total was -19.000000. running mean: -20.792229\n","resetting env. episode 40.000000, reward total was -20.000000. running mean: -20.784307\n","resetting env. episode 41.000000, reward total was -19.000000. running mean: -20.766464\n","resetting env. episode 42.000000, reward total was -19.000000. running mean: -20.748799\n","resetting env. episode 43.000000, reward total was -20.000000. running mean: -20.741311\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.733898\n","resetting env. episode 45.000000, reward total was -20.000000. running mean: -20.726559\n","resetting env. episode 46.000000, reward total was -20.000000. running mean: -20.719293\n","resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.712100\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.714979\n","resetting env. episode 49.000000, reward total was -19.000000. running mean: -20.697830\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.690851\n","resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.683943\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.687103\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.690232\n","resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.683330\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.686497\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.689632\n","resetting env. episode 57.000000, reward total was -20.000000. running mean: -20.682735\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.685908\n","resetting env. episode 59.000000, reward total was -20.000000. running mean: -20.679049\n","resetting env. episode 60.000000, reward total was -20.000000. running mean: -20.672259\n","resetting env. episode 61.000000, reward total was -21.000000. running mean: -20.675536\n","resetting env. episode 62.000000, reward total was -19.000000. running mean: -20.658781\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.662193\n","resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.655571\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.659015\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.662425\n","resetting env. episode 67.000000, reward total was -20.000000. running mean: -20.655801\n","resetting env. episode 68.000000, reward total was -19.000000. running mean: -20.639243\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.642850\n","resetting env. episode 70.000000, reward total was -19.000000. running mean: -20.626422\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.620158\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.623956\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.617716\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.621539\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.625324\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.629071\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.632780\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.626452\n","resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.620188\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.623986\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.627746\n","resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.631468\n","resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.625154\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.628902\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.632613\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.636287\n","resetting env. episode 87.000000, reward total was -18.000000. running mean: -20.609924\n","resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.603825\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.607787\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.611709\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.615592\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.619436\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.623241\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.627009\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.620739\n","resetting env. episode 96.000000, reward total was -20.000000. running mean: -20.614532\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.618386\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.622202\n","resetting env. episode 99.000000, reward total was -21.000000. running mean: -20.625980\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.629721\n","resetting env. episode 101.000000, reward total was -21.000000. running mean: -20.633423\n","resetting env. episode 102.000000, reward total was -20.000000. running mean: -20.627089\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.630818\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.634510\n","resetting env. episode 105.000000, reward total was -20.000000. running mean: -20.628165\n","resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.631883\n","resetting env. episode 107.000000, reward total was -20.000000. running mean: -20.625564\n","resetting env. episode 108.000000, reward total was -19.000000. running mean: -20.609309\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.613216\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.617084\n","resetting env. episode 111.000000, reward total was -18.000000. running mean: -20.590913\n","resetting env. episode 112.000000, reward total was -19.000000. running mean: -20.575004\n","resetting env. episode 113.000000, reward total was -20.000000. running mean: -20.569254\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.573561\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.577825\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.582047\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.586227\n","resetting env. episode 118.000000, reward total was -19.000000. running mean: -20.570364\n","resetting env. episode 119.000000, reward total was -20.000000. running mean: -20.564661\n","resetting env. episode 120.000000, reward total was -20.000000. running mean: -20.559014\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.563424\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.557790\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.562212\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.566590\n","resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.560924\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.565315\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.569661\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.573965\n","resetting env. episode 129.000000, reward total was -19.000000. running mean: -20.558225\n","resetting env. episode 130.000000, reward total was -19.000000. running mean: -20.542643\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.547217\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.551744\n","resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.546227\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.550765\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.555257\n","resetting env. episode 136.000000, reward total was -19.000000. running mean: -20.539704\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.544307\n","resetting env. episode 138.000000, reward total was -19.000000. running mean: -20.528864\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.533576\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.538240\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.542858\n","resetting env. episode 142.000000, reward total was -19.000000. running mean: -20.527429\n","resetting env. episode 143.000000, reward total was -18.000000. running mean: -20.502155\n","resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.497133\n","resetting env. episode 145.000000, reward total was -19.000000. running mean: -20.482162\n","resetting env. episode 146.000000, reward total was -19.000000. running mean: -20.467340\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.472667\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.477940\n","resetting env. episode 149.000000, reward total was -19.000000. running mean: -20.463161\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.468529\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.473844\n","resetting env. episode 152.000000, reward total was -18.000000. running mean: -20.449105\n","resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.444614\n","resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.440168\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.445766\n","resetting env. episode 156.000000, reward total was -19.000000. running mean: -20.431309\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.436996\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.442626\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.448200\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.453718\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.459180\n","resetting env. episode 162.000000, reward total was -19.000000. running mean: -20.444589\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.450143\n","resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.445641\n","resetting env. episode 165.000000, reward total was -20.000000. running mean: -20.441185\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.446773\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.442305\n","resetting env. episode 168.000000, reward total was -20.000000. running mean: -20.437882\n","resetting env. episode 169.000000, reward total was -19.000000. running mean: -20.423503\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.429268\n","resetting env. episode 171.000000, reward total was -20.000000. running mean: -20.424976\n","resetting env. episode 172.000000, reward total was -19.000000. running mean: -20.410726\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.406619\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.412552\n","resetting env. episode 175.000000, reward total was -19.000000. running mean: -20.398427\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.404443\n","resetting env. episode 177.000000, reward total was -18.000000. running mean: -20.380398\n","resetting env. episode 178.000000, reward total was -19.000000. running mean: -20.366594\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.372928\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.379199\n","resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.375407\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.381653\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.387836\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.393958\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.400018\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.406018\n","resetting env. episode 187.000000, reward total was -19.000000. running mean: -20.391958\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.388039\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.394158\n","resetting env. episode 190.000000, reward total was -19.000000. running mean: -20.380217\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.386414\n","resetting env. episode 192.000000, reward total was -20.000000. running mean: -20.382550\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.388725\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.394838\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.400889\n","resetting env. episode 196.000000, reward total was -18.000000. running mean: -20.376880\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.383111\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.379280\n","resetting env. episode 199.000000, reward total was -19.000000. running mean: -20.365488\n","resetting env. episode 200.000000, reward total was -20.000000. running mean: -20.361833\n","resetting env. episode 201.000000, reward total was -19.000000. running mean: -20.348214\n","resetting env. episode 202.000000, reward total was -19.000000. running mean: -20.334732\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.331385\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.338071\n","resetting env. episode 205.000000, reward total was -20.000000. running mean: -20.334690\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.341343\n","resetting env. episode 207.000000, reward total was -20.000000. running mean: -20.337930\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.344551\n","resetting env. episode 209.000000, reward total was -20.000000. running mean: -20.341105\n","resetting env. episode 210.000000, reward total was -17.000000. running mean: -20.307694\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.314617\n","resetting env. episode 212.000000, reward total was -20.000000. running mean: -20.311471\n","resetting env. episode 213.000000, reward total was -19.000000. running mean: -20.298356\n","resetting env. episode 214.000000, reward total was -21.000000. running mean: -20.305373\n","resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.302319\n","resetting env. episode 216.000000, reward total was -19.000000. running mean: -20.289296\n","resetting env. episode 217.000000, reward total was -17.000000. running mean: -20.256403\n","resetting env. episode 218.000000, reward total was -20.000000. running mean: -20.253839\n","resetting env. episode 219.000000, reward total was -20.000000. running mean: -20.251300\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.258787\n","resetting env. episode 221.000000, reward total was -20.000000. running mean: -20.256200\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.263638\n","resetting env. episode 223.000000, reward total was -19.000000. running mean: -20.251001\n","resetting env. episode 224.000000, reward total was -19.000000. running mean: -20.238491\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.246106\n","resetting env. episode 226.000000, reward total was -20.000000. running mean: -20.243645\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.251209\n","resetting env. episode 228.000000, reward total was -21.000000. running mean: -20.258697\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.266110\n","resetting env. episode 230.000000, reward total was -20.000000. running mean: -20.263449\n","resetting env. episode 231.000000, reward total was -18.000000. running mean: -20.240814\n","resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.248406\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.245922\n","resetting env. episode 234.000000, reward total was -21.000000. running mean: -20.253463\n","resetting env. episode 235.000000, reward total was -20.000000. running mean: -20.250928\n","resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.248419\n","resetting env. episode 237.000000, reward total was -20.000000. running mean: -20.245935\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.253475\n","resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.250940\n","resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.248431\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.255947\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.253387\n","resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.250853\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.258345\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.265761\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.273104\n","resetting env. episode 247.000000, reward total was -20.000000. running mean: -20.270373\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.277669\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.284892\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.292043\n","resetting env. episode 251.000000, reward total was -19.000000. running mean: -20.279123\n","resetting env. episode 252.000000, reward total was -18.000000. running mean: -20.256332\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.263768\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.271131\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.278419\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.285635\n","resetting env. episode 257.000000, reward total was -20.000000. running mean: -20.282779\n","resetting env. episode 258.000000, reward total was -19.000000. running mean: -20.269951\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.277252\n","resetting env. episode 260.000000, reward total was -20.000000. running mean: -20.274479\n","resetting env. episode 261.000000, reward total was -19.000000. running mean: -20.261734\n","resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.259117\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.266526\n","resetting env. episode 264.000000, reward total was -20.000000. running mean: -20.263861\n","resetting env. episode 265.000000, reward total was -20.000000. running mean: -20.261222\n","resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.268610\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.275924\n","resetting env. episode 268.000000, reward total was -20.000000. running mean: -20.273164\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.280433\n","resetting env. episode 270.000000, reward total was -20.000000. running mean: -20.277628\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.274852\n","resetting env. episode 272.000000, reward total was -19.000000. running mean: -20.262104\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.269483\n","resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.266788\n","resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.264120\n","resetting env. episode 276.000000, reward total was -18.000000. running mean: -20.241479\n","resetting env. episode 277.000000, reward total was -19.000000. running mean: -20.229064\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.236773\n","resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.234406\n","resetting env. episode 280.000000, reward total was -20.000000. running mean: -20.232061\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.239741\n","resetting env. episode 282.000000, reward total was -19.000000. running mean: -20.227343\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.235070\n","resetting env. episode 284.000000, reward total was -20.000000. running mean: -20.232719\n","resetting env. episode 285.000000, reward total was -19.000000. running mean: -20.220392\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.228188\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.235906\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.243547\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.251112\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.248601\n","resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.256115\n","resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.263554\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.270918\n","resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.268209\n","resetting env. episode 295.000000, reward total was -19.000000. running mean: -20.255527\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.262971\n","resetting env. episode 297.000000, reward total was -20.000000. running mean: -20.260342\n","resetting env. episode 298.000000, reward total was -20.000000. running mean: -20.257738\n","resetting env. episode 299.000000, reward total was -17.000000. running mean: -20.225161\n","resetting env. episode 300.000000, reward total was -20.000000. running mean: -20.222909\n","resetting env. episode 301.000000, reward total was -17.000000. running mean: -20.190680\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.198773\n","resetting env. episode 303.000000, reward total was -20.000000. running mean: -20.196786\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.204818\n","resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.202770\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.210742\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.218635\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.226448\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.234184\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.241842\n","resetting env. episode 311.000000, reward total was -19.000000. running mean: -20.229423\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.237129\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.234758\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.242410\n","resetting env. episode 315.000000, reward total was -19.000000. running mean: -20.229986\n","resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.227686\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.235410\n","resetting env. episode 318.000000, reward total was -19.000000. running mean: -20.223055\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.230825\n","resetting env. episode 320.000000, reward total was -20.000000. running mean: -20.228517\n","resetting env. episode 321.000000, reward total was -19.000000. running mean: -20.216231\n","resetting env. episode 322.000000, reward total was -20.000000. running mean: -20.214069\n","resetting env. episode 323.000000, reward total was -19.000000. running mean: -20.201928\n","resetting env. episode 324.000000, reward total was -20.000000. running mean: -20.199909\n","resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.197910\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.205931\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.213872\n","resetting env. episode 328.000000, reward total was -19.000000. running mean: -20.201733\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.209716\n","resetting env. episode 330.000000, reward total was -19.000000. running mean: -20.197618\n","resetting env. episode 331.000000, reward total was -19.000000. running mean: -20.185642\n","resetting env. episode 332.000000, reward total was -20.000000. running mean: -20.183786\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.191948\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.200029\n","resetting env. episode 335.000000, reward total was -20.000000. running mean: -20.198028\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.206048\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.213987\n","resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.211848\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.219729\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.227532\n","resetting env. episode 341.000000, reward total was -19.000000. running mean: -20.215257\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.223104\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.230873\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.238564\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.246179\n","resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.243717\n","resetting env. episode 347.000000, reward total was -20.000000. running mean: -20.241280\n","resetting env. episode 348.000000, reward total was -18.000000. running mean: -20.218867\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.226678\n","resetting env. episode 350.000000, reward total was -20.000000. running mean: -20.224411\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.232167\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.239846\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.247447\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.254973\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.262423\n","resetting env. episode 356.000000, reward total was -19.000000. running mean: -20.249799\n","resetting env. episode 357.000000, reward total was -19.000000. running mean: -20.237301\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.244928\n","resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.242478\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.250054\n","resetting env. episode 361.000000, reward total was -18.000000. running mean: -20.227553\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.235278\n","resetting env. episode 363.000000, reward total was -20.000000. running mean: -20.232925\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.240596\n","resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.248190\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.255708\n","resetting env. episode 367.000000, reward total was -17.000000. running mean: -20.223151\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.230919\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.238610\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.246224\n","resetting env. episode 371.000000, reward total was -19.000000. running mean: -20.233762\n","resetting env. episode 372.000000, reward total was -20.000000. running mean: -20.231424\n","resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.229110\n","resetting env. episode 374.000000, reward total was -18.000000. running mean: -20.206819\n","resetting env. episode 375.000000, reward total was -19.000000. running mean: -20.194750\n","resetting env. episode 376.000000, reward total was -19.000000. running mean: -20.182803\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.190975\n","resetting env. episode 378.000000, reward total was -20.000000. running mean: -20.189065\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.197174\n","resetting env. episode 380.000000, reward total was -20.000000. running mean: -20.195203\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.203251\n","resetting env. episode 382.000000, reward total was -21.000000. running mean: -20.211218\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.209106\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.207015\n","resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.204945\n","resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.202895\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.210866\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.218758\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.226570\n","resetting env. episode 390.000000, reward total was -18.000000. running mean: -20.204304\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.212261\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.220139\n","resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.217937\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.225758\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.233500\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.241165\n","resetting env. episode 397.000000, reward total was -19.000000. running mean: -20.228754\n","resetting env. episode 398.000000, reward total was -18.000000. running mean: -20.206466\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.214402\n","resetting env. episode 400.000000, reward total was -19.000000. running mean: -20.202258\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.210235\n","resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.208133\n","resetting env. episode 403.000000, reward total was -19.000000. running mean: -20.196051\n","resetting env. episode 404.000000, reward total was -18.000000. running mean: -20.174091\n","resetting env. episode 405.000000, reward total was -19.000000. running mean: -20.162350\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.170726\n","resetting env. episode 407.000000, reward total was -20.000000. running mean: -20.169019\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.177329\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.185556\n","resetting env. episode 410.000000, reward total was -19.000000. running mean: -20.173700\n","resetting env. episode 411.000000, reward total was -20.000000. running mean: -20.171963\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.170243\n","resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.168541\n","resetting env. episode 414.000000, reward total was -20.000000. running mean: -20.166856\n","resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.175187\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.183435\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.191601\n","resetting env. episode 418.000000, reward total was -20.000000. running mean: -20.189685\n","resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.187788\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.195910\n","resetting env. episode 421.000000, reward total was -18.000000. running mean: -20.173951\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.182212\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.180389\n","resetting env. episode 424.000000, reward total was -20.000000. running mean: -20.178586\n","resetting env. episode 425.000000, reward total was -19.000000. running mean: -20.166800\n","resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.165132\n","resetting env. episode 427.000000, reward total was -17.000000. running mean: -20.133480\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.142146\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.150724\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -20.149217\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.157725\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.166147\n","resetting env. episode 433.000000, reward total was -20.000000. running mean: -20.164486\n","resetting env. episode 434.000000, reward total was -18.000000. running mean: -20.142841\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.151413\n","resetting env. episode 436.000000, reward total was -19.000000. running mean: -20.139899\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.148500\n","resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.147015\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.155544\n","resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.153989\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.162449\n","resetting env. episode 442.000000, reward total was -18.000000. running mean: -20.140825\n","resetting env. episode 443.000000, reward total was -20.000000. running mean: -20.139416\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.148022\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.156542\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.164977\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.173327\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.181594\n","resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.179778\n","resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.177980\n","resetting env. episode 451.000000, reward total was -19.000000. running mean: -20.166200\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.174538\n","resetting env. episode 453.000000, reward total was -19.000000. running mean: -20.162793\n","resetting env. episode 454.000000, reward total was -18.000000. running mean: -20.141165\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.149753\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.158256\n","resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.156673\n","resetting env. episode 458.000000, reward total was -18.000000. running mean: -20.135106\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.143755\n","resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.152318\n","resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.150794\n","resetting env. episode 462.000000, reward total was -20.000000. running mean: -20.149286\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.157794\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.166216\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.174554\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.182808\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.190980\n","resetting env. episode 468.000000, reward total was -20.000000. running mean: -20.189070\n","resetting env. episode 469.000000, reward total was -19.000000. running mean: -20.177179\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.185408\n","resetting env. episode 471.000000, reward total was -17.000000. running mean: -20.153554\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.162018\n","resetting env. episode 473.000000, reward total was -20.000000. running mean: -20.160398\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.168794\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.177106\n","resetting env. episode 476.000000, reward total was -18.000000. running mean: -20.155335\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.163782\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.172144\n","resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.180422\n","resetting env. episode 480.000000, reward total was -19.000000. running mean: -20.168618\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.176932\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.175163\n","resetting env. episode 483.000000, reward total was -19.000000. running mean: -20.163411\n","resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.151777\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.160259\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.168656\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.176970\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.175200\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.183448\n","resetting env. episode 490.000000, reward total was -20.000000. running mean: -20.181614\n","resetting env. episode 491.000000, reward total was -19.000000. running mean: -20.169798\n","resetting env. episode 492.000000, reward total was -19.000000. running mean: -20.158100\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.166519\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.174853\n","resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.173105\n","resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.171374\n","resetting env. episode 497.000000, reward total was -20.000000. running mean: -20.169660\n","resetting env. episode 498.000000, reward total was -19.000000. running mean: -20.157963\n","resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.156384\n","resetting env. episode 500.000000, reward total was -19.000000. running mean: -20.144820\n","CPU times: user 1h 44min 58s, sys: 17min 4s, total: 2h 2min 3s\n","Wall time: 1h 3min 12s\n"]}],"source":["%time hist2 = train_model(env, model, total_episodes=500)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"elapsed":45263,"status":"ok","timestamp":1660681573934,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"},"user_tz":-330},"id":"8fheN9DRlWXQ","outputId":"fff3ea12-5265-47ef-d108-b85e041ed5e8"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -11.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["play_game(env, model)"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9AxOcQhIsKow","executionInfo":{"status":"ok","timestamp":1660694203595,"user_tz":-330,"elapsed":12629673,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}},"outputId":"1831761f-5974-45fa-c0ea-215fcfcc006e"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n","resetting env. episode 2.000000, reward total was -20.000000. running mean: -20.000000\n","resetting env. episode 3.000000, reward total was -19.000000. running mean: -19.990000\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.000100\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.010099\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.019998\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.019798\n","resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.019600\n","resetting env. episode 9.000000, reward total was -20.000000. running mean: -20.019404\n","resetting env. episode 10.000000, reward total was -20.000000. running mean: -20.019210\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.029018\n","resetting env. episode 12.000000, reward total was -21.000000. running mean: -20.038728\n","resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.038340\n","resetting env. episode 14.000000, reward total was -19.000000. running mean: -20.027957\n","resetting env. episode 15.000000, reward total was -20.000000. running mean: -20.027677\n","resetting env. episode 16.000000, reward total was -19.000000. running mean: -20.017401\n","resetting env. episode 17.000000, reward total was -19.000000. running mean: -20.007227\n","resetting env. episode 18.000000, reward total was -20.000000. running mean: -20.007154\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.017083\n","resetting env. episode 20.000000, reward total was -18.000000. running mean: -19.996912\n","resetting env. episode 21.000000, reward total was -20.000000. running mean: -19.996943\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.006974\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.016904\n","resetting env. episode 24.000000, reward total was -20.000000. running mean: -20.016735\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.026567\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.036302\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.035939\n","resetting env. episode 28.000000, reward total was -20.000000. running mean: -20.035579\n","resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.035224\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.044871\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.044423\n","resetting env. episode 32.000000, reward total was -20.000000. running mean: -20.043978\n","resetting env. episode 33.000000, reward total was -20.000000. running mean: -20.043539\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.053103\n","resetting env. episode 35.000000, reward total was -20.000000. running mean: -20.052572\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.062046\n","resetting env. episode 37.000000, reward total was -21.000000. running mean: -20.071426\n","resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.070712\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.080005\n","resetting env. episode 40.000000, reward total was -19.000000. running mean: -20.069205\n","resetting env. episode 41.000000, reward total was -19.000000. running mean: -20.058512\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.067927\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.077248\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.076476\n","resetting env. episode 45.000000, reward total was -19.000000. running mean: -20.065711\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.075054\n","resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.074303\n","resetting env. episode 48.000000, reward total was -20.000000. running mean: -20.073560\n","resetting env. episode 49.000000, reward total was -18.000000. running mean: -20.052825\n","resetting env. episode 50.000000, reward total was -19.000000. running mean: -20.042296\n","resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.041873\n","resetting env. episode 52.000000, reward total was -20.000000. running mean: -20.041455\n","resetting env. episode 53.000000, reward total was -20.000000. running mean: -20.041040\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.050630\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.060123\n","resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.059522\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.068927\n","resetting env. episode 58.000000, reward total was -20.000000. running mean: -20.068238\n","resetting env. episode 59.000000, reward total was -19.000000. running mean: -20.057555\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.066980\n","resetting env. episode 61.000000, reward total was -20.000000. running mean: -20.066310\n","resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.065647\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.074990\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.084240\n","resetting env. episode 65.000000, reward total was -21.000000. running mean: -20.093398\n","resetting env. episode 66.000000, reward total was -20.000000. running mean: -20.092464\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.101539\n","resetting env. episode 68.000000, reward total was -19.000000. running mean: -20.090524\n","resetting env. episode 69.000000, reward total was -19.000000. running mean: -20.079619\n","resetting env. episode 70.000000, reward total was -20.000000. running mean: -20.078823\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.078034\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.087254\n","resetting env. episode 73.000000, reward total was -19.000000. running mean: -20.076382\n","resetting env. episode 74.000000, reward total was -20.000000. running mean: -20.075618\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.084862\n","resetting env. episode 76.000000, reward total was -19.000000. running mean: -20.074013\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.083273\n","resetting env. episode 78.000000, reward total was -19.000000. running mean: -20.072440\n","resetting env. episode 79.000000, reward total was -18.000000. running mean: -20.051716\n","resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.051198\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.060686\n","resetting env. episode 82.000000, reward total was -21.000000. running mean: -20.070080\n","resetting env. episode 83.000000, reward total was -19.000000. running mean: -20.059379\n","resetting env. episode 84.000000, reward total was -20.000000. running mean: -20.058785\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.068197\n","resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.067515\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.076840\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.086072\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.095211\n","resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.094259\n","resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.093316\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.102383\n","resetting env. episode 93.000000, reward total was -20.000000. running mean: -20.101359\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.110346\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.119242\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.128050\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.136769\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.135402\n","resetting env. episode 99.000000, reward total was -20.000000. running mean: -20.134048\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.142707\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.141280\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.149867\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.158369\n","resetting env. episode 104.000000, reward total was -20.000000. running mean: -20.156785\n","resetting env. episode 105.000000, reward total was -20.000000. running mean: -20.155217\n","resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.163665\n","resetting env. episode 107.000000, reward total was -20.000000. running mean: -20.162028\n","resetting env. episode 108.000000, reward total was -20.000000. running mean: -20.160408\n","resetting env. episode 109.000000, reward total was -20.000000. running mean: -20.158804\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.167216\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.175544\n","resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.173788\n","resetting env. episode 113.000000, reward total was -20.000000. running mean: -20.172050\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.180330\n","resetting env. episode 115.000000, reward total was -19.000000. running mean: -20.168527\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.176841\n","resetting env. episode 117.000000, reward total was -20.000000. running mean: -20.175073\n","resetting env. episode 118.000000, reward total was -20.000000. running mean: -20.173322\n","resetting env. episode 119.000000, reward total was -19.000000. running mean: -20.161589\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.169973\n","resetting env. episode 121.000000, reward total was -20.000000. running mean: -20.168273\n","resetting env. episode 122.000000, reward total was -19.000000. running mean: -20.156591\n","resetting env. episode 123.000000, reward total was -20.000000. running mean: -20.155025\n","resetting env. episode 124.000000, reward total was -20.000000. running mean: -20.153474\n","resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.151940\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.160420\n","resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.158816\n","resetting env. episode 128.000000, reward total was -18.000000. running mean: -20.137228\n","resetting env. episode 129.000000, reward total was -19.000000. running mean: -20.125856\n","resetting env. episode 130.000000, reward total was -20.000000. running mean: -20.124597\n","resetting env. episode 131.000000, reward total was -20.000000. running mean: -20.123351\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.132118\n","resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.130796\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.139488\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.148094\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.156613\n","resetting env. episode 137.000000, reward total was -21.000000. running mean: -20.165046\n","resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.163396\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.171762\n","resetting env. episode 140.000000, reward total was -20.000000. running mean: -20.170044\n","resetting env. episode 141.000000, reward total was -19.000000. running mean: -20.158344\n","resetting env. episode 142.000000, reward total was -20.000000. running mean: -20.156761\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.165193\n","resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.163541\n","resetting env. episode 145.000000, reward total was -20.000000. running mean: -20.161906\n","resetting env. episode 146.000000, reward total was -20.000000. running mean: -20.160287\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.168684\n","resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.166997\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.175327\n","resetting env. episode 150.000000, reward total was -19.000000. running mean: -20.163574\n","resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.161938\n","resetting env. episode 152.000000, reward total was -19.000000. running mean: -20.150319\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.158815\n","resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.157227\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.165655\n","resetting env. episode 156.000000, reward total was -20.000000. running mean: -20.163998\n","resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.162358\n","resetting env. episode 158.000000, reward total was -19.000000. running mean: -20.150735\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.159227\n","resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.157635\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.166059\n","resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.164398\n","resetting env. episode 163.000000, reward total was -20.000000. running mean: -20.162754\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.171127\n","resetting env. episode 165.000000, reward total was -18.000000. running mean: -20.149415\n","resetting env. episode 166.000000, reward total was -19.000000. running mean: -20.137921\n","resetting env. episode 167.000000, reward total was -19.000000. running mean: -20.126542\n","resetting env. episode 168.000000, reward total was -20.000000. running mean: -20.125277\n","resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.124024\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.132784\n","resetting env. episode 171.000000, reward total was -21.000000. running mean: -20.141456\n","resetting env. episode 172.000000, reward total was -20.000000. running mean: -20.140041\n","resetting env. episode 173.000000, reward total was -19.000000. running mean: -20.128641\n","resetting env. episode 174.000000, reward total was -19.000000. running mean: -20.117354\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.126181\n","resetting env. episode 176.000000, reward total was -20.000000. running mean: -20.124919\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.133670\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.142333\n","resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.140910\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.149501\n","resetting env. episode 181.000000, reward total was -19.000000. running mean: -20.138006\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.146626\n","resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.145159\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.153708\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.162171\n","resetting env. episode 186.000000, reward total was -19.000000. running mean: -20.150549\n","resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.149044\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.147553\n","resetting env. episode 189.000000, reward total was -20.000000. running mean: -20.146078\n","resetting env. episode 190.000000, reward total was -19.000000. running mean: -20.134617\n","resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.133271\n","resetting env. episode 192.000000, reward total was -20.000000. running mean: -20.131938\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.140619\n","resetting env. episode 194.000000, reward total was -18.000000. running mean: -20.119212\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.128020\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.136740\n","resetting env. episode 197.000000, reward total was -18.000000. running mean: -20.115373\n","resetting env. episode 198.000000, reward total was -20.000000. running mean: -20.114219\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.113077\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.121946\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.130727\n","resetting env. episode 202.000000, reward total was -20.000000. running mean: -20.129419\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.128125\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.136844\n","resetting env. episode 205.000000, reward total was -19.000000. running mean: -20.125475\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.134221\n","resetting env. episode 207.000000, reward total was -20.000000. running mean: -20.132878\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.141550\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.150134\n","resetting env. episode 210.000000, reward total was -19.000000. running mean: -20.138633\n","resetting env. episode 211.000000, reward total was -19.000000. running mean: -20.127246\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.135974\n","resetting env. episode 213.000000, reward total was -20.000000. running mean: -20.134614\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -20.133268\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.141935\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.150516\n","resetting env. episode 217.000000, reward total was -19.000000. running mean: -20.139011\n","resetting env. episode 218.000000, reward total was -19.000000. running mean: -20.127621\n","resetting env. episode 219.000000, reward total was -19.000000. running mean: -20.116345\n","resetting env. episode 220.000000, reward total was -18.000000. running mean: -20.095181\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.104229\n","resetting env. episode 222.000000, reward total was -20.000000. running mean: -20.103187\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.112155\n","resetting env. episode 224.000000, reward total was -19.000000. running mean: -20.101034\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.100023\n","resetting env. episode 226.000000, reward total was -20.000000. running mean: -20.099023\n","resetting env. episode 227.000000, reward total was -20.000000. running mean: -20.098033\n","resetting env. episode 228.000000, reward total was -17.000000. running mean: -20.067052\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.076382\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.085618\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.094762\n","resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.103814\n","resetting env. episode 233.000000, reward total was -21.000000. running mean: -20.112776\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.111648\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.120532\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.129327\n","resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.118033\n","resetting env. episode 238.000000, reward total was -19.000000. running mean: -20.106853\n","resetting env. episode 239.000000, reward total was -19.000000. running mean: -20.095785\n","resetting env. episode 240.000000, reward total was -18.000000. running mean: -20.074827\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.084078\n","resetting env. episode 242.000000, reward total was -20.000000. running mean: -20.083238\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.092405\n","resetting env. episode 244.000000, reward total was -19.000000. running mean: -20.081481\n","resetting env. episode 245.000000, reward total was -19.000000. running mean: -20.070666\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.079960\n","resetting env. episode 247.000000, reward total was -19.000000. running mean: -20.069160\n","resetting env. episode 248.000000, reward total was -17.000000. running mean: -20.038469\n","resetting env. episode 249.000000, reward total was -20.000000. running mean: -20.038084\n","resetting env. episode 250.000000, reward total was -19.000000. running mean: -20.027703\n","resetting env. episode 251.000000, reward total was -20.000000. running mean: -20.027426\n","resetting env. episode 252.000000, reward total was -19.000000. running mean: -20.017152\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.026980\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.036710\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.046343\n","resetting env. episode 256.000000, reward total was -17.000000. running mean: -20.015880\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.025721\n","resetting env. episode 258.000000, reward total was -20.000000. running mean: -20.025464\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.035209\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.044857\n","resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.054409\n","resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.053864\n","resetting env. episode 263.000000, reward total was -20.000000. running mean: -20.053326\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.062793\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.072165\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.071443\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.080729\n","resetting env. episode 268.000000, reward total was -20.000000. running mean: -20.079921\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.089122\n","resetting env. episode 270.000000, reward total was -19.000000. running mean: -20.078231\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.087449\n","resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.096574\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.105608\n","resetting env. episode 274.000000, reward total was -21.000000. running mean: -20.114552\n","resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.113407\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.122273\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.131050\n","resetting env. episode 278.000000, reward total was -20.000000. running mean: -20.129739\n","resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.128442\n","resetting env. episode 280.000000, reward total was -18.000000. running mean: -20.107158\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.116086\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.124925\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.133676\n","resetting env. episode 284.000000, reward total was -19.000000. running mean: -20.122339\n","resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.121116\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.129905\n","resetting env. episode 287.000000, reward total was -19.000000. running mean: -20.118606\n","resetting env. episode 288.000000, reward total was -20.000000. running mean: -20.117419\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.126245\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.124983\n","resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.123733\n","resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.132496\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.141171\n","resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.139759\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.148361\n","resetting env. episode 296.000000, reward total was -17.000000. running mean: -20.116878\n","resetting env. episode 297.000000, reward total was -20.000000. running mean: -20.115709\n","resetting env. episode 298.000000, reward total was -17.000000. running mean: -20.084552\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.083706\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.092869\n","resetting env. episode 301.000000, reward total was -20.000000. running mean: -20.091941\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.101021\n","resetting env. episode 303.000000, reward total was -19.000000. running mean: -20.090011\n","resetting env. episode 304.000000, reward total was -19.000000. running mean: -20.079111\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.088320\n","resetting env. episode 306.000000, reward total was -20.000000. running mean: -20.087437\n","resetting env. episode 307.000000, reward total was -20.000000. running mean: -20.086562\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.085697\n","resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.084840\n","resetting env. episode 310.000000, reward total was -18.000000. running mean: -20.063991\n","resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.063351\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.072718\n","resetting env. episode 313.000000, reward total was -19.000000. running mean: -20.061991\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.061371\n","resetting env. episode 315.000000, reward total was -20.000000. running mean: -20.060757\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.070149\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.079448\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.088654\n","resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.087767\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.096889\n","resetting env. episode 321.000000, reward total was -18.000000. running mean: -20.075920\n","resetting env. episode 322.000000, reward total was -19.000000. running mean: -20.065161\n","resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.064510\n","resetting env. episode 324.000000, reward total was -20.000000. running mean: -20.063864\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.073226\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.082494\n","resetting env. episode 327.000000, reward total was -20.000000. running mean: -20.081669\n","resetting env. episode 328.000000, reward total was -20.000000. running mean: -20.080852\n","resetting env. episode 329.000000, reward total was -20.000000. running mean: -20.080043\n","resetting env. episode 330.000000, reward total was -19.000000. running mean: -20.069243\n","resetting env. episode 331.000000, reward total was -19.000000. running mean: -20.058551\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.067965\n","resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.067285\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.076613\n","resetting env. episode 335.000000, reward total was -19.000000. running mean: -20.065846\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.075188\n","resetting env. episode 337.000000, reward total was -19.000000. running mean: -20.064436\n","resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.063792\n","resetting env. episode 339.000000, reward total was -19.000000. running mean: -20.053154\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.062622\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.071996\n","resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.071276\n","resetting env. episode 343.000000, reward total was -19.000000. running mean: -20.060563\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.069958\n","resetting env. episode 345.000000, reward total was -19.000000. running mean: -20.059258\n","resetting env. episode 346.000000, reward total was -19.000000. running mean: -20.048666\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.058179\n","resetting env. episode 348.000000, reward total was -19.000000. running mean: -20.047597\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.057121\n","resetting env. episode 350.000000, reward total was -20.000000. running mean: -20.056550\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.065984\n","resetting env. episode 352.000000, reward total was -20.000000. running mean: -20.065325\n","resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.064671\n","resetting env. episode 354.000000, reward total was -20.000000. running mean: -20.064025\n","resetting env. episode 355.000000, reward total was -19.000000. running mean: -20.053384\n","resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.052851\n","resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.052322\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.061799\n","resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.061181\n","resetting env. episode 360.000000, reward total was -19.000000. running mean: -20.050569\n","resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.060063\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.069463\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.078768\n","resetting env. episode 364.000000, reward total was -20.000000. running mean: -20.077980\n","resetting env. episode 365.000000, reward total was -19.000000. running mean: -20.067201\n","resetting env. episode 366.000000, reward total was -19.000000. running mean: -20.056529\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.065963\n","resetting env. episode 368.000000, reward total was -20.000000. running mean: -20.065304\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.074651\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.083904\n","resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.093065\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.102134\n","resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.101113\n","resetting env. episode 374.000000, reward total was -19.000000. running mean: -20.090102\n","resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.089201\n","resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.098309\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.107326\n","resetting env. episode 378.000000, reward total was -18.000000. running mean: -20.086253\n","resetting env. episode 379.000000, reward total was -20.000000. running mean: -20.085390\n","resetting env. episode 380.000000, reward total was -17.000000. running mean: -20.054536\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.063991\n","resetting env. episode 382.000000, reward total was -20.000000. running mean: -20.063351\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.062717\n","resetting env. episode 384.000000, reward total was -19.000000. running mean: -20.052090\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.061569\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.070954\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.080244\n","resetting env. episode 388.000000, reward total was -21.000000. running mean: -20.089442\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.098547\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.107562\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.116486\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.125321\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.134068\n","resetting env. episode 394.000000, reward total was -18.000000. running mean: -20.112727\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.111600\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.110484\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.119379\n","resetting env. episode 398.000000, reward total was -20.000000. running mean: -20.118185\n","resetting env. episode 399.000000, reward total was -20.000000. running mean: -20.117004\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.125834\n","resetting env. episode 401.000000, reward total was -20.000000. running mean: -20.124575\n","resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.123329\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.132096\n","resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.130775\n","resetting env. episode 405.000000, reward total was -20.000000. running mean: -20.129467\n","resetting env. episode 406.000000, reward total was -20.000000. running mean: -20.128173\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.136891\n","resetting env. episode 408.000000, reward total was -18.000000. running mean: -20.115522\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.124367\n","resetting env. episode 410.000000, reward total was -18.000000. running mean: -20.103123\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.112092\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.110971\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.119861\n","resetting env. episode 414.000000, reward total was -19.000000. running mean: -20.108663\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.107576\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.116500\n","resetting env. episode 417.000000, reward total was -19.000000. running mean: -20.105335\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.114282\n","resetting env. episode 419.000000, reward total was -20.000000. running mean: -20.113139\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.122008\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.130788\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.139480\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.138085\n","resetting env. episode 424.000000, reward total was -19.000000. running mean: -20.126704\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.125437\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.134183\n","resetting env. episode 427.000000, reward total was -19.000000. running mean: -20.122841\n","resetting env. episode 428.000000, reward total was -20.000000. running mean: -20.121613\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.130396\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.139092\n","resetting env. episode 431.000000, reward total was -19.000000. running mean: -20.127702\n","resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.126425\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.135160\n","resetting env. episode 434.000000, reward total was -19.000000. running mean: -20.123809\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.132571\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.141245\n","resetting env. episode 437.000000, reward total was -20.000000. running mean: -20.139832\n","resetting env. episode 438.000000, reward total was -19.000000. running mean: -20.128434\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.137150\n","resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.135778\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.144420\n","resetting env. episode 442.000000, reward total was -20.000000. running mean: -20.142976\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.151547\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.160031\n","resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.158431\n","resetting env. episode 446.000000, reward total was -20.000000. running mean: -20.156846\n","resetting env. episode 447.000000, reward total was -20.000000. running mean: -20.155278\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.163725\n","resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.162088\n","resetting env. episode 450.000000, reward total was -19.000000. running mean: -20.150467\n","resetting env. episode 451.000000, reward total was -19.000000. running mean: -20.138962\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.147573\n","resetting env. episode 453.000000, reward total was -21.000000. running mean: -20.156097\n","resetting env. episode 454.000000, reward total was -20.000000. running mean: -20.154536\n","resetting env. episode 455.000000, reward total was -20.000000. running mean: -20.152991\n","resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.151461\n","resetting env. episode 457.000000, reward total was -19.000000. running mean: -20.139946\n","resetting env. episode 458.000000, reward total was -19.000000. running mean: -20.128547\n","resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.127261\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.125989\n","resetting env. episode 461.000000, reward total was -18.000000. running mean: -20.104729\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.113681\n","resetting env. episode 463.000000, reward total was -19.000000. running mean: -20.102545\n","resetting env. episode 464.000000, reward total was -18.000000. running mean: -20.081519\n","resetting env. episode 465.000000, reward total was -20.000000. running mean: -20.080704\n","resetting env. episode 466.000000, reward total was -19.000000. running mean: -20.069897\n","resetting env. episode 467.000000, reward total was -20.000000. running mean: -20.069198\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.078506\n","resetting env. episode 469.000000, reward total was -18.000000. running mean: -20.057721\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.067144\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.076472\n","resetting env. episode 472.000000, reward total was -20.000000. running mean: -20.075708\n","resetting env. episode 473.000000, reward total was -19.000000. running mean: -20.064951\n","resetting env. episode 474.000000, reward total was -17.000000. running mean: -20.034301\n","resetting env. episode 475.000000, reward total was -19.000000. running mean: -20.023958\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.033718\n","resetting env. episode 477.000000, reward total was -20.000000. running mean: -20.033381\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.043047\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.042617\n","resetting env. episode 480.000000, reward total was -20.000000. running mean: -20.042191\n","resetting env. episode 481.000000, reward total was -20.000000. running mean: -20.041769\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.041351\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.050938\n","resetting env. episode 484.000000, reward total was -20.000000. running mean: -20.050428\n","resetting env. episode 485.000000, reward total was -18.000000. running mean: -20.029924\n","resetting env. episode 486.000000, reward total was -18.000000. running mean: -20.009625\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.019529\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.029333\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.039040\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.048650\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.058163\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.067581\n","resetting env. episode 493.000000, reward total was -20.000000. running mean: -20.066906\n","resetting env. episode 494.000000, reward total was -20.000000. running mean: -20.066237\n","resetting env. episode 495.000000, reward total was -20.000000. running mean: -20.065574\n","resetting env. episode 496.000000, reward total was -20.000000. running mean: -20.064918\n","resetting env. episode 497.000000, reward total was -19.000000. running mean: -20.054269\n","resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.053727\n","resetting env. episode 499.000000, reward total was -18.000000. running mean: -20.033189\n","resetting env. episode 500.000000, reward total was -20.000000. running mean: -20.032857\n","resetting env. episode 501.000000, reward total was -19.000000. running mean: -20.022529\n","resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.032304\n","resetting env. episode 503.000000, reward total was -20.000000. running mean: -20.031980\n","resetting env. episode 504.000000, reward total was -18.000000. running mean: -20.011661\n","resetting env. episode 505.000000, reward total was -21.000000. running mean: -20.021544\n","resetting env. episode 506.000000, reward total was -20.000000. running mean: -20.021329\n","resetting env. episode 507.000000, reward total was -20.000000. running mean: -20.021115\n","resetting env. episode 508.000000, reward total was -20.000000. running mean: -20.020904\n","resetting env. episode 509.000000, reward total was -21.000000. running mean: -20.030695\n","resetting env. episode 510.000000, reward total was -21.000000. running mean: -20.040388\n","resetting env. episode 511.000000, reward total was -19.000000. running mean: -20.029984\n","resetting env. episode 512.000000, reward total was -21.000000. running mean: -20.039684\n","resetting env. episode 513.000000, reward total was -19.000000. running mean: -20.029288\n","resetting env. episode 514.000000, reward total was -19.000000. running mean: -20.018995\n","resetting env. episode 515.000000, reward total was -19.000000. running mean: -20.008805\n","resetting env. episode 516.000000, reward total was -19.000000. running mean: -19.998717\n","resetting env. episode 517.000000, reward total was -21.000000. running mean: -20.008730\n","resetting env. episode 518.000000, reward total was -21.000000. running mean: -20.018642\n","resetting env. episode 519.000000, reward total was -19.000000. running mean: -20.008456\n","resetting env. episode 520.000000, reward total was -21.000000. running mean: -20.018371\n","resetting env. episode 521.000000, reward total was -20.000000. running mean: -20.018188\n","resetting env. episode 522.000000, reward total was -21.000000. running mean: -20.028006\n","resetting env. episode 523.000000, reward total was -20.000000. running mean: -20.027726\n","resetting env. episode 524.000000, reward total was -20.000000. running mean: -20.027448\n","resetting env. episode 525.000000, reward total was -20.000000. running mean: -20.027174\n","resetting env. episode 526.000000, reward total was -19.000000. running mean: -20.016902\n","resetting env. episode 527.000000, reward total was -20.000000. running mean: -20.016733\n","resetting env. episode 528.000000, reward total was -21.000000. running mean: -20.026566\n","resetting env. episode 529.000000, reward total was -21.000000. running mean: -20.036300\n","resetting env. episode 530.000000, reward total was -18.000000. running mean: -20.015937\n","resetting env. episode 531.000000, reward total was -18.000000. running mean: -19.995778\n","resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.005820\n","resetting env. episode 533.000000, reward total was -21.000000. running mean: -20.015762\n","resetting env. episode 534.000000, reward total was -20.000000. running mean: -20.015604\n","resetting env. episode 535.000000, reward total was -18.000000. running mean: -19.995448\n","resetting env. episode 536.000000, reward total was -21.000000. running mean: -20.005494\n","resetting env. episode 537.000000, reward total was -20.000000. running mean: -20.005439\n","resetting env. episode 538.000000, reward total was -19.000000. running mean: -19.995384\n","resetting env. episode 539.000000, reward total was -21.000000. running mean: -20.005431\n","resetting env. episode 540.000000, reward total was -19.000000. running mean: -19.995376\n","resetting env. episode 541.000000, reward total was -18.000000. running mean: -19.975422\n","resetting env. episode 542.000000, reward total was -21.000000. running mean: -19.985668\n","resetting env. episode 543.000000, reward total was -19.000000. running mean: -19.975812\n","resetting env. episode 544.000000, reward total was -21.000000. running mean: -19.986053\n","resetting env. episode 545.000000, reward total was -21.000000. running mean: -19.996193\n","resetting env. episode 546.000000, reward total was -20.000000. running mean: -19.996231\n","resetting env. episode 547.000000, reward total was -20.000000. running mean: -19.996269\n","resetting env. episode 548.000000, reward total was -21.000000. running mean: -20.006306\n","resetting env. episode 549.000000, reward total was -21.000000. running mean: -20.016243\n","resetting env. episode 550.000000, reward total was -21.000000. running mean: -20.026080\n","resetting env. episode 551.000000, reward total was -20.000000. running mean: -20.025820\n","resetting env. episode 552.000000, reward total was -20.000000. running mean: -20.025561\n","resetting env. episode 553.000000, reward total was -21.000000. running mean: -20.035306\n","resetting env. episode 554.000000, reward total was -21.000000. running mean: -20.044953\n","resetting env. episode 555.000000, reward total was -20.000000. running mean: -20.044503\n","resetting env. episode 556.000000, reward total was -21.000000. running mean: -20.054058\n","resetting env. episode 557.000000, reward total was -20.000000. running mean: -20.053518\n","resetting env. episode 558.000000, reward total was -21.000000. running mean: -20.062982\n","resetting env. episode 559.000000, reward total was -21.000000. running mean: -20.072353\n","resetting env. episode 560.000000, reward total was -20.000000. running mean: -20.071629\n","resetting env. episode 561.000000, reward total was -21.000000. running mean: -20.080913\n","resetting env. episode 562.000000, reward total was -21.000000. running mean: -20.090104\n","resetting env. episode 563.000000, reward total was -20.000000. running mean: -20.089203\n","resetting env. episode 564.000000, reward total was -21.000000. running mean: -20.098311\n","resetting env. episode 565.000000, reward total was -20.000000. running mean: -20.097328\n","resetting env. episode 566.000000, reward total was -21.000000. running mean: -20.106354\n","resetting env. episode 567.000000, reward total was -20.000000. running mean: -20.105291\n","resetting env. episode 568.000000, reward total was -20.000000. running mean: -20.104238\n","resetting env. episode 569.000000, reward total was -19.000000. running mean: -20.093195\n","resetting env. episode 570.000000, reward total was -20.000000. running mean: -20.092263\n","resetting env. episode 571.000000, reward total was -20.000000. running mean: -20.091341\n","resetting env. episode 572.000000, reward total was -20.000000. running mean: -20.090427\n","resetting env. episode 573.000000, reward total was -20.000000. running mean: -20.089523\n","resetting env. episode 574.000000, reward total was -19.000000. running mean: -20.078628\n","resetting env. episode 575.000000, reward total was -20.000000. running mean: -20.077842\n","resetting env. episode 576.000000, reward total was -21.000000. running mean: -20.087063\n","resetting env. episode 577.000000, reward total was -21.000000. running mean: -20.096193\n","resetting env. episode 578.000000, reward total was -19.000000. running mean: -20.085231\n","resetting env. episode 579.000000, reward total was -19.000000. running mean: -20.074378\n","resetting env. episode 580.000000, reward total was -20.000000. running mean: -20.073635\n","resetting env. episode 581.000000, reward total was -21.000000. running mean: -20.082898\n","resetting env. episode 582.000000, reward total was -19.000000. running mean: -20.072069\n","resetting env. episode 583.000000, reward total was -21.000000. running mean: -20.081349\n","resetting env. episode 584.000000, reward total was -20.000000. running mean: -20.080535\n","resetting env. episode 585.000000, reward total was -19.000000. running mean: -20.069730\n","resetting env. episode 586.000000, reward total was -19.000000. running mean: -20.059032\n","resetting env. episode 587.000000, reward total was -20.000000. running mean: -20.058442\n","resetting env. episode 588.000000, reward total was -20.000000. running mean: -20.057858\n","resetting env. episode 589.000000, reward total was -17.000000. running mean: -20.027279\n","resetting env. episode 590.000000, reward total was -20.000000. running mean: -20.027006\n","resetting env. episode 591.000000, reward total was -21.000000. running mean: -20.036736\n","resetting env. episode 592.000000, reward total was -21.000000. running mean: -20.046369\n","resetting env. episode 593.000000, reward total was -20.000000. running mean: -20.045905\n","resetting env. episode 594.000000, reward total was -19.000000. running mean: -20.035446\n","resetting env. episode 595.000000, reward total was -20.000000. running mean: -20.035092\n","resetting env. episode 596.000000, reward total was -18.000000. running mean: -20.014741\n","resetting env. episode 597.000000, reward total was -21.000000. running mean: -20.024593\n","resetting env. episode 598.000000, reward total was -21.000000. running mean: -20.034347\n","resetting env. episode 599.000000, reward total was -20.000000. running mean: -20.034004\n","resetting env. episode 600.000000, reward total was -21.000000. running mean: -20.043664\n","resetting env. episode 601.000000, reward total was -18.000000. running mean: -20.023227\n","resetting env. episode 602.000000, reward total was -18.000000. running mean: -20.002995\n","resetting env. episode 603.000000, reward total was -20.000000. running mean: -20.002965\n","resetting env. episode 604.000000, reward total was -21.000000. running mean: -20.012935\n","resetting env. episode 605.000000, reward total was -21.000000. running mean: -20.022806\n","resetting env. episode 606.000000, reward total was -19.000000. running mean: -20.012578\n","resetting env. episode 607.000000, reward total was -20.000000. running mean: -20.012452\n","resetting env. episode 608.000000, reward total was -21.000000. running mean: -20.022328\n","resetting env. episode 609.000000, reward total was -20.000000. running mean: -20.022104\n","resetting env. episode 610.000000, reward total was -20.000000. running mean: -20.021883\n","resetting env. episode 611.000000, reward total was -19.000000. running mean: -20.011665\n","resetting env. episode 612.000000, reward total was -21.000000. running mean: -20.021548\n","resetting env. episode 613.000000, reward total was -20.000000. running mean: -20.021332\n","resetting env. episode 614.000000, reward total was -19.000000. running mean: -20.011119\n","resetting env. episode 615.000000, reward total was -21.000000. running mean: -20.021008\n","resetting env. episode 616.000000, reward total was -21.000000. running mean: -20.030798\n","resetting env. episode 617.000000, reward total was -20.000000. running mean: -20.030490\n","resetting env. episode 618.000000, reward total was -18.000000. running mean: -20.010185\n","resetting env. episode 619.000000, reward total was -21.000000. running mean: -20.020083\n","resetting env. episode 620.000000, reward total was -21.000000. running mean: -20.029882\n","resetting env. episode 621.000000, reward total was -21.000000. running mean: -20.039583\n","resetting env. episode 622.000000, reward total was -18.000000. running mean: -20.019188\n","resetting env. episode 623.000000, reward total was -21.000000. running mean: -20.028996\n","resetting env. episode 624.000000, reward total was -20.000000. running mean: -20.028706\n","resetting env. episode 625.000000, reward total was -21.000000. running mean: -20.038419\n","resetting env. episode 626.000000, reward total was -20.000000. running mean: -20.038035\n","resetting env. episode 627.000000, reward total was -19.000000. running mean: -20.027654\n","resetting env. episode 628.000000, reward total was -18.000000. running mean: -20.007378\n","resetting env. episode 629.000000, reward total was -20.000000. running mean: -20.007304\n","resetting env. episode 630.000000, reward total was -20.000000. running mean: -20.007231\n","resetting env. episode 631.000000, reward total was -21.000000. running mean: -20.017159\n","resetting env. episode 632.000000, reward total was -21.000000. running mean: -20.026987\n","resetting env. episode 633.000000, reward total was -20.000000. running mean: -20.026717\n","resetting env. episode 634.000000, reward total was -20.000000. running mean: -20.026450\n","resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.036185\n","resetting env. episode 636.000000, reward total was -21.000000. running mean: -20.045824\n","resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.055365\n","resetting env. episode 638.000000, reward total was -21.000000. running mean: -20.064812\n","resetting env. episode 639.000000, reward total was -20.000000. running mean: -20.064164\n","resetting env. episode 640.000000, reward total was -19.000000. running mean: -20.053522\n","resetting env. episode 641.000000, reward total was -19.000000. running mean: -20.042987\n","resetting env. episode 642.000000, reward total was -21.000000. running mean: -20.052557\n","resetting env. episode 643.000000, reward total was -19.000000. running mean: -20.042031\n","resetting env. episode 644.000000, reward total was -21.000000. running mean: -20.051611\n","resetting env. episode 645.000000, reward total was -21.000000. running mean: -20.061095\n","resetting env. episode 646.000000, reward total was -18.000000. running mean: -20.040484\n","resetting env. episode 647.000000, reward total was -21.000000. running mean: -20.050079\n","resetting env. episode 648.000000, reward total was -20.000000. running mean: -20.049578\n","resetting env. episode 649.000000, reward total was -21.000000. running mean: -20.059082\n","resetting env. episode 650.000000, reward total was -20.000000. running mean: -20.058492\n","resetting env. episode 651.000000, reward total was -17.000000. running mean: -20.027907\n","resetting env. episode 652.000000, reward total was -21.000000. running mean: -20.037628\n","resetting env. episode 653.000000, reward total was -20.000000. running mean: -20.037251\n","resetting env. episode 654.000000, reward total was -21.000000. running mean: -20.046879\n","resetting env. episode 655.000000, reward total was -20.000000. running mean: -20.046410\n","resetting env. episode 656.000000, reward total was -20.000000. running mean: -20.045946\n","resetting env. episode 657.000000, reward total was -20.000000. running mean: -20.045487\n","resetting env. episode 658.000000, reward total was -19.000000. running mean: -20.035032\n","resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.044681\n","resetting env. episode 660.000000, reward total was -17.000000. running mean: -20.014235\n","resetting env. episode 661.000000, reward total was -21.000000. running mean: -20.024092\n","resetting env. episode 662.000000, reward total was -19.000000. running mean: -20.013851\n","resetting env. episode 663.000000, reward total was -21.000000. running mean: -20.023713\n","resetting env. episode 664.000000, reward total was -21.000000. running mean: -20.033476\n","resetting env. episode 665.000000, reward total was -21.000000. running mean: -20.043141\n","resetting env. episode 666.000000, reward total was -21.000000. running mean: -20.052709\n","resetting env. episode 667.000000, reward total was -18.000000. running mean: -20.032182\n","resetting env. episode 668.000000, reward total was -20.000000. running mean: -20.031861\n","resetting env. episode 669.000000, reward total was -21.000000. running mean: -20.041542\n","resetting env. episode 670.000000, reward total was -20.000000. running mean: -20.041127\n","resetting env. episode 671.000000, reward total was -18.000000. running mean: -20.020715\n","resetting env. episode 672.000000, reward total was -21.000000. running mean: -20.030508\n","resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.040203\n","resetting env. episode 674.000000, reward total was -21.000000. running mean: -20.049801\n","resetting env. episode 675.000000, reward total was -18.000000. running mean: -20.029303\n","resetting env. episode 676.000000, reward total was -19.000000. running mean: -20.019010\n","resetting env. episode 677.000000, reward total was -21.000000. running mean: -20.028820\n","resetting env. episode 678.000000, reward total was -20.000000. running mean: -20.028532\n","resetting env. episode 679.000000, reward total was -20.000000. running mean: -20.028246\n","resetting env. episode 680.000000, reward total was -20.000000. running mean: -20.027964\n","resetting env. episode 681.000000, reward total was -20.000000. running mean: -20.027684\n","resetting env. episode 682.000000, reward total was -21.000000. running mean: -20.037407\n","resetting env. episode 683.000000, reward total was -21.000000. running mean: -20.047033\n","resetting env. episode 684.000000, reward total was -19.000000. running mean: -20.036563\n","resetting env. episode 685.000000, reward total was -21.000000. running mean: -20.046197\n","resetting env. episode 686.000000, reward total was -21.000000. running mean: -20.055735\n","resetting env. episode 687.000000, reward total was -20.000000. running mean: -20.055178\n","resetting env. episode 688.000000, reward total was -18.000000. running mean: -20.034626\n","resetting env. episode 689.000000, reward total was -21.000000. running mean: -20.044280\n","resetting env. episode 690.000000, reward total was -20.000000. running mean: -20.043837\n","resetting env. episode 691.000000, reward total was -18.000000. running mean: -20.023399\n","resetting env. episode 692.000000, reward total was -21.000000. running mean: -20.033165\n","resetting env. episode 693.000000, reward total was -21.000000. running mean: -20.042833\n","resetting env. episode 694.000000, reward total was -20.000000. running mean: -20.042405\n","resetting env. episode 695.000000, reward total was -18.000000. running mean: -20.021981\n","resetting env. episode 696.000000, reward total was -20.000000. running mean: -20.021761\n","resetting env. episode 697.000000, reward total was -18.000000. running mean: -20.001543\n","resetting env. episode 698.000000, reward total was -21.000000. running mean: -20.011528\n","resetting env. episode 699.000000, reward total was -21.000000. running mean: -20.021413\n","resetting env. episode 700.000000, reward total was -21.000000. running mean: -20.031199\n","resetting env. episode 701.000000, reward total was -20.000000. running mean: -20.030887\n","resetting env. episode 702.000000, reward total was -20.000000. running mean: -20.030578\n","resetting env. episode 703.000000, reward total was -20.000000. running mean: -20.030272\n","resetting env. episode 704.000000, reward total was -20.000000. running mean: -20.029969\n","resetting env. episode 705.000000, reward total was -20.000000. running mean: -20.029669\n","resetting env. episode 706.000000, reward total was -21.000000. running mean: -20.039373\n","resetting env. episode 707.000000, reward total was -21.000000. running mean: -20.048979\n","resetting env. episode 708.000000, reward total was -19.000000. running mean: -20.038489\n","resetting env. episode 709.000000, reward total was -19.000000. running mean: -20.028104\n","resetting env. episode 710.000000, reward total was -20.000000. running mean: -20.027823\n","resetting env. episode 711.000000, reward total was -21.000000. running mean: -20.037545\n","resetting env. episode 712.000000, reward total was -19.000000. running mean: -20.027170\n","resetting env. episode 713.000000, reward total was -19.000000. running mean: -20.016898\n","resetting env. episode 714.000000, reward total was -21.000000. running mean: -20.026729\n","resetting env. episode 715.000000, reward total was -19.000000. running mean: -20.016462\n","resetting env. episode 716.000000, reward total was -20.000000. running mean: -20.016297\n","resetting env. episode 717.000000, reward total was -20.000000. running mean: -20.016134\n","resetting env. episode 718.000000, reward total was -21.000000. running mean: -20.025973\n","resetting env. episode 719.000000, reward total was -19.000000. running mean: -20.015713\n","resetting env. episode 720.000000, reward total was -21.000000. running mean: -20.025556\n","resetting env. episode 721.000000, reward total was -21.000000. running mean: -20.035300\n","resetting env. episode 722.000000, reward total was -21.000000. running mean: -20.044947\n","resetting env. episode 723.000000, reward total was -21.000000. running mean: -20.054498\n","resetting env. episode 724.000000, reward total was -21.000000. running mean: -20.063953\n","resetting env. episode 725.000000, reward total was -21.000000. running mean: -20.073313\n","resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.082580\n","resetting env. episode 727.000000, reward total was -21.000000. running mean: -20.091754\n","resetting env. episode 728.000000, reward total was -20.000000. running mean: -20.090837\n","resetting env. episode 729.000000, reward total was -20.000000. running mean: -20.089929\n","resetting env. episode 730.000000, reward total was -19.000000. running mean: -20.079029\n","resetting env. episode 731.000000, reward total was -19.000000. running mean: -20.068239\n","resetting env. episode 732.000000, reward total was -20.000000. running mean: -20.067557\n","resetting env. episode 733.000000, reward total was -21.000000. running mean: -20.076881\n","resetting env. episode 734.000000, reward total was -21.000000. running mean: -20.086112\n","resetting env. episode 735.000000, reward total was -19.000000. running mean: -20.075251\n","resetting env. episode 736.000000, reward total was -20.000000. running mean: -20.074499\n","resetting env. episode 737.000000, reward total was -19.000000. running mean: -20.063754\n","resetting env. episode 738.000000, reward total was -20.000000. running mean: -20.063116\n","resetting env. episode 739.000000, reward total was -20.000000. running mean: -20.062485\n","resetting env. episode 740.000000, reward total was -20.000000. running mean: -20.061860\n","resetting env. episode 741.000000, reward total was -18.000000. running mean: -20.041241\n","resetting env. episode 742.000000, reward total was -21.000000. running mean: -20.050829\n","resetting env. episode 743.000000, reward total was -20.000000. running mean: -20.050321\n","resetting env. episode 744.000000, reward total was -20.000000. running mean: -20.049817\n","resetting env. episode 745.000000, reward total was -18.000000. running mean: -20.029319\n","resetting env. episode 746.000000, reward total was -20.000000. running mean: -20.029026\n","resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.038736\n","resetting env. episode 748.000000, reward total was -20.000000. running mean: -20.038349\n","resetting env. episode 749.000000, reward total was -19.000000. running mean: -20.027965\n","resetting env. episode 750.000000, reward total was -21.000000. running mean: -20.037685\n","resetting env. episode 751.000000, reward total was -20.000000. running mean: -20.037309\n","resetting env. episode 752.000000, reward total was -21.000000. running mean: -20.046935\n","resetting env. episode 753.000000, reward total was -17.000000. running mean: -20.016466\n","resetting env. episode 754.000000, reward total was -19.000000. running mean: -20.006301\n","resetting env. episode 755.000000, reward total was -21.000000. running mean: -20.016238\n","resetting env. episode 756.000000, reward total was -17.000000. running mean: -19.986076\n","resetting env. episode 757.000000, reward total was -21.000000. running mean: -19.996215\n","resetting env. episode 758.000000, reward total was -21.000000. running mean: -20.006253\n","resetting env. episode 759.000000, reward total was -19.000000. running mean: -19.996191\n","resetting env. episode 760.000000, reward total was -17.000000. running mean: -19.966229\n","resetting env. episode 761.000000, reward total was -19.000000. running mean: -19.956566\n","resetting env. episode 762.000000, reward total was -20.000000. running mean: -19.957001\n","resetting env. episode 763.000000, reward total was -20.000000. running mean: -19.957431\n","resetting env. episode 764.000000, reward total was -18.000000. running mean: -19.937856\n","resetting env. episode 765.000000, reward total was -18.000000. running mean: -19.918478\n","resetting env. episode 766.000000, reward total was -18.000000. running mean: -19.899293\n","resetting env. episode 767.000000, reward total was -19.000000. running mean: -19.890300\n","resetting env. episode 768.000000, reward total was -21.000000. running mean: -19.901397\n","resetting env. episode 769.000000, reward total was -20.000000. running mean: -19.902383\n","resetting env. episode 770.000000, reward total was -20.000000. running mean: -19.903359\n","resetting env. episode 771.000000, reward total was -18.000000. running mean: -19.884326\n","resetting env. episode 772.000000, reward total was -20.000000. running mean: -19.885482\n","resetting env. episode 773.000000, reward total was -20.000000. running mean: -19.886628\n","resetting env. episode 774.000000, reward total was -19.000000. running mean: -19.877761\n","resetting env. episode 775.000000, reward total was -21.000000. running mean: -19.888984\n","resetting env. episode 776.000000, reward total was -17.000000. running mean: -19.860094\n","resetting env. episode 777.000000, reward total was -21.000000. running mean: -19.871493\n","resetting env. episode 778.000000, reward total was -20.000000. running mean: -19.872778\n","resetting env. episode 779.000000, reward total was -20.000000. running mean: -19.874050\n","resetting env. episode 780.000000, reward total was -21.000000. running mean: -19.885310\n","resetting env. episode 781.000000, reward total was -21.000000. running mean: -19.896457\n","resetting env. episode 782.000000, reward total was -20.000000. running mean: -19.897492\n","resetting env. episode 783.000000, reward total was -21.000000. running mean: -19.908517\n","resetting env. episode 784.000000, reward total was -21.000000. running mean: -19.919432\n","resetting env. episode 785.000000, reward total was -19.000000. running mean: -19.910238\n","resetting env. episode 786.000000, reward total was -20.000000. running mean: -19.911135\n","resetting env. episode 787.000000, reward total was -21.000000. running mean: -19.922024\n","resetting env. episode 788.000000, reward total was -20.000000. running mean: -19.922804\n","resetting env. episode 789.000000, reward total was -20.000000. running mean: -19.923576\n","resetting env. episode 790.000000, reward total was -21.000000. running mean: -19.934340\n","resetting env. episode 791.000000, reward total was -20.000000. running mean: -19.934997\n","resetting env. episode 792.000000, reward total was -21.000000. running mean: -19.945647\n","resetting env. episode 793.000000, reward total was -21.000000. running mean: -19.956190\n","resetting env. episode 794.000000, reward total was -21.000000. running mean: -19.966628\n","resetting env. episode 795.000000, reward total was -21.000000. running mean: -19.976962\n","resetting env. episode 796.000000, reward total was -20.000000. running mean: -19.977192\n","resetting env. episode 797.000000, reward total was -19.000000. running mean: -19.967420\n","resetting env. episode 798.000000, reward total was -18.000000. running mean: -19.947746\n","resetting env. episode 799.000000, reward total was -19.000000. running mean: -19.938269\n","resetting env. episode 800.000000, reward total was -20.000000. running mean: -19.938886\n","resetting env. episode 801.000000, reward total was -20.000000. running mean: -19.939497\n","resetting env. episode 802.000000, reward total was -21.000000. running mean: -19.950102\n","resetting env. episode 803.000000, reward total was -19.000000. running mean: -19.940601\n","resetting env. episode 804.000000, reward total was -19.000000. running mean: -19.931195\n","resetting env. episode 805.000000, reward total was -21.000000. running mean: -19.941883\n","resetting env. episode 806.000000, reward total was -20.000000. running mean: -19.942464\n","resetting env. episode 807.000000, reward total was -21.000000. running mean: -19.953040\n","resetting env. episode 808.000000, reward total was -21.000000. running mean: -19.963509\n","resetting env. episode 809.000000, reward total was -20.000000. running mean: -19.963874\n","resetting env. episode 810.000000, reward total was -21.000000. running mean: -19.974235\n","resetting env. episode 811.000000, reward total was -20.000000. running mean: -19.974493\n","resetting env. episode 812.000000, reward total was -21.000000. running mean: -19.984748\n","resetting env. episode 813.000000, reward total was -21.000000. running mean: -19.994901\n","resetting env. episode 814.000000, reward total was -21.000000. running mean: -20.004952\n","resetting env. episode 815.000000, reward total was -20.000000. running mean: -20.004902\n","resetting env. episode 816.000000, reward total was -21.000000. running mean: -20.014853\n","resetting env. episode 817.000000, reward total was -19.000000. running mean: -20.004705\n","resetting env. episode 818.000000, reward total was -20.000000. running mean: -20.004658\n","resetting env. episode 819.000000, reward total was -18.000000. running mean: -19.984611\n","resetting env. episode 820.000000, reward total was -21.000000. running mean: -19.994765\n","resetting env. episode 821.000000, reward total was -20.000000. running mean: -19.994817\n","resetting env. episode 822.000000, reward total was -20.000000. running mean: -19.994869\n","resetting env. episode 823.000000, reward total was -19.000000. running mean: -19.984920\n","resetting env. episode 824.000000, reward total was -21.000000. running mean: -19.995071\n","resetting env. episode 825.000000, reward total was -21.000000. running mean: -20.005120\n","resetting env. episode 826.000000, reward total was -21.000000. running mean: -20.015069\n","resetting env. episode 827.000000, reward total was -20.000000. running mean: -20.014919\n","resetting env. episode 828.000000, reward total was -20.000000. running mean: -20.014769\n","resetting env. episode 829.000000, reward total was -20.000000. running mean: -20.014622\n","resetting env. episode 830.000000, reward total was -21.000000. running mean: -20.024475\n","resetting env. episode 831.000000, reward total was -20.000000. running mean: -20.024231\n","resetting env. episode 832.000000, reward total was -20.000000. running mean: -20.023988\n","resetting env. episode 833.000000, reward total was -21.000000. running mean: -20.033749\n","resetting env. episode 834.000000, reward total was -18.000000. running mean: -20.013411\n","resetting env. episode 835.000000, reward total was -19.000000. running mean: -20.003277\n","resetting env. episode 836.000000, reward total was -19.000000. running mean: -19.993244\n","resetting env. episode 837.000000, reward total was -18.000000. running mean: -19.973312\n","resetting env. episode 838.000000, reward total was -18.000000. running mean: -19.953579\n","resetting env. episode 839.000000, reward total was -21.000000. running mean: -19.964043\n","resetting env. episode 840.000000, reward total was -18.000000. running mean: -19.944402\n","resetting env. episode 841.000000, reward total was -18.000000. running mean: -19.924958\n","resetting env. episode 842.000000, reward total was -19.000000. running mean: -19.915709\n","resetting env. episode 843.000000, reward total was -21.000000. running mean: -19.926552\n","resetting env. episode 844.000000, reward total was -21.000000. running mean: -19.937286\n","resetting env. episode 845.000000, reward total was -18.000000. running mean: -19.917913\n","resetting env. episode 846.000000, reward total was -21.000000. running mean: -19.928734\n","resetting env. episode 847.000000, reward total was -17.000000. running mean: -19.899447\n","resetting env. episode 848.000000, reward total was -20.000000. running mean: -19.900452\n","resetting env. episode 849.000000, reward total was -21.000000. running mean: -19.911448\n","resetting env. episode 850.000000, reward total was -21.000000. running mean: -19.922333\n","resetting env. episode 851.000000, reward total was -20.000000. running mean: -19.923110\n","resetting env. episode 852.000000, reward total was -19.000000. running mean: -19.913879\n","resetting env. episode 853.000000, reward total was -20.000000. running mean: -19.914740\n","resetting env. episode 854.000000, reward total was -19.000000. running mean: -19.905593\n","resetting env. episode 855.000000, reward total was -18.000000. running mean: -19.886537\n","resetting env. episode 856.000000, reward total was -21.000000. running mean: -19.897671\n","resetting env. episode 857.000000, reward total was -19.000000. running mean: -19.888695\n","resetting env. episode 858.000000, reward total was -21.000000. running mean: -19.899808\n","resetting env. episode 859.000000, reward total was -21.000000. running mean: -19.910810\n","resetting env. episode 860.000000, reward total was -20.000000. running mean: -19.911702\n","resetting env. episode 861.000000, reward total was -20.000000. running mean: -19.912585\n","resetting env. episode 862.000000, reward total was -19.000000. running mean: -19.903459\n","resetting env. episode 863.000000, reward total was -19.000000. running mean: -19.894424\n","resetting env. episode 864.000000, reward total was -19.000000. running mean: -19.885480\n","resetting env. episode 865.000000, reward total was -19.000000. running mean: -19.876625\n","resetting env. episode 866.000000, reward total was -20.000000. running mean: -19.877859\n","resetting env. episode 867.000000, reward total was -21.000000. running mean: -19.889080\n","resetting env. episode 868.000000, reward total was -21.000000. running mean: -19.900189\n","resetting env. episode 869.000000, reward total was -19.000000. running mean: -19.891188\n","resetting env. episode 870.000000, reward total was -21.000000. running mean: -19.902276\n","resetting env. episode 871.000000, reward total was -17.000000. running mean: -19.873253\n","resetting env. episode 872.000000, reward total was -19.000000. running mean: -19.864520\n","resetting env. episode 873.000000, reward total was -21.000000. running mean: -19.875875\n","resetting env. episode 874.000000, reward total was -20.000000. running mean: -19.877116\n","resetting env. episode 875.000000, reward total was -20.000000. running mean: -19.878345\n","resetting env. episode 876.000000, reward total was -21.000000. running mean: -19.889562\n","resetting env. episode 877.000000, reward total was -21.000000. running mean: -19.900666\n","resetting env. episode 878.000000, reward total was -21.000000. running mean: -19.911660\n","resetting env. episode 879.000000, reward total was -19.000000. running mean: -19.902543\n","resetting env. episode 880.000000, reward total was -19.000000. running mean: -19.893518\n","resetting env. episode 881.000000, reward total was -21.000000. running mean: -19.904582\n","resetting env. episode 882.000000, reward total was -19.000000. running mean: -19.895537\n","resetting env. episode 883.000000, reward total was -20.000000. running mean: -19.896581\n","resetting env. episode 884.000000, reward total was -18.000000. running mean: -19.877615\n","resetting env. episode 885.000000, reward total was -20.000000. running mean: -19.878839\n","resetting env. episode 886.000000, reward total was -20.000000. running mean: -19.880051\n","resetting env. episode 887.000000, reward total was -18.000000. running mean: -19.861250\n","resetting env. episode 888.000000, reward total was -18.000000. running mean: -19.842638\n","resetting env. episode 889.000000, reward total was -19.000000. running mean: -19.834211\n","resetting env. episode 890.000000, reward total was -20.000000. running mean: -19.835869\n","resetting env. episode 891.000000, reward total was -18.000000. running mean: -19.817511\n","resetting env. episode 892.000000, reward total was -19.000000. running mean: -19.809336\n","resetting env. episode 893.000000, reward total was -21.000000. running mean: -19.821242\n","resetting env. episode 894.000000, reward total was -21.000000. running mean: -19.833030\n","resetting env. episode 895.000000, reward total was -19.000000. running mean: -19.824699\n","resetting env. episode 896.000000, reward total was -19.000000. running mean: -19.816452\n","resetting env. episode 897.000000, reward total was -21.000000. running mean: -19.828288\n","resetting env. episode 898.000000, reward total was -21.000000. running mean: -19.840005\n","resetting env. episode 899.000000, reward total was -20.000000. running mean: -19.841605\n","resetting env. episode 900.000000, reward total was -20.000000. running mean: -19.843189\n","resetting env. episode 901.000000, reward total was -20.000000. running mean: -19.844757\n","resetting env. episode 902.000000, reward total was -21.000000. running mean: -19.856309\n","resetting env. episode 903.000000, reward total was -20.000000. running mean: -19.857746\n","resetting env. episode 904.000000, reward total was -21.000000. running mean: -19.869169\n","resetting env. episode 905.000000, reward total was -20.000000. running mean: -19.870477\n","resetting env. episode 906.000000, reward total was -20.000000. running mean: -19.871772\n","resetting env. episode 907.000000, reward total was -18.000000. running mean: -19.853055\n","resetting env. episode 908.000000, reward total was -21.000000. running mean: -19.864524\n","resetting env. episode 909.000000, reward total was -21.000000. running mean: -19.875879\n","resetting env. episode 910.000000, reward total was -18.000000. running mean: -19.857120\n","resetting env. episode 911.000000, reward total was -18.000000. running mean: -19.838549\n","resetting env. episode 912.000000, reward total was -21.000000. running mean: -19.850163\n","resetting env. episode 913.000000, reward total was -18.000000. running mean: -19.831662\n","resetting env. episode 914.000000, reward total was -20.000000. running mean: -19.833345\n","resetting env. episode 915.000000, reward total was -19.000000. running mean: -19.825012\n","resetting env. episode 916.000000, reward total was -20.000000. running mean: -19.826762\n","resetting env. episode 917.000000, reward total was -20.000000. running mean: -19.828494\n","resetting env. episode 918.000000, reward total was -21.000000. running mean: -19.840209\n","resetting env. episode 919.000000, reward total was -18.000000. running mean: -19.821807\n","resetting env. episode 920.000000, reward total was -21.000000. running mean: -19.833589\n","resetting env. episode 921.000000, reward total was -19.000000. running mean: -19.825253\n","resetting env. episode 922.000000, reward total was -20.000000. running mean: -19.827001\n","resetting env. episode 923.000000, reward total was -21.000000. running mean: -19.838731\n","resetting env. episode 924.000000, reward total was -19.000000. running mean: -19.830343\n","resetting env. episode 925.000000, reward total was -21.000000. running mean: -19.842040\n","resetting env. episode 926.000000, reward total was -21.000000. running mean: -19.853619\n","resetting env. episode 927.000000, reward total was -21.000000. running mean: -19.865083\n","resetting env. episode 928.000000, reward total was -16.000000. running mean: -19.826432\n","resetting env. episode 929.000000, reward total was -19.000000. running mean: -19.818168\n","resetting env. episode 930.000000, reward total was -20.000000. running mean: -19.819986\n","resetting env. episode 931.000000, reward total was -19.000000. running mean: -19.811786\n","resetting env. episode 932.000000, reward total was -19.000000. running mean: -19.803669\n","resetting env. episode 933.000000, reward total was -19.000000. running mean: -19.795632\n","resetting env. episode 934.000000, reward total was -19.000000. running mean: -19.787676\n","resetting env. episode 935.000000, reward total was -20.000000. running mean: -19.789799\n","resetting env. episode 936.000000, reward total was -21.000000. running mean: -19.801901\n","resetting env. episode 937.000000, reward total was -21.000000. running mean: -19.813882\n","resetting env. episode 938.000000, reward total was -18.000000. running mean: -19.795743\n","resetting env. episode 939.000000, reward total was -20.000000. running mean: -19.797786\n","resetting env. episode 940.000000, reward total was -20.000000. running mean: -19.799808\n","resetting env. episode 941.000000, reward total was -20.000000. running mean: -19.801810\n","resetting env. episode 942.000000, reward total was -20.000000. running mean: -19.803792\n","resetting env. episode 943.000000, reward total was -17.000000. running mean: -19.775754\n","resetting env. episode 944.000000, reward total was -20.000000. running mean: -19.777996\n","resetting env. episode 945.000000, reward total was -20.000000. running mean: -19.780216\n","resetting env. episode 946.000000, reward total was -17.000000. running mean: -19.752414\n","resetting env. episode 947.000000, reward total was -20.000000. running mean: -19.754890\n","resetting env. episode 948.000000, reward total was -20.000000. running mean: -19.757341\n","resetting env. episode 949.000000, reward total was -18.000000. running mean: -19.739768\n","resetting env. episode 950.000000, reward total was -20.000000. running mean: -19.742370\n","resetting env. episode 951.000000, reward total was -21.000000. running mean: -19.754946\n","resetting env. episode 952.000000, reward total was -21.000000. running mean: -19.767397\n","resetting env. episode 953.000000, reward total was -20.000000. running mean: -19.769723\n","resetting env. episode 954.000000, reward total was -20.000000. running mean: -19.772026\n","resetting env. episode 955.000000, reward total was -21.000000. running mean: -19.784305\n","resetting env. episode 956.000000, reward total was -21.000000. running mean: -19.796462\n","resetting env. episode 957.000000, reward total was -21.000000. running mean: -19.808498\n","resetting env. episode 958.000000, reward total was -20.000000. running mean: -19.810413\n","resetting env. episode 959.000000, reward total was -21.000000. running mean: -19.822308\n","resetting env. episode 960.000000, reward total was -20.000000. running mean: -19.824085\n","resetting env. episode 961.000000, reward total was -20.000000. running mean: -19.825845\n","resetting env. episode 962.000000, reward total was -21.000000. running mean: -19.837586\n","resetting env. episode 963.000000, reward total was -20.000000. running mean: -19.839210\n","resetting env. episode 964.000000, reward total was -18.000000. running mean: -19.820818\n","resetting env. episode 965.000000, reward total was -21.000000. running mean: -19.832610\n","resetting env. episode 966.000000, reward total was -21.000000. running mean: -19.844284\n","resetting env. episode 967.000000, reward total was -21.000000. running mean: -19.855841\n","resetting env. episode 968.000000, reward total was -19.000000. running mean: -19.847283\n","resetting env. episode 969.000000, reward total was -19.000000. running mean: -19.838810\n","resetting env. episode 970.000000, reward total was -21.000000. running mean: -19.850422\n","resetting env. episode 971.000000, reward total was -21.000000. running mean: -19.861917\n","resetting env. episode 972.000000, reward total was -18.000000. running mean: -19.843298\n","resetting env. episode 973.000000, reward total was -21.000000. running mean: -19.854865\n","resetting env. episode 974.000000, reward total was -20.000000. running mean: -19.856317\n","resetting env. episode 975.000000, reward total was -21.000000. running mean: -19.867753\n","resetting env. episode 976.000000, reward total was -19.000000. running mean: -19.859076\n","resetting env. episode 977.000000, reward total was -20.000000. running mean: -19.860485\n","resetting env. episode 978.000000, reward total was -20.000000. running mean: -19.861880\n","resetting env. episode 979.000000, reward total was -17.000000. running mean: -19.833262\n","resetting env. episode 980.000000, reward total was -19.000000. running mean: -19.824929\n","resetting env. episode 981.000000, reward total was -20.000000. running mean: -19.826680\n","resetting env. episode 982.000000, reward total was -18.000000. running mean: -19.808413\n","resetting env. episode 983.000000, reward total was -21.000000. running mean: -19.820329\n","resetting env. episode 984.000000, reward total was -21.000000. running mean: -19.832125\n","resetting env. episode 985.000000, reward total was -19.000000. running mean: -19.823804\n","resetting env. episode 986.000000, reward total was -21.000000. running mean: -19.835566\n","resetting env. episode 987.000000, reward total was -18.000000. running mean: -19.817210\n","resetting env. episode 988.000000, reward total was -20.000000. running mean: -19.819038\n","resetting env. episode 989.000000, reward total was -21.000000. running mean: -19.830848\n","resetting env. episode 990.000000, reward total was -21.000000. running mean: -19.842540\n","resetting env. episode 991.000000, reward total was -21.000000. running mean: -19.854114\n","resetting env. episode 992.000000, reward total was -21.000000. running mean: -19.865573\n","resetting env. episode 993.000000, reward total was -18.000000. running mean: -19.846917\n","resetting env. episode 994.000000, reward total was -19.000000. running mean: -19.838448\n","resetting env. episode 995.000000, reward total was -21.000000. running mean: -19.850064\n","resetting env. episode 996.000000, reward total was -17.000000. running mean: -19.821563\n","resetting env. episode 997.000000, reward total was -19.000000. running mean: -19.813347\n","resetting env. episode 998.000000, reward total was -21.000000. running mean: -19.825214\n","resetting env. episode 999.000000, reward total was -19.000000. running mean: -19.816962\n","resetting env. episode 1000.000000, reward total was -19.000000. running mean: -19.808792\n","resetting env. episode 1001.000000, reward total was -21.000000. running mean: -19.820704\n","resetting env. episode 1002.000000, reward total was -21.000000. running mean: -19.832497\n","resetting env. episode 1003.000000, reward total was -19.000000. running mean: -19.824172\n","resetting env. episode 1004.000000, reward total was -20.000000. running mean: -19.825930\n","resetting env. episode 1005.000000, reward total was -20.000000. running mean: -19.827671\n","resetting env. episode 1006.000000, reward total was -21.000000. running mean: -19.839394\n","resetting env. episode 1007.000000, reward total was -19.000000. running mean: -19.831000\n","resetting env. episode 1008.000000, reward total was -17.000000. running mean: -19.802690\n","resetting env. episode 1009.000000, reward total was -19.000000. running mean: -19.794664\n","resetting env. episode 1010.000000, reward total was -18.000000. running mean: -19.776717\n","resetting env. episode 1011.000000, reward total was -19.000000. running mean: -19.768950\n","resetting env. episode 1012.000000, reward total was -18.000000. running mean: -19.751260\n","resetting env. episode 1013.000000, reward total was -20.000000. running mean: -19.753748\n","resetting env. episode 1014.000000, reward total was -21.000000. running mean: -19.766210\n","resetting env. episode 1015.000000, reward total was -20.000000. running mean: -19.768548\n","resetting env. episode 1016.000000, reward total was -19.000000. running mean: -19.760863\n","resetting env. episode 1017.000000, reward total was -17.000000. running mean: -19.733254\n","resetting env. episode 1018.000000, reward total was -20.000000. running mean: -19.735921\n","resetting env. episode 1019.000000, reward total was -21.000000. running mean: -19.748562\n","resetting env. episode 1020.000000, reward total was -21.000000. running mean: -19.761077\n","resetting env. episode 1021.000000, reward total was -19.000000. running mean: -19.753466\n","resetting env. episode 1022.000000, reward total was -19.000000. running mean: -19.745931\n","resetting env. episode 1023.000000, reward total was -21.000000. running mean: -19.758472\n","resetting env. episode 1024.000000, reward total was -18.000000. running mean: -19.740887\n","resetting env. episode 1025.000000, reward total was -19.000000. running mean: -19.733478\n","resetting env. episode 1026.000000, reward total was -21.000000. running mean: -19.746143\n","resetting env. episode 1027.000000, reward total was -20.000000. running mean: -19.748682\n","resetting env. episode 1028.000000, reward total was -19.000000. running mean: -19.741195\n","resetting env. episode 1029.000000, reward total was -19.000000. running mean: -19.733783\n","resetting env. episode 1030.000000, reward total was -21.000000. running mean: -19.746445\n","resetting env. episode 1031.000000, reward total was -21.000000. running mean: -19.758981\n","resetting env. episode 1032.000000, reward total was -20.000000. running mean: -19.761391\n","resetting env. episode 1033.000000, reward total was -20.000000. running mean: -19.763777\n","resetting env. episode 1034.000000, reward total was -21.000000. running mean: -19.776140\n","resetting env. episode 1035.000000, reward total was -20.000000. running mean: -19.778378\n","resetting env. episode 1036.000000, reward total was -21.000000. running mean: -19.790594\n","resetting env. episode 1037.000000, reward total was -21.000000. running mean: -19.802688\n","resetting env. episode 1038.000000, reward total was -19.000000. running mean: -19.794661\n","resetting env. episode 1039.000000, reward total was -21.000000. running mean: -19.806715\n","resetting env. episode 1040.000000, reward total was -21.000000. running mean: -19.818648\n","resetting env. episode 1041.000000, reward total was -19.000000. running mean: -19.810461\n","resetting env. episode 1042.000000, reward total was -20.000000. running mean: -19.812357\n","resetting env. episode 1043.000000, reward total was -21.000000. running mean: -19.824233\n","resetting env. episode 1044.000000, reward total was -21.000000. running mean: -19.835991\n","resetting env. episode 1045.000000, reward total was -20.000000. running mean: -19.837631\n","resetting env. episode 1046.000000, reward total was -21.000000. running mean: -19.849255\n","resetting env. episode 1047.000000, reward total was -20.000000. running mean: -19.850762\n","resetting env. episode 1048.000000, reward total was -19.000000. running mean: -19.842254\n","resetting env. episode 1049.000000, reward total was -19.000000. running mean: -19.833832\n","resetting env. episode 1050.000000, reward total was -20.000000. running mean: -19.835494\n","resetting env. episode 1051.000000, reward total was -21.000000. running mean: -19.847139\n","resetting env. episode 1052.000000, reward total was -20.000000. running mean: -19.848667\n","resetting env. episode 1053.000000, reward total was -16.000000. running mean: -19.810181\n","resetting env. episode 1054.000000, reward total was -21.000000. running mean: -19.822079\n","resetting env. episode 1055.000000, reward total was -19.000000. running mean: -19.813858\n","resetting env. episode 1056.000000, reward total was -20.000000. running mean: -19.815719\n","resetting env. episode 1057.000000, reward total was -21.000000. running mean: -19.827562\n","resetting env. episode 1058.000000, reward total was -21.000000. running mean: -19.839287\n","resetting env. episode 1059.000000, reward total was -21.000000. running mean: -19.850894\n","resetting env. episode 1060.000000, reward total was -21.000000. running mean: -19.862385\n","resetting env. episode 1061.000000, reward total was -21.000000. running mean: -19.873761\n","resetting env. episode 1062.000000, reward total was -20.000000. running mean: -19.875023\n","resetting env. episode 1063.000000, reward total was -19.000000. running mean: -19.866273\n","resetting env. episode 1064.000000, reward total was -19.000000. running mean: -19.857610\n","resetting env. episode 1065.000000, reward total was -18.000000. running mean: -19.839034\n","resetting env. episode 1066.000000, reward total was -20.000000. running mean: -19.840644\n","resetting env. episode 1067.000000, reward total was -19.000000. running mean: -19.832237\n","resetting env. episode 1068.000000, reward total was -21.000000. running mean: -19.843915\n","resetting env. episode 1069.000000, reward total was -20.000000. running mean: -19.845476\n","resetting env. episode 1070.000000, reward total was -19.000000. running mean: -19.837021\n","resetting env. episode 1071.000000, reward total was -20.000000. running mean: -19.838651\n","resetting env. episode 1072.000000, reward total was -21.000000. running mean: -19.850264\n","resetting env. episode 1073.000000, reward total was -21.000000. running mean: -19.861762\n","resetting env. episode 1074.000000, reward total was -18.000000. running mean: -19.843144\n","resetting env. episode 1075.000000, reward total was -19.000000. running mean: -19.834713\n","resetting env. episode 1076.000000, reward total was -20.000000. running mean: -19.836366\n","resetting env. episode 1077.000000, reward total was -19.000000. running mean: -19.828002\n","resetting env. episode 1078.000000, reward total was -21.000000. running mean: -19.839722\n","resetting env. episode 1079.000000, reward total was -15.000000. running mean: -19.791325\n","resetting env. episode 1080.000000, reward total was -21.000000. running mean: -19.803411\n","resetting env. episode 1081.000000, reward total was -21.000000. running mean: -19.815377\n","resetting env. episode 1082.000000, reward total was -19.000000. running mean: -19.807224\n","resetting env. episode 1083.000000, reward total was -20.000000. running mean: -19.809151\n","resetting env. episode 1084.000000, reward total was -21.000000. running mean: -19.821060\n","resetting env. episode 1085.000000, reward total was -21.000000. running mean: -19.832849\n","resetting env. episode 1086.000000, reward total was -20.000000. running mean: -19.834521\n","resetting env. episode 1087.000000, reward total was -18.000000. running mean: -19.816176\n","resetting env. episode 1088.000000, reward total was -21.000000. running mean: -19.828014\n","resetting env. episode 1089.000000, reward total was -21.000000. running mean: -19.839734\n","resetting env. episode 1090.000000, reward total was -21.000000. running mean: -19.851336\n","resetting env. episode 1091.000000, reward total was -19.000000. running mean: -19.842823\n","resetting env. episode 1092.000000, reward total was -19.000000. running mean: -19.834395\n","resetting env. episode 1093.000000, reward total was -20.000000. running mean: -19.836051\n","resetting env. episode 1094.000000, reward total was -21.000000. running mean: -19.847690\n","resetting env. episode 1095.000000, reward total was -20.000000. running mean: -19.849213\n","resetting env. episode 1096.000000, reward total was -21.000000. running mean: -19.860721\n","resetting env. episode 1097.000000, reward total was -20.000000. running mean: -19.862114\n","resetting env. episode 1098.000000, reward total was -19.000000. running mean: -19.853493\n","resetting env. episode 1099.000000, reward total was -19.000000. running mean: -19.844958\n","resetting env. episode 1100.000000, reward total was -21.000000. running mean: -19.856508\n","resetting env. episode 1101.000000, reward total was -20.000000. running mean: -19.857943\n","resetting env. episode 1102.000000, reward total was -18.000000. running mean: -19.839364\n","resetting env. episode 1103.000000, reward total was -20.000000. running mean: -19.840970\n","resetting env. episode 1104.000000, reward total was -20.000000. running mean: -19.842560\n","resetting env. episode 1105.000000, reward total was -21.000000. running mean: -19.854135\n","resetting env. episode 1106.000000, reward total was -19.000000. running mean: -19.845594\n","resetting env. episode 1107.000000, reward total was -21.000000. running mean: -19.857138\n","resetting env. episode 1108.000000, reward total was -21.000000. running mean: -19.868566\n","resetting env. episode 1109.000000, reward total was -21.000000. running mean: -19.879881\n","resetting env. episode 1110.000000, reward total was -20.000000. running mean: -19.881082\n","resetting env. episode 1111.000000, reward total was -21.000000. running mean: -19.892271\n","resetting env. episode 1112.000000, reward total was -20.000000. running mean: -19.893348\n","resetting env. episode 1113.000000, reward total was -20.000000. running mean: -19.894415\n","resetting env. episode 1114.000000, reward total was -21.000000. running mean: -19.905471\n","resetting env. episode 1115.000000, reward total was -20.000000. running mean: -19.906416\n","resetting env. episode 1116.000000, reward total was -21.000000. running mean: -19.917352\n","resetting env. episode 1117.000000, reward total was -19.000000. running mean: -19.908178\n","resetting env. episode 1118.000000, reward total was -21.000000. running mean: -19.919096\n","resetting env. episode 1119.000000, reward total was -21.000000. running mean: -19.929905\n","resetting env. episode 1120.000000, reward total was -20.000000. running mean: -19.930606\n","resetting env. episode 1121.000000, reward total was -19.000000. running mean: -19.921300\n","resetting env. episode 1122.000000, reward total was -21.000000. running mean: -19.932087\n","resetting env. episode 1123.000000, reward total was -21.000000. running mean: -19.942766\n","resetting env. episode 1124.000000, reward total was -19.000000. running mean: -19.933339\n","resetting env. episode 1125.000000, reward total was -20.000000. running mean: -19.934005\n","resetting env. episode 1126.000000, reward total was -21.000000. running mean: -19.944665\n","resetting env. episode 1127.000000, reward total was -20.000000. running mean: -19.945219\n","resetting env. episode 1128.000000, reward total was -18.000000. running mean: -19.925767\n","resetting env. episode 1129.000000, reward total was -18.000000. running mean: -19.906509\n","resetting env. episode 1130.000000, reward total was -18.000000. running mean: -19.887444\n","resetting env. episode 1131.000000, reward total was -21.000000. running mean: -19.898569\n","resetting env. episode 1132.000000, reward total was -20.000000. running mean: -19.899584\n","resetting env. episode 1133.000000, reward total was -21.000000. running mean: -19.910588\n","resetting env. episode 1134.000000, reward total was -21.000000. running mean: -19.921482\n","resetting env. episode 1135.000000, reward total was -19.000000. running mean: -19.912267\n","resetting env. episode 1136.000000, reward total was -20.000000. running mean: -19.913144\n","resetting env. episode 1137.000000, reward total was -20.000000. running mean: -19.914013\n","resetting env. episode 1138.000000, reward total was -20.000000. running mean: -19.914873\n","resetting env. episode 1139.000000, reward total was -20.000000. running mean: -19.915724\n","resetting env. episode 1140.000000, reward total was -21.000000. running mean: -19.926567\n","resetting env. episode 1141.000000, reward total was -16.000000. running mean: -19.887301\n","resetting env. episode 1142.000000, reward total was -21.000000. running mean: -19.898428\n","resetting env. episode 1143.000000, reward total was -20.000000. running mean: -19.899444\n","resetting env. episode 1144.000000, reward total was -18.000000. running mean: -19.880449\n","resetting env. episode 1145.000000, reward total was -19.000000. running mean: -19.871645\n","resetting env. episode 1146.000000, reward total was -20.000000. running mean: -19.872929\n","resetting env. episode 1147.000000, reward total was -15.000000. running mean: -19.824199\n","resetting env. episode 1148.000000, reward total was -21.000000. running mean: -19.835957\n","resetting env. episode 1149.000000, reward total was -17.000000. running mean: -19.807598\n","resetting env. episode 1150.000000, reward total was -20.000000. running mean: -19.809522\n","resetting env. episode 1151.000000, reward total was -19.000000. running mean: -19.801426\n","resetting env. episode 1152.000000, reward total was -17.000000. running mean: -19.773412\n","resetting env. episode 1153.000000, reward total was -20.000000. running mean: -19.775678\n","resetting env. episode 1154.000000, reward total was -21.000000. running mean: -19.787921\n","resetting env. episode 1155.000000, reward total was -21.000000. running mean: -19.800042\n","resetting env. episode 1156.000000, reward total was -16.000000. running mean: -19.762042\n","resetting env. episode 1157.000000, reward total was -19.000000. running mean: -19.754421\n","resetting env. episode 1158.000000, reward total was -20.000000. running mean: -19.756877\n","resetting env. episode 1159.000000, reward total was -19.000000. running mean: -19.749308\n","resetting env. episode 1160.000000, reward total was -21.000000. running mean: -19.761815\n","resetting env. episode 1161.000000, reward total was -21.000000. running mean: -19.774197\n","resetting env. episode 1162.000000, reward total was -18.000000. running mean: -19.756455\n","resetting env. episode 1163.000000, reward total was -21.000000. running mean: -19.768891\n","resetting env. episode 1164.000000, reward total was -20.000000. running mean: -19.771202\n","resetting env. episode 1165.000000, reward total was -20.000000. running mean: -19.773490\n","resetting env. episode 1166.000000, reward total was -21.000000. running mean: -19.785755\n","resetting env. episode 1167.000000, reward total was -21.000000. running mean: -19.797897\n","resetting env. episode 1168.000000, reward total was -20.000000. running mean: -19.799918\n","resetting env. episode 1169.000000, reward total was -19.000000. running mean: -19.791919\n","resetting env. episode 1170.000000, reward total was -20.000000. running mean: -19.794000\n","resetting env. episode 1171.000000, reward total was -19.000000. running mean: -19.786060\n","resetting env. episode 1172.000000, reward total was -19.000000. running mean: -19.778199\n","resetting env. episode 1173.000000, reward total was -19.000000. running mean: -19.770417\n","resetting env. episode 1174.000000, reward total was -20.000000. running mean: -19.772713\n","resetting env. episode 1175.000000, reward total was -19.000000. running mean: -19.764986\n","resetting env. episode 1176.000000, reward total was -20.000000. running mean: -19.767336\n","resetting env. episode 1177.000000, reward total was -21.000000. running mean: -19.779663\n","resetting env. episode 1178.000000, reward total was -20.000000. running mean: -19.781866\n","resetting env. episode 1179.000000, reward total was -20.000000. running mean: -19.784047\n","resetting env. episode 1180.000000, reward total was -18.000000. running mean: -19.766207\n","resetting env. episode 1181.000000, reward total was -20.000000. running mean: -19.768545\n","resetting env. episode 1182.000000, reward total was -21.000000. running mean: -19.780859\n","resetting env. episode 1183.000000, reward total was -19.000000. running mean: -19.773051\n","resetting env. episode 1184.000000, reward total was -18.000000. running mean: -19.755320\n","resetting env. episode 1185.000000, reward total was -19.000000. running mean: -19.747767\n","resetting env. episode 1186.000000, reward total was -19.000000. running mean: -19.740289\n","resetting env. episode 1187.000000, reward total was -21.000000. running mean: -19.752887\n","resetting env. episode 1188.000000, reward total was -19.000000. running mean: -19.745358\n","resetting env. episode 1189.000000, reward total was -21.000000. running mean: -19.757904\n","resetting env. episode 1190.000000, reward total was -21.000000. running mean: -19.770325\n","resetting env. episode 1191.000000, reward total was -20.000000. running mean: -19.772622\n","resetting env. episode 1192.000000, reward total was -21.000000. running mean: -19.784896\n","resetting env. episode 1193.000000, reward total was -19.000000. running mean: -19.777047\n","resetting env. episode 1194.000000, reward total was -21.000000. running mean: -19.789276\n","resetting env. episode 1195.000000, reward total was -19.000000. running mean: -19.781383\n","resetting env. episode 1196.000000, reward total was -19.000000. running mean: -19.773570\n","resetting env. episode 1197.000000, reward total was -21.000000. running mean: -19.785834\n","resetting env. episode 1198.000000, reward total was -19.000000. running mean: -19.777976\n","resetting env. episode 1199.000000, reward total was -19.000000. running mean: -19.770196\n","resetting env. episode 1200.000000, reward total was -19.000000. running mean: -19.762494\n","resetting env. episode 1201.000000, reward total was -21.000000. running mean: -19.774869\n","resetting env. episode 1202.000000, reward total was -20.000000. running mean: -19.777120\n","resetting env. episode 1203.000000, reward total was -20.000000. running mean: -19.779349\n","resetting env. episode 1204.000000, reward total was -19.000000. running mean: -19.771556\n","resetting env. episode 1205.000000, reward total was -20.000000. running mean: -19.773840\n","resetting env. episode 1206.000000, reward total was -18.000000. running mean: -19.756102\n","resetting env. episode 1207.000000, reward total was -19.000000. running mean: -19.748541\n","resetting env. episode 1208.000000, reward total was -20.000000. running mean: -19.751055\n","resetting env. episode 1209.000000, reward total was -21.000000. running mean: -19.763545\n","resetting env. episode 1210.000000, reward total was -20.000000. running mean: -19.765909\n","resetting env. episode 1211.000000, reward total was -20.000000. running mean: -19.768250\n","resetting env. episode 1212.000000, reward total was -21.000000. running mean: -19.780568\n","resetting env. episode 1213.000000, reward total was -21.000000. running mean: -19.792762\n","resetting env. episode 1214.000000, reward total was -18.000000. running mean: -19.774834\n","resetting env. episode 1215.000000, reward total was -21.000000. running mean: -19.787086\n","resetting env. episode 1216.000000, reward total was -20.000000. running mean: -19.789215\n","resetting env. episode 1217.000000, reward total was -18.000000. running mean: -19.771323\n","resetting env. episode 1218.000000, reward total was -20.000000. running mean: -19.773610\n","resetting env. episode 1219.000000, reward total was -21.000000. running mean: -19.785874\n","resetting env. episode 1220.000000, reward total was -18.000000. running mean: -19.768015\n","resetting env. episode 1221.000000, reward total was -20.000000. running mean: -19.770335\n","resetting env. episode 1222.000000, reward total was -20.000000. running mean: -19.772631\n","resetting env. episode 1223.000000, reward total was -20.000000. running mean: -19.774905\n","resetting env. episode 1224.000000, reward total was -20.000000. running mean: -19.777156\n","resetting env. episode 1225.000000, reward total was -18.000000. running mean: -19.759384\n","resetting env. episode 1226.000000, reward total was -19.000000. running mean: -19.751791\n","resetting env. episode 1227.000000, reward total was -21.000000. running mean: -19.764273\n","resetting env. episode 1228.000000, reward total was -20.000000. running mean: -19.766630\n","resetting env. episode 1229.000000, reward total was -21.000000. running mean: -19.778964\n","resetting env. episode 1230.000000, reward total was -17.000000. running mean: -19.751174\n","resetting env. episode 1231.000000, reward total was -21.000000. running mean: -19.763662\n","resetting env. episode 1232.000000, reward total was -20.000000. running mean: -19.766026\n","resetting env. episode 1233.000000, reward total was -19.000000. running mean: -19.758365\n","resetting env. episode 1234.000000, reward total was -18.000000. running mean: -19.740782\n","resetting env. episode 1235.000000, reward total was -21.000000. running mean: -19.753374\n","resetting env. episode 1236.000000, reward total was -17.000000. running mean: -19.725840\n","resetting env. episode 1237.000000, reward total was -21.000000. running mean: -19.738582\n","resetting env. episode 1238.000000, reward total was -19.000000. running mean: -19.731196\n","resetting env. episode 1239.000000, reward total was -20.000000. running mean: -19.733884\n","resetting env. episode 1240.000000, reward total was -21.000000. running mean: -19.746545\n","resetting env. episode 1241.000000, reward total was -19.000000. running mean: -19.739080\n","resetting env. episode 1242.000000, reward total was -17.000000. running mean: -19.711689\n","resetting env. episode 1243.000000, reward total was -18.000000. running mean: -19.694572\n","resetting env. episode 1244.000000, reward total was -20.000000. running mean: -19.697626\n","resetting env. episode 1245.000000, reward total was -20.000000. running mean: -19.700650\n","resetting env. episode 1246.000000, reward total was -19.000000. running mean: -19.693644\n","resetting env. episode 1247.000000, reward total was -21.000000. running mean: -19.706707\n","resetting env. episode 1248.000000, reward total was -20.000000. running mean: -19.709640\n","resetting env. episode 1249.000000, reward total was -21.000000. running mean: -19.722544\n","resetting env. episode 1250.000000, reward total was -21.000000. running mean: -19.735318\n","resetting env. episode 1251.000000, reward total was -18.000000. running mean: -19.717965\n","resetting env. episode 1252.000000, reward total was -20.000000. running mean: -19.720785\n","resetting env. episode 1253.000000, reward total was -21.000000. running mean: -19.733578\n","resetting env. episode 1254.000000, reward total was -20.000000. running mean: -19.736242\n","resetting env. episode 1255.000000, reward total was -21.000000. running mean: -19.748879\n","resetting env. episode 1256.000000, reward total was -19.000000. running mean: -19.741391\n","resetting env. episode 1257.000000, reward total was -21.000000. running mean: -19.753977\n","resetting env. episode 1258.000000, reward total was -18.000000. running mean: -19.736437\n","resetting env. episode 1259.000000, reward total was -20.000000. running mean: -19.739072\n","resetting env. episode 1260.000000, reward total was -16.000000. running mean: -19.701682\n","resetting env. episode 1261.000000, reward total was -20.000000. running mean: -19.704665\n","resetting env. episode 1262.000000, reward total was -19.000000. running mean: -19.697618\n","resetting env. episode 1263.000000, reward total was -19.000000. running mean: -19.690642\n","resetting env. episode 1264.000000, reward total was -17.000000. running mean: -19.663736\n","resetting env. episode 1265.000000, reward total was -19.000000. running mean: -19.657098\n","resetting env. episode 1266.000000, reward total was -19.000000. running mean: -19.650527\n","resetting env. episode 1267.000000, reward total was -20.000000. running mean: -19.654022\n","resetting env. episode 1268.000000, reward total was -21.000000. running mean: -19.667482\n","resetting env. episode 1269.000000, reward total was -21.000000. running mean: -19.680807\n","resetting env. episode 1270.000000, reward total was -17.000000. running mean: -19.653999\n","resetting env. episode 1271.000000, reward total was -21.000000. running mean: -19.667459\n","resetting env. episode 1272.000000, reward total was -18.000000. running mean: -19.650784\n","resetting env. episode 1273.000000, reward total was -20.000000. running mean: -19.654277\n","resetting env. episode 1274.000000, reward total was -21.000000. running mean: -19.667734\n","resetting env. episode 1275.000000, reward total was -21.000000. running mean: -19.681056\n","resetting env. episode 1276.000000, reward total was -18.000000. running mean: -19.664246\n","resetting env. episode 1277.000000, reward total was -19.000000. running mean: -19.657603\n","resetting env. episode 1278.000000, reward total was -21.000000. running mean: -19.671027\n","resetting env. episode 1279.000000, reward total was -20.000000. running mean: -19.674317\n","resetting env. episode 1280.000000, reward total was -18.000000. running mean: -19.657574\n","resetting env. episode 1281.000000, reward total was -21.000000. running mean: -19.670998\n","resetting env. episode 1282.000000, reward total was -20.000000. running mean: -19.674288\n","resetting env. episode 1283.000000, reward total was -19.000000. running mean: -19.667545\n","resetting env. episode 1284.000000, reward total was -21.000000. running mean: -19.680870\n","resetting env. episode 1285.000000, reward total was -21.000000. running mean: -19.694061\n","resetting env. episode 1286.000000, reward total was -19.000000. running mean: -19.687121\n","resetting env. episode 1287.000000, reward total was -19.000000. running mean: -19.680249\n","resetting env. episode 1288.000000, reward total was -17.000000. running mean: -19.653447\n","resetting env. episode 1289.000000, reward total was -21.000000. running mean: -19.666912\n","resetting env. episode 1290.000000, reward total was -20.000000. running mean: -19.670243\n","resetting env. episode 1291.000000, reward total was -20.000000. running mean: -19.673541\n","resetting env. episode 1292.000000, reward total was -19.000000. running mean: -19.666805\n","resetting env. episode 1293.000000, reward total was -19.000000. running mean: -19.660137\n","resetting env. episode 1294.000000, reward total was -21.000000. running mean: -19.673536\n","resetting env. episode 1295.000000, reward total was -21.000000. running mean: -19.686801\n","resetting env. episode 1296.000000, reward total was -21.000000. running mean: -19.699933\n","resetting env. episode 1297.000000, reward total was -21.000000. running mean: -19.712933\n","resetting env. episode 1298.000000, reward total was -19.000000. running mean: -19.705804\n","resetting env. episode 1299.000000, reward total was -20.000000. running mean: -19.708746\n","resetting env. episode 1300.000000, reward total was -19.000000. running mean: -19.701658\n","resetting env. episode 1301.000000, reward total was -20.000000. running mean: -19.704642\n","resetting env. episode 1302.000000, reward total was -21.000000. running mean: -19.717595\n","resetting env. episode 1303.000000, reward total was -18.000000. running mean: -19.700420\n","resetting env. episode 1304.000000, reward total was -18.000000. running mean: -19.683415\n","resetting env. episode 1305.000000, reward total was -20.000000. running mean: -19.686581\n","resetting env. episode 1306.000000, reward total was -20.000000. running mean: -19.689715\n","resetting env. episode 1307.000000, reward total was -20.000000. running mean: -19.692818\n","resetting env. episode 1308.000000, reward total was -20.000000. running mean: -19.695890\n","resetting env. episode 1309.000000, reward total was -15.000000. running mean: -19.648931\n","resetting env. episode 1310.000000, reward total was -18.000000. running mean: -19.632442\n","resetting env. episode 1311.000000, reward total was -21.000000. running mean: -19.646117\n","resetting env. episode 1312.000000, reward total was -19.000000. running mean: -19.639656\n","resetting env. episode 1313.000000, reward total was -19.000000. running mean: -19.633260\n","resetting env. episode 1314.000000, reward total was -21.000000. running mean: -19.646927\n","resetting env. episode 1315.000000, reward total was -19.000000. running mean: -19.640458\n","resetting env. episode 1316.000000, reward total was -19.000000. running mean: -19.634053\n","resetting env. episode 1317.000000, reward total was -21.000000. running mean: -19.647713\n","resetting env. episode 1318.000000, reward total was -20.000000. running mean: -19.651236\n","resetting env. episode 1319.000000, reward total was -21.000000. running mean: -19.664723\n","resetting env. episode 1320.000000, reward total was -19.000000. running mean: -19.658076\n","resetting env. episode 1321.000000, reward total was -21.000000. running mean: -19.671495\n","resetting env. episode 1322.000000, reward total was -21.000000. running mean: -19.684780\n","resetting env. episode 1323.000000, reward total was -20.000000. running mean: -19.687932\n","resetting env. episode 1324.000000, reward total was -19.000000. running mean: -19.681053\n","resetting env. episode 1325.000000, reward total was -18.000000. running mean: -19.664243\n","resetting env. episode 1326.000000, reward total was -19.000000. running mean: -19.657600\n","resetting env. episode 1327.000000, reward total was -18.000000. running mean: -19.641024\n","resetting env. episode 1328.000000, reward total was -20.000000. running mean: -19.644614\n","resetting env. episode 1329.000000, reward total was -21.000000. running mean: -19.658168\n","resetting env. episode 1330.000000, reward total was -20.000000. running mean: -19.661586\n","resetting env. episode 1331.000000, reward total was -21.000000. running mean: -19.674970\n","resetting env. episode 1332.000000, reward total was -21.000000. running mean: -19.688221\n","resetting env. episode 1333.000000, reward total was -21.000000. running mean: -19.701338\n","resetting env. episode 1334.000000, reward total was -20.000000. running mean: -19.704325\n","resetting env. episode 1335.000000, reward total was -19.000000. running mean: -19.697282\n","resetting env. episode 1336.000000, reward total was -20.000000. running mean: -19.700309\n","resetting env. episode 1337.000000, reward total was -21.000000. running mean: -19.713306\n","resetting env. episode 1338.000000, reward total was -21.000000. running mean: -19.726173\n","resetting env. episode 1339.000000, reward total was -21.000000. running mean: -19.738911\n","resetting env. episode 1340.000000, reward total was -19.000000. running mean: -19.731522\n","resetting env. episode 1341.000000, reward total was -21.000000. running mean: -19.744207\n","resetting env. episode 1342.000000, reward total was -19.000000. running mean: -19.736765\n","resetting env. episode 1343.000000, reward total was -21.000000. running mean: -19.749397\n","resetting env. episode 1344.000000, reward total was -19.000000. running mean: -19.741903\n","resetting env. episode 1345.000000, reward total was -20.000000. running mean: -19.744484\n","resetting env. episode 1346.000000, reward total was -17.000000. running mean: -19.717039\n","resetting env. episode 1347.000000, reward total was -19.000000. running mean: -19.709869\n","resetting env. episode 1348.000000, reward total was -19.000000. running mean: -19.702770\n","resetting env. episode 1349.000000, reward total was -21.000000. running mean: -19.715742\n","resetting env. episode 1350.000000, reward total was -21.000000. running mean: -19.728585\n","resetting env. episode 1351.000000, reward total was -20.000000. running mean: -19.731299\n","resetting env. episode 1352.000000, reward total was -21.000000. running mean: -19.743986\n","resetting env. episode 1353.000000, reward total was -20.000000. running mean: -19.746546\n","resetting env. episode 1354.000000, reward total was -20.000000. running mean: -19.749081\n","resetting env. episode 1355.000000, reward total was -21.000000. running mean: -19.761590\n","resetting env. episode 1356.000000, reward total was -19.000000. running mean: -19.753974\n","resetting env. episode 1357.000000, reward total was -20.000000. running mean: -19.756434\n","resetting env. episode 1358.000000, reward total was -18.000000. running mean: -19.738870\n","resetting env. episode 1359.000000, reward total was -20.000000. running mean: -19.741481\n","resetting env. episode 1360.000000, reward total was -20.000000. running mean: -19.744066\n","resetting env. episode 1361.000000, reward total was -19.000000. running mean: -19.736626\n","resetting env. episode 1362.000000, reward total was -19.000000. running mean: -19.729260\n","resetting env. episode 1363.000000, reward total was -18.000000. running mean: -19.711967\n","resetting env. episode 1364.000000, reward total was -21.000000. running mean: -19.724847\n","resetting env. episode 1365.000000, reward total was -16.000000. running mean: -19.687599\n","resetting env. episode 1366.000000, reward total was -21.000000. running mean: -19.700723\n","resetting env. episode 1367.000000, reward total was -21.000000. running mean: -19.713716\n","resetting env. episode 1368.000000, reward total was -17.000000. running mean: -19.686578\n","resetting env. episode 1369.000000, reward total was -18.000000. running mean: -19.669713\n","resetting env. episode 1370.000000, reward total was -19.000000. running mean: -19.663016\n","resetting env. episode 1371.000000, reward total was -21.000000. running mean: -19.676385\n","resetting env. episode 1372.000000, reward total was -21.000000. running mean: -19.689622\n","resetting env. episode 1373.000000, reward total was -20.000000. running mean: -19.692725\n","resetting env. episode 1374.000000, reward total was -21.000000. running mean: -19.705798\n","resetting env. episode 1375.000000, reward total was -19.000000. running mean: -19.698740\n","resetting env. episode 1376.000000, reward total was -18.000000. running mean: -19.681753\n","resetting env. episode 1377.000000, reward total was -20.000000. running mean: -19.684935\n","resetting env. episode 1378.000000, reward total was -21.000000. running mean: -19.698086\n","resetting env. episode 1379.000000, reward total was -19.000000. running mean: -19.691105\n","resetting env. episode 1380.000000, reward total was -18.000000. running mean: -19.674194\n","resetting env. episode 1381.000000, reward total was -20.000000. running mean: -19.677452\n","resetting env. episode 1382.000000, reward total was -17.000000. running mean: -19.650677\n","resetting env. episode 1383.000000, reward total was -18.000000. running mean: -19.634171\n","resetting env. episode 1384.000000, reward total was -20.000000. running mean: -19.637829\n","resetting env. episode 1385.000000, reward total was -21.000000. running mean: -19.651451\n","resetting env. episode 1386.000000, reward total was -20.000000. running mean: -19.654936\n","resetting env. episode 1387.000000, reward total was -19.000000. running mean: -19.648387\n","resetting env. episode 1388.000000, reward total was -21.000000. running mean: -19.661903\n","resetting env. episode 1389.000000, reward total was -19.000000. running mean: -19.655284\n","resetting env. episode 1390.000000, reward total was -17.000000. running mean: -19.628731\n","resetting env. episode 1391.000000, reward total was -20.000000. running mean: -19.632444\n","resetting env. episode 1392.000000, reward total was -20.000000. running mean: -19.636119\n","resetting env. episode 1393.000000, reward total was -19.000000. running mean: -19.629758\n","resetting env. episode 1394.000000, reward total was -21.000000. running mean: -19.643461\n","resetting env. episode 1395.000000, reward total was -20.000000. running mean: -19.647026\n","resetting env. episode 1396.000000, reward total was -19.000000. running mean: -19.640556\n","resetting env. episode 1397.000000, reward total was -20.000000. running mean: -19.644150\n","resetting env. episode 1398.000000, reward total was -21.000000. running mean: -19.657709\n","resetting env. episode 1399.000000, reward total was -18.000000. running mean: -19.641132\n","resetting env. episode 1400.000000, reward total was -20.000000. running mean: -19.644720\n","resetting env. episode 1401.000000, reward total was -21.000000. running mean: -19.658273\n","resetting env. episode 1402.000000, reward total was -21.000000. running mean: -19.671690\n","resetting env. episode 1403.000000, reward total was -21.000000. running mean: -19.684973\n","resetting env. episode 1404.000000, reward total was -19.000000. running mean: -19.678124\n","resetting env. episode 1405.000000, reward total was -16.000000. running mean: -19.641342\n","resetting env. episode 1406.000000, reward total was -21.000000. running mean: -19.654929\n","resetting env. episode 1407.000000, reward total was -19.000000. running mean: -19.648380\n","resetting env. episode 1408.000000, reward total was -20.000000. running mean: -19.651896\n","resetting env. episode 1409.000000, reward total was -21.000000. running mean: -19.665377\n","resetting env. episode 1410.000000, reward total was -21.000000. running mean: -19.678723\n","resetting env. episode 1411.000000, reward total was -20.000000. running mean: -19.681936\n","resetting env. episode 1412.000000, reward total was -19.000000. running mean: -19.675117\n","resetting env. episode 1413.000000, reward total was -21.000000. running mean: -19.688365\n","resetting env. episode 1414.000000, reward total was -20.000000. running mean: -19.691482\n","resetting env. episode 1415.000000, reward total was -19.000000. running mean: -19.684567\n","resetting env. episode 1416.000000, reward total was -17.000000. running mean: -19.657721\n","resetting env. episode 1417.000000, reward total was -20.000000. running mean: -19.661144\n","resetting env. episode 1418.000000, reward total was -18.000000. running mean: -19.644533\n","resetting env. episode 1419.000000, reward total was -19.000000. running mean: -19.638087\n","resetting env. episode 1420.000000, reward total was -19.000000. running mean: -19.631706\n","resetting env. episode 1421.000000, reward total was -19.000000. running mean: -19.625389\n","resetting env. episode 1422.000000, reward total was -21.000000. running mean: -19.639135\n","resetting env. episode 1423.000000, reward total was -19.000000. running mean: -19.632744\n","resetting env. episode 1424.000000, reward total was -20.000000. running mean: -19.636417\n","resetting env. episode 1425.000000, reward total was -20.000000. running mean: -19.640052\n","resetting env. episode 1426.000000, reward total was -19.000000. running mean: -19.633652\n","resetting env. episode 1427.000000, reward total was -17.000000. running mean: -19.607315\n","resetting env. episode 1428.000000, reward total was -21.000000. running mean: -19.621242\n","resetting env. episode 1429.000000, reward total was -21.000000. running mean: -19.635030\n","resetting env. episode 1430.000000, reward total was -19.000000. running mean: -19.628680\n","resetting env. episode 1431.000000, reward total was -18.000000. running mean: -19.612393\n","resetting env. episode 1432.000000, reward total was -21.000000. running mean: -19.626269\n","resetting env. episode 1433.000000, reward total was -17.000000. running mean: -19.600006\n","resetting env. episode 1434.000000, reward total was -21.000000. running mean: -19.614006\n","resetting env. episode 1435.000000, reward total was -20.000000. running mean: -19.617866\n","resetting env. episode 1436.000000, reward total was -20.000000. running mean: -19.621687\n","resetting env. episode 1437.000000, reward total was -20.000000. running mean: -19.625471\n","resetting env. episode 1438.000000, reward total was -20.000000. running mean: -19.629216\n","resetting env. episode 1439.000000, reward total was -18.000000. running mean: -19.612924\n","resetting env. episode 1440.000000, reward total was -21.000000. running mean: -19.626794\n","resetting env. episode 1441.000000, reward total was -19.000000. running mean: -19.620526\n","resetting env. episode 1442.000000, reward total was -21.000000. running mean: -19.634321\n","resetting env. episode 1443.000000, reward total was -20.000000. running mean: -19.637978\n","resetting env. episode 1444.000000, reward total was -21.000000. running mean: -19.651598\n","resetting env. episode 1445.000000, reward total was -18.000000. running mean: -19.635082\n","resetting env. episode 1446.000000, reward total was -21.000000. running mean: -19.648731\n","resetting env. episode 1447.000000, reward total was -20.000000. running mean: -19.652244\n","resetting env. episode 1448.000000, reward total was -21.000000. running mean: -19.665722\n","resetting env. episode 1449.000000, reward total was -19.000000. running mean: -19.659064\n","resetting env. episode 1450.000000, reward total was -20.000000. running mean: -19.662474\n","resetting env. episode 1451.000000, reward total was -21.000000. running mean: -19.675849\n","resetting env. episode 1452.000000, reward total was -20.000000. running mean: -19.679091\n","resetting env. episode 1453.000000, reward total was -20.000000. running mean: -19.682300\n","resetting env. episode 1454.000000, reward total was -19.000000. running mean: -19.675477\n","resetting env. episode 1455.000000, reward total was -21.000000. running mean: -19.688722\n","resetting env. episode 1456.000000, reward total was -21.000000. running mean: -19.701835\n","resetting env. episode 1457.000000, reward total was -19.000000. running mean: -19.694816\n","resetting env. episode 1458.000000, reward total was -20.000000. running mean: -19.697868\n","resetting env. episode 1459.000000, reward total was -19.000000. running mean: -19.690889\n","resetting env. episode 1460.000000, reward total was -21.000000. running mean: -19.703981\n","resetting env. episode 1461.000000, reward total was -19.000000. running mean: -19.696941\n","resetting env. episode 1462.000000, reward total was -17.000000. running mean: -19.669971\n","resetting env. episode 1463.000000, reward total was -20.000000. running mean: -19.673272\n","resetting env. episode 1464.000000, reward total was -18.000000. running mean: -19.656539\n","resetting env. episode 1465.000000, reward total was -17.000000. running mean: -19.629974\n","resetting env. episode 1466.000000, reward total was -20.000000. running mean: -19.633674\n","resetting env. episode 1467.000000, reward total was -20.000000. running mean: -19.637337\n","resetting env. episode 1468.000000, reward total was -18.000000. running mean: -19.620964\n","resetting env. episode 1469.000000, reward total was -21.000000. running mean: -19.634754\n","resetting env. episode 1470.000000, reward total was -20.000000. running mean: -19.638407\n","resetting env. episode 1471.000000, reward total was -18.000000. running mean: -19.622022\n","resetting env. episode 1472.000000, reward total was -20.000000. running mean: -19.625802\n","resetting env. episode 1473.000000, reward total was -20.000000. running mean: -19.629544\n","resetting env. episode 1474.000000, reward total was -21.000000. running mean: -19.643249\n","resetting env. episode 1475.000000, reward total was -20.000000. running mean: -19.646816\n","resetting env. episode 1476.000000, reward total was -18.000000. running mean: -19.630348\n","resetting env. episode 1477.000000, reward total was -19.000000. running mean: -19.624045\n","resetting env. episode 1478.000000, reward total was -20.000000. running mean: -19.627804\n","resetting env. episode 1479.000000, reward total was -19.000000. running mean: -19.621526\n","resetting env. episode 1480.000000, reward total was -21.000000. running mean: -19.635311\n","resetting env. episode 1481.000000, reward total was -21.000000. running mean: -19.648958\n","resetting env. episode 1482.000000, reward total was -16.000000. running mean: -19.612468\n","resetting env. episode 1483.000000, reward total was -19.000000. running mean: -19.606344\n","resetting env. episode 1484.000000, reward total was -18.000000. running mean: -19.590280\n","resetting env. episode 1485.000000, reward total was -19.000000. running mean: -19.584377\n","resetting env. episode 1486.000000, reward total was -21.000000. running mean: -19.598534\n","resetting env. episode 1487.000000, reward total was -19.000000. running mean: -19.592548\n","resetting env. episode 1488.000000, reward total was -21.000000. running mean: -19.606623\n","resetting env. episode 1489.000000, reward total was -21.000000. running mean: -19.620556\n","resetting env. episode 1490.000000, reward total was -21.000000. running mean: -19.634351\n","resetting env. episode 1491.000000, reward total was -17.000000. running mean: -19.608007\n","resetting env. episode 1492.000000, reward total was -19.000000. running mean: -19.601927\n","resetting env. episode 1493.000000, reward total was -20.000000. running mean: -19.605908\n","resetting env. episode 1494.000000, reward total was -20.000000. running mean: -19.609849\n","resetting env. episode 1495.000000, reward total was -19.000000. running mean: -19.603750\n","resetting env. episode 1496.000000, reward total was -21.000000. running mean: -19.617713\n","resetting env. episode 1497.000000, reward total was -20.000000. running mean: -19.621536\n","resetting env. episode 1498.000000, reward total was -21.000000. running mean: -19.635320\n","resetting env. episode 1499.000000, reward total was -18.000000. running mean: -19.618967\n","resetting env. episode 1500.000000, reward total was -21.000000. running mean: -19.632778\n","CPU times: user 5h 48min 53s, sys: 56min 55s, total: 6h 45min 49s\n","Wall time: 3h 30min 30s\n"]}],"source":["%time hist3 = train_model(env, model, total_episodes=1500)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"w2NblmwDsL3y","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"ok","timestamp":1660694248124,"user_tz":-330,"elapsed":44595,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}},"outputId":"041b9f73-e2aa-4315-be2f-eccc88a3f282"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -6.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}],"source":["play_game(env, model)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"800N-4LR.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}