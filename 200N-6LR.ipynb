{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"200N-6LR.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"cWACPRL869I4","executionInfo":{"status":"ok","timestamp":1660789782033,"user_tz":-330,"elapsed":4438,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install gym >/dev/null"],"execution_count":1,"outputs":[]},{"metadata":{"id":"2Os6feRY6ec_","executionInfo":{"status":"ok","timestamp":1660789787102,"user_tz":-330,"elapsed":5077,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["!pip install JSAnimation >/dev/null"],"execution_count":2,"outputs":[]},{"metadata":{"id":"wotUOa_e6edP","executionInfo":{"status":"ok","timestamp":1660789787103,"user_tz":-330,"elapsed":8,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%matplotlib inline\n","from JSAnimation.IPython_display import display_animation\n","from matplotlib import animation\n","import matplotlib.pyplot as plt\n","from IPython.display import HTML\n","\n","def display_frames_as_gif(frames):\n","    \"\"\"\n","    Displays a list of frames as a gif, with controls\n","    \"\"\"\n","    plt.figure(figsize=(frames[0].shape[1] / 72.0, frames[0].shape[0] / 72.0), dpi = 144)\n","    patch = plt.imshow(frames[0])\n","    plt.axis('off')\n","\n","    def animate(i):\n","        patch.set_data(frames[i])\n","\n","    anim = animation.FuncAnimation(plt.gcf(), animate, frames = len(frames), interval=50)\n","    HTML(anim.to_jshtml())"],"execution_count":3,"outputs":[]},{"metadata":{"id":"R66_INeZ9nYX"},"cell_type":"markdown","source":["## Step 2: Playing Pong"]},{"cell_type":"code","source":["%pip install -U gym>=0.21.0\n","%pip install -U gym[atari,accept-rom-license]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8ngMhg3fB9aA","outputId":"4df7d355-b77b-4d40-f34d-f1cbef84bac1","executionInfo":{"status":"ok","timestamp":1660789821085,"user_tz":-330,"elapsed":33989,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.25.1)\n","Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.12.0)\n","Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n","Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.8)\n","Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n","Collecting ale-py~=0.7.5\n","  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n","\u001b[K     |████████████████████████████████| 1.6 MB 5.1 MB/s \n","\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n","  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.9.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n","Collecting AutoROM.accept-rom-license\n","  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.1)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n","Building wheels for collected packages: AutoROM.accept-rom-license\n","  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=c498da37f296d64a5d62de3a9676e055ad8443c4059099631bf6cdf99070e935\n","  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n","Successfully built AutoROM.accept-rom-license\n","Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n","Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n"]}]},{"metadata":{"id":"MtT2GyK_6edc","outputId":"eeb86b60-2f21-4acc-fb06-a0dc56105b05","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660789822815,"user_tz":-330,"elapsed":1750,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import gym\n","env = gym.make('Pong-v0')"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:594: UserWarning: \u001b[33mWARN: The environment Pong-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n","  f\"The environment {id} is out of date. You should consider \"\n","/usr/local/lib/python3.7/dist-packages/gym/core.py:330: DeprecationWarning: \u001b[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n","/usr/local/lib/python3.7/dist-packages/gym/wrappers/step_api_compatibility.py:40: DeprecationWarning: \u001b[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001b[0m\n","  \"Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\"\n"]}]},{"metadata":{"id":"oRE6WmXQJ1Z0","outputId":"ca7412f8-5a12-4c7a-8ca7-05e740a679f2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660789822816,"user_tz":-330,"elapsed":20,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.action_space"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Discrete(6)"]},"metadata":{},"execution_count":6}]},{"metadata":{"id":"yl_9d4HFJ31W","outputId":"4e9c0f0c-ff4b-4ac3-efdd-4fc24194811f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660789822817,"user_tz":-330,"elapsed":14,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["env.observation_space"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Box(0, 255, (210, 160, 3), uint8)"]},"metadata":{},"execution_count":7}]},{"metadata":{"id":"trwRXI-h6eeI","outputId":"97eb4cba-8f6c-4aad-9fdc-744a54699e06","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660789823708,"user_tz":-330,"elapsed":903,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# Run a demo of the environment\n","observation = env.reset()\n","cumulated_reward = 0\n","\n","frames = []\n","for t in range(1000):\n","#     print(observation)\n","    frames.append(env.render(mode = 'rgb_array'))\n","    # very stupid agent, just makes a random action within the allowd action space\n","    action = env.action_space.sample()\n","#     print(\"Action: {}\".format(t+1))    \n","    observation, reward, done, info = env.step(action)\n","#     print(reward)\n","    cumulated_reward += reward\n","    if done:\n","        print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","        break\n","print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","\n","env.close()"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\u001b[0m\n","  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps.\"\n","/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:228: DeprecationWarning: \u001b[33mWARN: Core environment is written in old step API which returns one bool instead of two. It is recommended to rewrite the environment with new step API. \u001b[0m\n","  \"Core environment is written in old step API which returns one bool instead of two. \"\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -18.0\n"]}]},{"metadata":{"id":"3zZTecVWLLes","executionInfo":{"status":"ok","timestamp":1660789823709,"user_tz":-330,"elapsed":11,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["def sigmoid(x): \n","  return 1.0 / (1.0 + np.exp(-x)) # sigmoid \"squashing\" function to interval [0,1]\n","\n","def prepro(I):\n","  \"\"\" prepro 210x160x3 uint8 frame into 6400 (80x80) 1D float vector \"\"\"\n","  I = I[35:195] # crop\n","  I = I[::2,::2,0] # downsample by factor of 2\n","  I[I == 144] = 0 # erase background (background type 1)\n","  I[I == 109] = 0 # erase background (background type 2)\n","  I[I != 0] = 1 # everything else (paddles, ball) just set to 1\n","  return I.astype(np.float).ravel()\n","\n","def policy_forward(x):\n","  h = np.dot(model['W1'], x)\n","  h[h<0] = 0 # ReLU nonlinearity\n","  logp = np.dot(model['W2'], h)\n","  p = sigmoid(logp)\n","  return p, h # return probability of taking action 2, and hidden state\n","\n","def model_step(model, observation, prev_x):\n","  # preprocess the observation, set input to network to be difference image\n","  cur_x = prepro(observation)\n","  x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","  prev_x = cur_x\n","  \n","  # forward the policy network and sample an action from the returned probability\n","  aprob, _ = policy_forward(x)\n","  action = 2 if aprob >= 0.5 else 3 # roll the dice!\n","  \n","  return action, prev_x\n","\n","def play_game(env, model):\n","  observation = env.reset()\n","\n","  frames = []\n","  cumulated_reward = 0\n","\n","  prev_x = None # used in computing the difference frame\n","\n","  for t in range(1000):\n","      frames.append(env.render(mode = 'rgb_array'))\n","      action, prev_x = model_step(model, observation, prev_x)\n","      observation, reward, done, info = env.step(action)\n","      cumulated_reward += reward\n","      if done:\n","          print(\"Episode finished after {} timesteps, accumulated reward = {}\".format(t+1, cumulated_reward))\n","          break\n","  print(\"Episode finished without success, accumulated reward = {}\".format(cumulated_reward))\n","  display_frames_as_gif(frames)\n","  env.close()"],"execution_count":9,"outputs":[]},{"metadata":{"id":"6gWvZQ7AQLQt"},"cell_type":"markdown","source":["## Step 3: Policy Gradient from Scratch"]},{"metadata":{"id":"eqFm7hqcItWl","executionInfo":{"status":"ok","timestamp":1660789823710,"user_tz":-330,"elapsed":11,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["import numpy as np\n","\n","# model initialization\n","H = 200 # number of hidden layer neurons\n","D = 80 * 80 # input dimensionality: 80x80 grid\n","model = {}\n","model['W1'] = np.random.randn(H,D) / np.sqrt(D) # \"Xavier\" initialization\n","model['W2'] = np.random.randn(H) / np.sqrt(H)\n","\n","# import pickle\n","# model = pickle.load(open('model.pkl', 'rb'))"],"execution_count":10,"outputs":[]},{"metadata":{"id":"TwjiwKisQM19","executionInfo":{"status":"ok","timestamp":1660789823710,"user_tz":-330,"elapsed":10,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["# hyperparameters\n","batch_size = 10 # every how many episodes to do a param update?\n","# learning_rate = 1e-6\n","learning_rate = 1e-6\n"," \n","gamma = 0.99 # discount factor for reward\n","decay_rate = 0.99 # decay factor for RMSProp leaky sum of grad^2\n","  \n","grad_buffer = { k : np.zeros_like(v) for k,v in model.items() } # update buffers that add up gradients over a batch\n","rmsprop_cache = { k : np.zeros_like(v) for k,v in model.items() } # rmsprop memory\n","\n","def discount_rewards(r):\n","  \"\"\" take 1D float array of rewards and compute discounted reward \"\"\"\n","  discounted_r = np.zeros_like(r, dtype=np.float32)\n","  running_add = 0\n","  for t in reversed(range(0, r.size)):\n","    if r[t] != 0: running_add = 0 # reset the sum, since this was a game boundary (pong specific!)\n","    running_add = running_add * gamma + r[t]\n","    discounted_r[t] = running_add\n","  return discounted_r\n","\n","def policy_backward(epx, eph, epdlogp):\n","  \"\"\" backward pass. (eph is array of intermediate hidden states) \"\"\"\n","  dW2 = np.dot(eph.T, epdlogp).ravel()\n","  dh = np.outer(epdlogp, model['W2'])\n","  dh[eph <= 0] = 0 # backpro prelu\n","  dW1 = np.dot(dh.T, epx)\n","  return {'W1':dW1, 'W2':dW2}\n","\n","def train_model(env, model, total_episodes = 100):\n","  hist = []\n","  observation = env.reset()\n","\n","  prev_x = None # used in computing the difference frame\n","  xs,hs,dlogps,drs = [],[],[],[]\n","  running_reward = None\n","  reward_sum = 0\n","  episode_number = 0\n","\n","  while True:\n","    # preprocess the observation, set input to network to be difference image\n","    cur_x = prepro(observation)\n","    x = cur_x - prev_x if prev_x is not None else np.zeros(D)\n","    prev_x = cur_x\n","\n","    # forward the policy network and sample an action from the returned probability\n","    aprob, h = policy_forward(x)\n","    action = 2 if np.random.uniform() < aprob else 3 # roll the dice!\n","\n","    # record various intermediates (needed later for backprop)\n","    xs.append(x) # observation\n","    hs.append(h) # hidden state\n","    y = 1 if action == 2 else 0 # a \"fake label\"\n","    dlogps.append(y - aprob) # grad that encourages the action that was taken to be taken (see http://cs231n.github.io/neural-networks-2/#losses if confused)\n","\n","    # step the environment and get new measurements\n","    observation, reward, done, info = env.step(action)\n","    reward_sum += reward\n","\n","    drs.append(reward) # record reward (has to be done after we call step() to get reward for previous action)\n","\n","    if done: # an episode finished\n","      episode_number += 1\n","\n","      # stack together all inputs, hidden states, action gradients, and rewards for this episode\n","      epx = np.vstack(xs)\n","      eph = np.vstack(hs)\n","      epdlogp = np.vstack(dlogps)\n","      epr = np.vstack(drs)\n","      xs,hs,dlogps,drs = [],[],[],[] # reset array memory\n","\n","      # compute the discounted reward backwards through time\n","      discounted_epr = discount_rewards(epr)\n","      # standardize the rewards to be unit normal (helps control the gradient estimator variance)\n","      discounted_epr -= np.mean(discounted_epr)\n","      discounted_epr /= np.std(discounted_epr)\n","\n","      epdlogp *= discounted_epr # modulate the gradient with advantage (PG magic happens right here.)\n","      grad = policy_backward(epx, eph, epdlogp)\n","      for k in model: grad_buffer[k] += grad[k] # accumulate grad over batch\n","\n","      # perform rmsprop parameter update every batch_size episodes\n","      if episode_number % batch_size == 0:\n","        for k,v in model.items():\n","          g = grad_buffer[k] # gradient\n","          rmsprop_cache[k] = decay_rate * rmsprop_cache[k] + (1 - decay_rate) * g**2\n","          model[k] += learning_rate * g / (np.sqrt(rmsprop_cache[k]) + 1e-5)\n","          grad_buffer[k] = np.zeros_like(v) # reset batch gradient buffer\n","\n","      # boring book-keeping\n","      running_reward = reward_sum if running_reward is None else running_reward * 0.99 + reward_sum * 0.01\n","      hist.append((episode_number, reward_sum, running_reward))\n","      print ('resetting env. episode %f, reward total was %f. running mean: %f' % (episode_number, reward_sum, running_reward))\n","      reward_sum = 0\n","      observation = env.reset() # reset env\n","      prev_x = None\n","      if episode_number == total_episodes: return hist\n","\n","      if reward != 0: # Pong has either +1 or -1 reward exactly when game ends.\n","        print (('ep %d: game finished, reward: %f' % (episode_number, reward)) + ('' if reward == -1 else ' !!!!!!!!'))"],"execution_count":11,"outputs":[]},{"metadata":{"id":"G6Ka_5Vl9Orm","outputId":"f8ac5753-aa75-443a-9e6f-ef0ef5bd3ea5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660791088825,"user_tz":-330,"elapsed":1265124,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist1 = train_model(env, model, total_episodes=500)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -20.010000\n","resetting env. episode 3.000000, reward total was -19.000000. running mean: -19.999900\n","resetting env. episode 4.000000, reward total was -19.000000. running mean: -19.989901\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.000002\n","resetting env. episode 6.000000, reward total was -20.000000. running mean: -20.000002\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.000002\n","resetting env. episode 8.000000, reward total was -20.000000. running mean: -20.000002\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.010002\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -20.019902\n","resetting env. episode 11.000000, reward total was -21.000000. running mean: -20.029703\n","resetting env. episode 12.000000, reward total was -19.000000. running mean: -20.019406\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.029212\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.038920\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.048530\n","resetting env. episode 16.000000, reward total was -20.000000. running mean: -20.048045\n","resetting env. episode 17.000000, reward total was -21.000000. running mean: -20.057565\n","resetting env. episode 18.000000, reward total was -21.000000. running mean: -20.066989\n","resetting env. episode 19.000000, reward total was -20.000000. running mean: -20.066319\n","resetting env. episode 20.000000, reward total was -21.000000. running mean: -20.075656\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.084899\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.094050\n","resetting env. episode 23.000000, reward total was -21.000000. running mean: -20.103110\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.112079\n","resetting env. episode 25.000000, reward total was -20.000000. running mean: -20.110958\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.119848\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.118650\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.127463\n","resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.126189\n","resetting env. episode 30.000000, reward total was -19.000000. running mean: -20.114927\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.113778\n","resetting env. episode 32.000000, reward total was -19.000000. running mean: -20.102640\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.111614\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.120497\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.129292\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.137999\n","resetting env. episode 37.000000, reward total was -20.000000. running mean: -20.136619\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.145253\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.153801\n","resetting env. episode 40.000000, reward total was -18.000000. running mean: -20.132263\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.140940\n","resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.139531\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.148135\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.146654\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.155188\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.163636\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.171999\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.180279\n","resetting env. episode 49.000000, reward total was -19.000000. running mean: -20.168476\n","resetting env. episode 50.000000, reward total was -20.000000. running mean: -20.166792\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.175124\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.183373\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.191539\n","resetting env. episode 54.000000, reward total was -21.000000. running mean: -20.199623\n","resetting env. episode 55.000000, reward total was -20.000000. running mean: -20.197627\n","resetting env. episode 56.000000, reward total was -21.000000. running mean: -20.205651\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.213594\n","resetting env. episode 58.000000, reward total was -18.000000. running mean: -20.191459\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.199544\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.207548\n","resetting env. episode 61.000000, reward total was -20.000000. running mean: -20.205473\n","resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.203418\n","resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.201384\n","resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.199370\n","resetting env. episode 65.000000, reward total was -20.000000. running mean: -20.197377\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.205403\n","resetting env. episode 67.000000, reward total was -21.000000. running mean: -20.213349\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.221215\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.229003\n","resetting env. episode 70.000000, reward total was -21.000000. running mean: -20.236713\n","resetting env. episode 71.000000, reward total was -21.000000. running mean: -20.244346\n","resetting env. episode 72.000000, reward total was -20.000000. running mean: -20.241902\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.249483\n","resetting env. episode 74.000000, reward total was -20.000000. running mean: -20.246989\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.254519\n","resetting env. episode 76.000000, reward total was -18.000000. running mean: -20.231974\n","resetting env. episode 77.000000, reward total was -18.000000. running mean: -20.209654\n","resetting env. episode 78.000000, reward total was -21.000000. running mean: -20.217557\n","resetting env. episode 79.000000, reward total was -19.000000. running mean: -20.205382\n","resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.203328\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.211295\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.209182\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.217090\n","resetting env. episode 84.000000, reward total was -19.000000. running mean: -20.204919\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.212870\n","resetting env. episode 86.000000, reward total was -19.000000. running mean: -20.200741\n","resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.198734\n","resetting env. episode 88.000000, reward total was -21.000000. running mean: -20.206746\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.214679\n","resetting env. episode 90.000000, reward total was -19.000000. running mean: -20.202532\n","resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.200507\n","resetting env. episode 92.000000, reward total was -21.000000. running mean: -20.208502\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.216417\n","resetting env. episode 94.000000, reward total was -20.000000. running mean: -20.214252\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.222110\n","resetting env. episode 96.000000, reward total was -21.000000. running mean: -20.229889\n","resetting env. episode 97.000000, reward total was -20.000000. running mean: -20.227590\n","resetting env. episode 98.000000, reward total was -21.000000. running mean: -20.235314\n","resetting env. episode 99.000000, reward total was -20.000000. running mean: -20.232961\n","resetting env. episode 100.000000, reward total was -20.000000. running mean: -20.230631\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.228325\n","resetting env. episode 102.000000, reward total was -20.000000. running mean: -20.226042\n","resetting env. episode 103.000000, reward total was -19.000000. running mean: -20.213781\n","resetting env. episode 104.000000, reward total was -21.000000. running mean: -20.221644\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.229427\n","resetting env. episode 106.000000, reward total was -20.000000. running mean: -20.227133\n","resetting env. episode 107.000000, reward total was -18.000000. running mean: -20.204861\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.212813\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.220685\n","resetting env. episode 110.000000, reward total was -17.000000. running mean: -20.188478\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.196593\n","resetting env. episode 112.000000, reward total was -21.000000. running mean: -20.204627\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.212581\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.220455\n","resetting env. episode 115.000000, reward total was -20.000000. running mean: -20.218251\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.226068\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.233807\n","resetting env. episode 118.000000, reward total was -17.000000. running mean: -20.201469\n","resetting env. episode 119.000000, reward total was -20.000000. running mean: -20.199455\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.207460\n","resetting env. episode 121.000000, reward total was -20.000000. running mean: -20.205385\n","resetting env. episode 122.000000, reward total was -21.000000. running mean: -20.213332\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.221198\n","resetting env. episode 124.000000, reward total was -19.000000. running mean: -20.208986\n","resetting env. episode 125.000000, reward total was -20.000000. running mean: -20.206896\n","resetting env. episode 126.000000, reward total was -20.000000. running mean: -20.204827\n","resetting env. episode 127.000000, reward total was -20.000000. running mean: -20.202779\n","resetting env. episode 128.000000, reward total was -20.000000. running mean: -20.200751\n","resetting env. episode 129.000000, reward total was -20.000000. running mean: -20.198744\n","resetting env. episode 130.000000, reward total was -19.000000. running mean: -20.186756\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.194889\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.202940\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.210911\n","resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.208802\n","resetting env. episode 135.000000, reward total was -20.000000. running mean: -20.206713\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.214646\n","resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.212500\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.220375\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.228171\n","resetting env. episode 140.000000, reward total was -19.000000. running mean: -20.215889\n","resetting env. episode 141.000000, reward total was -19.000000. running mean: -20.203731\n","resetting env. episode 142.000000, reward total was -20.000000. running mean: -20.201693\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.209676\n","resetting env. episode 144.000000, reward total was -21.000000. running mean: -20.217580\n","resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.225404\n","resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.233150\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.240818\n","resetting env. episode 148.000000, reward total was -20.000000. running mean: -20.238410\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.246026\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.253566\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.261030\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.268420\n","resetting env. episode 153.000000, reward total was -20.000000. running mean: -20.265736\n","resetting env. episode 154.000000, reward total was -20.000000. running mean: -20.263078\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.270447\n","resetting env. episode 156.000000, reward total was -21.000000. running mean: -20.277743\n","resetting env. episode 157.000000, reward total was -20.000000. running mean: -20.274965\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.282216\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.289394\n","resetting env. episode 160.000000, reward total was -19.000000. running mean: -20.276500\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.283735\n","resetting env. episode 162.000000, reward total was -20.000000. running mean: -20.280897\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.288088\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.295208\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.302255\n","resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.299233\n","resetting env. episode 167.000000, reward total was -18.000000. running mean: -20.276241\n","resetting env. episode 168.000000, reward total was -21.000000. running mean: -20.283478\n","resetting env. episode 169.000000, reward total was -21.000000. running mean: -20.290643\n","resetting env. episode 170.000000, reward total was -21.000000. running mean: -20.297737\n","resetting env. episode 171.000000, reward total was -17.000000. running mean: -20.264760\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.272112\n","resetting env. episode 173.000000, reward total was -18.000000. running mean: -20.249391\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.256897\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.264328\n","resetting env. episode 176.000000, reward total was -19.000000. running mean: -20.251685\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.259168\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.266576\n","resetting env. episode 179.000000, reward total was -21.000000. running mean: -20.273910\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.281171\n","resetting env. episode 181.000000, reward total was -20.000000. running mean: -20.278360\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.285576\n","resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.282720\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.289893\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.296994\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.304024\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.310984\n","resetting env. episode 188.000000, reward total was -20.000000. running mean: -20.307874\n","resetting env. episode 189.000000, reward total was -21.000000. running mean: -20.314795\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.321647\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.328431\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.335147\n","resetting env. episode 193.000000, reward total was -18.000000. running mean: -20.311795\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.318677\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.325490\n","resetting env. episode 196.000000, reward total was -21.000000. running mean: -20.332236\n","resetting env. episode 197.000000, reward total was -19.000000. running mean: -20.318913\n","resetting env. episode 198.000000, reward total was -19.000000. running mean: -20.305724\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.312667\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.319540\n","resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.316345\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.323181\n","resetting env. episode 203.000000, reward total was -21.000000. running mean: -20.329949\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.336650\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.343283\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.349851\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.356352\n","resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.352789\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.359261\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.365668\n","resetting env. episode 211.000000, reward total was -19.000000. running mean: -20.352011\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.358491\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.364906\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -20.361257\n","resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.357645\n","resetting env. episode 216.000000, reward total was -20.000000. running mean: -20.354068\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.360528\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.366922\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.373253\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.379521\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.385725\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.391868\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.397949\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.403970\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.409930\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.415831\n","resetting env. episode 227.000000, reward total was -20.000000. running mean: -20.411673\n","resetting env. episode 228.000000, reward total was -19.000000. running mean: -20.397556\n","resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.393580\n","resetting env. episode 230.000000, reward total was -21.000000. running mean: -20.399645\n","resetting env. episode 231.000000, reward total was -21.000000. running mean: -20.405648\n","resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.411592\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.407476\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.403401\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.409367\n","resetting env. episode 236.000000, reward total was -20.000000. running mean: -20.405273\n","resetting env. episode 237.000000, reward total was -20.000000. running mean: -20.401221\n","resetting env. episode 238.000000, reward total was -21.000000. running mean: -20.407208\n","resetting env. episode 239.000000, reward total was -20.000000. running mean: -20.403136\n","resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.399105\n","resetting env. episode 241.000000, reward total was -20.000000. running mean: -20.395114\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.401163\n","resetting env. episode 243.000000, reward total was -20.000000. running mean: -20.397151\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.403180\n","resetting env. episode 245.000000, reward total was -20.000000. running mean: -20.399148\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.405156\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.411105\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.416994\n","resetting env. episode 249.000000, reward total was -20.000000. running mean: -20.412824\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.418696\n","resetting env. episode 251.000000, reward total was -20.000000. running mean: -20.414509\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.420363\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.426160\n","resetting env. episode 254.000000, reward total was -19.000000. running mean: -20.411898\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.417779\n","resetting env. episode 256.000000, reward total was -20.000000. running mean: -20.413601\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.419465\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.425271\n","resetting env. episode 259.000000, reward total was -19.000000. running mean: -20.411018\n","resetting env. episode 260.000000, reward total was -20.000000. running mean: -20.406908\n","resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.412839\n","resetting env. episode 262.000000, reward total was -21.000000. running mean: -20.418710\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.424523\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.430278\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.435975\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.431616\n","resetting env. episode 267.000000, reward total was -20.000000. running mean: -20.427299\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.433026\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.438696\n","resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.444309\n","resetting env. episode 271.000000, reward total was -20.000000. running mean: -20.439866\n","resetting env. episode 272.000000, reward total was -21.000000. running mean: -20.445467\n","resetting env. episode 273.000000, reward total was -20.000000. running mean: -20.441013\n","resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.436603\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.442237\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.447814\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.453336\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.458803\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.464215\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.469573\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.474877\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.480128\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.485327\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.490474\n","resetting env. episode 285.000000, reward total was -21.000000. running mean: -20.495569\n","resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.490613\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.495707\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.500750\n","resetting env. episode 289.000000, reward total was -20.000000. running mean: -20.495742\n","resetting env. episode 290.000000, reward total was -20.000000. running mean: -20.490785\n","resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.485877\n","resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.491018\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.496108\n","resetting env. episode 294.000000, reward total was -20.000000. running mean: -20.491147\n","resetting env. episode 295.000000, reward total was -20.000000. running mean: -20.486236\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.491373\n","resetting env. episode 297.000000, reward total was -20.000000. running mean: -20.486460\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.491595\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.486679\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.491812\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.496894\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.501925\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.506906\n","resetting env. episode 304.000000, reward total was -18.000000. running mean: -20.481837\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.487018\n","resetting env. episode 306.000000, reward total was -20.000000. running mean: -20.482148\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.487327\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.492454\n","resetting env. episode 309.000000, reward total was -21.000000. running mean: -20.497529\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.502554\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.507528\n","resetting env. episode 312.000000, reward total was -20.000000. running mean: -20.502453\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.507428\n","resetting env. episode 314.000000, reward total was -20.000000. running mean: -20.502354\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.507331\n","resetting env. episode 316.000000, reward total was -21.000000. running mean: -20.512257\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.517135\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -20.511963\n","resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.506844\n","resetting env. episode 320.000000, reward total was -20.000000. running mean: -20.501775\n","resetting env. episode 321.000000, reward total was -20.000000. running mean: -20.496757\n","resetting env. episode 322.000000, reward total was -18.000000. running mean: -20.471790\n","resetting env. episode 323.000000, reward total was -21.000000. running mean: -20.477072\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.482301\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.487478\n","resetting env. episode 326.000000, reward total was -19.000000. running mean: -20.472603\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.477877\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.483099\n","resetting env. episode 329.000000, reward total was -20.000000. running mean: -20.478268\n","resetting env. episode 330.000000, reward total was -21.000000. running mean: -20.483485\n","resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.478650\n","resetting env. episode 332.000000, reward total was -19.000000. running mean: -20.463864\n","resetting env. episode 333.000000, reward total was -20.000000. running mean: -20.459225\n","resetting env. episode 334.000000, reward total was -19.000000. running mean: -20.444633\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.450186\n","resetting env. episode 336.000000, reward total was -19.000000. running mean: -20.435685\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.441328\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.446914\n","resetting env. episode 339.000000, reward total was -19.000000. running mean: -20.432445\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.438121\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.443740\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.449302\n","resetting env. episode 343.000000, reward total was -21.000000. running mean: -20.454809\n","resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.450261\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.455759\n","resetting env. episode 346.000000, reward total was -20.000000. running mean: -20.451201\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.456689\n","resetting env. episode 348.000000, reward total was -19.000000. running mean: -20.442122\n","resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.437701\n","resetting env. episode 350.000000, reward total was -20.000000. running mean: -20.433324\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.438991\n","resetting env. episode 352.000000, reward total was -21.000000. running mean: -20.444601\n","resetting env. episode 353.000000, reward total was -21.000000. running mean: -20.450155\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.455653\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.461097\n","resetting env. episode 356.000000, reward total was -20.000000. running mean: -20.456486\n","resetting env. episode 357.000000, reward total was -21.000000. running mean: -20.461921\n","resetting env. episode 358.000000, reward total was -19.000000. running mean: -20.447302\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.452829\n","resetting env. episode 360.000000, reward total was -20.000000. running mean: -20.448300\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.443817\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.449379\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.454885\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.460336\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.455733\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.461176\n","resetting env. episode 367.000000, reward total was -19.000000. running mean: -20.446564\n","resetting env. episode 368.000000, reward total was -20.000000. running mean: -20.442098\n","resetting env. episode 369.000000, reward total was -20.000000. running mean: -20.437677\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.433301\n","resetting env. episode 371.000000, reward total was -21.000000. running mean: -20.438968\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.444578\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.450132\n","resetting env. episode 374.000000, reward total was -19.000000. running mean: -20.435631\n","resetting env. episode 375.000000, reward total was -19.000000. running mean: -20.421275\n","resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.427062\n","resetting env. episode 377.000000, reward total was -20.000000. running mean: -20.422791\n","resetting env. episode 378.000000, reward total was -20.000000. running mean: -20.418563\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.424378\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.430134\n","resetting env. episode 381.000000, reward total was -20.000000. running mean: -20.425832\n","resetting env. episode 382.000000, reward total was -17.000000. running mean: -20.391574\n","resetting env. episode 383.000000, reward total was -21.000000. running mean: -20.397658\n","resetting env. episode 384.000000, reward total was -16.000000. running mean: -20.353682\n","resetting env. episode 385.000000, reward total was -20.000000. running mean: -20.350145\n","resetting env. episode 386.000000, reward total was -21.000000. running mean: -20.356644\n","resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.353077\n","resetting env. episode 388.000000, reward total was -19.000000. running mean: -20.339546\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.346151\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.352689\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.359162\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.365571\n","resetting env. episode 393.000000, reward total was -21.000000. running mean: -20.371915\n","resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.368196\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.364514\n","resetting env. episode 396.000000, reward total was -20.000000. running mean: -20.360869\n","resetting env. episode 397.000000, reward total was -21.000000. running mean: -20.367260\n","resetting env. episode 398.000000, reward total was -19.000000. running mean: -20.353588\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.360052\n","resetting env. episode 400.000000, reward total was -21.000000. running mean: -20.366451\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.372787\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.379059\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.385268\n","resetting env. episode 404.000000, reward total was -18.000000. running mean: -20.361416\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.367801\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.374123\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.380382\n","resetting env. episode 408.000000, reward total was -20.000000. running mean: -20.376578\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.382813\n","resetting env. episode 410.000000, reward total was -20.000000. running mean: -20.378984\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.385195\n","resetting env. episode 412.000000, reward total was -21.000000. running mean: -20.391343\n","resetting env. episode 413.000000, reward total was -20.000000. running mean: -20.387429\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.393555\n","resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.399619\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.405623\n","resetting env. episode 417.000000, reward total was -20.000000. running mean: -20.401567\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.407551\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.413476\n","resetting env. episode 420.000000, reward total was -21.000000. running mean: -20.419341\n","resetting env. episode 421.000000, reward total was -19.000000. running mean: -20.405148\n","resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.401096\n","resetting env. episode 423.000000, reward total was -21.000000. running mean: -20.407085\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.413014\n","resetting env. episode 425.000000, reward total was -21.000000. running mean: -20.418884\n","resetting env. episode 426.000000, reward total was -21.000000. running mean: -20.424695\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.430448\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.436144\n","resetting env. episode 429.000000, reward total was -20.000000. running mean: -20.431782\n","resetting env. episode 430.000000, reward total was -20.000000. running mean: -20.427465\n","resetting env. episode 431.000000, reward total was -21.000000. running mean: -20.433190\n","resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.428858\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.434569\n","resetting env. episode 434.000000, reward total was -21.000000. running mean: -20.440224\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.445822\n","resetting env. episode 436.000000, reward total was -21.000000. running mean: -20.451363\n","resetting env. episode 437.000000, reward total was -19.000000. running mean: -20.436850\n","resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.442481\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.448056\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.453576\n","resetting env. episode 441.000000, reward total was -17.000000. running mean: -20.419040\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.424850\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.430601\n","resetting env. episode 444.000000, reward total was -19.000000. running mean: -20.416295\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.422132\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.427911\n","resetting env. episode 447.000000, reward total was -21.000000. running mean: -20.433632\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.439295\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.444903\n","resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.440453\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.446049\n","resetting env. episode 452.000000, reward total was -20.000000. running mean: -20.441588\n","resetting env. episode 453.000000, reward total was -19.000000. running mean: -20.427173\n","resetting env. episode 454.000000, reward total was -20.000000. running mean: -20.422901\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.428672\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.434385\n","resetting env. episode 457.000000, reward total was -21.000000. running mean: -20.440041\n","resetting env. episode 458.000000, reward total was -19.000000. running mean: -20.425641\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.431384\n","resetting env. episode 460.000000, reward total was -21.000000. running mean: -20.437071\n","resetting env. episode 461.000000, reward total was -20.000000. running mean: -20.432700\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.438373\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.443989\n","resetting env. episode 464.000000, reward total was -19.000000. running mean: -20.429549\n","resetting env. episode 465.000000, reward total was -20.000000. running mean: -20.425254\n","resetting env. episode 466.000000, reward total was -18.000000. running mean: -20.401001\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.406991\n","resetting env. episode 468.000000, reward total was -18.000000. running mean: -20.382921\n","resetting env. episode 469.000000, reward total was -20.000000. running mean: -20.379092\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.385301\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.391448\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.397534\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.403558\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.409523\n","resetting env. episode 475.000000, reward total was -21.000000. running mean: -20.415428\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.421273\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.427061\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.432790\n","resetting env. episode 479.000000, reward total was -21.000000. running mean: -20.438462\n","resetting env. episode 480.000000, reward total was -19.000000. running mean: -20.424077\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.429837\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.425538\n","resetting env. episode 483.000000, reward total was -19.000000. running mean: -20.411283\n","resetting env. episode 484.000000, reward total was -21.000000. running mean: -20.417170\n","resetting env. episode 485.000000, reward total was -20.000000. running mean: -20.412998\n","resetting env. episode 486.000000, reward total was -21.000000. running mean: -20.418868\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.424680\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.430433\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.436129\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.441767\n","resetting env. episode 491.000000, reward total was -21.000000. running mean: -20.447350\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.452876\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.458347\n","resetting env. episode 494.000000, reward total was -19.000000. running mean: -20.443764\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.449326\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.454833\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.460285\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.465682\n","resetting env. episode 499.000000, reward total was -20.000000. running mean: -20.461025\n","resetting env. episode 500.000000, reward total was -21.000000. running mean: -20.466415\n","CPU times: user 27min 46s, sys: 12min 22s, total: 40min 8s\n","Wall time: 21min 5s\n"]}]},{"metadata":{"id":"cHYCDYwhlVLV","outputId":"2389987b-07bd-4688-a5d4-b666f1842376","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660792328920,"user_tz":-330,"elapsed":1240124,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist2 = train_model(env, model, total_episodes=500)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 2.000000, reward total was -21.000000. running mean: -21.000000\n","resetting env. episode 3.000000, reward total was -20.000000. running mean: -20.990000\n","resetting env. episode 4.000000, reward total was -21.000000. running mean: -20.990100\n","resetting env. episode 5.000000, reward total was -21.000000. running mean: -20.990199\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -20.990297\n","resetting env. episode 7.000000, reward total was -20.000000. running mean: -20.980394\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -20.980590\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -20.980784\n","resetting env. episode 10.000000, reward total was -20.000000. running mean: -20.970976\n","resetting env. episode 11.000000, reward total was -19.000000. running mean: -20.951267\n","resetting env. episode 12.000000, reward total was -20.000000. running mean: -20.941754\n","resetting env. episode 13.000000, reward total was -20.000000. running mean: -20.932336\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.933013\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.933683\n","resetting env. episode 16.000000, reward total was -19.000000. running mean: -20.914346\n","resetting env. episode 17.000000, reward total was -19.000000. running mean: -20.895203\n","resetting env. episode 18.000000, reward total was -20.000000. running mean: -20.886251\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.887388\n","resetting env. episode 20.000000, reward total was -19.000000. running mean: -20.868514\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.869829\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.871131\n","resetting env. episode 23.000000, reward total was -20.000000. running mean: -20.862419\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.863795\n","resetting env. episode 25.000000, reward total was -21.000000. running mean: -20.865157\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.866506\n","resetting env. episode 27.000000, reward total was -18.000000. running mean: -20.837841\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.839462\n","resetting env. episode 29.000000, reward total was -21.000000. running mean: -20.841068\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.842657\n","resetting env. episode 31.000000, reward total was -20.000000. running mean: -20.834230\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.835888\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.837529\n","resetting env. episode 34.000000, reward total was -21.000000. running mean: -20.839154\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.840762\n","resetting env. episode 36.000000, reward total was -21.000000. running mean: -20.842355\n","resetting env. episode 37.000000, reward total was -20.000000. running mean: -20.833931\n","resetting env. episode 38.000000, reward total was -20.000000. running mean: -20.825592\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.827336\n","resetting env. episode 40.000000, reward total was -20.000000. running mean: -20.819063\n","resetting env. episode 41.000000, reward total was -21.000000. running mean: -20.820872\n","resetting env. episode 42.000000, reward total was -20.000000. running mean: -20.812663\n","resetting env. episode 43.000000, reward total was -19.000000. running mean: -20.794537\n","resetting env. episode 44.000000, reward total was -20.000000. running mean: -20.786591\n","resetting env. episode 45.000000, reward total was -18.000000. running mean: -20.758725\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.761138\n","resetting env. episode 47.000000, reward total was -21.000000. running mean: -20.763527\n","resetting env. episode 48.000000, reward total was -21.000000. running mean: -20.765891\n","resetting env. episode 49.000000, reward total was -20.000000. running mean: -20.758233\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.760650\n","resetting env. episode 51.000000, reward total was -21.000000. running mean: -20.763044\n","resetting env. episode 52.000000, reward total was -19.000000. running mean: -20.745413\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.747959\n","resetting env. episode 54.000000, reward total was -20.000000. running mean: -20.740480\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.743075\n","resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.735644\n","resetting env. episode 57.000000, reward total was -21.000000. running mean: -20.738288\n","resetting env. episode 58.000000, reward total was -21.000000. running mean: -20.740905\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.743496\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.746061\n","resetting env. episode 61.000000, reward total was -19.000000. running mean: -20.728600\n","resetting env. episode 62.000000, reward total was -20.000000. running mean: -20.721314\n","resetting env. episode 63.000000, reward total was -21.000000. running mean: -20.724101\n","resetting env. episode 64.000000, reward total was -21.000000. running mean: -20.726860\n","resetting env. episode 65.000000, reward total was -20.000000. running mean: -20.719591\n","resetting env. episode 66.000000, reward total was -21.000000. running mean: -20.722395\n","resetting env. episode 67.000000, reward total was -18.000000. running mean: -20.695171\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.698220\n","resetting env. episode 69.000000, reward total was -20.000000. running mean: -20.691238\n","resetting env. episode 70.000000, reward total was -20.000000. running mean: -20.684325\n","resetting env. episode 71.000000, reward total was -19.000000. running mean: -20.667482\n","resetting env. episode 72.000000, reward total was -20.000000. running mean: -20.660807\n","resetting env. episode 73.000000, reward total was -20.000000. running mean: -20.654199\n","resetting env. episode 74.000000, reward total was -19.000000. running mean: -20.637657\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.641280\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.644868\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.648419\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.641935\n","resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.635515\n","resetting env. episode 80.000000, reward total was -21.000000. running mean: -20.639160\n","resetting env. episode 81.000000, reward total was -19.000000. running mean: -20.622769\n","resetting env. episode 82.000000, reward total was -19.000000. running mean: -20.606541\n","resetting env. episode 83.000000, reward total was -21.000000. running mean: -20.610476\n","resetting env. episode 84.000000, reward total was -19.000000. running mean: -20.594371\n","resetting env. episode 85.000000, reward total was -20.000000. running mean: -20.588427\n","resetting env. episode 86.000000, reward total was -21.000000. running mean: -20.592543\n","resetting env. episode 87.000000, reward total was -20.000000. running mean: -20.586617\n","resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.580751\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.584944\n","resetting env. episode 90.000000, reward total was -20.000000. running mean: -20.579094\n","resetting env. episode 91.000000, reward total was -21.000000. running mean: -20.583303\n","resetting env. episode 92.000000, reward total was -19.000000. running mean: -20.567470\n","resetting env. episode 93.000000, reward total was -20.000000. running mean: -20.561796\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.566178\n","resetting env. episode 95.000000, reward total was -20.000000. running mean: -20.560516\n","resetting env. episode 96.000000, reward total was -20.000000. running mean: -20.554911\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.559362\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.553768\n","resetting env. episode 99.000000, reward total was -20.000000. running mean: -20.548230\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.552748\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.547221\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.551748\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.556231\n","resetting env. episode 104.000000, reward total was -19.000000. running mean: -20.540669\n","resetting env. episode 105.000000, reward total was -20.000000. running mean: -20.535262\n","resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.539909\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.544510\n","resetting env. episode 108.000000, reward total was -21.000000. running mean: -20.549065\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.553574\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.558039\n","resetting env. episode 111.000000, reward total was -21.000000. running mean: -20.562458\n","resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.556834\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.561265\n","resetting env. episode 114.000000, reward total was -21.000000. running mean: -20.565653\n","resetting env. episode 115.000000, reward total was -20.000000. running mean: -20.559996\n","resetting env. episode 116.000000, reward total was -20.000000. running mean: -20.554396\n","resetting env. episode 117.000000, reward total was -19.000000. running mean: -20.538852\n","resetting env. episode 118.000000, reward total was -21.000000. running mean: -20.543464\n","resetting env. episode 119.000000, reward total was -20.000000. running mean: -20.538029\n","resetting env. episode 120.000000, reward total was -19.000000. running mean: -20.522649\n","resetting env. episode 121.000000, reward total was -18.000000. running mean: -20.497422\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.492448\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.497524\n","resetting env. episode 124.000000, reward total was -21.000000. running mean: -20.502548\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.507523\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.512448\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.517323\n","resetting env. episode 128.000000, reward total was -21.000000. running mean: -20.522150\n","resetting env. episode 129.000000, reward total was -19.000000. running mean: -20.506928\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.511859\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.516741\n","resetting env. episode 132.000000, reward total was -21.000000. running mean: -20.521573\n","resetting env. episode 133.000000, reward total was -20.000000. running mean: -20.516357\n","resetting env. episode 134.000000, reward total was -20.000000. running mean: -20.511194\n","resetting env. episode 135.000000, reward total was -19.000000. running mean: -20.496082\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.501121\n","resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.496110\n","resetting env. episode 138.000000, reward total was -20.000000. running mean: -20.491149\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.496237\n","resetting env. episode 140.000000, reward total was -19.000000. running mean: -20.481275\n","resetting env. episode 141.000000, reward total was -20.000000. running mean: -20.476462\n","resetting env. episode 142.000000, reward total was -20.000000. running mean: -20.471698\n","resetting env. episode 143.000000, reward total was -21.000000. running mean: -20.476981\n","resetting env. episode 144.000000, reward total was -20.000000. running mean: -20.472211\n","resetting env. episode 145.000000, reward total was -21.000000. running mean: -20.477489\n","resetting env. episode 146.000000, reward total was -21.000000. running mean: -20.482714\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.487887\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.493008\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.498078\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.503097\n","resetting env. episode 151.000000, reward total was -21.000000. running mean: -20.508066\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.512985\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.517855\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.522677\n","resetting env. episode 155.000000, reward total was -19.000000. running mean: -20.507450\n","resetting env. episode 156.000000, reward total was -20.000000. running mean: -20.502376\n","resetting env. episode 157.000000, reward total was -19.000000. running mean: -20.487352\n","resetting env. episode 158.000000, reward total was -19.000000. running mean: -20.472478\n","resetting env. episode 159.000000, reward total was -20.000000. running mean: -20.467754\n","resetting env. episode 160.000000, reward total was -20.000000. running mean: -20.463076\n","resetting env. episode 161.000000, reward total was -20.000000. running mean: -20.458445\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.463861\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.469222\n","resetting env. episode 164.000000, reward total was -20.000000. running mean: -20.464530\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.469885\n","resetting env. episode 166.000000, reward total was -20.000000. running mean: -20.465186\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.460534\n","resetting env. episode 168.000000, reward total was -20.000000. running mean: -20.455929\n","resetting env. episode 169.000000, reward total was -20.000000. running mean: -20.451369\n","resetting env. episode 170.000000, reward total was -20.000000. running mean: -20.446856\n","resetting env. episode 171.000000, reward total was -18.000000. running mean: -20.422387\n","resetting env. episode 172.000000, reward total was -18.000000. running mean: -20.398163\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.394182\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.400240\n","resetting env. episode 175.000000, reward total was -20.000000. running mean: -20.396237\n","resetting env. episode 176.000000, reward total was -20.000000. running mean: -20.392275\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.398352\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.404369\n","resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.400325\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.406322\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.412259\n","resetting env. episode 182.000000, reward total was -20.000000. running mean: -20.408136\n","resetting env. episode 183.000000, reward total was -20.000000. running mean: -20.404055\n","resetting env. episode 184.000000, reward total was -19.000000. running mean: -20.390014\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.396114\n","resetting env. episode 186.000000, reward total was -19.000000. running mean: -20.382153\n","resetting env. episode 187.000000, reward total was -20.000000. running mean: -20.378331\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.384548\n","resetting env. episode 189.000000, reward total was -19.000000. running mean: -20.370702\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.376995\n","resetting env. episode 191.000000, reward total was -21.000000. running mean: -20.383226\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.389393\n","resetting env. episode 193.000000, reward total was -21.000000. running mean: -20.395499\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.401544\n","resetting env. episode 195.000000, reward total was -21.000000. running mean: -20.407529\n","resetting env. episode 196.000000, reward total was -19.000000. running mean: -20.393454\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.399519\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.405524\n","resetting env. episode 199.000000, reward total was -20.000000. running mean: -20.401469\n","resetting env. episode 200.000000, reward total was -21.000000. running mean: -20.407454\n","resetting env. episode 201.000000, reward total was -21.000000. running mean: -20.413379\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.419246\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.415053\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.420903\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.426694\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.432427\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.438102\n","resetting env. episode 208.000000, reward total was -21.000000. running mean: -20.443721\n","resetting env. episode 209.000000, reward total was -21.000000. running mean: -20.449284\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.454791\n","resetting env. episode 211.000000, reward total was -21.000000. running mean: -20.460243\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.465641\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.470985\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -20.466275\n","resetting env. episode 215.000000, reward total was -21.000000. running mean: -20.471612\n","resetting env. episode 216.000000, reward total was -21.000000. running mean: -20.476896\n","resetting env. episode 217.000000, reward total was -19.000000. running mean: -20.462127\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.467506\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.472831\n","resetting env. episode 220.000000, reward total was -21.000000. running mean: -20.478102\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.483321\n","resetting env. episode 222.000000, reward total was -20.000000. running mean: -20.478488\n","resetting env. episode 223.000000, reward total was -21.000000. running mean: -20.483703\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.488866\n","resetting env. episode 225.000000, reward total was -21.000000. running mean: -20.493977\n","resetting env. episode 226.000000, reward total was -21.000000. running mean: -20.499038\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.504047\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.499007\n","resetting env. episode 229.000000, reward total was -21.000000. running mean: -20.504017\n","resetting env. episode 230.000000, reward total was -19.000000. running mean: -20.488977\n","resetting env. episode 231.000000, reward total was -18.000000. running mean: -20.464087\n","resetting env. episode 232.000000, reward total was -21.000000. running mean: -20.469446\n","resetting env. episode 233.000000, reward total was -20.000000. running mean: -20.464751\n","resetting env. episode 234.000000, reward total was -18.000000. running mean: -20.440104\n","resetting env. episode 235.000000, reward total was -19.000000. running mean: -20.425703\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.431446\n","resetting env. episode 237.000000, reward total was -21.000000. running mean: -20.437131\n","resetting env. episode 238.000000, reward total was -20.000000. running mean: -20.432760\n","resetting env. episode 239.000000, reward total was -21.000000. running mean: -20.438433\n","resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.434048\n","resetting env. episode 241.000000, reward total was -19.000000. running mean: -20.419708\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.425511\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.431256\n","resetting env. episode 244.000000, reward total was -21.000000. running mean: -20.436943\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.442574\n","resetting env. episode 246.000000, reward total was -20.000000. running mean: -20.438148\n","resetting env. episode 247.000000, reward total was -21.000000. running mean: -20.443766\n","resetting env. episode 248.000000, reward total was -20.000000. running mean: -20.439329\n","resetting env. episode 249.000000, reward total was -21.000000. running mean: -20.444935\n","resetting env. episode 250.000000, reward total was -20.000000. running mean: -20.440486\n","resetting env. episode 251.000000, reward total was -17.000000. running mean: -20.406081\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.412020\n","resetting env. episode 253.000000, reward total was -21.000000. running mean: -20.417900\n","resetting env. episode 254.000000, reward total was -20.000000. running mean: -20.413721\n","resetting env. episode 255.000000, reward total was -21.000000. running mean: -20.419584\n","resetting env. episode 256.000000, reward total was -20.000000. running mean: -20.415388\n","resetting env. episode 257.000000, reward total was -21.000000. running mean: -20.421234\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.427022\n","resetting env. episode 259.000000, reward total was -21.000000. running mean: -20.432752\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.438424\n","resetting env. episode 261.000000, reward total was -21.000000. running mean: -20.444040\n","resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.439600\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.445204\n","resetting env. episode 264.000000, reward total was -20.000000. running mean: -20.440751\n","resetting env. episode 265.000000, reward total was -21.000000. running mean: -20.446344\n","resetting env. episode 266.000000, reward total was -21.000000. running mean: -20.451881\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.457362\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.462788\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.468160\n","resetting env. episode 270.000000, reward total was -21.000000. running mean: -20.473479\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.478744\n","resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.473956\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.479217\n","resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.474425\n","resetting env. episode 275.000000, reward total was -20.000000. running mean: -20.469680\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.474984\n","resetting env. episode 277.000000, reward total was -21.000000. running mean: -20.480234\n","resetting env. episode 278.000000, reward total was -18.000000. running mean: -20.455431\n","resetting env. episode 279.000000, reward total was -20.000000. running mean: -20.450877\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.456368\n","resetting env. episode 281.000000, reward total was -20.000000. running mean: -20.451805\n","resetting env. episode 282.000000, reward total was -20.000000. running mean: -20.447287\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.452814\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.458286\n","resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.453703\n","resetting env. episode 286.000000, reward total was -20.000000. running mean: -20.449166\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.454674\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.460127\n","resetting env. episode 289.000000, reward total was -18.000000. running mean: -20.435526\n","resetting env. episode 290.000000, reward total was -19.000000. running mean: -20.421171\n","resetting env. episode 291.000000, reward total was -21.000000. running mean: -20.426959\n","resetting env. episode 292.000000, reward total was -21.000000. running mean: -20.432690\n","resetting env. episode 293.000000, reward total was -21.000000. running mean: -20.438363\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.443979\n","resetting env. episode 295.000000, reward total was -21.000000. running mean: -20.449539\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.455044\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.460493\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.465888\n","resetting env. episode 299.000000, reward total was -21.000000. running mean: -20.471230\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.476517\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.481752\n","resetting env. episode 302.000000, reward total was -20.000000. running mean: -20.476935\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.482165\n","resetting env. episode 304.000000, reward total was -21.000000. running mean: -20.487344\n","resetting env. episode 305.000000, reward total was -20.000000. running mean: -20.482470\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.487645\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.492769\n","resetting env. episode 308.000000, reward total was -20.000000. running mean: -20.487841\n","resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.482963\n","resetting env. episode 310.000000, reward total was -21.000000. running mean: -20.488133\n","resetting env. episode 311.000000, reward total was -21.000000. running mean: -20.493252\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.498319\n","resetting env. episode 313.000000, reward total was -20.000000. running mean: -20.493336\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.498403\n","resetting env. episode 315.000000, reward total was -21.000000. running mean: -20.503419\n","resetting env. episode 316.000000, reward total was -19.000000. running mean: -20.488385\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.493501\n","resetting env. episode 318.000000, reward total was -21.000000. running mean: -20.498566\n","resetting env. episode 319.000000, reward total was -20.000000. running mean: -20.493580\n","resetting env. episode 320.000000, reward total was -21.000000. running mean: -20.498644\n","resetting env. episode 321.000000, reward total was -21.000000. running mean: -20.503658\n","resetting env. episode 322.000000, reward total was -21.000000. running mean: -20.508621\n","resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.503535\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.508500\n","resetting env. episode 325.000000, reward total was -21.000000. running mean: -20.513415\n","resetting env. episode 326.000000, reward total was -20.000000. running mean: -20.508281\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.513198\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.518066\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.522885\n","resetting env. episode 330.000000, reward total was -20.000000. running mean: -20.517656\n","resetting env. episode 331.000000, reward total was -21.000000. running mean: -20.522480\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.527255\n","resetting env. episode 333.000000, reward total was -19.000000. running mean: -20.511982\n","resetting env. episode 334.000000, reward total was -20.000000. running mean: -20.506863\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.511794\n","resetting env. episode 336.000000, reward total was -21.000000. running mean: -20.516676\n","resetting env. episode 337.000000, reward total was -21.000000. running mean: -20.521509\n","resetting env. episode 338.000000, reward total was -20.000000. running mean: -20.516294\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.521131\n","resetting env. episode 340.000000, reward total was -21.000000. running mean: -20.525920\n","resetting env. episode 341.000000, reward total was -21.000000. running mean: -20.530661\n","resetting env. episode 342.000000, reward total was -21.000000. running mean: -20.535354\n","resetting env. episode 343.000000, reward total was -19.000000. running mean: -20.520001\n","resetting env. episode 344.000000, reward total was -20.000000. running mean: -20.514801\n","resetting env. episode 345.000000, reward total was -20.000000. running mean: -20.509653\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.514556\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.519410\n","resetting env. episode 348.000000, reward total was -20.000000. running mean: -20.514216\n","resetting env. episode 349.000000, reward total was -20.000000. running mean: -20.509074\n","resetting env. episode 350.000000, reward total was -21.000000. running mean: -20.513983\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.518844\n","resetting env. episode 352.000000, reward total was -19.000000. running mean: -20.503655\n","resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.498619\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.503632\n","resetting env. episode 355.000000, reward total was -21.000000. running mean: -20.508596\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.513510\n","resetting env. episode 357.000000, reward total was -19.000000. running mean: -20.498375\n","resetting env. episode 358.000000, reward total was -20.000000. running mean: -20.493391\n","resetting env. episode 359.000000, reward total was -21.000000. running mean: -20.498457\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.503473\n","resetting env. episode 361.000000, reward total was -21.000000. running mean: -20.508438\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.513354\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.518220\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.523038\n","resetting env. episode 365.000000, reward total was -20.000000. running mean: -20.517808\n","resetting env. episode 366.000000, reward total was -21.000000. running mean: -20.522629\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.527403\n","resetting env. episode 368.000000, reward total was -21.000000. running mean: -20.532129\n","resetting env. episode 369.000000, reward total was -21.000000. running mean: -20.536808\n","resetting env. episode 370.000000, reward total was -21.000000. running mean: -20.541440\n","resetting env. episode 371.000000, reward total was -19.000000. running mean: -20.526025\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.530765\n","resetting env. episode 373.000000, reward total was -21.000000. running mean: -20.535457\n","resetting env. episode 374.000000, reward total was -20.000000. running mean: -20.530103\n","resetting env. episode 375.000000, reward total was -19.000000. running mean: -20.514802\n","resetting env. episode 376.000000, reward total was -19.000000. running mean: -20.499654\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.504657\n","resetting env. episode 378.000000, reward total was -20.000000. running mean: -20.499611\n","resetting env. episode 379.000000, reward total was -21.000000. running mean: -20.504615\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.509569\n","resetting env. episode 381.000000, reward total was -18.000000. running mean: -20.484473\n","resetting env. episode 382.000000, reward total was -19.000000. running mean: -20.469628\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.464932\n","resetting env. episode 384.000000, reward total was -21.000000. running mean: -20.470282\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.475580\n","resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.470824\n","resetting env. episode 387.000000, reward total was -21.000000. running mean: -20.476116\n","resetting env. episode 388.000000, reward total was -20.000000. running mean: -20.471354\n","resetting env. episode 389.000000, reward total was -21.000000. running mean: -20.476641\n","resetting env. episode 390.000000, reward total was -21.000000. running mean: -20.481875\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.487056\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.492185\n","resetting env. episode 393.000000, reward total was -19.000000. running mean: -20.477263\n","resetting env. episode 394.000000, reward total was -20.000000. running mean: -20.472491\n","resetting env. episode 395.000000, reward total was -20.000000. running mean: -20.467766\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.473088\n","resetting env. episode 397.000000, reward total was -18.000000. running mean: -20.448357\n","resetting env. episode 398.000000, reward total was -19.000000. running mean: -20.433874\n","resetting env. episode 399.000000, reward total was -18.000000. running mean: -20.409535\n","resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.405440\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.411385\n","resetting env. episode 402.000000, reward total was -21.000000. running mean: -20.417271\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.423099\n","resetting env. episode 404.000000, reward total was -21.000000. running mean: -20.428868\n","resetting env. episode 405.000000, reward total was -21.000000. running mean: -20.434579\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.440233\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.445831\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.451373\n","resetting env. episode 409.000000, reward total was -20.000000. running mean: -20.446859\n","resetting env. episode 410.000000, reward total was -20.000000. running mean: -20.442390\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.447966\n","resetting env. episode 412.000000, reward total was -20.000000. running mean: -20.443487\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.449052\n","resetting env. episode 414.000000, reward total was -21.000000. running mean: -20.454561\n","resetting env. episode 415.000000, reward total was -21.000000. running mean: -20.460016\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.465416\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.470761\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.476054\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.481293\n","resetting env. episode 420.000000, reward total was -20.000000. running mean: -20.476480\n","resetting env. episode 421.000000, reward total was -19.000000. running mean: -20.461715\n","resetting env. episode 422.000000, reward total was -21.000000. running mean: -20.467098\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.462427\n","resetting env. episode 424.000000, reward total was -21.000000. running mean: -20.467803\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.463125\n","resetting env. episode 426.000000, reward total was -19.000000. running mean: -20.448494\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.454009\n","resetting env. episode 428.000000, reward total was -18.000000. running mean: -20.429469\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.435174\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.440822\n","resetting env. episode 431.000000, reward total was -20.000000. running mean: -20.436414\n","resetting env. episode 432.000000, reward total was -21.000000. running mean: -20.442050\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.447629\n","resetting env. episode 434.000000, reward total was -20.000000. running mean: -20.443153\n","resetting env. episode 435.000000, reward total was -20.000000. running mean: -20.438722\n","resetting env. episode 436.000000, reward total was -20.000000. running mean: -20.434334\n","resetting env. episode 437.000000, reward total was -21.000000. running mean: -20.439991\n","resetting env. episode 438.000000, reward total was -21.000000. running mean: -20.445591\n","resetting env. episode 439.000000, reward total was -20.000000. running mean: -20.441135\n","resetting env. episode 440.000000, reward total was -20.000000. running mean: -20.436724\n","resetting env. episode 441.000000, reward total was -21.000000. running mean: -20.442357\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.447933\n","resetting env. episode 443.000000, reward total was -21.000000. running mean: -20.453454\n","resetting env. episode 444.000000, reward total was -21.000000. running mean: -20.458919\n","resetting env. episode 445.000000, reward total was -20.000000. running mean: -20.454330\n","resetting env. episode 446.000000, reward total was -19.000000. running mean: -20.439787\n","resetting env. episode 447.000000, reward total was -20.000000. running mean: -20.435389\n","resetting env. episode 448.000000, reward total was -20.000000. running mean: -20.431035\n","resetting env. episode 449.000000, reward total was -20.000000. running mean: -20.426725\n","resetting env. episode 450.000000, reward total was -20.000000. running mean: -20.422457\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.428233\n","resetting env. episode 452.000000, reward total was -21.000000. running mean: -20.433950\n","resetting env. episode 453.000000, reward total was -20.000000. running mean: -20.429611\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.435315\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.440962\n","resetting env. episode 456.000000, reward total was -20.000000. running mean: -20.436552\n","resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.432187\n","resetting env. episode 458.000000, reward total was -21.000000. running mean: -20.437865\n","resetting env. episode 459.000000, reward total was -21.000000. running mean: -20.443486\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.439051\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.444661\n","resetting env. episode 462.000000, reward total was -19.000000. running mean: -20.430214\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.435912\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.441553\n","resetting env. episode 465.000000, reward total was -19.000000. running mean: -20.427137\n","resetting env. episode 466.000000, reward total was -21.000000. running mean: -20.432866\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.438537\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.444152\n","resetting env. episode 469.000000, reward total was -20.000000. running mean: -20.439710\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.445313\n","resetting env. episode 471.000000, reward total was -20.000000. running mean: -20.440860\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.446452\n","resetting env. episode 473.000000, reward total was -19.000000. running mean: -20.431987\n","resetting env. episode 474.000000, reward total was -21.000000. running mean: -20.437667\n","resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.433290\n","resetting env. episode 476.000000, reward total was -21.000000. running mean: -20.438958\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.444568\n","resetting env. episode 478.000000, reward total was -21.000000. running mean: -20.450122\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.445621\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.451165\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.456653\n","resetting env. episode 482.000000, reward total was -21.000000. running mean: -20.462087\n","resetting env. episode 483.000000, reward total was -21.000000. running mean: -20.467466\n","resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.452791\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.458263\n","resetting env. episode 486.000000, reward total was -18.000000. running mean: -20.433681\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.439344\n","resetting env. episode 488.000000, reward total was -21.000000. running mean: -20.444950\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.450501\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.455996\n","resetting env. episode 491.000000, reward total was -19.000000. running mean: -20.441436\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.447022\n","resetting env. episode 493.000000, reward total was -19.000000. running mean: -20.432551\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.438226\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.443844\n","resetting env. episode 496.000000, reward total was -21.000000. running mean: -20.449405\n","resetting env. episode 497.000000, reward total was -20.000000. running mean: -20.444911\n","resetting env. episode 498.000000, reward total was -21.000000. running mean: -20.450462\n","resetting env. episode 499.000000, reward total was -18.000000. running mean: -20.425957\n","resetting env. episode 500.000000, reward total was -20.000000. running mean: -20.421698\n","CPU times: user 27min 20s, sys: 12min 11s, total: 39min 31s\n","Wall time: 20min 40s\n"]}]},{"metadata":{"id":"8fheN9DRlWXQ","outputId":"31e1f810-31ca-4d9a-d53f-65e66fd30ee0","colab":{"base_uri":"https://localhost:8080/","height":451},"executionInfo":{"status":"ok","timestamp":1660792371128,"user_tz":-330,"elapsed":42226,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -19.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"id":"9AxOcQhIsKow","outputId":"be1980ac-2f08-47a1-f5e8-a909be23f54c","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1660796078536,"user_tz":-330,"elapsed":3707416,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["%time hist3 = train_model(env, model, total_episodes=1500)"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["resetting env. episode 1.000000, reward total was -20.000000. running mean: -20.000000\n","resetting env. episode 2.000000, reward total was -17.000000. running mean: -19.970000\n","resetting env. episode 3.000000, reward total was -20.000000. running mean: -19.970300\n","resetting env. episode 4.000000, reward total was -19.000000. running mean: -19.960597\n","resetting env. episode 5.000000, reward total was -20.000000. running mean: -19.960991\n","resetting env. episode 6.000000, reward total was -21.000000. running mean: -19.971381\n","resetting env. episode 7.000000, reward total was -19.000000. running mean: -19.961667\n","resetting env. episode 8.000000, reward total was -21.000000. running mean: -19.972051\n","resetting env. episode 9.000000, reward total was -21.000000. running mean: -19.982330\n","resetting env. episode 10.000000, reward total was -21.000000. running mean: -19.992507\n","resetting env. episode 11.000000, reward total was -20.000000. running mean: -19.992582\n","resetting env. episode 12.000000, reward total was -20.000000. running mean: -19.992656\n","resetting env. episode 13.000000, reward total was -21.000000. running mean: -20.002729\n","resetting env. episode 14.000000, reward total was -21.000000. running mean: -20.012702\n","resetting env. episode 15.000000, reward total was -21.000000. running mean: -20.022575\n","resetting env. episode 16.000000, reward total was -20.000000. running mean: -20.022349\n","resetting env. episode 17.000000, reward total was -19.000000. running mean: -20.012126\n","resetting env. episode 18.000000, reward total was -18.000000. running mean: -19.992005\n","resetting env. episode 19.000000, reward total was -21.000000. running mean: -20.002085\n","resetting env. episode 20.000000, reward total was -19.000000. running mean: -19.992064\n","resetting env. episode 21.000000, reward total was -21.000000. running mean: -20.002143\n","resetting env. episode 22.000000, reward total was -21.000000. running mean: -20.012122\n","resetting env. episode 23.000000, reward total was -19.000000. running mean: -20.002000\n","resetting env. episode 24.000000, reward total was -21.000000. running mean: -20.011980\n","resetting env. episode 25.000000, reward total was -20.000000. running mean: -20.011861\n","resetting env. episode 26.000000, reward total was -21.000000. running mean: -20.021742\n","resetting env. episode 27.000000, reward total was -20.000000. running mean: -20.021525\n","resetting env. episode 28.000000, reward total was -21.000000. running mean: -20.031309\n","resetting env. episode 29.000000, reward total was -20.000000. running mean: -20.030996\n","resetting env. episode 30.000000, reward total was -21.000000. running mean: -20.040686\n","resetting env. episode 31.000000, reward total was -21.000000. running mean: -20.050279\n","resetting env. episode 32.000000, reward total was -21.000000. running mean: -20.059777\n","resetting env. episode 33.000000, reward total was -21.000000. running mean: -20.069179\n","resetting env. episode 34.000000, reward total was -18.000000. running mean: -20.048487\n","resetting env. episode 35.000000, reward total was -21.000000. running mean: -20.058002\n","resetting env. episode 36.000000, reward total was -18.000000. running mean: -20.037422\n","resetting env. episode 37.000000, reward total was -19.000000. running mean: -20.027048\n","resetting env. episode 38.000000, reward total was -21.000000. running mean: -20.036777\n","resetting env. episode 39.000000, reward total was -21.000000. running mean: -20.046410\n","resetting env. episode 40.000000, reward total was -21.000000. running mean: -20.055946\n","resetting env. episode 41.000000, reward total was -19.000000. running mean: -20.045386\n","resetting env. episode 42.000000, reward total was -21.000000. running mean: -20.054932\n","resetting env. episode 43.000000, reward total was -21.000000. running mean: -20.064383\n","resetting env. episode 44.000000, reward total was -21.000000. running mean: -20.073739\n","resetting env. episode 45.000000, reward total was -21.000000. running mean: -20.083002\n","resetting env. episode 46.000000, reward total was -21.000000. running mean: -20.092172\n","resetting env. episode 47.000000, reward total was -20.000000. running mean: -20.091250\n","resetting env. episode 48.000000, reward total was -20.000000. running mean: -20.090337\n","resetting env. episode 49.000000, reward total was -20.000000. running mean: -20.089434\n","resetting env. episode 50.000000, reward total was -21.000000. running mean: -20.098540\n","resetting env. episode 51.000000, reward total was -20.000000. running mean: -20.097554\n","resetting env. episode 52.000000, reward total was -21.000000. running mean: -20.106579\n","resetting env. episode 53.000000, reward total was -21.000000. running mean: -20.115513\n","resetting env. episode 54.000000, reward total was -19.000000. running mean: -20.104358\n","resetting env. episode 55.000000, reward total was -21.000000. running mean: -20.113314\n","resetting env. episode 56.000000, reward total was -20.000000. running mean: -20.112181\n","resetting env. episode 57.000000, reward total was -19.000000. running mean: -20.101059\n","resetting env. episode 58.000000, reward total was -19.000000. running mean: -20.090049\n","resetting env. episode 59.000000, reward total was -21.000000. running mean: -20.099148\n","resetting env. episode 60.000000, reward total was -21.000000. running mean: -20.108157\n","resetting env. episode 61.000000, reward total was -19.000000. running mean: -20.097075\n","resetting env. episode 62.000000, reward total was -19.000000. running mean: -20.086104\n","resetting env. episode 63.000000, reward total was -20.000000. running mean: -20.085243\n","resetting env. episode 64.000000, reward total was -20.000000. running mean: -20.084391\n","resetting env. episode 65.000000, reward total was -20.000000. running mean: -20.083547\n","resetting env. episode 66.000000, reward total was -20.000000. running mean: -20.082712\n","resetting env. episode 67.000000, reward total was -20.000000. running mean: -20.081885\n","resetting env. episode 68.000000, reward total was -21.000000. running mean: -20.091066\n","resetting env. episode 69.000000, reward total was -21.000000. running mean: -20.100155\n","resetting env. episode 70.000000, reward total was -20.000000. running mean: -20.099153\n","resetting env. episode 71.000000, reward total was -20.000000. running mean: -20.098162\n","resetting env. episode 72.000000, reward total was -21.000000. running mean: -20.107180\n","resetting env. episode 73.000000, reward total was -21.000000. running mean: -20.116109\n","resetting env. episode 74.000000, reward total was -21.000000. running mean: -20.124947\n","resetting env. episode 75.000000, reward total was -21.000000. running mean: -20.133698\n","resetting env. episode 76.000000, reward total was -21.000000. running mean: -20.142361\n","resetting env. episode 77.000000, reward total was -21.000000. running mean: -20.150937\n","resetting env. episode 78.000000, reward total was -20.000000. running mean: -20.149428\n","resetting env. episode 79.000000, reward total was -20.000000. running mean: -20.147934\n","resetting env. episode 80.000000, reward total was -20.000000. running mean: -20.146454\n","resetting env. episode 81.000000, reward total was -21.000000. running mean: -20.154990\n","resetting env. episode 82.000000, reward total was -20.000000. running mean: -20.153440\n","resetting env. episode 83.000000, reward total was -20.000000. running mean: -20.151906\n","resetting env. episode 84.000000, reward total was -21.000000. running mean: -20.160386\n","resetting env. episode 85.000000, reward total was -21.000000. running mean: -20.168783\n","resetting env. episode 86.000000, reward total was -20.000000. running mean: -20.167095\n","resetting env. episode 87.000000, reward total was -21.000000. running mean: -20.175424\n","resetting env. episode 88.000000, reward total was -20.000000. running mean: -20.173670\n","resetting env. episode 89.000000, reward total was -21.000000. running mean: -20.181933\n","resetting env. episode 90.000000, reward total was -21.000000. running mean: -20.190114\n","resetting env. episode 91.000000, reward total was -20.000000. running mean: -20.188212\n","resetting env. episode 92.000000, reward total was -20.000000. running mean: -20.186330\n","resetting env. episode 93.000000, reward total was -21.000000. running mean: -20.194467\n","resetting env. episode 94.000000, reward total was -21.000000. running mean: -20.202522\n","resetting env. episode 95.000000, reward total was -21.000000. running mean: -20.210497\n","resetting env. episode 96.000000, reward total was -20.000000. running mean: -20.208392\n","resetting env. episode 97.000000, reward total was -21.000000. running mean: -20.216308\n","resetting env. episode 98.000000, reward total was -20.000000. running mean: -20.214145\n","resetting env. episode 99.000000, reward total was -19.000000. running mean: -20.202004\n","resetting env. episode 100.000000, reward total was -21.000000. running mean: -20.209984\n","resetting env. episode 101.000000, reward total was -20.000000. running mean: -20.207884\n","resetting env. episode 102.000000, reward total was -21.000000. running mean: -20.215805\n","resetting env. episode 103.000000, reward total was -21.000000. running mean: -20.223647\n","resetting env. episode 104.000000, reward total was -19.000000. running mean: -20.211410\n","resetting env. episode 105.000000, reward total was -21.000000. running mean: -20.219296\n","resetting env. episode 106.000000, reward total was -21.000000. running mean: -20.227103\n","resetting env. episode 107.000000, reward total was -21.000000. running mean: -20.234832\n","resetting env. episode 108.000000, reward total was -19.000000. running mean: -20.222484\n","resetting env. episode 109.000000, reward total was -21.000000. running mean: -20.230259\n","resetting env. episode 110.000000, reward total was -21.000000. running mean: -20.237957\n","resetting env. episode 111.000000, reward total was -19.000000. running mean: -20.225577\n","resetting env. episode 112.000000, reward total was -20.000000. running mean: -20.223321\n","resetting env. episode 113.000000, reward total was -21.000000. running mean: -20.231088\n","resetting env. episode 114.000000, reward total was -20.000000. running mean: -20.228777\n","resetting env. episode 115.000000, reward total was -21.000000. running mean: -20.236489\n","resetting env. episode 116.000000, reward total was -21.000000. running mean: -20.244125\n","resetting env. episode 117.000000, reward total was -21.000000. running mean: -20.251683\n","resetting env. episode 118.000000, reward total was -20.000000. running mean: -20.249166\n","resetting env. episode 119.000000, reward total was -20.000000. running mean: -20.246675\n","resetting env. episode 120.000000, reward total was -21.000000. running mean: -20.254208\n","resetting env. episode 121.000000, reward total was -21.000000. running mean: -20.261666\n","resetting env. episode 122.000000, reward total was -20.000000. running mean: -20.259049\n","resetting env. episode 123.000000, reward total was -21.000000. running mean: -20.266459\n","resetting env. episode 124.000000, reward total was -20.000000. running mean: -20.263794\n","resetting env. episode 125.000000, reward total was -21.000000. running mean: -20.271156\n","resetting env. episode 126.000000, reward total was -21.000000. running mean: -20.278445\n","resetting env. episode 127.000000, reward total was -21.000000. running mean: -20.285660\n","resetting env. episode 128.000000, reward total was -20.000000. running mean: -20.282804\n","resetting env. episode 129.000000, reward total was -21.000000. running mean: -20.289976\n","resetting env. episode 130.000000, reward total was -21.000000. running mean: -20.297076\n","resetting env. episode 131.000000, reward total was -21.000000. running mean: -20.304105\n","resetting env. episode 132.000000, reward total was -20.000000. running mean: -20.301064\n","resetting env. episode 133.000000, reward total was -21.000000. running mean: -20.308053\n","resetting env. episode 134.000000, reward total was -21.000000. running mean: -20.314973\n","resetting env. episode 135.000000, reward total was -21.000000. running mean: -20.321823\n","resetting env. episode 136.000000, reward total was -21.000000. running mean: -20.328605\n","resetting env. episode 137.000000, reward total was -20.000000. running mean: -20.325319\n","resetting env. episode 138.000000, reward total was -21.000000. running mean: -20.332066\n","resetting env. episode 139.000000, reward total was -21.000000. running mean: -20.338745\n","resetting env. episode 140.000000, reward total was -21.000000. running mean: -20.345358\n","resetting env. episode 141.000000, reward total was -21.000000. running mean: -20.351904\n","resetting env. episode 142.000000, reward total was -20.000000. running mean: -20.348385\n","resetting env. episode 143.000000, reward total was -20.000000. running mean: -20.344901\n","resetting env. episode 144.000000, reward total was -17.000000. running mean: -20.311452\n","resetting env. episode 145.000000, reward total was -19.000000. running mean: -20.298338\n","resetting env. episode 146.000000, reward total was -20.000000. running mean: -20.295354\n","resetting env. episode 147.000000, reward total was -21.000000. running mean: -20.302401\n","resetting env. episode 148.000000, reward total was -21.000000. running mean: -20.309377\n","resetting env. episode 149.000000, reward total was -21.000000. running mean: -20.316283\n","resetting env. episode 150.000000, reward total was -21.000000. running mean: -20.323120\n","resetting env. episode 151.000000, reward total was -20.000000. running mean: -20.319889\n","resetting env. episode 152.000000, reward total was -21.000000. running mean: -20.326690\n","resetting env. episode 153.000000, reward total was -21.000000. running mean: -20.333423\n","resetting env. episode 154.000000, reward total was -21.000000. running mean: -20.340089\n","resetting env. episode 155.000000, reward total was -21.000000. running mean: -20.346688\n","resetting env. episode 156.000000, reward total was -20.000000. running mean: -20.343221\n","resetting env. episode 157.000000, reward total was -21.000000. running mean: -20.349789\n","resetting env. episode 158.000000, reward total was -21.000000. running mean: -20.356291\n","resetting env. episode 159.000000, reward total was -21.000000. running mean: -20.362728\n","resetting env. episode 160.000000, reward total was -21.000000. running mean: -20.369101\n","resetting env. episode 161.000000, reward total was -21.000000. running mean: -20.375410\n","resetting env. episode 162.000000, reward total was -21.000000. running mean: -20.381656\n","resetting env. episode 163.000000, reward total was -21.000000. running mean: -20.387839\n","resetting env. episode 164.000000, reward total was -21.000000. running mean: -20.393961\n","resetting env. episode 165.000000, reward total was -21.000000. running mean: -20.400021\n","resetting env. episode 166.000000, reward total was -21.000000. running mean: -20.406021\n","resetting env. episode 167.000000, reward total was -20.000000. running mean: -20.401961\n","resetting env. episode 168.000000, reward total was -20.000000. running mean: -20.397941\n","resetting env. episode 169.000000, reward total was -19.000000. running mean: -20.383962\n","resetting env. episode 170.000000, reward total was -20.000000. running mean: -20.380122\n","resetting env. episode 171.000000, reward total was -20.000000. running mean: -20.376321\n","resetting env. episode 172.000000, reward total was -21.000000. running mean: -20.382558\n","resetting env. episode 173.000000, reward total was -20.000000. running mean: -20.378732\n","resetting env. episode 174.000000, reward total was -21.000000. running mean: -20.384945\n","resetting env. episode 175.000000, reward total was -21.000000. running mean: -20.391095\n","resetting env. episode 176.000000, reward total was -21.000000. running mean: -20.397184\n","resetting env. episode 177.000000, reward total was -21.000000. running mean: -20.403212\n","resetting env. episode 178.000000, reward total was -21.000000. running mean: -20.409180\n","resetting env. episode 179.000000, reward total was -20.000000. running mean: -20.405089\n","resetting env. episode 180.000000, reward total was -21.000000. running mean: -20.411038\n","resetting env. episode 181.000000, reward total was -21.000000. running mean: -20.416927\n","resetting env. episode 182.000000, reward total was -21.000000. running mean: -20.422758\n","resetting env. episode 183.000000, reward total was -21.000000. running mean: -20.428530\n","resetting env. episode 184.000000, reward total was -21.000000. running mean: -20.434245\n","resetting env. episode 185.000000, reward total was -21.000000. running mean: -20.439903\n","resetting env. episode 186.000000, reward total was -21.000000. running mean: -20.445504\n","resetting env. episode 187.000000, reward total was -21.000000. running mean: -20.451049\n","resetting env. episode 188.000000, reward total was -21.000000. running mean: -20.456538\n","resetting env. episode 189.000000, reward total was -19.000000. running mean: -20.441973\n","resetting env. episode 190.000000, reward total was -21.000000. running mean: -20.447553\n","resetting env. episode 191.000000, reward total was -20.000000. running mean: -20.443077\n","resetting env. episode 192.000000, reward total was -21.000000. running mean: -20.448647\n","resetting env. episode 193.000000, reward total was -20.000000. running mean: -20.444160\n","resetting env. episode 194.000000, reward total was -21.000000. running mean: -20.449719\n","resetting env. episode 195.000000, reward total was -20.000000. running mean: -20.445221\n","resetting env. episode 196.000000, reward total was -20.000000. running mean: -20.440769\n","resetting env. episode 197.000000, reward total was -21.000000. running mean: -20.446362\n","resetting env. episode 198.000000, reward total was -21.000000. running mean: -20.451898\n","resetting env. episode 199.000000, reward total was -21.000000. running mean: -20.457379\n","resetting env. episode 200.000000, reward total was -19.000000. running mean: -20.442805\n","resetting env. episode 201.000000, reward total was -20.000000. running mean: -20.438377\n","resetting env. episode 202.000000, reward total was -21.000000. running mean: -20.443993\n","resetting env. episode 203.000000, reward total was -20.000000. running mean: -20.439553\n","resetting env. episode 204.000000, reward total was -21.000000. running mean: -20.445158\n","resetting env. episode 205.000000, reward total was -21.000000. running mean: -20.450706\n","resetting env. episode 206.000000, reward total was -21.000000. running mean: -20.456199\n","resetting env. episode 207.000000, reward total was -21.000000. running mean: -20.461637\n","resetting env. episode 208.000000, reward total was -20.000000. running mean: -20.457021\n","resetting env. episode 209.000000, reward total was -18.000000. running mean: -20.432451\n","resetting env. episode 210.000000, reward total was -21.000000. running mean: -20.438126\n","resetting env. episode 211.000000, reward total was -18.000000. running mean: -20.413745\n","resetting env. episode 212.000000, reward total was -21.000000. running mean: -20.419607\n","resetting env. episode 213.000000, reward total was -21.000000. running mean: -20.425411\n","resetting env. episode 214.000000, reward total was -20.000000. running mean: -20.421157\n","resetting env. episode 215.000000, reward total was -20.000000. running mean: -20.416946\n","resetting env. episode 216.000000, reward total was -20.000000. running mean: -20.412776\n","resetting env. episode 217.000000, reward total was -21.000000. running mean: -20.418648\n","resetting env. episode 218.000000, reward total was -21.000000. running mean: -20.424462\n","resetting env. episode 219.000000, reward total was -21.000000. running mean: -20.430217\n","resetting env. episode 220.000000, reward total was -19.000000. running mean: -20.415915\n","resetting env. episode 221.000000, reward total was -21.000000. running mean: -20.421756\n","resetting env. episode 222.000000, reward total was -21.000000. running mean: -20.427538\n","resetting env. episode 223.000000, reward total was -20.000000. running mean: -20.423263\n","resetting env. episode 224.000000, reward total was -21.000000. running mean: -20.429030\n","resetting env. episode 225.000000, reward total was -20.000000. running mean: -20.424740\n","resetting env. episode 226.000000, reward total was -18.000000. running mean: -20.400493\n","resetting env. episode 227.000000, reward total was -21.000000. running mean: -20.406488\n","resetting env. episode 228.000000, reward total was -20.000000. running mean: -20.402423\n","resetting env. episode 229.000000, reward total was -20.000000. running mean: -20.398399\n","resetting env. episode 230.000000, reward total was -17.000000. running mean: -20.364415\n","resetting env. episode 231.000000, reward total was -20.000000. running mean: -20.360771\n","resetting env. episode 232.000000, reward total was -20.000000. running mean: -20.357163\n","resetting env. episode 233.000000, reward total was -18.000000. running mean: -20.333591\n","resetting env. episode 234.000000, reward total was -20.000000. running mean: -20.330255\n","resetting env. episode 235.000000, reward total was -21.000000. running mean: -20.336953\n","resetting env. episode 236.000000, reward total was -21.000000. running mean: -20.343583\n","resetting env. episode 237.000000, reward total was -19.000000. running mean: -20.330147\n","resetting env. episode 238.000000, reward total was -19.000000. running mean: -20.316846\n","resetting env. episode 239.000000, reward total was -18.000000. running mean: -20.293677\n","resetting env. episode 240.000000, reward total was -20.000000. running mean: -20.290741\n","resetting env. episode 241.000000, reward total was -21.000000. running mean: -20.297833\n","resetting env. episode 242.000000, reward total was -21.000000. running mean: -20.304855\n","resetting env. episode 243.000000, reward total was -21.000000. running mean: -20.311806\n","resetting env. episode 244.000000, reward total was -20.000000. running mean: -20.308688\n","resetting env. episode 245.000000, reward total was -21.000000. running mean: -20.315601\n","resetting env. episode 246.000000, reward total was -21.000000. running mean: -20.322445\n","resetting env. episode 247.000000, reward total was -19.000000. running mean: -20.309221\n","resetting env. episode 248.000000, reward total was -21.000000. running mean: -20.316129\n","resetting env. episode 249.000000, reward total was -19.000000. running mean: -20.302968\n","resetting env. episode 250.000000, reward total was -21.000000. running mean: -20.309938\n","resetting env. episode 251.000000, reward total was -21.000000. running mean: -20.316838\n","resetting env. episode 252.000000, reward total was -21.000000. running mean: -20.323670\n","resetting env. episode 253.000000, reward total was -20.000000. running mean: -20.320433\n","resetting env. episode 254.000000, reward total was -21.000000. running mean: -20.327229\n","resetting env. episode 255.000000, reward total was -20.000000. running mean: -20.323957\n","resetting env. episode 256.000000, reward total was -21.000000. running mean: -20.330717\n","resetting env. episode 257.000000, reward total was -19.000000. running mean: -20.317410\n","resetting env. episode 258.000000, reward total was -21.000000. running mean: -20.324236\n","resetting env. episode 259.000000, reward total was -20.000000. running mean: -20.320994\n","resetting env. episode 260.000000, reward total was -21.000000. running mean: -20.327784\n","resetting env. episode 261.000000, reward total was -20.000000. running mean: -20.324506\n","resetting env. episode 262.000000, reward total was -20.000000. running mean: -20.321261\n","resetting env. episode 263.000000, reward total was -21.000000. running mean: -20.328048\n","resetting env. episode 264.000000, reward total was -21.000000. running mean: -20.334768\n","resetting env. episode 265.000000, reward total was -19.000000. running mean: -20.321420\n","resetting env. episode 266.000000, reward total was -20.000000. running mean: -20.318206\n","resetting env. episode 267.000000, reward total was -21.000000. running mean: -20.325024\n","resetting env. episode 268.000000, reward total was -21.000000. running mean: -20.331773\n","resetting env. episode 269.000000, reward total was -21.000000. running mean: -20.338456\n","resetting env. episode 270.000000, reward total was -20.000000. running mean: -20.335071\n","resetting env. episode 271.000000, reward total was -21.000000. running mean: -20.341720\n","resetting env. episode 272.000000, reward total was -20.000000. running mean: -20.338303\n","resetting env. episode 273.000000, reward total was -21.000000. running mean: -20.344920\n","resetting env. episode 274.000000, reward total was -20.000000. running mean: -20.341471\n","resetting env. episode 275.000000, reward total was -21.000000. running mean: -20.348056\n","resetting env. episode 276.000000, reward total was -21.000000. running mean: -20.354576\n","resetting env. episode 277.000000, reward total was -20.000000. running mean: -20.351030\n","resetting env. episode 278.000000, reward total was -21.000000. running mean: -20.357520\n","resetting env. episode 279.000000, reward total was -21.000000. running mean: -20.363944\n","resetting env. episode 280.000000, reward total was -21.000000. running mean: -20.370305\n","resetting env. episode 281.000000, reward total was -21.000000. running mean: -20.376602\n","resetting env. episode 282.000000, reward total was -21.000000. running mean: -20.382836\n","resetting env. episode 283.000000, reward total was -21.000000. running mean: -20.389008\n","resetting env. episode 284.000000, reward total was -21.000000. running mean: -20.395118\n","resetting env. episode 285.000000, reward total was -20.000000. running mean: -20.391166\n","resetting env. episode 286.000000, reward total was -21.000000. running mean: -20.397255\n","resetting env. episode 287.000000, reward total was -21.000000. running mean: -20.403282\n","resetting env. episode 288.000000, reward total was -21.000000. running mean: -20.409249\n","resetting env. episode 289.000000, reward total was -21.000000. running mean: -20.415157\n","resetting env. episode 290.000000, reward total was -21.000000. running mean: -20.421005\n","resetting env. episode 291.000000, reward total was -20.000000. running mean: -20.416795\n","resetting env. episode 292.000000, reward total was -19.000000. running mean: -20.402627\n","resetting env. episode 293.000000, reward total was -20.000000. running mean: -20.398601\n","resetting env. episode 294.000000, reward total was -21.000000. running mean: -20.404615\n","resetting env. episode 295.000000, reward total was -20.000000. running mean: -20.400569\n","resetting env. episode 296.000000, reward total was -21.000000. running mean: -20.406563\n","resetting env. episode 297.000000, reward total was -21.000000. running mean: -20.412498\n","resetting env. episode 298.000000, reward total was -21.000000. running mean: -20.418373\n","resetting env. episode 299.000000, reward total was -20.000000. running mean: -20.414189\n","resetting env. episode 300.000000, reward total was -21.000000. running mean: -20.420047\n","resetting env. episode 301.000000, reward total was -21.000000. running mean: -20.425846\n","resetting env. episode 302.000000, reward total was -21.000000. running mean: -20.431588\n","resetting env. episode 303.000000, reward total was -21.000000. running mean: -20.437272\n","resetting env. episode 304.000000, reward total was -19.000000. running mean: -20.422899\n","resetting env. episode 305.000000, reward total was -21.000000. running mean: -20.428670\n","resetting env. episode 306.000000, reward total was -21.000000. running mean: -20.434384\n","resetting env. episode 307.000000, reward total was -21.000000. running mean: -20.440040\n","resetting env. episode 308.000000, reward total was -21.000000. running mean: -20.445639\n","resetting env. episode 309.000000, reward total was -20.000000. running mean: -20.441183\n","resetting env. episode 310.000000, reward total was -20.000000. running mean: -20.436771\n","resetting env. episode 311.000000, reward total was -20.000000. running mean: -20.432404\n","resetting env. episode 312.000000, reward total was -21.000000. running mean: -20.438079\n","resetting env. episode 313.000000, reward total was -21.000000. running mean: -20.443699\n","resetting env. episode 314.000000, reward total was -21.000000. running mean: -20.449262\n","resetting env. episode 315.000000, reward total was -19.000000. running mean: -20.434769\n","resetting env. episode 316.000000, reward total was -20.000000. running mean: -20.430421\n","resetting env. episode 317.000000, reward total was -21.000000. running mean: -20.436117\n","resetting env. episode 318.000000, reward total was -20.000000. running mean: -20.431756\n","resetting env. episode 319.000000, reward total was -21.000000. running mean: -20.437438\n","resetting env. episode 320.000000, reward total was -19.000000. running mean: -20.423064\n","resetting env. episode 321.000000, reward total was -18.000000. running mean: -20.398833\n","resetting env. episode 322.000000, reward total was -19.000000. running mean: -20.384845\n","resetting env. episode 323.000000, reward total was -20.000000. running mean: -20.380997\n","resetting env. episode 324.000000, reward total was -21.000000. running mean: -20.387187\n","resetting env. episode 325.000000, reward total was -20.000000. running mean: -20.383315\n","resetting env. episode 326.000000, reward total was -21.000000. running mean: -20.389482\n","resetting env. episode 327.000000, reward total was -21.000000. running mean: -20.395587\n","resetting env. episode 328.000000, reward total was -21.000000. running mean: -20.401631\n","resetting env. episode 329.000000, reward total was -21.000000. running mean: -20.407615\n","resetting env. episode 330.000000, reward total was -18.000000. running mean: -20.383539\n","resetting env. episode 331.000000, reward total was -20.000000. running mean: -20.379703\n","resetting env. episode 332.000000, reward total was -21.000000. running mean: -20.385906\n","resetting env. episode 333.000000, reward total was -21.000000. running mean: -20.392047\n","resetting env. episode 334.000000, reward total was -21.000000. running mean: -20.398127\n","resetting env. episode 335.000000, reward total was -21.000000. running mean: -20.404145\n","resetting env. episode 336.000000, reward total was -20.000000. running mean: -20.400104\n","resetting env. episode 337.000000, reward total was -20.000000. running mean: -20.396103\n","resetting env. episode 338.000000, reward total was -21.000000. running mean: -20.402142\n","resetting env. episode 339.000000, reward total was -21.000000. running mean: -20.408120\n","resetting env. episode 340.000000, reward total was -19.000000. running mean: -20.394039\n","resetting env. episode 341.000000, reward total was -20.000000. running mean: -20.390099\n","resetting env. episode 342.000000, reward total was -20.000000. running mean: -20.386198\n","resetting env. episode 343.000000, reward total was -20.000000. running mean: -20.382336\n","resetting env. episode 344.000000, reward total was -21.000000. running mean: -20.388512\n","resetting env. episode 345.000000, reward total was -21.000000. running mean: -20.394627\n","resetting env. episode 346.000000, reward total was -21.000000. running mean: -20.400681\n","resetting env. episode 347.000000, reward total was -21.000000. running mean: -20.406674\n","resetting env. episode 348.000000, reward total was -21.000000. running mean: -20.412607\n","resetting env. episode 349.000000, reward total was -21.000000. running mean: -20.418481\n","resetting env. episode 350.000000, reward total was -20.000000. running mean: -20.414297\n","resetting env. episode 351.000000, reward total was -21.000000. running mean: -20.420154\n","resetting env. episode 352.000000, reward total was -18.000000. running mean: -20.395952\n","resetting env. episode 353.000000, reward total was -20.000000. running mean: -20.391993\n","resetting env. episode 354.000000, reward total was -21.000000. running mean: -20.398073\n","resetting env. episode 355.000000, reward total was -19.000000. running mean: -20.384092\n","resetting env. episode 356.000000, reward total was -21.000000. running mean: -20.390251\n","resetting env. episode 357.000000, reward total was -20.000000. running mean: -20.386349\n","resetting env. episode 358.000000, reward total was -21.000000. running mean: -20.392485\n","resetting env. episode 359.000000, reward total was -20.000000. running mean: -20.388560\n","resetting env. episode 360.000000, reward total was -21.000000. running mean: -20.394675\n","resetting env. episode 361.000000, reward total was -20.000000. running mean: -20.390728\n","resetting env. episode 362.000000, reward total was -21.000000. running mean: -20.396821\n","resetting env. episode 363.000000, reward total was -21.000000. running mean: -20.402852\n","resetting env. episode 364.000000, reward total was -21.000000. running mean: -20.408824\n","resetting env. episode 365.000000, reward total was -21.000000. running mean: -20.414736\n","resetting env. episode 366.000000, reward total was -20.000000. running mean: -20.410588\n","resetting env. episode 367.000000, reward total was -21.000000. running mean: -20.416482\n","resetting env. episode 368.000000, reward total was -20.000000. running mean: -20.412318\n","resetting env. episode 369.000000, reward total was -19.000000. running mean: -20.398194\n","resetting env. episode 370.000000, reward total was -20.000000. running mean: -20.394212\n","resetting env. episode 371.000000, reward total was -20.000000. running mean: -20.390270\n","resetting env. episode 372.000000, reward total was -21.000000. running mean: -20.396368\n","resetting env. episode 373.000000, reward total was -20.000000. running mean: -20.392404\n","resetting env. episode 374.000000, reward total was -18.000000. running mean: -20.368480\n","resetting env. episode 375.000000, reward total was -20.000000. running mean: -20.364795\n","resetting env. episode 376.000000, reward total was -21.000000. running mean: -20.371147\n","resetting env. episode 377.000000, reward total was -21.000000. running mean: -20.377436\n","resetting env. episode 378.000000, reward total was -21.000000. running mean: -20.383661\n","resetting env. episode 379.000000, reward total was -19.000000. running mean: -20.369825\n","resetting env. episode 380.000000, reward total was -21.000000. running mean: -20.376126\n","resetting env. episode 381.000000, reward total was -21.000000. running mean: -20.382365\n","resetting env. episode 382.000000, reward total was -19.000000. running mean: -20.368542\n","resetting env. episode 383.000000, reward total was -20.000000. running mean: -20.364856\n","resetting env. episode 384.000000, reward total was -20.000000. running mean: -20.361208\n","resetting env. episode 385.000000, reward total was -21.000000. running mean: -20.367595\n","resetting env. episode 386.000000, reward total was -20.000000. running mean: -20.363919\n","resetting env. episode 387.000000, reward total was -20.000000. running mean: -20.360280\n","resetting env. episode 388.000000, reward total was -19.000000. running mean: -20.346677\n","resetting env. episode 389.000000, reward total was -19.000000. running mean: -20.333211\n","resetting env. episode 390.000000, reward total was -19.000000. running mean: -20.319879\n","resetting env. episode 391.000000, reward total was -21.000000. running mean: -20.326680\n","resetting env. episode 392.000000, reward total was -21.000000. running mean: -20.333413\n","resetting env. episode 393.000000, reward total was -20.000000. running mean: -20.330079\n","resetting env. episode 394.000000, reward total was -21.000000. running mean: -20.336778\n","resetting env. episode 395.000000, reward total was -21.000000. running mean: -20.343410\n","resetting env. episode 396.000000, reward total was -21.000000. running mean: -20.349976\n","resetting env. episode 397.000000, reward total was -19.000000. running mean: -20.336476\n","resetting env. episode 398.000000, reward total was -21.000000. running mean: -20.343112\n","resetting env. episode 399.000000, reward total was -21.000000. running mean: -20.349681\n","resetting env. episode 400.000000, reward total was -20.000000. running mean: -20.346184\n","resetting env. episode 401.000000, reward total was -21.000000. running mean: -20.352722\n","resetting env. episode 402.000000, reward total was -20.000000. running mean: -20.349195\n","resetting env. episode 403.000000, reward total was -21.000000. running mean: -20.355703\n","resetting env. episode 404.000000, reward total was -20.000000. running mean: -20.352146\n","resetting env. episode 405.000000, reward total was -19.000000. running mean: -20.338624\n","resetting env. episode 406.000000, reward total was -21.000000. running mean: -20.345238\n","resetting env. episode 407.000000, reward total was -21.000000. running mean: -20.351786\n","resetting env. episode 408.000000, reward total was -21.000000. running mean: -20.358268\n","resetting env. episode 409.000000, reward total was -21.000000. running mean: -20.364685\n","resetting env. episode 410.000000, reward total was -21.000000. running mean: -20.371038\n","resetting env. episode 411.000000, reward total was -21.000000. running mean: -20.377328\n","resetting env. episode 412.000000, reward total was -17.000000. running mean: -20.343555\n","resetting env. episode 413.000000, reward total was -21.000000. running mean: -20.350119\n","resetting env. episode 414.000000, reward total was -20.000000. running mean: -20.346618\n","resetting env. episode 415.000000, reward total was -20.000000. running mean: -20.343152\n","resetting env. episode 416.000000, reward total was -21.000000. running mean: -20.349720\n","resetting env. episode 417.000000, reward total was -21.000000. running mean: -20.356223\n","resetting env. episode 418.000000, reward total was -21.000000. running mean: -20.362661\n","resetting env. episode 419.000000, reward total was -21.000000. running mean: -20.369034\n","resetting env. episode 420.000000, reward total was -19.000000. running mean: -20.355344\n","resetting env. episode 421.000000, reward total was -21.000000. running mean: -20.361790\n","resetting env. episode 422.000000, reward total was -20.000000. running mean: -20.358172\n","resetting env. episode 423.000000, reward total was -20.000000. running mean: -20.354591\n","resetting env. episode 424.000000, reward total was -19.000000. running mean: -20.341045\n","resetting env. episode 425.000000, reward total was -20.000000. running mean: -20.337634\n","resetting env. episode 426.000000, reward total was -20.000000. running mean: -20.334258\n","resetting env. episode 427.000000, reward total was -21.000000. running mean: -20.340915\n","resetting env. episode 428.000000, reward total was -21.000000. running mean: -20.347506\n","resetting env. episode 429.000000, reward total was -21.000000. running mean: -20.354031\n","resetting env. episode 430.000000, reward total was -21.000000. running mean: -20.360491\n","resetting env. episode 431.000000, reward total was -19.000000. running mean: -20.346886\n","resetting env. episode 432.000000, reward total was -20.000000. running mean: -20.343417\n","resetting env. episode 433.000000, reward total was -21.000000. running mean: -20.349983\n","resetting env. episode 434.000000, reward total was -20.000000. running mean: -20.346483\n","resetting env. episode 435.000000, reward total was -21.000000. running mean: -20.353018\n","resetting env. episode 436.000000, reward total was -18.000000. running mean: -20.329488\n","resetting env. episode 437.000000, reward total was -19.000000. running mean: -20.316193\n","resetting env. episode 438.000000, reward total was -20.000000. running mean: -20.313031\n","resetting env. episode 439.000000, reward total was -21.000000. running mean: -20.319901\n","resetting env. episode 440.000000, reward total was -21.000000. running mean: -20.326702\n","resetting env. episode 441.000000, reward total was -20.000000. running mean: -20.323435\n","resetting env. episode 442.000000, reward total was -21.000000. running mean: -20.330201\n","resetting env. episode 443.000000, reward total was -19.000000. running mean: -20.316899\n","resetting env. episode 444.000000, reward total was -20.000000. running mean: -20.313730\n","resetting env. episode 445.000000, reward total was -21.000000. running mean: -20.320592\n","resetting env. episode 446.000000, reward total was -21.000000. running mean: -20.327386\n","resetting env. episode 447.000000, reward total was -18.000000. running mean: -20.304113\n","resetting env. episode 448.000000, reward total was -21.000000. running mean: -20.311071\n","resetting env. episode 449.000000, reward total was -21.000000. running mean: -20.317961\n","resetting env. episode 450.000000, reward total was -21.000000. running mean: -20.324781\n","resetting env. episode 451.000000, reward total was -21.000000. running mean: -20.331533\n","resetting env. episode 452.000000, reward total was -17.000000. running mean: -20.298218\n","resetting env. episode 453.000000, reward total was -18.000000. running mean: -20.275236\n","resetting env. episode 454.000000, reward total was -21.000000. running mean: -20.282483\n","resetting env. episode 455.000000, reward total was -21.000000. running mean: -20.289659\n","resetting env. episode 456.000000, reward total was -21.000000. running mean: -20.296762\n","resetting env. episode 457.000000, reward total was -20.000000. running mean: -20.293794\n","resetting env. episode 458.000000, reward total was -20.000000. running mean: -20.290856\n","resetting env. episode 459.000000, reward total was -20.000000. running mean: -20.287948\n","resetting env. episode 460.000000, reward total was -20.000000. running mean: -20.285068\n","resetting env. episode 461.000000, reward total was -21.000000. running mean: -20.292218\n","resetting env. episode 462.000000, reward total was -21.000000. running mean: -20.299296\n","resetting env. episode 463.000000, reward total was -21.000000. running mean: -20.306303\n","resetting env. episode 464.000000, reward total was -21.000000. running mean: -20.313240\n","resetting env. episode 465.000000, reward total was -21.000000. running mean: -20.320107\n","resetting env. episode 466.000000, reward total was -20.000000. running mean: -20.316906\n","resetting env. episode 467.000000, reward total was -21.000000. running mean: -20.323737\n","resetting env. episode 468.000000, reward total was -21.000000. running mean: -20.330500\n","resetting env. episode 469.000000, reward total was -21.000000. running mean: -20.337195\n","resetting env. episode 470.000000, reward total was -21.000000. running mean: -20.343823\n","resetting env. episode 471.000000, reward total was -21.000000. running mean: -20.350384\n","resetting env. episode 472.000000, reward total was -21.000000. running mean: -20.356881\n","resetting env. episode 473.000000, reward total was -21.000000. running mean: -20.363312\n","resetting env. episode 474.000000, reward total was -20.000000. running mean: -20.359679\n","resetting env. episode 475.000000, reward total was -20.000000. running mean: -20.356082\n","resetting env. episode 476.000000, reward total was -20.000000. running mean: -20.352521\n","resetting env. episode 477.000000, reward total was -21.000000. running mean: -20.358996\n","resetting env. episode 478.000000, reward total was -20.000000. running mean: -20.355406\n","resetting env. episode 479.000000, reward total was -20.000000. running mean: -20.351852\n","resetting env. episode 480.000000, reward total was -21.000000. running mean: -20.358333\n","resetting env. episode 481.000000, reward total was -21.000000. running mean: -20.364750\n","resetting env. episode 482.000000, reward total was -20.000000. running mean: -20.361103\n","resetting env. episode 483.000000, reward total was -20.000000. running mean: -20.357492\n","resetting env. episode 484.000000, reward total was -19.000000. running mean: -20.343917\n","resetting env. episode 485.000000, reward total was -21.000000. running mean: -20.350477\n","resetting env. episode 486.000000, reward total was -20.000000. running mean: -20.346973\n","resetting env. episode 487.000000, reward total was -21.000000. running mean: -20.353503\n","resetting env. episode 488.000000, reward total was -20.000000. running mean: -20.349968\n","resetting env. episode 489.000000, reward total was -21.000000. running mean: -20.356468\n","resetting env. episode 490.000000, reward total was -21.000000. running mean: -20.362904\n","resetting env. episode 491.000000, reward total was -20.000000. running mean: -20.359274\n","resetting env. episode 492.000000, reward total was -21.000000. running mean: -20.365682\n","resetting env. episode 493.000000, reward total was -21.000000. running mean: -20.372025\n","resetting env. episode 494.000000, reward total was -21.000000. running mean: -20.378305\n","resetting env. episode 495.000000, reward total was -21.000000. running mean: -20.384522\n","resetting env. episode 496.000000, reward total was -19.000000. running mean: -20.370676\n","resetting env. episode 497.000000, reward total was -21.000000. running mean: -20.376970\n","resetting env. episode 498.000000, reward total was -20.000000. running mean: -20.373200\n","resetting env. episode 499.000000, reward total was -21.000000. running mean: -20.379468\n","resetting env. episode 500.000000, reward total was -20.000000. running mean: -20.375673\n","resetting env. episode 501.000000, reward total was -20.000000. running mean: -20.371917\n","resetting env. episode 502.000000, reward total was -21.000000. running mean: -20.378197\n","resetting env. episode 503.000000, reward total was -21.000000. running mean: -20.384415\n","resetting env. episode 504.000000, reward total was -20.000000. running mean: -20.380571\n","resetting env. episode 505.000000, reward total was -21.000000. running mean: -20.386766\n","resetting env. episode 506.000000, reward total was -21.000000. running mean: -20.392898\n","resetting env. episode 507.000000, reward total was -21.000000. running mean: -20.398969\n","resetting env. episode 508.000000, reward total was -20.000000. running mean: -20.394979\n","resetting env. episode 509.000000, reward total was -21.000000. running mean: -20.401029\n","resetting env. episode 510.000000, reward total was -21.000000. running mean: -20.407019\n","resetting env. episode 511.000000, reward total was -21.000000. running mean: -20.412949\n","resetting env. episode 512.000000, reward total was -20.000000. running mean: -20.408819\n","resetting env. episode 513.000000, reward total was -20.000000. running mean: -20.404731\n","resetting env. episode 514.000000, reward total was -21.000000. running mean: -20.410684\n","resetting env. episode 515.000000, reward total was -21.000000. running mean: -20.416577\n","resetting env. episode 516.000000, reward total was -21.000000. running mean: -20.422411\n","resetting env. episode 517.000000, reward total was -21.000000. running mean: -20.428187\n","resetting env. episode 518.000000, reward total was -20.000000. running mean: -20.423905\n","resetting env. episode 519.000000, reward total was -20.000000. running mean: -20.419666\n","resetting env. episode 520.000000, reward total was -21.000000. running mean: -20.425470\n","resetting env. episode 521.000000, reward total was -21.000000. running mean: -20.431215\n","resetting env. episode 522.000000, reward total was -21.000000. running mean: -20.436903\n","resetting env. episode 523.000000, reward total was -19.000000. running mean: -20.422534\n","resetting env. episode 524.000000, reward total was -20.000000. running mean: -20.418308\n","resetting env. episode 525.000000, reward total was -19.000000. running mean: -20.404125\n","resetting env. episode 526.000000, reward total was -21.000000. running mean: -20.410084\n","resetting env. episode 527.000000, reward total was -18.000000. running mean: -20.385983\n","resetting env. episode 528.000000, reward total was -21.000000. running mean: -20.392123\n","resetting env. episode 529.000000, reward total was -20.000000. running mean: -20.388202\n","resetting env. episode 530.000000, reward total was -19.000000. running mean: -20.374320\n","resetting env. episode 531.000000, reward total was -20.000000. running mean: -20.370577\n","resetting env. episode 532.000000, reward total was -21.000000. running mean: -20.376871\n","resetting env. episode 533.000000, reward total was -20.000000. running mean: -20.373102\n","resetting env. episode 534.000000, reward total was -18.000000. running mean: -20.349371\n","resetting env. episode 535.000000, reward total was -21.000000. running mean: -20.355878\n","resetting env. episode 536.000000, reward total was -20.000000. running mean: -20.352319\n","resetting env. episode 537.000000, reward total was -20.000000. running mean: -20.348796\n","resetting env. episode 538.000000, reward total was -18.000000. running mean: -20.325308\n","resetting env. episode 539.000000, reward total was -21.000000. running mean: -20.332055\n","resetting env. episode 540.000000, reward total was -21.000000. running mean: -20.338734\n","resetting env. episode 541.000000, reward total was -21.000000. running mean: -20.345347\n","resetting env. episode 542.000000, reward total was -20.000000. running mean: -20.341893\n","resetting env. episode 543.000000, reward total was -20.000000. running mean: -20.338474\n","resetting env. episode 544.000000, reward total was -21.000000. running mean: -20.345090\n","resetting env. episode 545.000000, reward total was -21.000000. running mean: -20.351639\n","resetting env. episode 546.000000, reward total was -21.000000. running mean: -20.358122\n","resetting env. episode 547.000000, reward total was -21.000000. running mean: -20.364541\n","resetting env. episode 548.000000, reward total was -21.000000. running mean: -20.370896\n","resetting env. episode 549.000000, reward total was -20.000000. running mean: -20.367187\n","resetting env. episode 550.000000, reward total was -20.000000. running mean: -20.363515\n","resetting env. episode 551.000000, reward total was -21.000000. running mean: -20.369880\n","resetting env. episode 552.000000, reward total was -20.000000. running mean: -20.366181\n","resetting env. episode 553.000000, reward total was -21.000000. running mean: -20.372519\n","resetting env. episode 554.000000, reward total was -20.000000. running mean: -20.368794\n","resetting env. episode 555.000000, reward total was -21.000000. running mean: -20.375106\n","resetting env. episode 556.000000, reward total was -21.000000. running mean: -20.381355\n","resetting env. episode 557.000000, reward total was -21.000000. running mean: -20.387541\n","resetting env. episode 558.000000, reward total was -20.000000. running mean: -20.383666\n","resetting env. episode 559.000000, reward total was -21.000000. running mean: -20.389829\n","resetting env. episode 560.000000, reward total was -21.000000. running mean: -20.395931\n","resetting env. episode 561.000000, reward total was -20.000000. running mean: -20.391972\n","resetting env. episode 562.000000, reward total was -20.000000. running mean: -20.388052\n","resetting env. episode 563.000000, reward total was -21.000000. running mean: -20.394172\n","resetting env. episode 564.000000, reward total was -21.000000. running mean: -20.400230\n","resetting env. episode 565.000000, reward total was -20.000000. running mean: -20.396228\n","resetting env. episode 566.000000, reward total was -21.000000. running mean: -20.402265\n","resetting env. episode 567.000000, reward total was -20.000000. running mean: -20.398243\n","resetting env. episode 568.000000, reward total was -21.000000. running mean: -20.404260\n","resetting env. episode 569.000000, reward total was -21.000000. running mean: -20.410218\n","resetting env. episode 570.000000, reward total was -21.000000. running mean: -20.416115\n","resetting env. episode 571.000000, reward total was -21.000000. running mean: -20.421954\n","resetting env. episode 572.000000, reward total was -21.000000. running mean: -20.427735\n","resetting env. episode 573.000000, reward total was -20.000000. running mean: -20.423457\n","resetting env. episode 574.000000, reward total was -20.000000. running mean: -20.419223\n","resetting env. episode 575.000000, reward total was -21.000000. running mean: -20.425031\n","resetting env. episode 576.000000, reward total was -21.000000. running mean: -20.430780\n","resetting env. episode 577.000000, reward total was -21.000000. running mean: -20.436472\n","resetting env. episode 578.000000, reward total was -21.000000. running mean: -20.442108\n","resetting env. episode 579.000000, reward total was -21.000000. running mean: -20.447687\n","resetting env. episode 580.000000, reward total was -20.000000. running mean: -20.443210\n","resetting env. episode 581.000000, reward total was -21.000000. running mean: -20.448778\n","resetting env. episode 582.000000, reward total was -21.000000. running mean: -20.454290\n","resetting env. episode 583.000000, reward total was -21.000000. running mean: -20.459747\n","resetting env. episode 584.000000, reward total was -21.000000. running mean: -20.465150\n","resetting env. episode 585.000000, reward total was -21.000000. running mean: -20.470498\n","resetting env. episode 586.000000, reward total was -21.000000. running mean: -20.475793\n","resetting env. episode 587.000000, reward total was -20.000000. running mean: -20.471035\n","resetting env. episode 588.000000, reward total was -20.000000. running mean: -20.466325\n","resetting env. episode 589.000000, reward total was -21.000000. running mean: -20.471662\n","resetting env. episode 590.000000, reward total was -19.000000. running mean: -20.456945\n","resetting env. episode 591.000000, reward total was -20.000000. running mean: -20.452375\n","resetting env. episode 592.000000, reward total was -21.000000. running mean: -20.457852\n","resetting env. episode 593.000000, reward total was -19.000000. running mean: -20.443273\n","resetting env. episode 594.000000, reward total was -21.000000. running mean: -20.448840\n","resetting env. episode 595.000000, reward total was -21.000000. running mean: -20.454352\n","resetting env. episode 596.000000, reward total was -21.000000. running mean: -20.459809\n","resetting env. episode 597.000000, reward total was -21.000000. running mean: -20.465210\n","resetting env. episode 598.000000, reward total was -21.000000. running mean: -20.470558\n","resetting env. episode 599.000000, reward total was -21.000000. running mean: -20.475853\n","resetting env. episode 600.000000, reward total was -21.000000. running mean: -20.481094\n","resetting env. episode 601.000000, reward total was -21.000000. running mean: -20.486283\n","resetting env. episode 602.000000, reward total was -20.000000. running mean: -20.481420\n","resetting env. episode 603.000000, reward total was -21.000000. running mean: -20.486606\n","resetting env. episode 604.000000, reward total was -21.000000. running mean: -20.491740\n","resetting env. episode 605.000000, reward total was -19.000000. running mean: -20.476823\n","resetting env. episode 606.000000, reward total was -19.000000. running mean: -20.462055\n","resetting env. episode 607.000000, reward total was -21.000000. running mean: -20.467434\n","resetting env. episode 608.000000, reward total was -20.000000. running mean: -20.462760\n","resetting env. episode 609.000000, reward total was -21.000000. running mean: -20.468132\n","resetting env. episode 610.000000, reward total was -19.000000. running mean: -20.453451\n","resetting env. episode 611.000000, reward total was -21.000000. running mean: -20.458916\n","resetting env. episode 612.000000, reward total was -21.000000. running mean: -20.464327\n","resetting env. episode 613.000000, reward total was -19.000000. running mean: -20.449684\n","resetting env. episode 614.000000, reward total was -21.000000. running mean: -20.455187\n","resetting env. episode 615.000000, reward total was -20.000000. running mean: -20.450635\n","resetting env. episode 616.000000, reward total was -20.000000. running mean: -20.446129\n","resetting env. episode 617.000000, reward total was -17.000000. running mean: -20.411667\n","resetting env. episode 618.000000, reward total was -21.000000. running mean: -20.417551\n","resetting env. episode 619.000000, reward total was -21.000000. running mean: -20.423375\n","resetting env. episode 620.000000, reward total was -20.000000. running mean: -20.419142\n","resetting env. episode 621.000000, reward total was -21.000000. running mean: -20.424950\n","resetting env. episode 622.000000, reward total was -21.000000. running mean: -20.430701\n","resetting env. episode 623.000000, reward total was -20.000000. running mean: -20.426394\n","resetting env. episode 624.000000, reward total was -21.000000. running mean: -20.432130\n","resetting env. episode 625.000000, reward total was -21.000000. running mean: -20.437808\n","resetting env. episode 626.000000, reward total was -21.000000. running mean: -20.443430\n","resetting env. episode 627.000000, reward total was -21.000000. running mean: -20.448996\n","resetting env. episode 628.000000, reward total was -21.000000. running mean: -20.454506\n","resetting env. episode 629.000000, reward total was -21.000000. running mean: -20.459961\n","resetting env. episode 630.000000, reward total was -20.000000. running mean: -20.455361\n","resetting env. episode 631.000000, reward total was -20.000000. running mean: -20.450808\n","resetting env. episode 632.000000, reward total was -18.000000. running mean: -20.426300\n","resetting env. episode 633.000000, reward total was -21.000000. running mean: -20.432037\n","resetting env. episode 634.000000, reward total was -20.000000. running mean: -20.427716\n","resetting env. episode 635.000000, reward total was -21.000000. running mean: -20.433439\n","resetting env. episode 636.000000, reward total was -21.000000. running mean: -20.439105\n","resetting env. episode 637.000000, reward total was -21.000000. running mean: -20.444714\n","resetting env. episode 638.000000, reward total was -21.000000. running mean: -20.450267\n","resetting env. episode 639.000000, reward total was -18.000000. running mean: -20.425764\n","resetting env. episode 640.000000, reward total was -21.000000. running mean: -20.431506\n","resetting env. episode 641.000000, reward total was -20.000000. running mean: -20.427191\n","resetting env. episode 642.000000, reward total was -21.000000. running mean: -20.432919\n","resetting env. episode 643.000000, reward total was -21.000000. running mean: -20.438590\n","resetting env. episode 644.000000, reward total was -21.000000. running mean: -20.444204\n","resetting env. episode 645.000000, reward total was -21.000000. running mean: -20.449762\n","resetting env. episode 646.000000, reward total was -20.000000. running mean: -20.445265\n","resetting env. episode 647.000000, reward total was -21.000000. running mean: -20.450812\n","resetting env. episode 648.000000, reward total was -21.000000. running mean: -20.456304\n","resetting env. episode 649.000000, reward total was -21.000000. running mean: -20.461741\n","resetting env. episode 650.000000, reward total was -21.000000. running mean: -20.467123\n","resetting env. episode 651.000000, reward total was -21.000000. running mean: -20.472452\n","resetting env. episode 652.000000, reward total was -21.000000. running mean: -20.477728\n","resetting env. episode 653.000000, reward total was -21.000000. running mean: -20.482950\n","resetting env. episode 654.000000, reward total was -21.000000. running mean: -20.488121\n","resetting env. episode 655.000000, reward total was -20.000000. running mean: -20.483240\n","resetting env. episode 656.000000, reward total was -19.000000. running mean: -20.468407\n","resetting env. episode 657.000000, reward total was -21.000000. running mean: -20.473723\n","resetting env. episode 658.000000, reward total was -20.000000. running mean: -20.468986\n","resetting env. episode 659.000000, reward total was -21.000000. running mean: -20.474296\n","resetting env. episode 660.000000, reward total was -21.000000. running mean: -20.479553\n","resetting env. episode 661.000000, reward total was -19.000000. running mean: -20.464758\n","resetting env. episode 662.000000, reward total was -21.000000. running mean: -20.470110\n","resetting env. episode 663.000000, reward total was -21.000000. running mean: -20.475409\n","resetting env. episode 664.000000, reward total was -20.000000. running mean: -20.470655\n","resetting env. episode 665.000000, reward total was -21.000000. running mean: -20.475948\n","resetting env. episode 666.000000, reward total was -21.000000. running mean: -20.481189\n","resetting env. episode 667.000000, reward total was -21.000000. running mean: -20.486377\n","resetting env. episode 668.000000, reward total was -20.000000. running mean: -20.481513\n","resetting env. episode 669.000000, reward total was -20.000000. running mean: -20.476698\n","resetting env. episode 670.000000, reward total was -20.000000. running mean: -20.471931\n","resetting env. episode 671.000000, reward total was -21.000000. running mean: -20.477212\n","resetting env. episode 672.000000, reward total was -20.000000. running mean: -20.472440\n","resetting env. episode 673.000000, reward total was -21.000000. running mean: -20.477715\n","resetting env. episode 674.000000, reward total was -21.000000. running mean: -20.482938\n","resetting env. episode 675.000000, reward total was -21.000000. running mean: -20.488109\n","resetting env. episode 676.000000, reward total was -21.000000. running mean: -20.493228\n","resetting env. episode 677.000000, reward total was -20.000000. running mean: -20.488295\n","resetting env. episode 678.000000, reward total was -19.000000. running mean: -20.473412\n","resetting env. episode 679.000000, reward total was -20.000000. running mean: -20.468678\n","resetting env. episode 680.000000, reward total was -20.000000. running mean: -20.463991\n","resetting env. episode 681.000000, reward total was -21.000000. running mean: -20.469351\n","resetting env. episode 682.000000, reward total was -21.000000. running mean: -20.474658\n","resetting env. episode 683.000000, reward total was -20.000000. running mean: -20.469911\n","resetting env. episode 684.000000, reward total was -20.000000. running mean: -20.465212\n","resetting env. episode 685.000000, reward total was -20.000000. running mean: -20.460560\n","resetting env. episode 686.000000, reward total was -21.000000. running mean: -20.465955\n","resetting env. episode 687.000000, reward total was -20.000000. running mean: -20.461295\n","resetting env. episode 688.000000, reward total was -21.000000. running mean: -20.466682\n","resetting env. episode 689.000000, reward total was -20.000000. running mean: -20.462015\n","resetting env. episode 690.000000, reward total was -21.000000. running mean: -20.467395\n","resetting env. episode 691.000000, reward total was -21.000000. running mean: -20.472721\n","resetting env. episode 692.000000, reward total was -21.000000. running mean: -20.477994\n","resetting env. episode 693.000000, reward total was -21.000000. running mean: -20.483214\n","resetting env. episode 694.000000, reward total was -21.000000. running mean: -20.488382\n","resetting env. episode 695.000000, reward total was -20.000000. running mean: -20.483498\n","resetting env. episode 696.000000, reward total was -20.000000. running mean: -20.478663\n","resetting env. episode 697.000000, reward total was -21.000000. running mean: -20.483876\n","resetting env. episode 698.000000, reward total was -21.000000. running mean: -20.489038\n","resetting env. episode 699.000000, reward total was -21.000000. running mean: -20.494147\n","resetting env. episode 700.000000, reward total was -21.000000. running mean: -20.499206\n","resetting env. episode 701.000000, reward total was -21.000000. running mean: -20.504214\n","resetting env. episode 702.000000, reward total was -19.000000. running mean: -20.489172\n","resetting env. episode 703.000000, reward total was -21.000000. running mean: -20.494280\n","resetting env. episode 704.000000, reward total was -20.000000. running mean: -20.489337\n","resetting env. episode 705.000000, reward total was -21.000000. running mean: -20.494444\n","resetting env. episode 706.000000, reward total was -21.000000. running mean: -20.499499\n","resetting env. episode 707.000000, reward total was -21.000000. running mean: -20.504504\n","resetting env. episode 708.000000, reward total was -21.000000. running mean: -20.509459\n","resetting env. episode 709.000000, reward total was -21.000000. running mean: -20.514365\n","resetting env. episode 710.000000, reward total was -21.000000. running mean: -20.519221\n","resetting env. episode 711.000000, reward total was -21.000000. running mean: -20.524029\n","resetting env. episode 712.000000, reward total was -20.000000. running mean: -20.518789\n","resetting env. episode 713.000000, reward total was -20.000000. running mean: -20.513601\n","resetting env. episode 714.000000, reward total was -20.000000. running mean: -20.508465\n","resetting env. episode 715.000000, reward total was -21.000000. running mean: -20.513380\n","resetting env. episode 716.000000, reward total was -21.000000. running mean: -20.518246\n","resetting env. episode 717.000000, reward total was -21.000000. running mean: -20.523064\n","resetting env. episode 718.000000, reward total was -21.000000. running mean: -20.527833\n","resetting env. episode 719.000000, reward total was -21.000000. running mean: -20.532555\n","resetting env. episode 720.000000, reward total was -20.000000. running mean: -20.527229\n","resetting env. episode 721.000000, reward total was -21.000000. running mean: -20.531957\n","resetting env. episode 722.000000, reward total was -21.000000. running mean: -20.536637\n","resetting env. episode 723.000000, reward total was -20.000000. running mean: -20.531271\n","resetting env. episode 724.000000, reward total was -20.000000. running mean: -20.525958\n","resetting env. episode 725.000000, reward total was -21.000000. running mean: -20.530699\n","resetting env. episode 726.000000, reward total was -21.000000. running mean: -20.535392\n","resetting env. episode 727.000000, reward total was -21.000000. running mean: -20.540038\n","resetting env. episode 728.000000, reward total was -21.000000. running mean: -20.544637\n","resetting env. episode 729.000000, reward total was -21.000000. running mean: -20.549191\n","resetting env. episode 730.000000, reward total was -20.000000. running mean: -20.543699\n","resetting env. episode 731.000000, reward total was -17.000000. running mean: -20.508262\n","resetting env. episode 732.000000, reward total was -21.000000. running mean: -20.513179\n","resetting env. episode 733.000000, reward total was -21.000000. running mean: -20.518048\n","resetting env. episode 734.000000, reward total was -20.000000. running mean: -20.512867\n","resetting env. episode 735.000000, reward total was -21.000000. running mean: -20.517739\n","resetting env. episode 736.000000, reward total was -21.000000. running mean: -20.522561\n","resetting env. episode 737.000000, reward total was -21.000000. running mean: -20.527336\n","resetting env. episode 738.000000, reward total was -18.000000. running mean: -20.502062\n","resetting env. episode 739.000000, reward total was -21.000000. running mean: -20.507042\n","resetting env. episode 740.000000, reward total was -21.000000. running mean: -20.511971\n","resetting env. episode 741.000000, reward total was -21.000000. running mean: -20.516851\n","resetting env. episode 742.000000, reward total was -20.000000. running mean: -20.511683\n","resetting env. episode 743.000000, reward total was -21.000000. running mean: -20.516566\n","resetting env. episode 744.000000, reward total was -21.000000. running mean: -20.521400\n","resetting env. episode 745.000000, reward total was -21.000000. running mean: -20.526186\n","resetting env. episode 746.000000, reward total was -21.000000. running mean: -20.530925\n","resetting env. episode 747.000000, reward total was -21.000000. running mean: -20.535615\n","resetting env. episode 748.000000, reward total was -21.000000. running mean: -20.540259\n","resetting env. episode 749.000000, reward total was -20.000000. running mean: -20.534857\n","resetting env. episode 750.000000, reward total was -19.000000. running mean: -20.519508\n","resetting env. episode 751.000000, reward total was -21.000000. running mean: -20.524313\n","resetting env. episode 752.000000, reward total was -21.000000. running mean: -20.529070\n","resetting env. episode 753.000000, reward total was -21.000000. running mean: -20.533779\n","resetting env. episode 754.000000, reward total was -20.000000. running mean: -20.528441\n","resetting env. episode 755.000000, reward total was -18.000000. running mean: -20.503157\n","resetting env. episode 756.000000, reward total was -20.000000. running mean: -20.498125\n","resetting env. episode 757.000000, reward total was -20.000000. running mean: -20.493144\n","resetting env. episode 758.000000, reward total was -21.000000. running mean: -20.498213\n","resetting env. episode 759.000000, reward total was -19.000000. running mean: -20.483231\n","resetting env. episode 760.000000, reward total was -21.000000. running mean: -20.488398\n","resetting env. episode 761.000000, reward total was -21.000000. running mean: -20.493514\n","resetting env. episode 762.000000, reward total was -21.000000. running mean: -20.498579\n","resetting env. episode 763.000000, reward total was -20.000000. running mean: -20.493593\n","resetting env. episode 764.000000, reward total was -21.000000. running mean: -20.498657\n","resetting env. episode 765.000000, reward total was -21.000000. running mean: -20.503671\n","resetting env. episode 766.000000, reward total was -20.000000. running mean: -20.498634\n","resetting env. episode 767.000000, reward total was -20.000000. running mean: -20.493648\n","resetting env. episode 768.000000, reward total was -20.000000. running mean: -20.488711\n","resetting env. episode 769.000000, reward total was -21.000000. running mean: -20.493824\n","resetting env. episode 770.000000, reward total was -21.000000. running mean: -20.498886\n","resetting env. episode 771.000000, reward total was -21.000000. running mean: -20.503897\n","resetting env. episode 772.000000, reward total was -20.000000. running mean: -20.498858\n","resetting env. episode 773.000000, reward total was -20.000000. running mean: -20.493869\n","resetting env. episode 774.000000, reward total was -21.000000. running mean: -20.498931\n","resetting env. episode 775.000000, reward total was -20.000000. running mean: -20.493941\n","resetting env. episode 776.000000, reward total was -20.000000. running mean: -20.489002\n","resetting env. episode 777.000000, reward total was -21.000000. running mean: -20.494112\n","resetting env. episode 778.000000, reward total was -21.000000. running mean: -20.499171\n","resetting env. episode 779.000000, reward total was -21.000000. running mean: -20.504179\n","resetting env. episode 780.000000, reward total was -21.000000. running mean: -20.509137\n","resetting env. episode 781.000000, reward total was -18.000000. running mean: -20.484046\n","resetting env. episode 782.000000, reward total was -21.000000. running mean: -20.489206\n","resetting env. episode 783.000000, reward total was -21.000000. running mean: -20.494314\n","resetting env. episode 784.000000, reward total was -21.000000. running mean: -20.499370\n","resetting env. episode 785.000000, reward total was -19.000000. running mean: -20.484377\n","resetting env. episode 786.000000, reward total was -20.000000. running mean: -20.479533\n","resetting env. episode 787.000000, reward total was -21.000000. running mean: -20.484738\n","resetting env. episode 788.000000, reward total was -21.000000. running mean: -20.489890\n","resetting env. episode 789.000000, reward total was -18.000000. running mean: -20.464991\n","resetting env. episode 790.000000, reward total was -21.000000. running mean: -20.470341\n","resetting env. episode 791.000000, reward total was -21.000000. running mean: -20.475638\n","resetting env. episode 792.000000, reward total was -20.000000. running mean: -20.470882\n","resetting env. episode 793.000000, reward total was -21.000000. running mean: -20.476173\n","resetting env. episode 794.000000, reward total was -21.000000. running mean: -20.481411\n","resetting env. episode 795.000000, reward total was -20.000000. running mean: -20.476597\n","resetting env. episode 796.000000, reward total was -21.000000. running mean: -20.481831\n","resetting env. episode 797.000000, reward total was -19.000000. running mean: -20.467013\n","resetting env. episode 798.000000, reward total was -21.000000. running mean: -20.472343\n","resetting env. episode 799.000000, reward total was -18.000000. running mean: -20.447619\n","resetting env. episode 800.000000, reward total was -20.000000. running mean: -20.443143\n","resetting env. episode 801.000000, reward total was -21.000000. running mean: -20.448712\n","resetting env. episode 802.000000, reward total was -21.000000. running mean: -20.454224\n","resetting env. episode 803.000000, reward total was -21.000000. running mean: -20.459682\n","resetting env. episode 804.000000, reward total was -20.000000. running mean: -20.455085\n","resetting env. episode 805.000000, reward total was -21.000000. running mean: -20.460534\n","resetting env. episode 806.000000, reward total was -20.000000. running mean: -20.455929\n","resetting env. episode 807.000000, reward total was -20.000000. running mean: -20.451370\n","resetting env. episode 808.000000, reward total was -21.000000. running mean: -20.456856\n","resetting env. episode 809.000000, reward total was -20.000000. running mean: -20.452288\n","resetting env. episode 810.000000, reward total was -21.000000. running mean: -20.457765\n","resetting env. episode 811.000000, reward total was -20.000000. running mean: -20.453187\n","resetting env. episode 812.000000, reward total was -21.000000. running mean: -20.458655\n","resetting env. episode 813.000000, reward total was -21.000000. running mean: -20.464069\n","resetting env. episode 814.000000, reward total was -21.000000. running mean: -20.469428\n","resetting env. episode 815.000000, reward total was -20.000000. running mean: -20.464734\n","resetting env. episode 816.000000, reward total was -19.000000. running mean: -20.450086\n","resetting env. episode 817.000000, reward total was -21.000000. running mean: -20.455585\n","resetting env. episode 818.000000, reward total was -20.000000. running mean: -20.451030\n","resetting env. episode 819.000000, reward total was -21.000000. running mean: -20.456519\n","resetting env. episode 820.000000, reward total was -21.000000. running mean: -20.461954\n","resetting env. episode 821.000000, reward total was -21.000000. running mean: -20.467335\n","resetting env. episode 822.000000, reward total was -19.000000. running mean: -20.452661\n","resetting env. episode 823.000000, reward total was -21.000000. running mean: -20.458135\n","resetting env. episode 824.000000, reward total was -21.000000. running mean: -20.463553\n","resetting env. episode 825.000000, reward total was -20.000000. running mean: -20.458918\n","resetting env. episode 826.000000, reward total was -21.000000. running mean: -20.464329\n","resetting env. episode 827.000000, reward total was -20.000000. running mean: -20.459685\n","resetting env. episode 828.000000, reward total was -21.000000. running mean: -20.465088\n","resetting env. episode 829.000000, reward total was -20.000000. running mean: -20.460438\n","resetting env. episode 830.000000, reward total was -20.000000. running mean: -20.455833\n","resetting env. episode 831.000000, reward total was -21.000000. running mean: -20.461275\n","resetting env. episode 832.000000, reward total was -20.000000. running mean: -20.456662\n","resetting env. episode 833.000000, reward total was -21.000000. running mean: -20.462095\n","resetting env. episode 834.000000, reward total was -21.000000. running mean: -20.467475\n","resetting env. episode 835.000000, reward total was -21.000000. running mean: -20.472800\n","resetting env. episode 836.000000, reward total was -20.000000. running mean: -20.468072\n","resetting env. episode 837.000000, reward total was -20.000000. running mean: -20.463391\n","resetting env. episode 838.000000, reward total was -20.000000. running mean: -20.458757\n","resetting env. episode 839.000000, reward total was -20.000000. running mean: -20.454170\n","resetting env. episode 840.000000, reward total was -20.000000. running mean: -20.449628\n","resetting env. episode 841.000000, reward total was -21.000000. running mean: -20.455132\n","resetting env. episode 842.000000, reward total was -21.000000. running mean: -20.460580\n","resetting env. episode 843.000000, reward total was -21.000000. running mean: -20.465974\n","resetting env. episode 844.000000, reward total was -21.000000. running mean: -20.471315\n","resetting env. episode 845.000000, reward total was -20.000000. running mean: -20.466602\n","resetting env. episode 846.000000, reward total was -20.000000. running mean: -20.461936\n","resetting env. episode 847.000000, reward total was -21.000000. running mean: -20.467316\n","resetting env. episode 848.000000, reward total was -18.000000. running mean: -20.442643\n","resetting env. episode 849.000000, reward total was -21.000000. running mean: -20.448217\n","resetting env. episode 850.000000, reward total was -19.000000. running mean: -20.433734\n","resetting env. episode 851.000000, reward total was -20.000000. running mean: -20.429397\n","resetting env. episode 852.000000, reward total was -21.000000. running mean: -20.435103\n","resetting env. episode 853.000000, reward total was -21.000000. running mean: -20.440752\n","resetting env. episode 854.000000, reward total was -21.000000. running mean: -20.446345\n","resetting env. episode 855.000000, reward total was -20.000000. running mean: -20.441881\n","resetting env. episode 856.000000, reward total was -21.000000. running mean: -20.447462\n","resetting env. episode 857.000000, reward total was -21.000000. running mean: -20.452988\n","resetting env. episode 858.000000, reward total was -21.000000. running mean: -20.458458\n","resetting env. episode 859.000000, reward total was -20.000000. running mean: -20.453873\n","resetting env. episode 860.000000, reward total was -20.000000. running mean: -20.449335\n","resetting env. episode 861.000000, reward total was -21.000000. running mean: -20.454841\n","resetting env. episode 862.000000, reward total was -21.000000. running mean: -20.460293\n","resetting env. episode 863.000000, reward total was -21.000000. running mean: -20.465690\n","resetting env. episode 864.000000, reward total was -20.000000. running mean: -20.461033\n","resetting env. episode 865.000000, reward total was -21.000000. running mean: -20.466423\n","resetting env. episode 866.000000, reward total was -20.000000. running mean: -20.461758\n","resetting env. episode 867.000000, reward total was -21.000000. running mean: -20.467141\n","resetting env. episode 868.000000, reward total was -19.000000. running mean: -20.452469\n","resetting env. episode 869.000000, reward total was -20.000000. running mean: -20.447945\n","resetting env. episode 870.000000, reward total was -21.000000. running mean: -20.453465\n","resetting env. episode 871.000000, reward total was -21.000000. running mean: -20.458931\n","resetting env. episode 872.000000, reward total was -21.000000. running mean: -20.464341\n","resetting env. episode 873.000000, reward total was -20.000000. running mean: -20.459698\n","resetting env. episode 874.000000, reward total was -21.000000. running mean: -20.465101\n","resetting env. episode 875.000000, reward total was -21.000000. running mean: -20.470450\n","resetting env. episode 876.000000, reward total was -20.000000. running mean: -20.465745\n","resetting env. episode 877.000000, reward total was -21.000000. running mean: -20.471088\n","resetting env. episode 878.000000, reward total was -20.000000. running mean: -20.466377\n","resetting env. episode 879.000000, reward total was -20.000000. running mean: -20.461713\n","resetting env. episode 880.000000, reward total was -21.000000. running mean: -20.467096\n","resetting env. episode 881.000000, reward total was -20.000000. running mean: -20.462425\n","resetting env. episode 882.000000, reward total was -21.000000. running mean: -20.467801\n","resetting env. episode 883.000000, reward total was -21.000000. running mean: -20.473123\n","resetting env. episode 884.000000, reward total was -20.000000. running mean: -20.468392\n","resetting env. episode 885.000000, reward total was -20.000000. running mean: -20.463708\n","resetting env. episode 886.000000, reward total was -21.000000. running mean: -20.469071\n","resetting env. episode 887.000000, reward total was -21.000000. running mean: -20.474380\n","resetting env. episode 888.000000, reward total was -21.000000. running mean: -20.479636\n","resetting env. episode 889.000000, reward total was -21.000000. running mean: -20.484840\n","resetting env. episode 890.000000, reward total was -21.000000. running mean: -20.489991\n","resetting env. episode 891.000000, reward total was -21.000000. running mean: -20.495092\n","resetting env. episode 892.000000, reward total was -21.000000. running mean: -20.500141\n","resetting env. episode 893.000000, reward total was -20.000000. running mean: -20.495139\n","resetting env. episode 894.000000, reward total was -19.000000. running mean: -20.480188\n","resetting env. episode 895.000000, reward total was -17.000000. running mean: -20.445386\n","resetting env. episode 896.000000, reward total was -21.000000. running mean: -20.450932\n","resetting env. episode 897.000000, reward total was -21.000000. running mean: -20.456423\n","resetting env. episode 898.000000, reward total was -21.000000. running mean: -20.461859\n","resetting env. episode 899.000000, reward total was -21.000000. running mean: -20.467240\n","resetting env. episode 900.000000, reward total was -18.000000. running mean: -20.442568\n","resetting env. episode 901.000000, reward total was -21.000000. running mean: -20.448142\n","resetting env. episode 902.000000, reward total was -21.000000. running mean: -20.453660\n","resetting env. episode 903.000000, reward total was -20.000000. running mean: -20.449124\n","resetting env. episode 904.000000, reward total was -20.000000. running mean: -20.444633\n","resetting env. episode 905.000000, reward total was -19.000000. running mean: -20.430186\n","resetting env. episode 906.000000, reward total was -21.000000. running mean: -20.435884\n","resetting env. episode 907.000000, reward total was -20.000000. running mean: -20.431526\n","resetting env. episode 908.000000, reward total was -21.000000. running mean: -20.437210\n","resetting env. episode 909.000000, reward total was -20.000000. running mean: -20.432838\n","resetting env. episode 910.000000, reward total was -21.000000. running mean: -20.438510\n","resetting env. episode 911.000000, reward total was -21.000000. running mean: -20.444125\n","resetting env. episode 912.000000, reward total was -20.000000. running mean: -20.439683\n","resetting env. episode 913.000000, reward total was -20.000000. running mean: -20.435287\n","resetting env. episode 914.000000, reward total was -21.000000. running mean: -20.440934\n","resetting env. episode 915.000000, reward total was -19.000000. running mean: -20.426524\n","resetting env. episode 916.000000, reward total was -21.000000. running mean: -20.432259\n","resetting env. episode 917.000000, reward total was -21.000000. running mean: -20.437937\n","resetting env. episode 918.000000, reward total was -20.000000. running mean: -20.433557\n","resetting env. episode 919.000000, reward total was -21.000000. running mean: -20.439222\n","resetting env. episode 920.000000, reward total was -20.000000. running mean: -20.434829\n","resetting env. episode 921.000000, reward total was -21.000000. running mean: -20.440481\n","resetting env. episode 922.000000, reward total was -21.000000. running mean: -20.446076\n","resetting env. episode 923.000000, reward total was -21.000000. running mean: -20.451616\n","resetting env. episode 924.000000, reward total was -19.000000. running mean: -20.437099\n","resetting env. episode 925.000000, reward total was -21.000000. running mean: -20.442728\n","resetting env. episode 926.000000, reward total was -21.000000. running mean: -20.448301\n","resetting env. episode 927.000000, reward total was -21.000000. running mean: -20.453818\n","resetting env. episode 928.000000, reward total was -21.000000. running mean: -20.459280\n","resetting env. episode 929.000000, reward total was -21.000000. running mean: -20.464687\n","resetting env. episode 930.000000, reward total was -21.000000. running mean: -20.470040\n","resetting env. episode 931.000000, reward total was -21.000000. running mean: -20.475340\n","resetting env. episode 932.000000, reward total was -21.000000. running mean: -20.480586\n","resetting env. episode 933.000000, reward total was -21.000000. running mean: -20.485781\n","resetting env. episode 934.000000, reward total was -21.000000. running mean: -20.490923\n","resetting env. episode 935.000000, reward total was -21.000000. running mean: -20.496014\n","resetting env. episode 936.000000, reward total was -21.000000. running mean: -20.501053\n","resetting env. episode 937.000000, reward total was -21.000000. running mean: -20.506043\n","resetting env. episode 938.000000, reward total was -21.000000. running mean: -20.510982\n","resetting env. episode 939.000000, reward total was -21.000000. running mean: -20.515873\n","resetting env. episode 940.000000, reward total was -20.000000. running mean: -20.510714\n","resetting env. episode 941.000000, reward total was -20.000000. running mean: -20.505607\n","resetting env. episode 942.000000, reward total was -21.000000. running mean: -20.510551\n","resetting env. episode 943.000000, reward total was -19.000000. running mean: -20.495445\n","resetting env. episode 944.000000, reward total was -20.000000. running mean: -20.490491\n","resetting env. episode 945.000000, reward total was -20.000000. running mean: -20.485586\n","resetting env. episode 946.000000, reward total was -20.000000. running mean: -20.480730\n","resetting env. episode 947.000000, reward total was -21.000000. running mean: -20.485923\n","resetting env. episode 948.000000, reward total was -21.000000. running mean: -20.491063\n","resetting env. episode 949.000000, reward total was -21.000000. running mean: -20.496153\n","resetting env. episode 950.000000, reward total was -20.000000. running mean: -20.491191\n","resetting env. episode 951.000000, reward total was -21.000000. running mean: -20.496279\n","resetting env. episode 952.000000, reward total was -21.000000. running mean: -20.501317\n","resetting env. episode 953.000000, reward total was -17.000000. running mean: -20.466303\n","resetting env. episode 954.000000, reward total was -21.000000. running mean: -20.471640\n","resetting env. episode 955.000000, reward total was -21.000000. running mean: -20.476924\n","resetting env. episode 956.000000, reward total was -21.000000. running mean: -20.482155\n","resetting env. episode 957.000000, reward total was -21.000000. running mean: -20.487333\n","resetting env. episode 958.000000, reward total was -20.000000. running mean: -20.482460\n","resetting env. episode 959.000000, reward total was -21.000000. running mean: -20.487635\n","resetting env. episode 960.000000, reward total was -19.000000. running mean: -20.472759\n","resetting env. episode 961.000000, reward total was -21.000000. running mean: -20.478031\n","resetting env. episode 962.000000, reward total was -20.000000. running mean: -20.473251\n","resetting env. episode 963.000000, reward total was -21.000000. running mean: -20.478519\n","resetting env. episode 964.000000, reward total was -21.000000. running mean: -20.483733\n","resetting env. episode 965.000000, reward total was -20.000000. running mean: -20.478896\n","resetting env. episode 966.000000, reward total was -20.000000. running mean: -20.474107\n","resetting env. episode 967.000000, reward total was -21.000000. running mean: -20.479366\n","resetting env. episode 968.000000, reward total was -21.000000. running mean: -20.484572\n","resetting env. episode 969.000000, reward total was -20.000000. running mean: -20.479727\n","resetting env. episode 970.000000, reward total was -21.000000. running mean: -20.484929\n","resetting env. episode 971.000000, reward total was -21.000000. running mean: -20.490080\n","resetting env. episode 972.000000, reward total was -21.000000. running mean: -20.495179\n","resetting env. episode 973.000000, reward total was -21.000000. running mean: -20.500227\n","resetting env. episode 974.000000, reward total was -19.000000. running mean: -20.485225\n","resetting env. episode 975.000000, reward total was -19.000000. running mean: -20.470373\n","resetting env. episode 976.000000, reward total was -21.000000. running mean: -20.475669\n","resetting env. episode 977.000000, reward total was -20.000000. running mean: -20.470912\n","resetting env. episode 978.000000, reward total was -21.000000. running mean: -20.476203\n","resetting env. episode 979.000000, reward total was -20.000000. running mean: -20.471441\n","resetting env. episode 980.000000, reward total was -19.000000. running mean: -20.456727\n","resetting env. episode 981.000000, reward total was -21.000000. running mean: -20.462160\n","resetting env. episode 982.000000, reward total was -21.000000. running mean: -20.467538\n","resetting env. episode 983.000000, reward total was -21.000000. running mean: -20.472863\n","resetting env. episode 984.000000, reward total was -18.000000. running mean: -20.448134\n","resetting env. episode 985.000000, reward total was -20.000000. running mean: -20.443653\n","resetting env. episode 986.000000, reward total was -21.000000. running mean: -20.449216\n","resetting env. episode 987.000000, reward total was -21.000000. running mean: -20.454724\n","resetting env. episode 988.000000, reward total was -19.000000. running mean: -20.440177\n","resetting env. episode 989.000000, reward total was -21.000000. running mean: -20.445775\n","resetting env. episode 990.000000, reward total was -21.000000. running mean: -20.451317\n","resetting env. episode 991.000000, reward total was -21.000000. running mean: -20.456804\n","resetting env. episode 992.000000, reward total was -21.000000. running mean: -20.462236\n","resetting env. episode 993.000000, reward total was -21.000000. running mean: -20.467614\n","resetting env. episode 994.000000, reward total was -21.000000. running mean: -20.472938\n","resetting env. episode 995.000000, reward total was -20.000000. running mean: -20.468208\n","resetting env. episode 996.000000, reward total was -20.000000. running mean: -20.463526\n","resetting env. episode 997.000000, reward total was -21.000000. running mean: -20.468891\n","resetting env. episode 998.000000, reward total was -21.000000. running mean: -20.474202\n","resetting env. episode 999.000000, reward total was -20.000000. running mean: -20.469460\n","resetting env. episode 1000.000000, reward total was -20.000000. running mean: -20.464765\n","resetting env. episode 1001.000000, reward total was -21.000000. running mean: -20.470118\n","resetting env. episode 1002.000000, reward total was -19.000000. running mean: -20.455416\n","resetting env. episode 1003.000000, reward total was -21.000000. running mean: -20.460862\n","resetting env. episode 1004.000000, reward total was -21.000000. running mean: -20.466254\n","resetting env. episode 1005.000000, reward total was -21.000000. running mean: -20.471591\n","resetting env. episode 1006.000000, reward total was -21.000000. running mean: -20.476875\n","resetting env. episode 1007.000000, reward total was -20.000000. running mean: -20.472106\n","resetting env. episode 1008.000000, reward total was -21.000000. running mean: -20.477385\n","resetting env. episode 1009.000000, reward total was -20.000000. running mean: -20.472612\n","resetting env. episode 1010.000000, reward total was -21.000000. running mean: -20.477885\n","resetting env. episode 1011.000000, reward total was -20.000000. running mean: -20.473107\n","resetting env. episode 1012.000000, reward total was -21.000000. running mean: -20.478376\n","resetting env. episode 1013.000000, reward total was -19.000000. running mean: -20.463592\n","resetting env. episode 1014.000000, reward total was -21.000000. running mean: -20.468956\n","resetting env. episode 1015.000000, reward total was -21.000000. running mean: -20.474266\n","resetting env. episode 1016.000000, reward total was -21.000000. running mean: -20.479524\n","resetting env. episode 1017.000000, reward total was -21.000000. running mean: -20.484728\n","resetting env. episode 1018.000000, reward total was -21.000000. running mean: -20.489881\n","resetting env. episode 1019.000000, reward total was -20.000000. running mean: -20.484982\n","resetting env. episode 1020.000000, reward total was -21.000000. running mean: -20.490132\n","resetting env. episode 1021.000000, reward total was -21.000000. running mean: -20.495231\n","resetting env. episode 1022.000000, reward total was -21.000000. running mean: -20.500279\n","resetting env. episode 1023.000000, reward total was -21.000000. running mean: -20.505276\n","resetting env. episode 1024.000000, reward total was -21.000000. running mean: -20.510223\n","resetting env. episode 1025.000000, reward total was -21.000000. running mean: -20.515121\n","resetting env. episode 1026.000000, reward total was -20.000000. running mean: -20.509970\n","resetting env. episode 1027.000000, reward total was -20.000000. running mean: -20.504870\n","resetting env. episode 1028.000000, reward total was -21.000000. running mean: -20.509821\n","resetting env. episode 1029.000000, reward total was -21.000000. running mean: -20.514723\n","resetting env. episode 1030.000000, reward total was -21.000000. running mean: -20.519576\n","resetting env. episode 1031.000000, reward total was -21.000000. running mean: -20.524380\n","resetting env. episode 1032.000000, reward total was -19.000000. running mean: -20.509136\n","resetting env. episode 1033.000000, reward total was -19.000000. running mean: -20.494045\n","resetting env. episode 1034.000000, reward total was -19.000000. running mean: -20.479105\n","resetting env. episode 1035.000000, reward total was -20.000000. running mean: -20.474314\n","resetting env. episode 1036.000000, reward total was -21.000000. running mean: -20.479570\n","resetting env. episode 1037.000000, reward total was -20.000000. running mean: -20.474775\n","resetting env. episode 1038.000000, reward total was -21.000000. running mean: -20.480027\n","resetting env. episode 1039.000000, reward total was -20.000000. running mean: -20.475227\n","resetting env. episode 1040.000000, reward total was -19.000000. running mean: -20.460474\n","resetting env. episode 1041.000000, reward total was -20.000000. running mean: -20.455870\n","resetting env. episode 1042.000000, reward total was -21.000000. running mean: -20.461311\n","resetting env. episode 1043.000000, reward total was -21.000000. running mean: -20.466698\n","resetting env. episode 1044.000000, reward total was -19.000000. running mean: -20.452031\n","resetting env. episode 1045.000000, reward total was -20.000000. running mean: -20.447511\n","resetting env. episode 1046.000000, reward total was -21.000000. running mean: -20.453036\n","resetting env. episode 1047.000000, reward total was -18.000000. running mean: -20.428505\n","resetting env. episode 1048.000000, reward total was -21.000000. running mean: -20.434220\n","resetting env. episode 1049.000000, reward total was -21.000000. running mean: -20.439878\n","resetting env. episode 1050.000000, reward total was -21.000000. running mean: -20.445479\n","resetting env. episode 1051.000000, reward total was -20.000000. running mean: -20.441024\n","resetting env. episode 1052.000000, reward total was -21.000000. running mean: -20.446614\n","resetting env. episode 1053.000000, reward total was -19.000000. running mean: -20.432148\n","resetting env. episode 1054.000000, reward total was -21.000000. running mean: -20.437826\n","resetting env. episode 1055.000000, reward total was -21.000000. running mean: -20.443448\n","resetting env. episode 1056.000000, reward total was -18.000000. running mean: -20.419014\n","resetting env. episode 1057.000000, reward total was -20.000000. running mean: -20.414824\n","resetting env. episode 1058.000000, reward total was -21.000000. running mean: -20.420675\n","resetting env. episode 1059.000000, reward total was -19.000000. running mean: -20.406469\n","resetting env. episode 1060.000000, reward total was -20.000000. running mean: -20.402404\n","resetting env. episode 1061.000000, reward total was -20.000000. running mean: -20.398380\n","resetting env. episode 1062.000000, reward total was -21.000000. running mean: -20.404396\n","resetting env. episode 1063.000000, reward total was -20.000000. running mean: -20.400352\n","resetting env. episode 1064.000000, reward total was -21.000000. running mean: -20.406349\n","resetting env. episode 1065.000000, reward total was -21.000000. running mean: -20.412285\n","resetting env. episode 1066.000000, reward total was -21.000000. running mean: -20.418162\n","resetting env. episode 1067.000000, reward total was -21.000000. running mean: -20.423981\n","resetting env. episode 1068.000000, reward total was -21.000000. running mean: -20.429741\n","resetting env. episode 1069.000000, reward total was -17.000000. running mean: -20.395443\n","resetting env. episode 1070.000000, reward total was -20.000000. running mean: -20.391489\n","resetting env. episode 1071.000000, reward total was -20.000000. running mean: -20.387574\n","resetting env. episode 1072.000000, reward total was -21.000000. running mean: -20.393698\n","resetting env. episode 1073.000000, reward total was -21.000000. running mean: -20.399761\n","resetting env. episode 1074.000000, reward total was -20.000000. running mean: -20.395764\n","resetting env. episode 1075.000000, reward total was -21.000000. running mean: -20.401806\n","resetting env. episode 1076.000000, reward total was -21.000000. running mean: -20.407788\n","resetting env. episode 1077.000000, reward total was -21.000000. running mean: -20.413710\n","resetting env. episode 1078.000000, reward total was -20.000000. running mean: -20.409573\n","resetting env. episode 1079.000000, reward total was -21.000000. running mean: -20.415477\n","resetting env. episode 1080.000000, reward total was -21.000000. running mean: -20.421323\n","resetting env. episode 1081.000000, reward total was -20.000000. running mean: -20.417109\n","resetting env. episode 1082.000000, reward total was -20.000000. running mean: -20.412938\n","resetting env. episode 1083.000000, reward total was -20.000000. running mean: -20.408809\n","resetting env. episode 1084.000000, reward total was -21.000000. running mean: -20.414721\n","resetting env. episode 1085.000000, reward total was -21.000000. running mean: -20.420574\n","resetting env. episode 1086.000000, reward total was -21.000000. running mean: -20.426368\n","resetting env. episode 1087.000000, reward total was -20.000000. running mean: -20.422104\n","resetting env. episode 1088.000000, reward total was -19.000000. running mean: -20.407883\n","resetting env. episode 1089.000000, reward total was -21.000000. running mean: -20.413804\n","resetting env. episode 1090.000000, reward total was -21.000000. running mean: -20.419666\n","resetting env. episode 1091.000000, reward total was -19.000000. running mean: -20.405470\n","resetting env. episode 1092.000000, reward total was -18.000000. running mean: -20.381415\n","resetting env. episode 1093.000000, reward total was -21.000000. running mean: -20.387601\n","resetting env. episode 1094.000000, reward total was -21.000000. running mean: -20.393725\n","resetting env. episode 1095.000000, reward total was -19.000000. running mean: -20.379787\n","resetting env. episode 1096.000000, reward total was -19.000000. running mean: -20.365990\n","resetting env. episode 1097.000000, reward total was -19.000000. running mean: -20.352330\n","resetting env. episode 1098.000000, reward total was -19.000000. running mean: -20.338806\n","resetting env. episode 1099.000000, reward total was -21.000000. running mean: -20.345418\n","resetting env. episode 1100.000000, reward total was -21.000000. running mean: -20.351964\n","resetting env. episode 1101.000000, reward total was -19.000000. running mean: -20.338445\n","resetting env. episode 1102.000000, reward total was -21.000000. running mean: -20.345060\n","resetting env. episode 1103.000000, reward total was -21.000000. running mean: -20.351609\n","resetting env. episode 1104.000000, reward total was -20.000000. running mean: -20.348093\n","resetting env. episode 1105.000000, reward total was -20.000000. running mean: -20.344612\n","resetting env. episode 1106.000000, reward total was -19.000000. running mean: -20.331166\n","resetting env. episode 1107.000000, reward total was -21.000000. running mean: -20.337855\n","resetting env. episode 1108.000000, reward total was -20.000000. running mean: -20.334476\n","resetting env. episode 1109.000000, reward total was -21.000000. running mean: -20.341131\n","resetting env. episode 1110.000000, reward total was -21.000000. running mean: -20.347720\n","resetting env. episode 1111.000000, reward total was -21.000000. running mean: -20.354243\n","resetting env. episode 1112.000000, reward total was -21.000000. running mean: -20.360700\n","resetting env. episode 1113.000000, reward total was -21.000000. running mean: -20.367093\n","resetting env. episode 1114.000000, reward total was -20.000000. running mean: -20.363422\n","resetting env. episode 1115.000000, reward total was -21.000000. running mean: -20.369788\n","resetting env. episode 1116.000000, reward total was -21.000000. running mean: -20.376090\n","resetting env. episode 1117.000000, reward total was -19.000000. running mean: -20.362329\n","resetting env. episode 1118.000000, reward total was -21.000000. running mean: -20.368706\n","resetting env. episode 1119.000000, reward total was -20.000000. running mean: -20.365019\n","resetting env. episode 1120.000000, reward total was -21.000000. running mean: -20.371369\n","resetting env. episode 1121.000000, reward total was -21.000000. running mean: -20.377655\n","resetting env. episode 1122.000000, reward total was -21.000000. running mean: -20.383879\n","resetting env. episode 1123.000000, reward total was -21.000000. running mean: -20.390040\n","resetting env. episode 1124.000000, reward total was -21.000000. running mean: -20.396139\n","resetting env. episode 1125.000000, reward total was -21.000000. running mean: -20.402178\n","resetting env. episode 1126.000000, reward total was -21.000000. running mean: -20.408156\n","resetting env. episode 1127.000000, reward total was -21.000000. running mean: -20.414075\n","resetting env. episode 1128.000000, reward total was -18.000000. running mean: -20.389934\n","resetting env. episode 1129.000000, reward total was -19.000000. running mean: -20.376035\n","resetting env. episode 1130.000000, reward total was -21.000000. running mean: -20.382274\n","resetting env. episode 1131.000000, reward total was -20.000000. running mean: -20.378452\n","resetting env. episode 1132.000000, reward total was -21.000000. running mean: -20.384667\n","resetting env. episode 1133.000000, reward total was -21.000000. running mean: -20.390820\n","resetting env. episode 1134.000000, reward total was -21.000000. running mean: -20.396912\n","resetting env. episode 1135.000000, reward total was -21.000000. running mean: -20.402943\n","resetting env. episode 1136.000000, reward total was -21.000000. running mean: -20.408914\n","resetting env. episode 1137.000000, reward total was -19.000000. running mean: -20.394824\n","resetting env. episode 1138.000000, reward total was -21.000000. running mean: -20.400876\n","resetting env. episode 1139.000000, reward total was -21.000000. running mean: -20.406867\n","resetting env. episode 1140.000000, reward total was -21.000000. running mean: -20.412799\n","resetting env. episode 1141.000000, reward total was -21.000000. running mean: -20.418671\n","resetting env. episode 1142.000000, reward total was -20.000000. running mean: -20.414484\n","resetting env. episode 1143.000000, reward total was -21.000000. running mean: -20.420339\n","resetting env. episode 1144.000000, reward total was -21.000000. running mean: -20.426136\n","resetting env. episode 1145.000000, reward total was -18.000000. running mean: -20.401875\n","resetting env. episode 1146.000000, reward total was -21.000000. running mean: -20.407856\n","resetting env. episode 1147.000000, reward total was -21.000000. running mean: -20.413777\n","resetting env. episode 1148.000000, reward total was -20.000000. running mean: -20.409639\n","resetting env. episode 1149.000000, reward total was -21.000000. running mean: -20.415543\n","resetting env. episode 1150.000000, reward total was -21.000000. running mean: -20.421388\n","resetting env. episode 1151.000000, reward total was -21.000000. running mean: -20.427174\n","resetting env. episode 1152.000000, reward total was -21.000000. running mean: -20.432902\n","resetting env. episode 1153.000000, reward total was -20.000000. running mean: -20.428573\n","resetting env. episode 1154.000000, reward total was -21.000000. running mean: -20.434287\n","resetting env. episode 1155.000000, reward total was -20.000000. running mean: -20.429944\n","resetting env. episode 1156.000000, reward total was -21.000000. running mean: -20.435645\n","resetting env. episode 1157.000000, reward total was -21.000000. running mean: -20.441288\n","resetting env. episode 1158.000000, reward total was -21.000000. running mean: -20.446876\n","resetting env. episode 1159.000000, reward total was -20.000000. running mean: -20.442407\n","resetting env. episode 1160.000000, reward total was -21.000000. running mean: -20.447983\n","resetting env. episode 1161.000000, reward total was -21.000000. running mean: -20.453503\n","resetting env. episode 1162.000000, reward total was -21.000000. running mean: -20.458968\n","resetting env. episode 1163.000000, reward total was -21.000000. running mean: -20.464378\n","resetting env. episode 1164.000000, reward total was -20.000000. running mean: -20.459734\n","resetting env. episode 1165.000000, reward total was -18.000000. running mean: -20.435137\n","resetting env. episode 1166.000000, reward total was -20.000000. running mean: -20.430786\n","resetting env. episode 1167.000000, reward total was -20.000000. running mean: -20.426478\n","resetting env. episode 1168.000000, reward total was -21.000000. running mean: -20.432213\n","resetting env. episode 1169.000000, reward total was -19.000000. running mean: -20.417891\n","resetting env. episode 1170.000000, reward total was -21.000000. running mean: -20.423712\n","resetting env. episode 1171.000000, reward total was -21.000000. running mean: -20.429475\n","resetting env. episode 1172.000000, reward total was -21.000000. running mean: -20.435180\n","resetting env. episode 1173.000000, reward total was -20.000000. running mean: -20.430828\n","resetting env. episode 1174.000000, reward total was -20.000000. running mean: -20.426520\n","resetting env. episode 1175.000000, reward total was -21.000000. running mean: -20.432255\n","resetting env. episode 1176.000000, reward total was -21.000000. running mean: -20.437932\n","resetting env. episode 1177.000000, reward total was -21.000000. running mean: -20.443553\n","resetting env. episode 1178.000000, reward total was -20.000000. running mean: -20.439118\n","resetting env. episode 1179.000000, reward total was -20.000000. running mean: -20.434726\n","resetting env. episode 1180.000000, reward total was -21.000000. running mean: -20.440379\n","resetting env. episode 1181.000000, reward total was -20.000000. running mean: -20.435975\n","resetting env. episode 1182.000000, reward total was -21.000000. running mean: -20.441616\n","resetting env. episode 1183.000000, reward total was -21.000000. running mean: -20.447199\n","resetting env. episode 1184.000000, reward total was -21.000000. running mean: -20.452727\n","resetting env. episode 1185.000000, reward total was -21.000000. running mean: -20.458200\n","resetting env. episode 1186.000000, reward total was -19.000000. running mean: -20.443618\n","resetting env. episode 1187.000000, reward total was -21.000000. running mean: -20.449182\n","resetting env. episode 1188.000000, reward total was -18.000000. running mean: -20.424690\n","resetting env. episode 1189.000000, reward total was -18.000000. running mean: -20.400443\n","resetting env. episode 1190.000000, reward total was -21.000000. running mean: -20.406439\n","resetting env. episode 1191.000000, reward total was -21.000000. running mean: -20.412374\n","resetting env. episode 1192.000000, reward total was -20.000000. running mean: -20.408251\n","resetting env. episode 1193.000000, reward total was -21.000000. running mean: -20.414168\n","resetting env. episode 1194.000000, reward total was -20.000000. running mean: -20.410026\n","resetting env. episode 1195.000000, reward total was -21.000000. running mean: -20.415926\n","resetting env. episode 1196.000000, reward total was -21.000000. running mean: -20.421767\n","resetting env. episode 1197.000000, reward total was -21.000000. running mean: -20.427549\n","resetting env. episode 1198.000000, reward total was -20.000000. running mean: -20.423274\n","resetting env. episode 1199.000000, reward total was -21.000000. running mean: -20.429041\n","resetting env. episode 1200.000000, reward total was -21.000000. running mean: -20.434751\n","resetting env. episode 1201.000000, reward total was -21.000000. running mean: -20.440403\n","resetting env. episode 1202.000000, reward total was -19.000000. running mean: -20.425999\n","resetting env. episode 1203.000000, reward total was -21.000000. running mean: -20.431739\n","resetting env. episode 1204.000000, reward total was -20.000000. running mean: -20.427422\n","resetting env. episode 1205.000000, reward total was -21.000000. running mean: -20.433147\n","resetting env. episode 1206.000000, reward total was -21.000000. running mean: -20.438816\n","resetting env. episode 1207.000000, reward total was -19.000000. running mean: -20.424428\n","resetting env. episode 1208.000000, reward total was -21.000000. running mean: -20.430184\n","resetting env. episode 1209.000000, reward total was -17.000000. running mean: -20.395882\n","resetting env. episode 1210.000000, reward total was -19.000000. running mean: -20.381923\n","resetting env. episode 1211.000000, reward total was -21.000000. running mean: -20.388104\n","resetting env. episode 1212.000000, reward total was -21.000000. running mean: -20.394223\n","resetting env. episode 1213.000000, reward total was -18.000000. running mean: -20.370280\n","resetting env. episode 1214.000000, reward total was -21.000000. running mean: -20.376578\n","resetting env. episode 1215.000000, reward total was -19.000000. running mean: -20.362812\n","resetting env. episode 1216.000000, reward total was -21.000000. running mean: -20.369184\n","resetting env. episode 1217.000000, reward total was -20.000000. running mean: -20.365492\n","resetting env. episode 1218.000000, reward total was -21.000000. running mean: -20.371837\n","resetting env. episode 1219.000000, reward total was -21.000000. running mean: -20.378119\n","resetting env. episode 1220.000000, reward total was -21.000000. running mean: -20.384337\n","resetting env. episode 1221.000000, reward total was -20.000000. running mean: -20.380494\n","resetting env. episode 1222.000000, reward total was -21.000000. running mean: -20.386689\n","resetting env. episode 1223.000000, reward total was -19.000000. running mean: -20.372822\n","resetting env. episode 1224.000000, reward total was -21.000000. running mean: -20.379094\n","resetting env. episode 1225.000000, reward total was -21.000000. running mean: -20.385303\n","resetting env. episode 1226.000000, reward total was -21.000000. running mean: -20.391450\n","resetting env. episode 1227.000000, reward total was -20.000000. running mean: -20.387536\n","resetting env. episode 1228.000000, reward total was -21.000000. running mean: -20.393660\n","resetting env. episode 1229.000000, reward total was -19.000000. running mean: -20.379724\n","resetting env. episode 1230.000000, reward total was -21.000000. running mean: -20.385926\n","resetting env. episode 1231.000000, reward total was -19.000000. running mean: -20.372067\n","resetting env. episode 1232.000000, reward total was -21.000000. running mean: -20.378346\n","resetting env. episode 1233.000000, reward total was -21.000000. running mean: -20.384563\n","resetting env. episode 1234.000000, reward total was -21.000000. running mean: -20.390717\n","resetting env. episode 1235.000000, reward total was -21.000000. running mean: -20.396810\n","resetting env. episode 1236.000000, reward total was -21.000000. running mean: -20.402842\n","resetting env. episode 1237.000000, reward total was -20.000000. running mean: -20.398814\n","resetting env. episode 1238.000000, reward total was -20.000000. running mean: -20.394825\n","resetting env. episode 1239.000000, reward total was -21.000000. running mean: -20.400877\n","resetting env. episode 1240.000000, reward total was -21.000000. running mean: -20.406868\n","resetting env. episode 1241.000000, reward total was -21.000000. running mean: -20.412800\n","resetting env. episode 1242.000000, reward total was -20.000000. running mean: -20.408672\n","resetting env. episode 1243.000000, reward total was -21.000000. running mean: -20.414585\n","resetting env. episode 1244.000000, reward total was -20.000000. running mean: -20.410439\n","resetting env. episode 1245.000000, reward total was -21.000000. running mean: -20.416335\n","resetting env. episode 1246.000000, reward total was -21.000000. running mean: -20.422171\n","resetting env. episode 1247.000000, reward total was -21.000000. running mean: -20.427950\n","resetting env. episode 1248.000000, reward total was -21.000000. running mean: -20.433670\n","resetting env. episode 1249.000000, reward total was -20.000000. running mean: -20.429334\n","resetting env. episode 1250.000000, reward total was -21.000000. running mean: -20.435040\n","resetting env. episode 1251.000000, reward total was -21.000000. running mean: -20.440690\n","resetting env. episode 1252.000000, reward total was -20.000000. running mean: -20.436283\n","resetting env. episode 1253.000000, reward total was -21.000000. running mean: -20.441920\n","resetting env. episode 1254.000000, reward total was -20.000000. running mean: -20.437501\n","resetting env. episode 1255.000000, reward total was -21.000000. running mean: -20.443126\n","resetting env. episode 1256.000000, reward total was -20.000000. running mean: -20.438695\n","resetting env. episode 1257.000000, reward total was -19.000000. running mean: -20.424308\n","resetting env. episode 1258.000000, reward total was -21.000000. running mean: -20.430065\n","resetting env. episode 1259.000000, reward total was -21.000000. running mean: -20.435764\n","resetting env. episode 1260.000000, reward total was -19.000000. running mean: -20.421406\n","resetting env. episode 1261.000000, reward total was -21.000000. running mean: -20.427192\n","resetting env. episode 1262.000000, reward total was -21.000000. running mean: -20.432920\n","resetting env. episode 1263.000000, reward total was -19.000000. running mean: -20.418591\n","resetting env. episode 1264.000000, reward total was -21.000000. running mean: -20.424405\n","resetting env. episode 1265.000000, reward total was -21.000000. running mean: -20.430161\n","resetting env. episode 1266.000000, reward total was -21.000000. running mean: -20.435860\n","resetting env. episode 1267.000000, reward total was -21.000000. running mean: -20.441501\n","resetting env. episode 1268.000000, reward total was -21.000000. running mean: -20.447086\n","resetting env. episode 1269.000000, reward total was -16.000000. running mean: -20.402615\n","resetting env. episode 1270.000000, reward total was -20.000000. running mean: -20.398589\n","resetting env. episode 1271.000000, reward total was -21.000000. running mean: -20.404603\n","resetting env. episode 1272.000000, reward total was -17.000000. running mean: -20.370557\n","resetting env. episode 1273.000000, reward total was -21.000000. running mean: -20.376851\n","resetting env. episode 1274.000000, reward total was -20.000000. running mean: -20.373083\n","resetting env. episode 1275.000000, reward total was -21.000000. running mean: -20.379352\n","resetting env. episode 1276.000000, reward total was -21.000000. running mean: -20.385559\n","resetting env. episode 1277.000000, reward total was -21.000000. running mean: -20.391703\n","resetting env. episode 1278.000000, reward total was -21.000000. running mean: -20.397786\n","resetting env. episode 1279.000000, reward total was -21.000000. running mean: -20.403808\n","resetting env. episode 1280.000000, reward total was -20.000000. running mean: -20.399770\n","resetting env. episode 1281.000000, reward total was -20.000000. running mean: -20.395772\n","resetting env. episode 1282.000000, reward total was -21.000000. running mean: -20.401815\n","resetting env. episode 1283.000000, reward total was -19.000000. running mean: -20.387796\n","resetting env. episode 1284.000000, reward total was -19.000000. running mean: -20.373918\n","resetting env. episode 1285.000000, reward total was -21.000000. running mean: -20.380179\n","resetting env. episode 1286.000000, reward total was -21.000000. running mean: -20.386377\n","resetting env. episode 1287.000000, reward total was -21.000000. running mean: -20.392514\n","resetting env. episode 1288.000000, reward total was -20.000000. running mean: -20.388589\n","resetting env. episode 1289.000000, reward total was -21.000000. running mean: -20.394703\n","resetting env. episode 1290.000000, reward total was -21.000000. running mean: -20.400756\n","resetting env. episode 1291.000000, reward total was -21.000000. running mean: -20.406748\n","resetting env. episode 1292.000000, reward total was -21.000000. running mean: -20.412681\n","resetting env. episode 1293.000000, reward total was -20.000000. running mean: -20.408554\n","resetting env. episode 1294.000000, reward total was -20.000000. running mean: -20.404468\n","resetting env. episode 1295.000000, reward total was -21.000000. running mean: -20.410424\n","resetting env. episode 1296.000000, reward total was -20.000000. running mean: -20.406319\n","resetting env. episode 1297.000000, reward total was -18.000000. running mean: -20.382256\n","resetting env. episode 1298.000000, reward total was -20.000000. running mean: -20.378434\n","resetting env. episode 1299.000000, reward total was -20.000000. running mean: -20.374649\n","resetting env. episode 1300.000000, reward total was -20.000000. running mean: -20.370903\n","resetting env. episode 1301.000000, reward total was -21.000000. running mean: -20.377194\n","resetting env. episode 1302.000000, reward total was -21.000000. running mean: -20.383422\n","resetting env. episode 1303.000000, reward total was -20.000000. running mean: -20.379588\n","resetting env. episode 1304.000000, reward total was -21.000000. running mean: -20.385792\n","resetting env. episode 1305.000000, reward total was -19.000000. running mean: -20.371934\n","resetting env. episode 1306.000000, reward total was -21.000000. running mean: -20.378214\n","resetting env. episode 1307.000000, reward total was -21.000000. running mean: -20.384432\n","resetting env. episode 1308.000000, reward total was -21.000000. running mean: -20.390588\n","resetting env. episode 1309.000000, reward total was -21.000000. running mean: -20.396682\n","resetting env. episode 1310.000000, reward total was -21.000000. running mean: -20.402715\n","resetting env. episode 1311.000000, reward total was -21.000000. running mean: -20.408688\n","resetting env. episode 1312.000000, reward total was -20.000000. running mean: -20.404601\n","resetting env. episode 1313.000000, reward total was -20.000000. running mean: -20.400555\n","resetting env. episode 1314.000000, reward total was -20.000000. running mean: -20.396550\n","resetting env. episode 1315.000000, reward total was -21.000000. running mean: -20.402584\n","resetting env. episode 1316.000000, reward total was -21.000000. running mean: -20.408558\n","resetting env. episode 1317.000000, reward total was -19.000000. running mean: -20.394473\n","resetting env. episode 1318.000000, reward total was -21.000000. running mean: -20.400528\n","resetting env. episode 1319.000000, reward total was -20.000000. running mean: -20.396523\n","resetting env. episode 1320.000000, reward total was -21.000000. running mean: -20.402558\n","resetting env. episode 1321.000000, reward total was -20.000000. running mean: -20.398532\n","resetting env. episode 1322.000000, reward total was -20.000000. running mean: -20.394547\n","resetting env. episode 1323.000000, reward total was -19.000000. running mean: -20.380601\n","resetting env. episode 1324.000000, reward total was -21.000000. running mean: -20.386795\n","resetting env. episode 1325.000000, reward total was -19.000000. running mean: -20.372927\n","resetting env. episode 1326.000000, reward total was -20.000000. running mean: -20.369198\n","resetting env. episode 1327.000000, reward total was -21.000000. running mean: -20.375506\n","resetting env. episode 1328.000000, reward total was -21.000000. running mean: -20.381751\n","resetting env. episode 1329.000000, reward total was -21.000000. running mean: -20.387933\n","resetting env. episode 1330.000000, reward total was -21.000000. running mean: -20.394054\n","resetting env. episode 1331.000000, reward total was -21.000000. running mean: -20.400114\n","resetting env. episode 1332.000000, reward total was -21.000000. running mean: -20.406112\n","resetting env. episode 1333.000000, reward total was -21.000000. running mean: -20.412051\n","resetting env. episode 1334.000000, reward total was -21.000000. running mean: -20.417931\n","resetting env. episode 1335.000000, reward total was -19.000000. running mean: -20.403751\n","resetting env. episode 1336.000000, reward total was -21.000000. running mean: -20.409714\n","resetting env. episode 1337.000000, reward total was -20.000000. running mean: -20.405617\n","resetting env. episode 1338.000000, reward total was -20.000000. running mean: -20.401561\n","resetting env. episode 1339.000000, reward total was -21.000000. running mean: -20.407545\n","resetting env. episode 1340.000000, reward total was -20.000000. running mean: -20.403470\n","resetting env. episode 1341.000000, reward total was -19.000000. running mean: -20.389435\n","resetting env. episode 1342.000000, reward total was -20.000000. running mean: -20.385541\n","resetting env. episode 1343.000000, reward total was -20.000000. running mean: -20.381685\n","resetting env. episode 1344.000000, reward total was -20.000000. running mean: -20.377868\n","resetting env. episode 1345.000000, reward total was -21.000000. running mean: -20.384090\n","resetting env. episode 1346.000000, reward total was -20.000000. running mean: -20.380249\n","resetting env. episode 1347.000000, reward total was -20.000000. running mean: -20.376446\n","resetting env. episode 1348.000000, reward total was -20.000000. running mean: -20.372682\n","resetting env. episode 1349.000000, reward total was -21.000000. running mean: -20.378955\n","resetting env. episode 1350.000000, reward total was -21.000000. running mean: -20.385165\n","resetting env. episode 1351.000000, reward total was -21.000000. running mean: -20.391314\n","resetting env. episode 1352.000000, reward total was -19.000000. running mean: -20.377401\n","resetting env. episode 1353.000000, reward total was -20.000000. running mean: -20.373627\n","resetting env. episode 1354.000000, reward total was -19.000000. running mean: -20.359890\n","resetting env. episode 1355.000000, reward total was -21.000000. running mean: -20.366291\n","resetting env. episode 1356.000000, reward total was -21.000000. running mean: -20.372628\n","resetting env. episode 1357.000000, reward total was -21.000000. running mean: -20.378902\n","resetting env. episode 1358.000000, reward total was -20.000000. running mean: -20.375113\n","resetting env. episode 1359.000000, reward total was -21.000000. running mean: -20.381362\n","resetting env. episode 1360.000000, reward total was -21.000000. running mean: -20.387548\n","resetting env. episode 1361.000000, reward total was -20.000000. running mean: -20.383673\n","resetting env. episode 1362.000000, reward total was -21.000000. running mean: -20.389836\n","resetting env. episode 1363.000000, reward total was -19.000000. running mean: -20.375938\n","resetting env. episode 1364.000000, reward total was -21.000000. running mean: -20.382178\n","resetting env. episode 1365.000000, reward total was -20.000000. running mean: -20.378357\n","resetting env. episode 1366.000000, reward total was -21.000000. running mean: -20.384573\n","resetting env. episode 1367.000000, reward total was -21.000000. running mean: -20.390727\n","resetting env. episode 1368.000000, reward total was -21.000000. running mean: -20.396820\n","resetting env. episode 1369.000000, reward total was -21.000000. running mean: -20.402852\n","resetting env. episode 1370.000000, reward total was -21.000000. running mean: -20.408823\n","resetting env. episode 1371.000000, reward total was -21.000000. running mean: -20.414735\n","resetting env. episode 1372.000000, reward total was -21.000000. running mean: -20.420588\n","resetting env. episode 1373.000000, reward total was -21.000000. running mean: -20.426382\n","resetting env. episode 1374.000000, reward total was -21.000000. running mean: -20.432118\n","resetting env. episode 1375.000000, reward total was -21.000000. running mean: -20.437797\n","resetting env. episode 1376.000000, reward total was -20.000000. running mean: -20.433419\n","resetting env. episode 1377.000000, reward total was -21.000000. running mean: -20.439085\n","resetting env. episode 1378.000000, reward total was -21.000000. running mean: -20.444694\n","resetting env. episode 1379.000000, reward total was -21.000000. running mean: -20.450247\n","resetting env. episode 1380.000000, reward total was -20.000000. running mean: -20.445745\n","resetting env. episode 1381.000000, reward total was -21.000000. running mean: -20.451287\n","resetting env. episode 1382.000000, reward total was -20.000000. running mean: -20.446774\n","resetting env. episode 1383.000000, reward total was -20.000000. running mean: -20.442306\n","resetting env. episode 1384.000000, reward total was -20.000000. running mean: -20.437883\n","resetting env. episode 1385.000000, reward total was -21.000000. running mean: -20.443505\n","resetting env. episode 1386.000000, reward total was -21.000000. running mean: -20.449070\n","resetting env. episode 1387.000000, reward total was -21.000000. running mean: -20.454579\n","resetting env. episode 1388.000000, reward total was -21.000000. running mean: -20.460033\n","resetting env. episode 1389.000000, reward total was -20.000000. running mean: -20.455433\n","resetting env. episode 1390.000000, reward total was -21.000000. running mean: -20.460878\n","resetting env. episode 1391.000000, reward total was -21.000000. running mean: -20.466270\n","resetting env. episode 1392.000000, reward total was -21.000000. running mean: -20.471607\n","resetting env. episode 1393.000000, reward total was -20.000000. running mean: -20.466891\n","resetting env. episode 1394.000000, reward total was -21.000000. running mean: -20.472222\n","resetting env. episode 1395.000000, reward total was -20.000000. running mean: -20.467500\n","resetting env. episode 1396.000000, reward total was -21.000000. running mean: -20.472825\n","resetting env. episode 1397.000000, reward total was -21.000000. running mean: -20.478096\n","resetting env. episode 1398.000000, reward total was -21.000000. running mean: -20.483315\n","resetting env. episode 1399.000000, reward total was -21.000000. running mean: -20.488482\n","resetting env. episode 1400.000000, reward total was -19.000000. running mean: -20.473598\n","resetting env. episode 1401.000000, reward total was -20.000000. running mean: -20.468862\n","resetting env. episode 1402.000000, reward total was -21.000000. running mean: -20.474173\n","resetting env. episode 1403.000000, reward total was -21.000000. running mean: -20.479431\n","resetting env. episode 1404.000000, reward total was -20.000000. running mean: -20.474637\n","resetting env. episode 1405.000000, reward total was -20.000000. running mean: -20.469891\n","resetting env. episode 1406.000000, reward total was -21.000000. running mean: -20.475192\n","resetting env. episode 1407.000000, reward total was -20.000000. running mean: -20.470440\n","resetting env. episode 1408.000000, reward total was -20.000000. running mean: -20.465735\n","resetting env. episode 1409.000000, reward total was -21.000000. running mean: -20.471078\n","resetting env. episode 1410.000000, reward total was -21.000000. running mean: -20.476367\n","resetting env. episode 1411.000000, reward total was -21.000000. running mean: -20.481603\n","resetting env. episode 1412.000000, reward total was -21.000000. running mean: -20.486787\n","resetting env. episode 1413.000000, reward total was -21.000000. running mean: -20.491920\n","resetting env. episode 1414.000000, reward total was -19.000000. running mean: -20.477000\n","resetting env. episode 1415.000000, reward total was -17.000000. running mean: -20.442230\n","resetting env. episode 1416.000000, reward total was -17.000000. running mean: -20.407808\n","resetting env. episode 1417.000000, reward total was -21.000000. running mean: -20.413730\n","resetting env. episode 1418.000000, reward total was -21.000000. running mean: -20.419593\n","resetting env. episode 1419.000000, reward total was -19.000000. running mean: -20.405397\n","resetting env. episode 1420.000000, reward total was -17.000000. running mean: -20.371343\n","resetting env. episode 1421.000000, reward total was -20.000000. running mean: -20.367629\n","resetting env. episode 1422.000000, reward total was -19.000000. running mean: -20.353953\n","resetting env. episode 1423.000000, reward total was -20.000000. running mean: -20.350414\n","resetting env. episode 1424.000000, reward total was -20.000000. running mean: -20.346909\n","resetting env. episode 1425.000000, reward total was -21.000000. running mean: -20.353440\n","resetting env. episode 1426.000000, reward total was -21.000000. running mean: -20.359906\n","resetting env. episode 1427.000000, reward total was -21.000000. running mean: -20.366307\n","resetting env. episode 1428.000000, reward total was -20.000000. running mean: -20.362644\n","resetting env. episode 1429.000000, reward total was -21.000000. running mean: -20.369017\n","resetting env. episode 1430.000000, reward total was -20.000000. running mean: -20.365327\n","resetting env. episode 1431.000000, reward total was -21.000000. running mean: -20.371674\n","resetting env. episode 1432.000000, reward total was -19.000000. running mean: -20.357957\n","resetting env. episode 1433.000000, reward total was -21.000000. running mean: -20.364378\n","resetting env. episode 1434.000000, reward total was -21.000000. running mean: -20.370734\n","resetting env. episode 1435.000000, reward total was -21.000000. running mean: -20.377026\n","resetting env. episode 1436.000000, reward total was -21.000000. running mean: -20.383256\n","resetting env. episode 1437.000000, reward total was -21.000000. running mean: -20.389424\n","resetting env. episode 1438.000000, reward total was -21.000000. running mean: -20.395529\n","resetting env. episode 1439.000000, reward total was -20.000000. running mean: -20.391574\n","resetting env. episode 1440.000000, reward total was -19.000000. running mean: -20.377658\n","resetting env. episode 1441.000000, reward total was -20.000000. running mean: -20.373882\n","resetting env. episode 1442.000000, reward total was -18.000000. running mean: -20.350143\n","resetting env. episode 1443.000000, reward total was -19.000000. running mean: -20.336642\n","resetting env. episode 1444.000000, reward total was -20.000000. running mean: -20.333275\n","resetting env. episode 1445.000000, reward total was -21.000000. running mean: -20.339942\n","resetting env. episode 1446.000000, reward total was -20.000000. running mean: -20.336543\n","resetting env. episode 1447.000000, reward total was -19.000000. running mean: -20.323178\n","resetting env. episode 1448.000000, reward total was -20.000000. running mean: -20.319946\n","resetting env. episode 1449.000000, reward total was -21.000000. running mean: -20.326746\n","resetting env. episode 1450.000000, reward total was -19.000000. running mean: -20.313479\n","resetting env. episode 1451.000000, reward total was -18.000000. running mean: -20.290344\n","resetting env. episode 1452.000000, reward total was -21.000000. running mean: -20.297441\n","resetting env. episode 1453.000000, reward total was -19.000000. running mean: -20.284466\n","resetting env. episode 1454.000000, reward total was -21.000000. running mean: -20.291622\n","resetting env. episode 1455.000000, reward total was -21.000000. running mean: -20.298705\n","resetting env. episode 1456.000000, reward total was -21.000000. running mean: -20.305718\n","resetting env. episode 1457.000000, reward total was -21.000000. running mean: -20.312661\n","resetting env. episode 1458.000000, reward total was -21.000000. running mean: -20.319534\n","resetting env. episode 1459.000000, reward total was -21.000000. running mean: -20.326339\n","resetting env. episode 1460.000000, reward total was -19.000000. running mean: -20.313076\n","resetting env. episode 1461.000000, reward total was -19.000000. running mean: -20.299945\n","resetting env. episode 1462.000000, reward total was -18.000000. running mean: -20.276946\n","resetting env. episode 1463.000000, reward total was -21.000000. running mean: -20.284176\n","resetting env. episode 1464.000000, reward total was -19.000000. running mean: -20.271334\n","resetting env. episode 1465.000000, reward total was -21.000000. running mean: -20.278621\n","resetting env. episode 1466.000000, reward total was -20.000000. running mean: -20.275835\n","resetting env. episode 1467.000000, reward total was -19.000000. running mean: -20.263076\n","resetting env. episode 1468.000000, reward total was -21.000000. running mean: -20.270446\n","resetting env. episode 1469.000000, reward total was -20.000000. running mean: -20.267741\n","resetting env. episode 1470.000000, reward total was -19.000000. running mean: -20.255064\n","resetting env. episode 1471.000000, reward total was -21.000000. running mean: -20.262513\n","resetting env. episode 1472.000000, reward total was -21.000000. running mean: -20.269888\n","resetting env. episode 1473.000000, reward total was -21.000000. running mean: -20.277189\n","resetting env. episode 1474.000000, reward total was -21.000000. running mean: -20.284417\n","resetting env. episode 1475.000000, reward total was -21.000000. running mean: -20.291573\n","resetting env. episode 1476.000000, reward total was -21.000000. running mean: -20.298657\n","resetting env. episode 1477.000000, reward total was -20.000000. running mean: -20.295671\n","resetting env. episode 1478.000000, reward total was -21.000000. running mean: -20.302714\n","resetting env. episode 1479.000000, reward total was -20.000000. running mean: -20.299687\n","resetting env. episode 1480.000000, reward total was -21.000000. running mean: -20.306690\n","resetting env. episode 1481.000000, reward total was -21.000000. running mean: -20.313623\n","resetting env. episode 1482.000000, reward total was -19.000000. running mean: -20.300487\n","resetting env. episode 1483.000000, reward total was -19.000000. running mean: -20.287482\n","resetting env. episode 1484.000000, reward total was -20.000000. running mean: -20.284607\n","resetting env. episode 1485.000000, reward total was -20.000000. running mean: -20.281761\n","resetting env. episode 1486.000000, reward total was -21.000000. running mean: -20.288944\n","resetting env. episode 1487.000000, reward total was -20.000000. running mean: -20.286054\n","resetting env. episode 1488.000000, reward total was -21.000000. running mean: -20.293194\n","resetting env. episode 1489.000000, reward total was -21.000000. running mean: -20.300262\n","resetting env. episode 1490.000000, reward total was -19.000000. running mean: -20.287259\n","resetting env. episode 1491.000000, reward total was -21.000000. running mean: -20.294386\n","resetting env. episode 1492.000000, reward total was -21.000000. running mean: -20.301443\n","resetting env. episode 1493.000000, reward total was -21.000000. running mean: -20.308428\n","resetting env. episode 1494.000000, reward total was -21.000000. running mean: -20.315344\n","resetting env. episode 1495.000000, reward total was -21.000000. running mean: -20.322190\n","resetting env. episode 1496.000000, reward total was -20.000000. running mean: -20.318969\n","resetting env. episode 1497.000000, reward total was -18.000000. running mean: -20.295779\n","resetting env. episode 1498.000000, reward total was -21.000000. running mean: -20.302821\n","resetting env. episode 1499.000000, reward total was -21.000000. running mean: -20.309793\n","resetting env. episode 1500.000000, reward total was -21.000000. running mean: -20.316695\n","CPU times: user 1h 21min 38s, sys: 36min 33s, total: 1h 58min 12s\n","Wall time: 1h 1min 47s\n"]}]},{"metadata":{"id":"w2NblmwDsL3y","outputId":"fd62413e-6a67-461b-fc74-3190145d5078","colab":{"base_uri":"https://localhost:8080/","height":504},"executionInfo":{"status":"ok","timestamp":1660796120986,"user_tz":-330,"elapsed":42536,"user":{"displayName":"Madhav Abhisheik","userId":"17313622204262214389"}}},"cell_type":"code","source":["play_game(env, model)"],"execution_count":16,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/gym/core.py:52: DeprecationWarning: \u001b[33mWARN: The argument mode in render method is deprecated; use render_mode during environment initialization instead.\n","See here for more information: https://www.gymlibrary.ml/content/api/\u001b[0m\n","  \"The argument mode in render method is deprecated; \"\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"output_type":"stream","name":"stdout","text":["Episode finished without success, accumulated reward = -18.0\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 320x420 with 1 Axes>"],"image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}